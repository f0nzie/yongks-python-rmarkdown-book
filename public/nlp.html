<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>17 NLP | Python Bookdown</title>
<meta name="author" content="Yong Keh Soon">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.5.3/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.2.9000/tabs.js"></script><script src="libs/bs3compat-0.2.2.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Python Bookdown</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction</a></li>
<li><a class="" href="fundamentals.html"><span class="header-section-number">1</span> Fundamentals</a></li>
<li><a class="" href="built-in-data-types.html"><span class="header-section-number">2</span> Built-in Data Types</a></li>
<li><a class="" href="built-in-data-structure.html"><span class="header-section-number">3</span> Built-In Data Structure</a></li>
<li><a class="" href="control-and-loops.html"><span class="header-section-number">4</span> Control and Loops</a></li>
<li><a class="" href="library-and-functions.html"><span class="header-section-number">5</span> Library and Functions</a></li>
<li><a class="" href="exception-handling.html"><span class="header-section-number">6</span> Exception Handling</a></li>
<li><a class="" href="object-oriented-programming.html"><span class="header-section-number">7</span> Object Oriented Programming</a></li>
<li><a class="" href="decorator.html"><span class="header-section-number">8</span> Decorator</a></li>
<li><a class="" href="datetime-standard-library.html"><span class="header-section-number">9</span> datetime Standard Library</a></li>
<li><a class="" href="getting-external-data.html"><span class="header-section-number">10</span> Getting External Data</a></li>
<li><a class="" href="plydata-dplyr-for-python.html"><span class="header-section-number">11</span> Plydata (dplyr for Python)</a></li>
<li><a class="" href="numpy-1.html"><span class="header-section-number">12</span> numpy</a></li>
<li><a class="" href="pandas-1.html"><span class="header-section-number">13</span> pandas</a></li>
<li><a class="" href="matplotlib-1.html"><span class="header-section-number">14</span> matplotlib</a></li>
<li><a class="" href="seaborn.html"><span class="header-section-number">15</span> seaborn</a></li>
<li><a class="" href="sklearn.html"><span class="header-section-number">16</span> sklearn</a></li>
<li><a class="active" href="nlp.html"><span class="header-section-number">17</span> NLP</a></li>
<li><a class="" href="web-scrapping.html"><span class="header-section-number">18</span> Web Scrapping</a></li>
<li><a class="" href="finance.html"><span class="header-section-number">19</span> Finance</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com//f0nzie/yongks-python-rmarkdown-book">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="nlp" class="section level1" number="17">
<h1>
<span class="header-section-number">17</span> NLP<a class="anchor" aria-label="anchor" href="#nlp"><i class="fas fa-link"></i></a>
</h1>
<p>Natural Language Processing</p>
<div id="regular-expression" class="section level2" number="17.1">
<h2>
<span class="header-section-number">17.1</span> Regular Expression<a class="anchor" aria-label="anchor" href="#regular-expression"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Rgular expressions (called REs or regexes) is mandatory skill for NLP. The <code>re</code> is a **built-in* library<br>
</li>
<li>It is essentially a tiny, highly specialized programming language embedded inside Python and made available through the re module<br>
</li>
<li>Regular expression patterns are compiled into a series of bytecodes which are then executed by a matching engine written in C</li>
</ul>
<div id="syntax" class="section level3" number="17.1.1">
<h3>
<span class="header-section-number">17.1.1</span> Syntax<a class="anchor" aria-label="anchor" href="#syntax"><i class="fas fa-link"></i></a>
</h3>
<p>There are two methods to emply re. Below method compile a regex first, then apply it multiple times in subsequent code.</p>
<div class="sourceCode" id="cb1711"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1711-1"><a href="nlp.html#cb1711-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1711-2"><a href="nlp.html#cb1711-2" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'put pattern here'</span>)</span>
<span id="cb1711-3"><a href="nlp.html#cb1711-3" aria-hidden="true" tabindex="-1"></a>pattern.match(<span class="st">'put text here'</span>)</span></code></pre></div>
<p>Second method below employ compile and match in single line. The pattern cannot be reused, therefore good for onetime usage only.</p>
<div class="sourceCode" id="cb1712"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1712-1"><a href="nlp.html#cb1712-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1712-2"><a href="nlp.html#cb1712-2" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> (<span class="vs">r'put pattern here'</span>)</span>
<span id="cb1712-3"><a href="nlp.html#cb1712-3" aria-hidden="true" tabindex="-1"></a>re.match(pattern, <span class="vs">r'put text here'</span>)  <span class="co"># compile and match in single line</span></span></code></pre></div>
</div>
<div id="finding" class="section level3" number="17.1.2">
<h3>
<span class="header-section-number">17.1.2</span> Finding<a class="anchor" aria-label="anchor" href="#finding"><i class="fas fa-link"></i></a>
</h3>
<div id="find-the-first-match" class="section level4" number="17.1.2.1">
<h4>
<span class="header-section-number">17.1.2.1</span> Find The First Match<a class="anchor" aria-label="anchor" href="#find-the-first-match"><i class="fas fa-link"></i></a>
</h4>
<p>There are two ways to find the first match:<br>
- <strong><code>re.search</code></strong> find first match anywhere in text, including multiline<br>
- <strong><code>re.match</code></strong> find first match at the BEGINNING of text, similar to <code>re.search</code>with <code><a href="https://rdrr.io/r/base/Arithmetic.html">^</a></code><br>
- Both returns first match, return <strong>MatchObject</strong><br>
- Both returns <strong>None</strong> if no match is found</p>
<div class="sourceCode" id="cb1713"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1713-1"><a href="nlp.html#cb1713-1" aria-hidden="true" tabindex="-1"></a>pattern1 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="st">'123'</span>) </span>
<span id="cb1713-2"><a href="nlp.html#cb1713-2" aria-hidden="true" tabindex="-1"></a>pattern2 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="st">'123'</span>)</span>
<span id="cb1713-3"><a href="nlp.html#cb1713-3" aria-hidden="true" tabindex="-1"></a>pattern3 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="st">'^123'</span>)  <span class="co"># equivalent to above</span></span>
<span id="cb1713-4"><a href="nlp.html#cb1713-4" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">'abc123xyz'</span></span>
<span id="cb1713-5"><a href="nlp.html#cb1713-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1713-6"><a href="nlp.html#cb1713-6" aria-hidden="true" tabindex="-1"></a><span class="co">## Single Line Text Example</span></span>
<span id="cb1713-7"><a href="nlp.html#cb1713-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">'re.search found a match somewhere:</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1713-8"><a href="nlp.html#cb1713-8" aria-hidden="true" tabindex="-1"></a>       pattern1.search(text), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>, <span class="co">## found</span></span>
<span id="cb1713-9"><a href="nlp.html#cb1713-9" aria-hidden="true" tabindex="-1"></a>       <span class="st">'</span><span class="ch">\n</span><span class="st">re.match did not find anything at the beginning:</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1713-10"><a href="nlp.html#cb1713-10" aria-hidden="true" tabindex="-1"></a>       pattern2.match(text), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1713-11"><a href="nlp.html#cb1713-11" aria-hidden="true" tabindex="-1"></a>       <span class="st">'</span><span class="ch">\n</span><span class="st">re.search did not find anything at beginning too:</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1713-12"><a href="nlp.html#cb1713-12" aria-hidden="true" tabindex="-1"></a>       pattern3.search(text))        <span class="co">## None</span></span></code></pre></div>
<pre><code>#:&gt; re.search found a match somewhere:
#:&gt;  &lt;re.Match object; span=(3, 6), match='123'&gt; 
#:&gt;  
#:&gt; re.match did not find anything at the beginning:
#:&gt;  None 
#:&gt;  
#:&gt; re.search did not find anything at beginning too:
#:&gt;  None</code></pre>
<p>Returned <strong>MatchObject</strong> provides useful information about the matched string.</p>
<div class="sourceCode" id="cb1715"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1715-1"><a href="nlp.html#cb1715-1" aria-hidden="true" tabindex="-1"></a>age_pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'\d+'</span>)</span>
<span id="cb1715-2"><a href="nlp.html#cb1715-2" aria-hidden="true" tabindex="-1"></a>age_text    <span class="op">=</span> <span class="st">'Ali is my teacher. He is 109 years old. his kid is 40 years old.'</span></span>
<span id="cb1715-3"><a href="nlp.html#cb1715-3" aria-hidden="true" tabindex="-1"></a>first_found <span class="op">=</span> age_pattern.search(age_text)</span>
<span id="cb1715-4"><a href="nlp.html#cb1715-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1715-5"><a href="nlp.html#cb1715-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Found Object:           '</span>, first_found,</span>
<span id="cb1715-6"><a href="nlp.html#cb1715-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">'</span><span class="ch">\n</span><span class="st">Input Text:             '</span>, first_found.string,</span>
<span id="cb1715-7"><a href="nlp.html#cb1715-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">'</span><span class="ch">\n</span><span class="st">Input Pattern:          '</span>, first_found.re,</span>
<span id="cb1715-8"><a href="nlp.html#cb1715-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">'</span><span class="ch">\n</span><span class="st">First Found string:     '</span>, first_found.group(),</span>
<span id="cb1715-9"><a href="nlp.html#cb1715-9" aria-hidden="true" tabindex="-1"></a>      <span class="st">'</span><span class="ch">\n</span><span class="st">Found Start Position:   '</span>, first_found.start(),</span>
<span id="cb1715-10"><a href="nlp.html#cb1715-10" aria-hidden="true" tabindex="-1"></a>      <span class="st">'</span><span class="ch">\n</span><span class="st">Found End Position:     '</span>, first_found.end(),</span>
<span id="cb1715-11"><a href="nlp.html#cb1715-11" aria-hidden="true" tabindex="-1"></a>      <span class="st">'</span><span class="ch">\n</span><span class="st">Found Span:             '</span>, first_found.span(),)</span></code></pre></div>
<pre><code>#:&gt; Found Object:            &lt;re.Match object; span=(25, 28), match='109'&gt; 
#:&gt; Input Text:              Ali is my teacher. He is 109 years old. his kid is 40 years old. 
#:&gt; Input Pattern:           re.compile('\\d+') 
#:&gt; First Found string:      109 
#:&gt; Found Start Position:    25 
#:&gt; Found End Position:      28 
#:&gt; Found Span:              (25, 28)</code></pre>
</div>
<div id="find-all-matches" class="section level4" number="17.1.2.2">
<h4>
<span class="header-section-number">17.1.2.2</span> Find All Matches<a class="anchor" aria-label="anchor" href="#find-all-matches"><i class="fas fa-link"></i></a>
</h4>
<p><strong><code>findall()</code></strong> returns all matching string as <strong>list</strong>. If no matches found, it return an empty list.</p>
<div class="sourceCode" id="cb1717"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1717-1"><a href="nlp.html#cb1717-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1717-2"><a href="nlp.html#cb1717-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Finding Two Digits:'</span>,</span>
<span id="cb1717-3"><a href="nlp.html#cb1717-3" aria-hidden="true" tabindex="-1"></a>  re.findall(<span class="vs">r'\d\d'</span>,<span class="st">'abc123xyz456'</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1717-4"><a href="nlp.html#cb1717-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n</span><span class="st">Found Nothing:'</span>,</span>
<span id="cb1717-5"><a href="nlp.html#cb1717-5" aria-hidden="true" tabindex="-1"></a>  re.findall(<span class="vs">r'\d\d'</span>,<span class="st">'abcxyz'</span>))</span></code></pre></div>
<pre><code>#:&gt; Finding Two Digits: ['12', '45'] 
#:&gt;  
#:&gt; Found Nothing: []</code></pre>
</div>
</div>
<div id="matching-condition" class="section level3" number="17.1.3">
<h3>
<span class="header-section-number">17.1.3</span> Matching Condition<a class="anchor" aria-label="anchor" href="#matching-condition"><i class="fas fa-link"></i></a>
</h3>
<div id="meta-characters" class="section level4" number="17.1.3.1">
<h4>
<span class="header-section-number">17.1.3.1</span> Meta Characters<a class="anchor" aria-label="anchor" href="#meta-characters"><i class="fas fa-link"></i></a>
</h4>
<pre><code>[]     match any single character within the bracket
[1234] is the same as [1-4]
[0-39] is the same as [01239]
[a-e]  is the same as [abcde]
[^abc] means any character except a,b,c
[^0-9] means any character except 0-9
a|b:   a or b
{n,m}  at least n repetition, but maximum m repetition
()     grouping</code></pre>
<div class="sourceCode" id="cb1720"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1720-1"><a href="nlp.html#cb1720-1" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'[a-z]+'</span>)</span>
<span id="cb1720-2"><a href="nlp.html#cb1720-2" aria-hidden="true" tabindex="-1"></a>text1 <span class="op">=</span> <span class="st">"tempo"</span></span>
<span id="cb1720-3"><a href="nlp.html#cb1720-3" aria-hidden="true" tabindex="-1"></a>text2 <span class="op">=</span> <span class="st">"tempo1"</span></span>
<span id="cb1720-4"><a href="nlp.html#cb1720-4" aria-hidden="true" tabindex="-1"></a>text3 <span class="op">=</span> <span class="st">"123 tempo1"</span></span>
<span id="cb1720-5"><a href="nlp.html#cb1720-5" aria-hidden="true" tabindex="-1"></a>text4 <span class="op">=</span> <span class="st">" tempo"</span></span>
<span id="cb1720-6"><a href="nlp.html#cb1720-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1720-7"><a href="nlp.html#cb1720-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Matching Text1:'</span>, pattern.match(text1),</span>
<span id="cb1720-8"><a href="nlp.html#cb1720-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n</span><span class="st">Matching Text2:'</span>, pattern.match(text2),</span>
<span id="cb1720-9"><a href="nlp.html#cb1720-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n</span><span class="st">Matching Text3:'</span>, pattern.match(text3),</span>
<span id="cb1720-10"><a href="nlp.html#cb1720-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n</span><span class="st">Matching Text4:'</span>, pattern.match(text4))</span></code></pre></div>
<pre><code>#:&gt; Matching Text1: &lt;re.Match object; span=(0, 5), match='tempo'&gt; 
#:&gt; Matching Text2: &lt;re.Match object; span=(0, 5), match='tempo'&gt; 
#:&gt; Matching Text3: None 
#:&gt; Matching Text4: None</code></pre>
</div>
<div id="special-sequence" class="section level4" number="17.1.3.2">
<h4>
<span class="header-section-number">17.1.3.2</span> Special Sequence<a class="anchor" aria-label="anchor" href="#special-sequence"><i class="fas fa-link"></i></a>
</h4>
<pre><code>. : [^\n]
\d: [0-9]              \D: [^0-9]
\s: [ \t\n\r\f\v]      \S: [^ \t\n\r\f\v]
\w: [a-zA-Z0-9_]       \W: [^a-zA-Z0-9_]
\t: tab
\n: newline
\b: word boundry (delimited by space, \t, \n)</code></pre>
<p><strong>Word Boundary Using <code>\b</code></strong>:</p>
<ul>
<li>
<code>\bABC</code> match if specified characters at the beginning of word (delimited by space, <code>\t</code>, <code>\n</code>), or beginning of newline<br>
</li>
<li>
<code>ABC\b</code> match if specified characters at the end of word (delimited by space, <code>\t</code>, <code>\n</code>), or end of the line</li>
</ul>
<div class="sourceCode" id="cb1723"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1723-1"><a href="nlp.html#cb1723-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"ABCD ABC XYZABC"</span></span>
<span id="cb1723-2"><a href="nlp.html#cb1723-2" aria-hidden="true" tabindex="-1"></a>pattern1 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'\bABC'</span>)</span>
<span id="cb1723-3"><a href="nlp.html#cb1723-3" aria-hidden="true" tabindex="-1"></a>pattern2 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'ABC\b'</span>)</span>
<span id="cb1723-4"><a href="nlp.html#cb1723-4" aria-hidden="true" tabindex="-1"></a>pattern3 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'\bABC\b'</span>)</span>
<span id="cb1723-5"><a href="nlp.html#cb1723-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1723-6"><a href="nlp.html#cb1723-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Match word that begins ABC:'</span>,</span>
<span id="cb1723-7"><a href="nlp.html#cb1723-7" aria-hidden="true" tabindex="-1"></a>  pattern1.findall(text), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1723-8"><a href="nlp.html#cb1723-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Match word that ends with ABC:'</span>,</span>
<span id="cb1723-9"><a href="nlp.html#cb1723-9" aria-hidden="true" tabindex="-1"></a>  pattern2.findall(text),<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1723-10"><a href="nlp.html#cb1723-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Match isolated word with ABC:'</span>,</span>
<span id="cb1723-11"><a href="nlp.html#cb1723-11" aria-hidden="true" tabindex="-1"></a>  pattern3.findall(text))</span></code></pre></div>
<pre><code>#:&gt; Match word that begins ABC: ['ABC', 'ABC'] 
#:&gt;  Match word that ends with ABC: ['ABC', 'ABC'] 
#:&gt;  Match isolated word with ABC: ['ABC']</code></pre>
</div>
<div id="repetition" class="section level4" number="17.1.3.3">
<h4>
<span class="header-section-number">17.1.3.3</span> Repetition<a class="anchor" aria-label="anchor" href="#repetition"><i class="fas fa-link"></i></a>
</h4>
<p>When repetition is used, re will be <strong>greedy</strong>; it try to repeat as many times as possible. If <strong>later portions of the pattern don’t match</strong>, the matching engine will then <strong>back up and try again</strong> with fewer repetitions.</p>
<pre><code>?:    zero or 1 occurance
*:    zero or more occurance
+:    one  or more occurance</code></pre>
<p><strong><code><a href="https://rdrr.io/r/utils/Question.html">?</a></code> Zero or 1 Occurance</strong></p>
<div class="sourceCode" id="cb1726"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1726-1"><a href="nlp.html#cb1726-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">'abcbcdd'</span></span>
<span id="cb1726-2"><a href="nlp.html#cb1726-2" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'a[bcd]?b'</span>)</span>
<span id="cb1726-3"><a href="nlp.html#cb1726-3" aria-hidden="true" tabindex="-1"></a>pattern.findall(text)</span></code></pre></div>
<pre><code>#:&gt; ['ab']</code></pre>
<p><strong><code><a href="https://rdrr.io/r/base/Arithmetic.html">+</a></code> At Least One Occurance</strong></p>
<div class="sourceCode" id="cb1728"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1728-1"><a href="nlp.html#cb1728-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">'abcbcdd'</span></span>
<span id="cb1728-2"><a href="nlp.html#cb1728-2" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'a[bcd]+b'</span>)</span>
<span id="cb1728-3"><a href="nlp.html#cb1728-3" aria-hidden="true" tabindex="-1"></a>pattern.findall(text)</span></code></pre></div>
<pre><code>#:&gt; ['abcb']</code></pre>
<p><strong><code><a href="https://rdrr.io/r/base/Arithmetic.html">*</a></code> Zero Or More Occurance Occurance</strong></p>
<div class="sourceCode" id="cb1730"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1730-1"><a href="nlp.html#cb1730-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">'abcbcdd'</span></span>
<span id="cb1730-2"><a href="nlp.html#cb1730-2" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'a[bcd]*b'</span>)</span>
<span id="cb1730-3"><a href="nlp.html#cb1730-3" aria-hidden="true" tabindex="-1"></a>pattern.findall(text)</span></code></pre></div>
<pre><code>#:&gt; ['abcb']</code></pre>
</div>
<div id="greedy-vs-non-greedy" class="section level4" number="17.1.3.4">
<h4>
<span class="header-section-number">17.1.3.4</span> Greedy vs Non-Greedy<a class="anchor" aria-label="anchor" href="#greedy-vs-non-greedy"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>The <code><a href="https://rdrr.io/r/base/Arithmetic.html">*</a></code>, <code><a href="https://rdrr.io/r/base/Arithmetic.html">+</a></code>, and <code><a href="https://rdrr.io/r/utils/Question.html">?</a></code> qualifiers are all greedy; they match as much text as possible<br>
</li>
<li>If the <code>&lt;.*&gt;</code> is matched against <code>&lt;a&gt; b &lt;c&gt;</code>, it will match the entire string, and not just <code>&lt;a&gt;</code><br>
</li>
<li>Adding <strong><code><a href="https://rdrr.io/r/utils/Question.html">?</a></code></strong> after the qualifier makes it perform the match in non-greedy; as few characters as possible will be matched. Using the RE &lt;.*?&gt; will match only ‘<a>’</a>
</li>
</ul>
<div class="sourceCode" id="cb1732"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1732-1"><a href="nlp.html#cb1732-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">'&lt;a&gt; ali baba &lt;c&gt;'</span></span>
<span id="cb1732-2"><a href="nlp.html#cb1732-2" aria-hidden="true" tabindex="-1"></a>greedy_pattern     <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'&lt;.*&gt;'</span>)</span>
<span id="cb1732-3"><a href="nlp.html#cb1732-3" aria-hidden="true" tabindex="-1"></a>non_greedy_pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'&lt;.*?&gt;'</span>)</span>
<span id="cb1732-4"><a href="nlp.html#cb1732-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">'Greedy:      '</span> ,        greedy_pattern.findall(text), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1732-5"><a href="nlp.html#cb1732-5" aria-hidden="true" tabindex="-1"></a>       <span class="st">'Non Greedy: '</span>, non_greedy_pattern.findall(text) )</span></code></pre></div>
<pre><code>#:&gt; Greedy:       ['&lt;a&gt; ali baba &lt;c&gt;'] 
#:&gt;  Non Greedy:  ['&lt;a&gt;', '&lt;c&gt;']</code></pre>
</div>
</div>
<div id="grouping-1" class="section level3" number="17.1.4">
<h3>
<span class="header-section-number">17.1.4</span> Grouping<a class="anchor" aria-label="anchor" href="#grouping-1"><i class="fas fa-link"></i></a>
</h3>
<p>When <code>()</code> is used in the pattern, retrive the grouping components in MatchObject with <code>.groups()</code>. Result is in list. Example below extract hours, minutes and am/pm into a list.</p>
<div id="capturing-group" class="section level4" number="17.1.4.1">
<h4>
<span class="header-section-number">17.1.4.1</span> Capturing Group<a class="anchor" aria-label="anchor" href="#capturing-group"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb1734"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1734-1"><a href="nlp.html#cb1734-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">'Today at Wednesday, 10:50pm, we go for a walk'</span></span>
<span id="cb1734-2"><a href="nlp.html#cb1734-2" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'(\d\d):(\d\d)(am|pm)'</span>)</span>
<span id="cb1734-3"><a href="nlp.html#cb1734-3" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> pattern.search(text)</span>
<span id="cb1734-4"><a href="nlp.html#cb1734-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1734-5"><a href="nlp.html#cb1734-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">'All Gropus: '</span>, m.groups(), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1734-6"><a href="nlp.html#cb1734-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Group 1: '</span>, m.group(<span class="dv">1</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1734-7"><a href="nlp.html#cb1734-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Group 2: '</span>, m.group(<span class="dv">2</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1734-8"><a href="nlp.html#cb1734-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Group 3: '</span>, m.group(<span class="dv">3</span>) )</span></code></pre></div>
<pre><code>#:&gt; All Gropus:  ('10', '50', 'pm') 
#:&gt;  Group 1:  10 
#:&gt;  Group 2:  50 
#:&gt;  Group 3:  pm</code></pre>
</div>
<div id="non-capturing-group" class="section level4" number="17.1.4.2">
<h4>
<span class="header-section-number">17.1.4.2</span> Non-Capturing Group<a class="anchor" aria-label="anchor" href="#non-capturing-group"><i class="fas fa-link"></i></a>
</h4>
<p>Having <code>(:? )</code> means don’t capture this group</p>
<div class="sourceCode" id="cb1736"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1736-1"><a href="nlp.html#cb1736-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">'Today at Wednesday, 10:50pm, we go for a walk'</span></span>
<span id="cb1736-2"><a href="nlp.html#cb1736-2" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'(:?\d\d):(?:\d\d)(am|pm)'</span>)</span>
<span id="cb1736-3"><a href="nlp.html#cb1736-3" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> pattern.search(text)</span>
<span id="cb1736-4"><a href="nlp.html#cb1736-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1736-5"><a href="nlp.html#cb1736-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">'All Gropus: '</span>, m.groups(), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1736-6"><a href="nlp.html#cb1736-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Group 1: '</span>, m.group(<span class="dv">1</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1736-7"><a href="nlp.html#cb1736-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Group 2: '</span>, m.group(<span class="dv">2</span>) )</span></code></pre></div>
<pre><code>#:&gt; All Gropus:  ('10', 'pm') 
#:&gt;  Group 1:  10 
#:&gt;  Group 2:  pm</code></pre>
</div>
</div>
<div id="splittitng" class="section level3" number="17.1.5">
<h3>
<span class="header-section-number">17.1.5</span> Splittitng<a class="anchor" aria-label="anchor" href="#splittitng"><i class="fas fa-link"></i></a>
</h3>
<p>Pattern is used to match <strong>delimters</strong>.</p>
<div id="use-re.split" class="section level4" number="17.1.5.1">
<h4>
<span class="header-section-number">17.1.5.1</span> Use <code>re.split()</code><a class="anchor" aria-label="anchor" href="#use-re.split"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb1738"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1738-1"><a href="nlp.html#cb1738-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( re.split(<span class="st">'@'</span>,  <span class="st">"aa@bb @ cc "</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1738-2"><a href="nlp.html#cb1738-2" aria-hidden="true" tabindex="-1"></a>       re.split(<span class="st">'\|'</span>, <span class="st">"aa|bb | cc "</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1738-3"><a href="nlp.html#cb1738-3" aria-hidden="true" tabindex="-1"></a>       re.split(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>, <span class="st">"sentence1</span><span class="ch">\n</span><span class="st">sentence2</span><span class="ch">\n</span><span class="st">sentence3"</span>) )</span></code></pre></div>
<pre><code>#:&gt; ['aa', 'bb ', ' cc '] 
#:&gt;  ['aa', 'bb ', ' cc '] 
#:&gt;  ['sentence1', 'sentence2', 'sentence3']</code></pre>
</div>
<div id="use-re.compile.split" class="section level4" number="17.1.5.2">
<h4>
<span class="header-section-number">17.1.5.2</span> Use <code>re.compile().split()</code><a class="anchor" aria-label="anchor" href="#use-re.compile.split"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb1740"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1740-1"><a href="nlp.html#cb1740-1" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r"\|"</span>)</span>
<span id="cb1740-2"><a href="nlp.html#cb1740-2" aria-hidden="true" tabindex="-1"></a>pattern.split(<span class="st">"aa|bb | cc "</span>)</span></code></pre></div>
<pre><code>#:&gt; ['aa', 'bb ', ' cc ']</code></pre>
</div>
</div>
<div id="substitution-re.sub" class="section level3" number="17.1.6">
<h3>
<span class="header-section-number">17.1.6</span> Substitution <code>re.sub()</code><a class="anchor" aria-label="anchor" href="#substitution-re.sub"><i class="fas fa-link"></i></a>
</h3>
<div id="found-match" class="section level4" number="17.1.6.1">
<h4>
<span class="header-section-number">17.1.6.1</span> Found Match<a class="anchor" aria-label="anchor" href="#found-match"><i class="fas fa-link"></i></a>
</h4>
<p>Example below repalce anything within <code>{{.*}}</code></p>
<div class="sourceCode" id="cb1742"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1742-1"><a href="nlp.html#cb1742-1" aria-hidden="true" tabindex="-1"></a>re.sub(<span class="vs">r'(</span><span class="sc">{{</span><span class="vs">.*</span><span class="sc">}}</span><span class="vs">)'</span>, <span class="st">'Durian'</span>, <span class="st">'I like to eat </span><span class="sc">{{</span><span class="st">Food</span><span class="sc">}}</span><span class="st">.'</span>, flags<span class="op">=</span>re.IGNORECASE)</span></code></pre></div>
<pre><code>#:&gt; 'I like to eat Durian.'</code></pre>
<p>Replace <code>AND</code> with <code><a href="https://rdrr.io/r/base/Logic.html">&amp;</a></code>. This does not require <code>()</code> grouping</p>
<div class="sourceCode" id="cb1744"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1744-1"><a href="nlp.html#cb1744-1" aria-hidden="true" tabindex="-1"></a>re.sub(<span class="vs">r'\sAND\s'</span>, <span class="st">' &amp; '</span>, <span class="st">'Baked Beans And Spam'</span>, flags<span class="op">=</span>re.IGNORECASE)</span></code></pre></div>
<pre><code>#:&gt; 'Baked Beans &amp; Spam'</code></pre>
</div>
<div id="no-match" class="section level4" number="17.1.6.2">
<h4>
<span class="header-section-number">17.1.6.2</span> No Match<a class="anchor" aria-label="anchor" href="#no-match"><i class="fas fa-link"></i></a>
</h4>
<p>If not pattern not found, return the original text.</p>
<div class="sourceCode" id="cb1746"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1746-1"><a href="nlp.html#cb1746-1" aria-hidden="true" tabindex="-1"></a>re.sub(<span class="vs">r'(</span><span class="sc">{{</span><span class="vs">.*</span><span class="sc">}}</span><span class="vs">)'</span>, <span class="st">'Durian'</span>, <span class="st">'I like to eat &lt;Food&gt;.'</span>, flags<span class="op">=</span>re.IGNORECASE)</span></code></pre></div>
<pre><code>#:&gt; 'I like to eat &lt;Food&gt;.'</code></pre>
</div>
</div>
<div id="practical-examples" class="section level3" number="17.1.7">
<h3>
<span class="header-section-number">17.1.7</span> Practical Examples<a class="anchor" aria-label="anchor" href="#practical-examples"><i class="fas fa-link"></i></a>
</h3>
<div id="extracting-float" class="section level4" number="17.1.7.1">
<h4>
<span class="header-section-number">17.1.7.1</span> Extracting Float<a class="anchor" aria-label="anchor" href="#extracting-float"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb1748"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1748-1"><a href="nlp.html#cb1748-1" aria-hidden="true" tabindex="-1"></a>re_float <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'\d+(\.\d+)?'</span>)</span>
<span id="cb1748-2"><a href="nlp.html#cb1748-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_float(x):</span>
<span id="cb1748-3"><a href="nlp.html#cb1748-3" aria-hidden="true" tabindex="-1"></a>    money <span class="op">=</span> x.replace(<span class="st">','</span>,<span class="st">''</span>)</span>
<span id="cb1748-4"><a href="nlp.html#cb1748-4" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> re_float.search(money)</span>
<span id="cb1748-5"><a href="nlp.html#cb1748-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(result.group()) <span class="cf">if</span> result <span class="cf">else</span> <span class="bu">float</span>(<span class="dv">0</span>)</span>
<span id="cb1748-6"><a href="nlp.html#cb1748-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1748-7"><a href="nlp.html#cb1748-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( extract_float(<span class="st">'123,456.78'</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1748-8"><a href="nlp.html#cb1748-8" aria-hidden="true" tabindex="-1"></a>       extract_float(<span class="st">'rm 123.78 (30%)'</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1748-9"><a href="nlp.html#cb1748-9" aria-hidden="true" tabindex="-1"></a>       extract_float(<span class="st">'rm 123,456.78 (30%)'</span>) )</span></code></pre></div>
<pre><code>#:&gt; 123456.78 
#:&gt;  123.78 
#:&gt;  123456.78</code></pre>
</div>
</div>
</div>
<div id="word-tokenizer" class="section level2" number="17.2">
<h2>
<span class="header-section-number">17.2</span> Word Tokenizer<a class="anchor" aria-label="anchor" href="#word-tokenizer"><i class="fas fa-link"></i></a>
</h2>
<div id="custom-tokenizer" class="section level3" number="17.2.1">
<h3>
<span class="header-section-number">17.2.1</span> Custom Tokenizer<a class="anchor" aria-label="anchor" href="#custom-tokenizer"><i class="fas fa-link"></i></a>
</h3>
<div id="split-by-regex-pattern" class="section level4" number="17.2.1.1">
<h4>
<span class="header-section-number">17.2.1.1</span> Split By Regex Pattern<a class="anchor" aria-label="anchor" href="#split-by-regex-pattern"><i class="fas fa-link"></i></a>
</h4>
<p>Use <strong>regex</strong> to split words based on <strong>specific punctuation as delimeter</strong>.<br>
The rule is: split input text when any one or more continuous occurances of specified character.</p>
<div class="sourceCode" id="cb1750"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1750-1"><a href="nlp.html#cb1750-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1750-2"><a href="nlp.html#cb1750-2" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r"[-\s.,;!?]+"</span>)</span>
<span id="cb1750-3"><a href="nlp.html#cb1750-3" aria-hidden="true" tabindex="-1"></a>pattern.split(<span class="st">"hi @ali--baba, you are aweeeeeesome! isn't it. Believe it.:)"</span>)</span></code></pre></div>
<pre><code>#:&gt; ['hi', '@ali', 'baba', 'you', 'are', 'aweeeeeesome', "isn't", 'it', 'Believe', 'it', ':)']</code></pre>
</div>
<div id="pick-by-regex-pattern-nltk.tokenize.regexptokenizer" class="section level4" number="17.2.1.2">
<h4>
<span class="header-section-number">17.2.1.2</span> Pick By Regex Pattern <code>nltk.tokenize.RegexpTokenizer</code><a class="anchor" aria-label="anchor" href="#pick-by-regex-pattern-nltk.tokenize.regexptokenizer"><i class="fas fa-link"></i></a>
</h4>
<p>Any sequence of chars fall within the bracket are considered tokens. Any chars not within the bracket are removed.</p>
<div class="sourceCode" id="cb1752"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1752-1"><a href="nlp.html#cb1752-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> RegexpTokenizer</span>
<span id="cb1752-2"><a href="nlp.html#cb1752-2" aria-hidden="true" tabindex="-1"></a>my_tokenizer <span class="op">=</span> RegexpTokenizer(<span class="vs">r'[a-zA-Z0-9\']+'</span>)</span>
<span id="cb1752-3"><a href="nlp.html#cb1752-3" aria-hidden="true" tabindex="-1"></a>my_tokenizer.tokenize(<span class="st">"hi @ali--baba, you are aweeeeeesome! isn't it. Believe it.:"</span>)</span></code></pre></div>
<pre><code>#:&gt; ['hi', 'ali', 'baba', 'you', 'are', 'aweeeeeesome', "isn't", 'it', 'Believe', 'it']</code></pre>
</div>
</div>
<div id="nltk.tokenize.word_tokenize" class="section level3" number="17.2.2">
<h3>
<span class="header-section-number">17.2.2</span> <code>nltk.tokenize.word_tokenize()</code><a class="anchor" aria-label="anchor" href="#nltk.tokenize.word_tokenize"><i class="fas fa-link"></i></a>
</h3>
<p>Words and punctuations are considered as tokens!</p>
<div class="sourceCode" id="cb1754"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1754-1"><a href="nlp.html#cb1754-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1754-2"><a href="nlp.html#cb1754-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span></code></pre></div>
<pre><code>#:&gt; True
#:&gt; 
#:&gt; [nltk_data] Downloading package punkt to /home/msfz751/nltk_data...
#:&gt; [nltk_data]   Package punkt is already up-to-date!</code></pre>
<div class="sourceCode" id="cb1756"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1756-1"><a href="nlp.html#cb1756-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb1756-2"><a href="nlp.html#cb1756-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( word_tokenize(<span class="st">"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it.:)"</span>) )</span></code></pre></div>
<pre><code>#:&gt; ['hi', '@', 'ali-baba', ',', 'you', 'are', 'aweeeeeesome', '!', 'is', "n't", 'it', '.', 'Believe', 'it', '.', ':', ')']</code></pre>
</div>
<div id="nltk.tokenize.casual.casual_tokenize" class="section level3" number="17.2.3">
<h3>
<span class="header-section-number">17.2.3</span> <code>nltk.tokenize.casual.casual_tokenize()</code><a class="anchor" aria-label="anchor" href="#nltk.tokenize.casual.casual_tokenize"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Support emoji</li>
<li>Support reduction of repetition chars</li>
<li>Support removing userid (@someone)</li>
<li>Good for social media text</li>
<li>Punctuations are tokens!</li>
</ul>
<div class="sourceCode" id="cb1758"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1758-1"><a href="nlp.html#cb1758-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize.casual     <span class="im">import</span> casual_tokenize</span>
<span id="cb1758-2"><a href="nlp.html#cb1758-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( casual_tokenize(<span class="st">"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it. :)"</span>) )  </span></code></pre></div>
<pre><code>#:&gt; ['hi', '@ali', '-', 'baba', ',', 'you', 'are', 'aweeeeeesome', '!', "isn't", 'it', '.', 'Believe', 'it', '.', ':)']</code></pre>
<p>Example below shorten repeating chars, notice aweeeeeesome becomes aweeesome</p>
<div class="sourceCode" id="cb1760"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1760-1"><a href="nlp.html#cb1760-1" aria-hidden="true" tabindex="-1"></a><span class="co">## shorten repeated chars</span></span>
<span id="cb1760-2"><a href="nlp.html#cb1760-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( casual_tokenize(<span class="st">"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it.:)"</span>, </span>
<span id="cb1760-3"><a href="nlp.html#cb1760-3" aria-hidden="true" tabindex="-1"></a>          reduce_len<span class="op">=</span><span class="va">True</span>))     </span></code></pre></div>
<pre><code>#:&gt; ['hi', '@ali', '-', 'baba', ',', 'you', 'are', 'aweeesome', '!', "isn't", 'it', '.', 'Believe', 'it', '.', ':)']</code></pre>
<p>Stripping off User ID</p>
<div class="sourceCode" id="cb1762"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1762-1"><a href="nlp.html#cb1762-1" aria-hidden="true" tabindex="-1"></a><span class="co">## shorten repeated chars, stirp usernames</span></span>
<span id="cb1762-2"><a href="nlp.html#cb1762-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( casual_tokenize(<span class="st">"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it.:)"</span>, </span>
<span id="cb1762-3"><a href="nlp.html#cb1762-3" aria-hidden="true" tabindex="-1"></a>          reduce_len<span class="op">=</span><span class="va">True</span>,      </span>
<span id="cb1762-4"><a href="nlp.html#cb1762-4" aria-hidden="true" tabindex="-1"></a>          strip_handles<span class="op">=</span><span class="va">True</span>))  </span></code></pre></div>
<pre><code>#:&gt; ['hi', '-', 'baba', ',', 'you', 'are', 'aweeesome', '!', "isn't", 'it', '.', 'Believe', 'it', '.', ':)']</code></pre>
</div>
<div id="nltk.tokenize.treebank.treebankwordtokenizer.tokenize" class="section level3" number="17.2.4">
<h3>
<span class="header-section-number">17.2.4</span> <code>nltk.tokenize.treebank.TreebankWordTokenizer().tokenize()</code><a class="anchor" aria-label="anchor" href="#nltk.tokenize.treebank.treebankwordtokenizer.tokenize"><i class="fas fa-link"></i></a>
</h3>
<p>Treebank assume input text is <strong>A sentence</strong>, hence any period combined with word is treated as token.</p>
<div class="sourceCode" id="cb1764"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1764-1"><a href="nlp.html#cb1764-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize.treebank   <span class="im">import</span> TreebankWordTokenizer</span>
<span id="cb1764-2"><a href="nlp.html#cb1764-2" aria-hidden="true" tabindex="-1"></a>TreebankWordTokenizer().tokenize(<span class="st">"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it.:)"</span>)</span></code></pre></div>
<pre><code>#:&gt; ['hi', '@', 'ali-baba', ',', 'you', 'are', 'aweeeeeesome', '!', 'is', "n't", 'it.', 'Believe', 'it.', ':', ')']</code></pre>
</div>
<div id="corpus-token-extractor" class="section level3" number="17.2.5">
<h3>
<span class="header-section-number">17.2.5</span> Corpus Token Extractor<a class="anchor" aria-label="anchor" href="#corpus-token-extractor"><i class="fas fa-link"></i></a>
</h3>
<p>A corpus is a collection of documents (list of documents).
A document is a text string containing one or many sentences.</p>
<div class="sourceCode" id="cb1766"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1766-1"><a href="nlp.html#cb1766-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb1766-2"><a href="nlp.html#cb1766-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nlpia.data.loaders <span class="im">import</span> harry_docs <span class="im">as</span> corpus</span></code></pre></div>
<div class="sourceCode" id="cb1767"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1767-1"><a href="nlp.html#cb1767-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Tokenize each doc to list, then add to a bigger list</span></span>
<span id="cb1767-2"><a href="nlp.html#cb1767-2" aria-hidden="true" tabindex="-1"></a>doc_tokens<span class="op">=</span>[]</span>
<span id="cb1767-3"><a href="nlp.html#cb1767-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> corpus:</span>
<span id="cb1767-4"><a href="nlp.html#cb1767-4" aria-hidden="true" tabindex="-1"></a>  doc_tokens <span class="op">+=</span> [word_tokenize(doc.lower())]</span>
<span id="cb1767-5"><a href="nlp.html#cb1767-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1767-6"><a href="nlp.html#cb1767-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Corpus (Contain 3 Documents):</span><span class="ch">\n</span><span class="st">'</span>,corpus,<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1767-7"><a href="nlp.html#cb1767-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">'</span><span class="ch">\n</span><span class="st">Tokenized result for each document:'</span>,<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,doc_tokens)</span></code></pre></div>
<pre><code>#:&gt; Corpus (Contain 3 Documents):
#:&gt;  ['The faster Harry got to the store, the faster and faster Harry would get home.', 'Harry is hairy and faster than Jill.', 'Jill is not as hairy as Harry.'] 
#:&gt;  
#:&gt; Tokenized result for each document: 
#:&gt;  [['the', 'faster', 'harry', 'got', 'to', 'the', 'store', ',', 'the', 'faster', 'and', 'faster', 'harry', 'would', 'get', 'home', '.'], ['harry', 'is', 'hairy', 'and', 'faster', 'than', 'jill', '.'], ['jill', 'is', 'not', 'as', 'hairy', 'as', 'harry', '.']]</code></pre>
<p>Unpack list of token lists from above using sum. To get the <strong>vocabulary</strong> (unique tokens), <strong>convert list to set</strong>.</p>
<div class="sourceCode" id="cb1769"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1769-1"><a href="nlp.html#cb1769-1" aria-hidden="true" tabindex="-1"></a><span class="co">## unpack list of list to list</span></span>
<span id="cb1769-2"><a href="nlp.html#cb1769-2" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> <span class="bu">sum</span>(doc_tokens,[])</span>
<span id="cb1769-3"><a href="nlp.html#cb1769-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">Corpus Vacabulary (Unique Tokens):</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1769-4"><a href="nlp.html#cb1769-4" aria-hidden="true" tabindex="-1"></a>       <span class="bu">sorted</span>(<span class="bu">set</span>(vocab)))</span></code></pre></div>
<pre><code>#:&gt; 
#:&gt; Corpus Vacabulary (Unique Tokens):
#:&gt;  [',', '.', 'and', 'as', 'faster', 'get', 'got', 'hairy', 'harry', 'home', 'is', 'jill', 'not', 'store', 'than', 'the', 'to', 'would']</code></pre>
</div>
</div>
<div id="sentence-tokenizer" class="section level2" number="17.3">
<h2>
<span class="header-section-number">17.3</span> Sentence Tokenizer<a class="anchor" aria-label="anchor" href="#sentence-tokenizer"><i class="fas fa-link"></i></a>
</h2>
<p>This is about detecting sentence boundry and split text into list of sentences</p>
<div id="sample-text" class="section level3" number="17.3.1">
<h3>
<span class="header-section-number">17.3.1</span> Sample Text<a class="anchor" aria-label="anchor" href="#sample-text"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb1771"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1771-1"><a href="nlp.html#cb1771-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">'''</span></span>
<span id="cb1771-2"><a href="nlp.html#cb1771-2" aria-hidden="true" tabindex="-1"></a><span class="st">Hello Mr. Smith, how are you doing today?</span></span>
<span id="cb1771-3"><a href="nlp.html#cb1771-3" aria-hidden="true" tabindex="-1"></a><span class="st">The weather is great, and city is awesome.</span></span>
<span id="cb1771-4"><a href="nlp.html#cb1771-4" aria-hidden="true" tabindex="-1"></a><span class="st">The sky is pinkish-blue, Dr. Alba would agree.</span></span>
<span id="cb1771-5"><a href="nlp.html#cb1771-5" aria-hidden="true" tabindex="-1"></a><span class="st">You shouldn't eat hard things i.e. cardboard, stones and bushes</span></span>
<span id="cb1771-6"><a href="nlp.html#cb1771-6" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span></code></pre></div>
</div>
<div id="nltk.tokenize.punkt.punktsentencetokenizer" class="section level3" number="17.3.2">
<h3>
<span class="header-section-number">17.3.2</span> ’nltk.tokenize.punkt.PunktSentenceTokenizer`<a class="anchor" aria-label="anchor" href="#nltk.tokenize.punkt.punktsentencetokenizer"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>The <code>PunktSentenceTokenizer</code> is an sentence boundary detection algorithm. It is an unsupervised trainable model. This means it can be trained on unlabeled data, aka text that is not split into sentences<br>
</li>
<li>PunkSentneceTokenizer is based on work published on this paepr: <a href="https://www.mitpressjournals.org/doi/abs/10.1162/coli.2006.32.4.485#.V2ouLXUrLeQ">Unsupervised Multilingual Sentence Boundary Detection</a>
</li>
</ul>
<div id="default-behavior" class="section level4" number="17.3.2.1">
<h4>
<span class="header-section-number">17.3.2.1</span> Default Behavior<a class="anchor" aria-label="anchor" href="#default-behavior"><i class="fas fa-link"></i></a>
</h4>
<p>Vanila tokenizer splits sentences on period <code>.</code>, which is not desirable</p>
<div class="sourceCode" id="cb1772"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1772-1"><a href="nlp.html#cb1772-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize.punkt <span class="im">import</span> PunktSentenceTokenizer, PunktTrainer</span>
<span id="cb1772-2"><a href="nlp.html#cb1772-2" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('punkt')</span></span>
<span id="cb1772-3"><a href="nlp.html#cb1772-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> PunktSentenceTokenizer()</span>
<span id="cb1772-4"><a href="nlp.html#cb1772-4" aria-hidden="true" tabindex="-1"></a>tokenized_text <span class="op">=</span> tokenizer.tokenize(text) </span>
<span id="cb1772-5"><a href="nlp.html#cb1772-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> tokenized_text:</span>
<span id="cb1772-6"><a href="nlp.html#cb1772-6" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(x) </span></code></pre></div>
<pre><code>#:&gt; 
#:&gt; Hello Mr.
#:&gt; Smith, how are you doing today?
#:&gt; The weather is great, and city is awesome.
#:&gt; The sky is pinkish-blue, Dr.
#:&gt; Alba would agree.
#:&gt; You shouldn't eat hard things i.e.
#:&gt; cardboard, stones and bushes</code></pre>
</div>
<div id="pretrained-model---english-pickle" class="section level4" number="17.3.2.2">
<h4>
<span class="header-section-number">17.3.2.2</span> Pretrained Model - English Pickle<a class="anchor" aria-label="anchor" href="#pretrained-model---english-pickle"><i class="fas fa-link"></i></a>
</h4>
<p>NLTK already includes a pre-trained version of the PunktSentenceTokenizer for English, as you can see, it is quite good</p>
<div class="sourceCode" id="cb1774"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1774-1"><a href="nlp.html#cb1774-1" aria-hidden="true" tabindex="-1"></a>tokenizer      <span class="op">=</span> nltk.data.load(<span class="st">'tokenizers/punkt/english.pickle'</span>)</span>
<span id="cb1774-2"><a href="nlp.html#cb1774-2" aria-hidden="true" tabindex="-1"></a>tokenized_text <span class="op">=</span> tokenizer.tokenize(text) </span>
<span id="cb1774-3"><a href="nlp.html#cb1774-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> tokenized_text:</span>
<span id="cb1774-4"><a href="nlp.html#cb1774-4" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(x) </span></code></pre></div>
<pre><code>#:&gt; 
#:&gt; Hello Mr. Smith, how are you doing today?
#:&gt; The weather is great, and city is awesome.
#:&gt; The sky is pinkish-blue, Dr. Alba would agree.
#:&gt; You shouldn't eat hard things i.e.
#:&gt; cardboard, stones and bushes</code></pre>
</div>
<div id="adding-abbreviations" class="section level4" number="17.3.2.3">
<h4>
<span class="header-section-number">17.3.2.3</span> Adding Abbreviations<a class="anchor" aria-label="anchor" href="#adding-abbreviations"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>The pretrained tokenizer is not perfect, it wrongly detected ‘i.e.’ as sentence boundary<br>
</li>
<li>Let’s <strong>teach</strong> Punkt by adding the abbreviation to its parameter</li>
</ul>
<p><strong>Adding Single Abbreviation</strong></p>
<div class="sourceCode" id="cb1776"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1776-1"><a href="nlp.html#cb1776-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1776-2"><a href="nlp.html#cb1776-2" aria-hidden="true" tabindex="-1"></a>tokenizer      <span class="op">=</span> nltk.data.load(<span class="st">'tokenizers/punkt/english.pickle'</span>)</span>
<span id="cb1776-3"><a href="nlp.html#cb1776-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1776-4"><a href="nlp.html#cb1776-4" aria-hidden="true" tabindex="-1"></a><span class="co">## Add apprevaitions to Tokenizer</span></span>
<span id="cb1776-5"><a href="nlp.html#cb1776-5" aria-hidden="true" tabindex="-1"></a>tokenizer._params.abbrev_types.add(<span class="st">'i.e'</span>)</span>
<span id="cb1776-6"><a href="nlp.html#cb1776-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1776-7"><a href="nlp.html#cb1776-7" aria-hidden="true" tabindex="-1"></a>tokenized_text <span class="op">=</span> tokenizer.tokenize(text) </span>
<span id="cb1776-8"><a href="nlp.html#cb1776-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> tokenized_text:</span>
<span id="cb1776-9"><a href="nlp.html#cb1776-9" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(x)</span></code></pre></div>
<pre><code>#:&gt; 
#:&gt; Hello Mr. Smith, how are you doing today?
#:&gt; The weather is great, and city is awesome.
#:&gt; The sky is pinkish-blue, Dr. Alba would agree.
#:&gt; You shouldn't eat hard things i.e. cardboard, stones and bushes</code></pre>
<p><strong>Add List of Abbreviations</strong></p>
<p>If you have more than one abbreviations, use <code><a href="https://rdrr.io/r/stats/update.html">update()</a></code> with the list of abbreviations</p>
<div class="sourceCode" id="cb1778"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1778-1"><a href="nlp.html#cb1778-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize.punkt <span class="im">import</span> PunktSentenceTokenizer, PunktParameters</span>
<span id="cb1778-2"><a href="nlp.html#cb1778-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1778-3"><a href="nlp.html#cb1778-3" aria-hidden="true" tabindex="-1"></a><span class="co">## Add Abbreviations to Tokenizer</span></span>
<span id="cb1778-4"><a href="nlp.html#cb1778-4" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span>  nltk.data.load(<span class="st">'tokenizers/punkt/english.pickle'</span>)</span>
<span id="cb1778-5"><a href="nlp.html#cb1778-5" aria-hidden="true" tabindex="-1"></a>tokenizer._params.abbrev_types.update([<span class="st">'dr'</span>, <span class="st">'vs'</span>, <span class="st">'mr'</span>, <span class="st">'mrs'</span>, <span class="st">'prof'</span>, <span class="st">'inc'</span>, <span class="st">'i.e'</span>])</span>
<span id="cb1778-6"><a href="nlp.html#cb1778-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1778-7"><a href="nlp.html#cb1778-7" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> tokenizer.tokenize(text) </span>
<span id="cb1778-8"><a href="nlp.html#cb1778-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> sentences:</span>
<span id="cb1778-9"><a href="nlp.html#cb1778-9" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(x) </span></code></pre></div>
<pre><code>#:&gt; 
#:&gt; Hello Mr. Smith, how are you doing today?
#:&gt; The weather is great, and city is awesome.
#:&gt; The sky is pinkish-blue, Dr. Alba would agree.
#:&gt; You shouldn't eat hard things i.e. cardboard, stones and bushes</code></pre>
</div>
</div>
<div id="nltk.tokenize.sent_tokenize" class="section level3" number="17.3.3">
<h3>
<span class="header-section-number">17.3.3</span> <code>nltk.tokenize.sent_tokenize()</code><a class="anchor" aria-label="anchor" href="#nltk.tokenize.sent_tokenize"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>sent_tokenize</code> function uses an instance of <strong>PunktSentenceTokenizer</strong>, which is already been trained and thus very well knows to mark the end and begining of sentence at what characters and punctuation.</p>
<div class="sourceCode" id="cb1780"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1780-1"><a href="nlp.html#cb1780-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize</span>
<span id="cb1780-2"><a href="nlp.html#cb1780-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1780-3"><a href="nlp.html#cb1780-3" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> sent_tokenize(text)</span>
<span id="cb1780-4"><a href="nlp.html#cb1780-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> sentences:</span>
<span id="cb1780-5"><a href="nlp.html#cb1780-5" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(x) </span></code></pre></div>
<pre><code>#:&gt; 
#:&gt; Hello Mr. Smith, how are you doing today?
#:&gt; The weather is great, and city is awesome.
#:&gt; The sky is pinkish-blue, Dr. Alba would agree.
#:&gt; You shouldn't eat hard things i.e. cardboard, stones and bushes</code></pre>
</div>
</div>
<div id="n-gram" class="section level2" number="17.4">
<h2>
<span class="header-section-number">17.4</span> N-Gram<a class="anchor" aria-label="anchor" href="#n-gram"><i class="fas fa-link"></i></a>
</h2>
<p>To create n-gram, first create 1-gram token</p>
<div class="sourceCode" id="cb1782"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1782-1"><a href="nlp.html#cb1782-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.util <span class="im">import</span> ngrams </span>
<span id="cb1782-2"><a href="nlp.html#cb1782-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1782-3"><a href="nlp.html#cb1782-3" aria-hidden="true" tabindex="-1"></a>sentence <span class="op">=</span> <span class="st">"Thomas Jefferson began building the city, at the age of 25"</span></span>
<span id="cb1782-4"><a href="nlp.html#cb1782-4" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r"[-\s.,;!?]+"</span>)</span>
<span id="cb1782-5"><a href="nlp.html#cb1782-5" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> pattern.split(sentence)</span>
<span id="cb1782-6"><a href="nlp.html#cb1782-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span></code></pre></div>
<pre><code>#:&gt; ['Thomas', 'Jefferson', 'began', 'building', 'the', 'city', 'at', 'the', 'age', 'of', '25']</code></pre>
<p><strong>ngrams()</strong> is a generator, therefore, use <strong>list()</strong> to convert into full list</p>
<div class="sourceCode" id="cb1784"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1784-1"><a href="nlp.html#cb1784-1" aria-hidden="true" tabindex="-1"></a>ngrams(tokens,<span class="dv">2</span>)</span></code></pre></div>
<pre><code>#:&gt; &lt;generator object ngrams at 0x7fcdc9eae850&gt;</code></pre>
<p>Convert 1-gram to 2-Gram, wrap into list</p>
<div class="sourceCode" id="cb1786"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1786-1"><a href="nlp.html#cb1786-1" aria-hidden="true" tabindex="-1"></a>grammy <span class="op">=</span> <span class="bu">list</span>( ngrams(tokens,<span class="dv">2</span>) )</span>
<span id="cb1786-2"><a href="nlp.html#cb1786-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(grammy)</span></code></pre></div>
<pre><code>#:&gt; [('Thomas', 'Jefferson'), ('Jefferson', 'began'), ('began', 'building'), ('building', 'the'), ('the', 'city'), ('city', 'at'), ('at', 'the'), ('the', 'age'), ('age', 'of'), ('of', '25')]</code></pre>
<p>Combine each 2-gram into a string object</p>
<div class="sourceCode" id="cb1788"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1788-1"><a href="nlp.html#cb1788-1" aria-hidden="true" tabindex="-1"></a>[ <span class="st">" "</span>.join(x) <span class="cf">for</span> x <span class="kw">in</span> grammy]</span></code></pre></div>
<pre><code>#:&gt; ['Thomas Jefferson', 'Jefferson began', 'began building', 'building the', 'the city', 'city at', 'at the', 'the age', 'age of', 'of 25']</code></pre>
</div>
<div id="stopwords" class="section level2" number="17.5">
<h2>
<span class="header-section-number">17.5</span> Stopwords<a class="anchor" aria-label="anchor" href="#stopwords"><i class="fas fa-link"></i></a>
</h2>
<div id="custom-stop-words" class="section level3" number="17.5.1">
<h3>
<span class="header-section-number">17.5.1</span> Custom Stop Words<a class="anchor" aria-label="anchor" href="#custom-stop-words"><i class="fas fa-link"></i></a>
</h3>
<p>Build the custom stop words dictionary.</p>
<div class="sourceCode" id="cb1790"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1790-1"><a href="nlp.html#cb1790-1" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> [<span class="st">'a'</span>,<span class="st">'an'</span>,<span class="st">'the'</span>,<span class="st">'on'</span>,<span class="st">'of'</span>,<span class="st">'off'</span>,<span class="st">'this'</span>,<span class="st">'is'</span>,<span class="st">'at'</span>]</span></code></pre></div>
<p>Tokenize text and remove stop words</p>
<div class="sourceCode" id="cb1791"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1791-1"><a href="nlp.html#cb1791-1" aria-hidden="true" tabindex="-1"></a>sentence <span class="op">=</span> <span class="st">"The house is on fire"</span></span>
<span id="cb1791-2"><a href="nlp.html#cb1791-2" aria-hidden="true" tabindex="-1"></a>tokens   <span class="op">=</span> word_tokenize(sentence)</span>
<span id="cb1791-3"><a href="nlp.html#cb1791-3" aria-hidden="true" tabindex="-1"></a>tokens_without_stopwords <span class="op">=</span> [ x <span class="cf">for</span> x <span class="kw">in</span> tokens <span class="cf">if</span> x <span class="kw">not</span> <span class="kw">in</span> stop_words ]</span>
<span id="cb1791-4"><a href="nlp.html#cb1791-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1791-5"><a href="nlp.html#cb1791-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' Original Tokens  : '</span>, tokens, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1791-6"><a href="nlp.html#cb1791-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Removed Stopwords: '</span>,tokens_without_stopwords)</span></code></pre></div>
<pre><code>#:&gt;  Original Tokens  :  ['The', 'house', 'is', 'on', 'fire'] 
#:&gt;  Removed Stopwords:  ['The', 'house', 'fire']</code></pre>
</div>
<div id="nltk-stop-words" class="section level3" number="17.5.2">
<h3>
<span class="header-section-number">17.5.2</span> NLTK Stop Words<a class="anchor" aria-label="anchor" href="#nltk-stop-words"><i class="fas fa-link"></i></a>
</h3>
<p>Contain 179 words, in a list form</p>
<div class="sourceCode" id="cb1793"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1793-1"><a href="nlp.html#cb1793-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1793-2"><a href="nlp.html#cb1793-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span></code></pre></div>
<pre><code>#:&gt; True
#:&gt; 
#:&gt; [nltk_data] Downloading package stopwords to
#:&gt; [nltk_data]     /home/msfz751/nltk_data...
#:&gt; [nltk_data]   Package stopwords is already up-to-date!</code></pre>
<div class="sourceCode" id="cb1795"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1795-1"><a href="nlp.html#cb1795-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1795-2"><a href="nlp.html#cb1795-2" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('stopwords')</span></span>
<span id="cb1795-3"><a href="nlp.html#cb1795-3" aria-hidden="true" tabindex="-1"></a>nltk_stop_words <span class="op">=</span> nltk.corpus.stopwords.words(<span class="st">'english'</span>)</span>
<span id="cb1795-4"><a href="nlp.html#cb1795-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Total NLTK Stopwords: '</span>, <span class="bu">len</span>(nltk_stop_words),<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1795-5"><a href="nlp.html#cb1795-5" aria-hidden="true" tabindex="-1"></a>      nltk_stop_words)</span></code></pre></div>
<pre><code>#:&gt; Total NLTK Stopwords:  179 
#:&gt;  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]</code></pre>
</div>
<div id="sklearn-stop-words" class="section level3" number="17.5.3">
<h3>
<span class="header-section-number">17.5.3</span> SKLearn Stop Words<a class="anchor" aria-label="anchor" href="#sklearn-stop-words"><i class="fas fa-link"></i></a>
</h3>
<p>Contain 318 stop words, in frozenset form</p>
<div class="sourceCode" id="cb1797"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1797-1"><a href="nlp.html#cb1797-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> ENGLISH_STOP_WORDS <span class="im">as</span> sklearn_stop_words</span>
<span id="cb1797-2"><a href="nlp.html#cb1797-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' Total Sklearn Stopwords: '</span>, <span class="bu">len</span>(sklearn_stop_words),<span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>,</span>
<span id="cb1797-3"><a href="nlp.html#cb1797-3" aria-hidden="true" tabindex="-1"></a>       sklearn_stop_words)</span></code></pre></div>
<pre><code>#:&gt;  Total Sklearn Stopwords:  318 
#:&gt; 
#:&gt;  frozenset({'before', 'becomes', 'down', 'see', 'already', 'cry', 'behind', 'first', 'such', 'con', 'neither', 'however', 'was', 'something', 'against', 'either', 'thence', 'well', 'to', 'when', 'those', 'whose', 'throughout', 'never', 'third', 'been', 'empty', 'anyway', 'if', 'their', 'amount', 'etc', 'others', 'nothing', 'around', 'every', 'how', 'into', 'then', 'along', 'amongst', 'should', 'upon', 'us', 'take', 'himself', 'namely', 'not', 'de', 'under', 'all', 'out', 'twelve', 'sincere', 'through', 'thru', 'get', 'across', 'mill', 'indeed', 'each', 'whereas', 'now', 'so', 'very', 'hereafter', 'them', 'few', 'most', 'call', 'hereby', 'sometime', 'many', 'ever', 'interest', 'twenty', 'any', 'might', 'thick', 'rather', 'until', 'besides', 're', 'back', 'hers', 'cant', 'enough', 'by', 'hence', 'would', 'via', 'for', 'yours', 'couldnt', 'will', 'thus', 'fire', 'wherever', 'but', 'none', 'name', 'somehow', 'almost', 'full', 'myself', 'fill', 'hasnt', 'sixty', 'who', 'what', 'keep', 'front', 'nevertheless', 'these', 'there', 'system', 'done', 'eleven', 'three', 'seem', 'why', 'anything', 'made', 'ourselves', 'had', 'nowhere', 'with', 'un', 'give', 'another', 'perhaps', 'everywhere', 'between', 'show', 'amoungst', 'further', 'whom', 'within', 'here', 'thereby', 'your', 'during', 'too', 'yourself', 'towards', 'and', 'at', 'move', 'eg', 'eight', 'be', 'above', 'among', 'do', 'a', 'inc', 'six', 'together', 'yet', 'up', 'toward', 'whatever', 'an', 'on', 'you', 'still', 'five', 'therein', 'noone', 'although', 'whereafter', 'alone', 'as', 'we', 'always', 'often', 'has', 'this', 'next', 'else', 'whoever', 'again', 'due', 'even', 'no', 'become', 'several', 'please', 'beforehand', 'least', 'nobody', 'could', 'both', 'mostly', 'may', 'latterly', 'own', 'because', 'that', 'thereupon', 'anyhow', 'hereupon', 'off', 'less', 'only', 'it', 'whole', 'than', 'seemed', 'more', 'whence', 'hundred', 'must', 'my', 'since', 'i', 'can', 'except', 'other', 'side', 'bill', 'after', 'our', 'were', 'meanwhile', 'herself', 'in', 'two', 'ltd', 'whereby', 'put', 'bottom', 'afterwards', 'his', 'its', 'everyone', 'one', 'everything', 'find', 'anyone', 'beside', 'though', 'he', 'from', 'she', 'are', 'former', 'or', 'otherwise', 'someone', 'top', 'me', 'of', 'therefore', 'whereupon', 'am', 'the', 'nine', 'ours', 'found', 'co', 'some', 'yourselves', 'have', 'once', 'describe', 'over', 'themselves', 'mine', 'detail', 'itself', 'per', 'they', 'latter', 'whither', 'forty', 'somewhere', 'fifteen', 'beyond', 'being', 'whether', 'cannot', 'is', 'nor', 'thin', 'became', 'onto', 'go', 'whenever', 'thereafter', 'seeming', 'without', 'formerly', 'sometimes', 'seems', 'last', 'much', 'fifty', 'which', 'serious', 'while', 'herein', 'ie', 'moreover', 'part', 'where', 'him', 'ten', 'four', 'elsewhere', 'below', 'same', 'about', 'anywhere', 'her', 'also', 'becoming', 'wherein'})</code></pre>
</div>
<div id="combined-nltk-and-sklearn-stop-words" class="section level3" number="17.5.4">
<h3>
<span class="header-section-number">17.5.4</span> Combined NLTK and SKLearn Stop Words<a class="anchor" aria-label="anchor" href="#combined-nltk-and-sklearn-stop-words"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb1799"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1799-1"><a href="nlp.html#cb1799-1" aria-hidden="true" tabindex="-1"></a>combined_stop_words <span class="op">=</span> <span class="bu">list</span>( <span class="bu">set</span>(nltk_stop_words) <span class="op">|</span> <span class="bu">set</span>(sklearn_stop_words) )</span>
<span id="cb1799-2"><a href="nlp.html#cb1799-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Total combined NLTK and SKLearn Stopwords:'</span>, <span class="bu">len</span>( combined_stop_words ),<span class="st">'</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb1799-3"><a href="nlp.html#cb1799-3" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Stopwords shared among NLTK and SKlearn  :'</span>, <span class="bu">len</span>( <span class="bu">list</span>( <span class="bu">set</span>(nltk_stop_words) <span class="op">&amp;</span> <span class="bu">set</span>(sklearn_stop_words)) ))</span></code></pre></div>
<pre><code>#:&gt; Total combined NLTK and SKLearn Stopwords: 378 
#:&gt; Stopwords shared among NLTK and SKlearn  : 119</code></pre>
</div>
</div>
<div id="normalizing" class="section level2" number="17.6">
<h2>
<span class="header-section-number">17.6</span> Normalizing<a class="anchor" aria-label="anchor" href="#normalizing"><i class="fas fa-link"></i></a>
</h2>
<p>Similar things are combined into single normalized form. This will reduced the vocabulary.</p>
<div id="case-folding" class="section level3" number="17.6.1">
<h3>
<span class="header-section-number">17.6.1</span> Case Folding<a class="anchor" aria-label="anchor" href="#case-folding"><i class="fas fa-link"></i></a>
</h3>
<p>If tokens aren’t cap normalized, you will end up with large word list.
However, some information is often communicated by capitalization of word, such as name of places. If names are important, consider using proper noun.</p>
<div class="sourceCode" id="cb1801"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1801-1"><a href="nlp.html#cb1801-1" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> [<span class="st">'House'</span>,<span class="st">'Visitor'</span>,<span class="st">'Center'</span>]</span>
<span id="cb1801-2"><a href="nlp.html#cb1801-2" aria-hidden="true" tabindex="-1"></a>[ x.lower() <span class="cf">for</span> x <span class="kw">in</span> tokens]</span></code></pre></div>
<pre><code>#:&gt; ['house', 'visitor', 'center']</code></pre>
</div>
<div id="stemming" class="section level3" number="17.6.2">
<h3>
<span class="header-section-number">17.6.2</span> Stemming<a class="anchor" aria-label="anchor" href="#stemming"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Output of a stemmer is <strong>not necessary a proper word</strong>
</li>
<li>Automatically convert words to <strong>lower cap</strong>
</li>
<li>
<strong>Porter stemmer</strong> is a lifetime refinement with 300 lines of python code<br>
</li>
<li>Stemming is faster then Lemmatization</li>
</ul>
<div class="sourceCode" id="cb1803"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1803-1"><a href="nlp.html#cb1803-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem.porter <span class="im">import</span> PorterStemmer</span>
<span id="cb1803-2"><a href="nlp.html#cb1803-2" aria-hidden="true" tabindex="-1"></a>stemmer <span class="op">=</span> PorterStemmer()</span>
<span id="cb1803-3"><a href="nlp.html#cb1803-3" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> (<span class="st">'house'</span>,<span class="st">'Housing'</span>,<span class="st">'hOuses'</span>, <span class="st">'Malicious'</span>,<span class="st">'goodness'</span>)</span>
<span id="cb1803-4"><a href="nlp.html#cb1803-4" aria-hidden="true" tabindex="-1"></a>[stemmer.stem(x) <span class="cf">for</span> x <span class="kw">in</span> tokens ]</span></code></pre></div>
<pre><code>#:&gt; ['hous', 'hous', 'hous', 'malici', 'good']</code></pre>
</div>
<div id="lemmatization" class="section level3" number="17.6.3">
<h3>
<span class="header-section-number">17.6.3</span> Lemmatization<a class="anchor" aria-label="anchor" href="#lemmatization"><i class="fas fa-link"></i></a>
</h3>
<p>NLTK uses connections within <strong>princeton WordNet</strong> graph for word meanings.</p>
<div class="sourceCode" id="cb1805"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1805-1"><a href="nlp.html#cb1805-1" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'wordnet'</span>)</span></code></pre></div>
<pre><code>#:&gt; True
#:&gt; 
#:&gt; [nltk_data] Downloading package wordnet to /home/msfz751/nltk_data...
#:&gt; [nltk_data]   Package wordnet is already up-to-date!</code></pre>
<div class="sourceCode" id="cb1807"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1807-1"><a href="nlp.html#cb1807-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb1807-2"><a href="nlp.html#cb1807-2" aria-hidden="true" tabindex="-1"></a>lemmatizer <span class="op">=</span> WordNetLemmatizer()</span>
<span id="cb1807-3"><a href="nlp.html#cb1807-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1807-4"><a href="nlp.html#cb1807-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( lemmatizer.lemmatize(<span class="st">"better"</span>, pos <span class="op">=</span><span class="st">'a'</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1807-5"><a href="nlp.html#cb1807-5" aria-hidden="true" tabindex="-1"></a>       lemmatizer.lemmatize(<span class="st">"better"</span>, pos <span class="op">=</span><span class="st">'n'</span>) )</span></code></pre></div>
<pre><code>#:&gt; good 
#:&gt;  better</code></pre>
<div class="sourceCode" id="cb1809"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1809-1"><a href="nlp.html#cb1809-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( lemmatizer.lemmatize(<span class="st">"good"</span>, pos <span class="op">=</span><span class="st">'a'</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1809-2"><a href="nlp.html#cb1809-2" aria-hidden="true" tabindex="-1"></a>       lemmatizer.lemmatize(<span class="st">"good"</span>, pos <span class="op">=</span><span class="st">'n'</span>) )</span></code></pre></div>
<pre><code>#:&gt; good 
#:&gt;  good</code></pre>
</div>
<div id="comparing-stemming-and-lemmatization" class="section level3" number="17.6.4">
<h3>
<span class="header-section-number">17.6.4</span> Comparing Stemming and Lemmatization<a class="anchor" aria-label="anchor" href="#comparing-stemming-and-lemmatization"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Lemmatization is slower than stemming
= Lemmatization is better at retaining meanings</li>
<li>Lemmatization produce valid english word</li>
<li>Stemming not necessary produce valid english word</li>
<li>Both reduce vocabulary size, but increase ambiguity</li>
<li>For search engine application, stemming and lemmatization will improve recall as it associate more documents with the same query words, however with the cost of reducing precision and accuracy.</li>
</ul>
<p>For search-based chatbot where accuracy is more important, it should first search with unnormalzied words.</p>
</div>
</div>
<div id="wordnet" class="section level2" number="17.7">
<h2>
<span class="header-section-number">17.7</span> Wordnet<a class="anchor" aria-label="anchor" href="#wordnet"><i class="fas fa-link"></i></a>
</h2>
<p>WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations.</p>
<p>WordNet superficially resembles a thesaurus, in that it groups words together based on their meanings. However, there are some important distinctions:<br>
- WordNet interlinks not just word forms—strings of letters—but specific senses of words. As a result, words that are found in close proximity to one another in the network are semantically disambiguated<br>
- WordNet labels the semantic relations among words, whereas the groupings of words in a thesaurus does not follow any explicit pattern other than meaning similarity</p>
<p><a href="https://wordnet.princeton.edu">Wordnet Princeton</a></p>
<p><a href="http://wordnetweb.princeton.edu/perl/webwn">Wordnet Online Browser</a></p>
<div id="nltk-and-wordnet" class="section level3" number="17.7.1">
<h3>
<span class="header-section-number">17.7.1</span> NLTK and Wordnet<a class="anchor" aria-label="anchor" href="#nltk-and-wordnet"><i class="fas fa-link"></i></a>
</h3>
<p>NLTK (version 3.7.6) includes the English WordNet (147,307 words and 117,659 synonym sets)</p>
<div class="sourceCode" id="cb1811"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1811-1"><a href="nlp.html#cb1811-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet <span class="im">as</span> wn</span>
<span id="cb1811-2"><a href="nlp.html#cb1811-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1811-3"><a href="nlp.html#cb1811-3" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="bu">set</span>( wn.all_synsets() )</span>
<span id="cb1811-4"><a href="nlp.html#cb1811-4" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="bu">set</span>(wn.words())</span>
<span id="cb1811-5"><a href="nlp.html#cb1811-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Total words in wordnet  : '</span> ,   <span class="bu">len</span>(w),</span>
<span id="cb1811-6"><a href="nlp.html#cb1811-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">'</span><span class="ch">\n</span><span class="st">Total synsets in wordnet: '</span> , <span class="bu">len</span>(s) )</span></code></pre></div>
<pre><code>#:&gt; Total words in wordnet  :  147306 
#:&gt; Total synsets in wordnet:  117659</code></pre>
</div>
<div id="synset" class="section level3" number="17.7.2">
<h3>
<span class="header-section-number">17.7.2</span> Synset<a class="anchor" aria-label="anchor" href="#synset"><i class="fas fa-link"></i></a>
</h3>
<div id="notation" class="section level4" number="17.7.2.1">
<h4>
<span class="header-section-number">17.7.2.1</span> Notation<a class="anchor" aria-label="anchor" href="#notation"><i class="fas fa-link"></i></a>
</h4>
<p>A synset is the basic construct of a word in wordnet. It contains the <strong>Word</strong> itself, with its <strong>POS</strong> tag and <strong>Usage</strong>: <strong><code>word.pos.nn</code></strong></p>
<div class="sourceCode" id="cb1813"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1813-1"><a href="nlp.html#cb1813-1" aria-hidden="true" tabindex="-1"></a>wn.synset(<span class="st">'breakdown.n.03'</span>)</span></code></pre></div>
<pre><code>#:&gt; Synset('breakdown.n.03')</code></pre>
<p>Breaking down the construct:</p>
<pre><code>'breakdown' = Word
'n'         = Part of Speech
'03'        = Usage (01 for most common usage and a higher number would indicate lesser common usages)</code></pre>
</div>
<div id="part-of-speech" class="section level4" number="17.7.2.2">
<h4>
<span class="header-section-number">17.7.2.2</span> Part of Speech<a class="anchor" aria-label="anchor" href="#part-of-speech"><i class="fas fa-link"></i></a>
</h4>
<p>Wordnet support five POS tags</p>
<pre><code>n - NOUN
v - VERB
a - ADJECTIVE
s - ADJECTIVE SATELLITE
r - ADVERB</code></pre>
<div class="sourceCode" id="cb1817"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1817-1"><a href="nlp.html#cb1817-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(wn.ADJ, wn.ADJ_SAT, wn.ADV, wn.NOUN, wn.VERB)</span></code></pre></div>
<pre><code>#:&gt; a s r n v</code></pre>
</div>
<div id="synset-similarity" class="section level4" number="17.7.2.3">
<h4>
<span class="header-section-number">17.7.2.3</span> Synset Similarity<a class="anchor" aria-label="anchor" href="#synset-similarity"><i class="fas fa-link"></i></a>
</h4>
<p>Let’s see how similar are the below two nouns</p>
<div class="sourceCode" id="cb1819"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1819-1"><a href="nlp.html#cb1819-1" aria-hidden="true" tabindex="-1"></a>w1 <span class="op">=</span> wn.synset(<span class="st">'dog.n.01'</span>)</span>
<span id="cb1819-2"><a href="nlp.html#cb1819-2" aria-hidden="true" tabindex="-1"></a>w2 <span class="op">=</span> wn.synset(<span class="st">'ship.n.01'</span>)</span>
<span id="cb1819-3"><a href="nlp.html#cb1819-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(w1.wup_similarity(w2))</span></code></pre></div>
<pre><code>#:&gt; 0.4</code></pre>
<div class="sourceCode" id="cb1821"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1821-1"><a href="nlp.html#cb1821-1" aria-hidden="true" tabindex="-1"></a>w1 <span class="op">=</span> wn.synset(<span class="st">'ship.n.01'</span>)</span>
<span id="cb1821-2"><a href="nlp.html#cb1821-2" aria-hidden="true" tabindex="-1"></a>w2 <span class="op">=</span> wn.synset(<span class="st">'boat.n.01'</span>)</span>
<span id="cb1821-3"><a href="nlp.html#cb1821-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(w1.wup_similarity(w2))</span></code></pre></div>
<pre><code>#:&gt; 0.9090909090909091</code></pre>
</div>
</div>
<div id="synsets" class="section level3" number="17.7.3">
<h3>
<span class="header-section-number">17.7.3</span> Synsets<a class="anchor" aria-label="anchor" href="#synsets"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Synsets is a collection of synsets, which are synonyms that share a common meaning<br>
</li>
<li>A synset (member of Synsets) is identified with a 3-part name of the form:</li>
<li>A synset can contain one or more lemmas, which represent a specific sense of a specific word<br>
</li>
<li>A synset can contain one or more <strong>Hyponyms and Hypernyms</strong>. These are specific and generalized concepts respectively. For example, ‘beach house’ and ‘guest house’ are hyponyms of ‘house.’ They are more specific concepts of ‘house.’ And ‘house’ is a hypernym of ‘guest house’ because it is the general concept<br>
</li>
<li>
<strong>Hyponyms and Hypernyms</strong> are also called lexical relations</li>
</ul>
<div class="sourceCode" id="cb1823"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1823-1"><a href="nlp.html#cb1823-1" aria-hidden="true" tabindex="-1"></a>dogs <span class="op">=</span> wn.synsets(<span class="st">'dog'</span>) <span class="co"># get all synsets for word 'dog'</span></span>
<span id="cb1823-2"><a href="nlp.html#cb1823-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1823-3"><a href="nlp.html#cb1823-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> dogs:  <span class="co">## iterate through each Synset</span></span>
<span id="cb1823-4"><a href="nlp.html#cb1823-4" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(d,<span class="st">':</span><span class="ch">\n</span><span class="st">Definition:'</span>, d.definition(),</span>
<span id="cb1823-5"><a href="nlp.html#cb1823-5" aria-hidden="true" tabindex="-1"></a>           <span class="st">'</span><span class="ch">\n</span><span class="st">Example:'</span>,    d.examples(),</span>
<span id="cb1823-6"><a href="nlp.html#cb1823-6" aria-hidden="true" tabindex="-1"></a>           <span class="st">'</span><span class="ch">\n</span><span class="st">Lemmas:'</span>,     d.lemma_names(),</span>
<span id="cb1823-7"><a href="nlp.html#cb1823-7" aria-hidden="true" tabindex="-1"></a>           <span class="st">'</span><span class="ch">\n</span><span class="st">Hyponyms:'</span>,   d.hyponyms(), </span>
<span id="cb1823-8"><a href="nlp.html#cb1823-8" aria-hidden="true" tabindex="-1"></a>           <span class="st">'</span><span class="ch">\n</span><span class="st">Hypernyms:'</span>,  d.hypernyms(), <span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>)</span></code></pre></div>
<pre><code>#:&gt; Synset('dog.n.01') :
#:&gt; Definition: a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds 
#:&gt; Example: ['the dog barked all night'] 
#:&gt; Lemmas: ['dog', 'domestic_dog', 'Canis_familiaris'] 
#:&gt; Hyponyms: [Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')] 
#:&gt; Hypernyms: [Synset('canine.n.02'), Synset('domestic_animal.n.01')] 
#:&gt; 
#:&gt; 
#:&gt; Synset('frump.n.01') :
#:&gt; Definition: a dull unattractive unpleasant girl or woman 
#:&gt; Example: ['she got a reputation as a frump', "she's a real dog"] 
#:&gt; Lemmas: ['frump', 'dog'] 
#:&gt; Hyponyms: [] 
#:&gt; Hypernyms: [Synset('unpleasant_woman.n.01')] 
#:&gt; 
#:&gt; 
#:&gt; Synset('dog.n.03') :
#:&gt; Definition: informal term for a man 
#:&gt; Example: ['you lucky dog'] 
#:&gt; Lemmas: ['dog'] 
#:&gt; Hyponyms: [] 
#:&gt; Hypernyms: [Synset('chap.n.01')] 
#:&gt; 
#:&gt; 
#:&gt; Synset('cad.n.01') :
#:&gt; Definition: someone who is morally reprehensible 
#:&gt; Example: ['you dirty dog'] 
#:&gt; Lemmas: ['cad', 'bounder', 'blackguard', 'dog', 'hound', 'heel'] 
#:&gt; Hyponyms: [Synset('perisher.n.01')] 
#:&gt; Hypernyms: [Synset('villain.n.01')] 
#:&gt; 
#:&gt; 
#:&gt; Synset('frank.n.02') :
#:&gt; Definition: a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll 
#:&gt; Example: [] 
#:&gt; Lemmas: ['frank', 'frankfurter', 'hotdog', 'hot_dog', 'dog', 'wiener', 'wienerwurst', 'weenie'] 
#:&gt; Hyponyms: [Synset('vienna_sausage.n.01')] 
#:&gt; Hypernyms: [Synset('sausage.n.01')] 
#:&gt; 
#:&gt; 
#:&gt; Synset('pawl.n.01') :
#:&gt; Definition: a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward 
#:&gt; Example: [] 
#:&gt; Lemmas: ['pawl', 'detent', 'click', 'dog'] 
#:&gt; Hyponyms: [] 
#:&gt; Hypernyms: [Synset('catch.n.06')] 
#:&gt; 
#:&gt; 
#:&gt; Synset('andiron.n.01') :
#:&gt; Definition: metal supports for logs in a fireplace 
#:&gt; Example: ['the andirons were too hot to touch'] 
#:&gt; Lemmas: ['andiron', 'firedog', 'dog', 'dog-iron'] 
#:&gt; Hyponyms: [] 
#:&gt; Hypernyms: [Synset('support.n.10')] 
#:&gt; 
#:&gt; 
#:&gt; Synset('chase.v.01') :
#:&gt; Definition: go after with the intent to catch 
#:&gt; Example: ['The policeman chased the mugger down the alley', 'the dog chased the rabbit'] 
#:&gt; Lemmas: ['chase', 'chase_after', 'trail', 'tail', 'tag', 'give_chase', 'dog', 'go_after', 'track'] 
#:&gt; Hyponyms: [Synset('hound.v.01'), Synset('quest.v.02'), Synset('run_down.v.07'), Synset('tree.v.03')] 
#:&gt; Hypernyms: [Synset('pursue.v.02')]</code></pre>
</div>
</div>
<div id="part-of-speech-pos" class="section level2" number="17.8">
<h2>
<span class="header-section-number">17.8</span> Part Of Speech (POS)<a class="anchor" aria-label="anchor" href="#part-of-speech-pos"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called <strong>grammatical tagging</strong> or <strong>word-category disambiguation</strong>, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context—i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph<br>
</li>
<li>This is useful for Information Retrieval, Text to Speech, Word Sense Disambiguation<br>
</li>
<li>The primary target of Part-of-Speech(POS) tagging is to identify the grammatical group of a given word. Whether it is a NOUN, PRONOUN, ADJECTIVE, VERB, ADVERBS, etc. based on the context<br>
</li>
<li>A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc</li>
</ul>
<div id="tag-sets" class="section level3" number="17.8.1">
<h3>
<span class="header-section-number">17.8.1</span> Tag Sets<a class="anchor" aria-label="anchor" href="#tag-sets"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Schools commonly teach that there are 9 parts of speech in English: noun, verb, article, adjective, preposition, pronoun, adverb, conjunction, and interjection<br>
</li>
<li>However, there are clearly many more categories and sub-categories</li>
</ul>
<div class="sourceCode" id="cb1825"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1825-1"><a href="nlp.html#cb1825-1" aria-hidden="true" tabindex="-1"></a> nltk.download(<span class="st">'universal_tagset'</span>)</span></code></pre></div>
<div id="universal-tagset" class="section level4" number="17.8.1.1">
<h4>
<span class="header-section-number">17.8.1.1</span> Universal Tagset<a class="anchor" aria-label="anchor" href="#universal-tagset"><i class="fas fa-link"></i></a>
</h4>
<p>This tagset contains <strong>12</strong> coarse tags</p>
<pre><code>VERB - verbs (all tenses and modes)
NOUN - nouns (common and proper)
PRON - pronouns
ADJ - adjectives
ADV - adverbs
ADP - adpositions (prepositions and postpositions)
CONJ - conjunctions
DET - determiners
NUM - cardinal numbers
PRT - particles or other function words
X - other: foreign words, typos, abbreviations
. - punctuation</code></pre>
</div>
<div id="penn-treebank-tagset" class="section level4" number="17.8.1.2">
<h4>
<span class="header-section-number">17.8.1.2</span> Penn Treebank Tagset<a class="anchor" aria-label="anchor" href="#penn-treebank-tagset"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>This is the most popular “tag set” for American English, developed in the Penn Treebank project<br>
</li>
<li>It has <strong>36 POS tags plus 12</strong> others for punctuations and special symbols</li>
</ul>
<p><a href="https://www.sketchengine.eu/penn-treebank-tagset/">PENN POS Tagset</a></p>
<div class="sourceCode" id="cb1827"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1827-1"><a href="nlp.html#cb1827-1" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'tagsets'</span>)</span></code></pre></div>
<pre><code>#:&gt; True
#:&gt; 
#:&gt; [nltk_data] Downloading package tagsets to /home/msfz751/nltk_data...
#:&gt; [nltk_data]   Package tagsets is already up-to-date!</code></pre>
<div class="sourceCode" id="cb1829"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1829-1"><a href="nlp.html#cb1829-1" aria-hidden="true" tabindex="-1"></a>nltk.<span class="bu">help</span>.upenn_tagset()</span></code></pre></div>
<pre><code>#:&gt; $: dollar
#:&gt;     $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$
#:&gt; '': closing quotation mark
#:&gt;     ' ''
#:&gt; (: opening parenthesis
#:&gt;     ( [ {
#:&gt; ): closing parenthesis
#:&gt;     ) ] }
#:&gt; ,: comma
#:&gt;     ,
#:&gt; --: dash
#:&gt;     --
#:&gt; .: sentence terminator
#:&gt;     . ! ?
#:&gt; :: colon or ellipsis
#:&gt;     : ; ...
#:&gt; CC: conjunction, coordinating
#:&gt;     &amp; 'n and both but either et for less minus neither nor or plus so
#:&gt;     therefore times v. versus vs. whether yet
#:&gt; CD: numeral, cardinal
#:&gt;     mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-
#:&gt;     seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025
#:&gt;     fifteen 271,124 dozen quintillion DM2,000 ...
#:&gt; DT: determiner
#:&gt;     all an another any both del each either every half la many much nary
#:&gt;     neither no some such that the them these this those
#:&gt; EX: existential there
#:&gt;     there
#:&gt; FW: foreign word
#:&gt;     gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous
#:&gt;     lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte
#:&gt;     terram fiche oui corporis ...
#:&gt; IN: preposition or conjunction, subordinating
#:&gt;     astride among uppon whether out inside pro despite on by throughout
#:&gt;     below within for towards near behind atop around if like until below
#:&gt;     next into if beside ...
#:&gt; JJ: adjective or numeral, ordinal
#:&gt;     third ill-mannered pre-war regrettable oiled calamitous first separable
#:&gt;     ectoplasmic battery-powered participatory fourth still-to-be-named
#:&gt;     multilingual multi-disciplinary ...
#:&gt; JJR: adjective, comparative
#:&gt;     bleaker braver breezier briefer brighter brisker broader bumper busier
#:&gt;     calmer cheaper choosier cleaner clearer closer colder commoner costlier
#:&gt;     cozier creamier crunchier cuter ...
#:&gt; JJS: adjective, superlative
#:&gt;     calmest cheapest choicest classiest cleanest clearest closest commonest
#:&gt;     corniest costliest crassest creepiest crudest cutest darkest deadliest
#:&gt;     dearest deepest densest dinkiest ...
#:&gt; LS: list item marker
#:&gt;     A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005
#:&gt;     SP-44007 Second Third Three Two * a b c d first five four one six three
#:&gt;     two
#:&gt; MD: modal auxiliary
#:&gt;     can cannot could couldn't dare may might must need ought shall should
#:&gt;     shouldn't will would
#:&gt; NN: noun, common, singular or mass
#:&gt;     common-carrier cabbage knuckle-duster Casino afghan shed thermostat
#:&gt;     investment slide humour falloff slick wind hyena override subhumanity
#:&gt;     machinist ...
#:&gt; NNP: noun, proper, singular
#:&gt;     Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos
#:&gt;     Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA
#:&gt;     Shannon A.K.C. Meltex Liverpool ...
#:&gt; NNPS: noun, proper, plural
#:&gt;     Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists
#:&gt;     Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques
#:&gt;     Apache Apaches Apocrypha ...
#:&gt; NNS: noun, common, plural
#:&gt;     undergraduates scotches bric-a-brac products bodyguards facets coasts
#:&gt;     divestitures storehouses designs clubs fragrances averages
#:&gt;     subjectivists apprehensions muses factory-jobs ...
#:&gt; PDT: pre-determiner
#:&gt;     all both half many quite such sure this
#:&gt; POS: genitive marker
#:&gt;     ' 's
#:&gt; PRP: pronoun, personal
#:&gt;     hers herself him himself hisself it itself me myself one oneself ours
#:&gt;     ourselves ownself self she thee theirs them themselves they thou thy us
#:&gt; PRP$: pronoun, possessive
#:&gt;     her his mine my our ours their thy your
#:&gt; RB: adverb
#:&gt;     occasionally unabatingly maddeningly adventurously professedly
#:&gt;     stirringly prominently technologically magisterially predominately
#:&gt;     swiftly fiscally pitilessly ...
#:&gt; RBR: adverb, comparative
#:&gt;     further gloomier grander graver greater grimmer harder harsher
#:&gt;     healthier heavier higher however larger later leaner lengthier less-
#:&gt;     perfectly lesser lonelier longer louder lower more ...
#:&gt; RBS: adverb, superlative
#:&gt;     best biggest bluntest earliest farthest first furthest hardest
#:&gt;     heartiest highest largest least less most nearest second tightest worst
#:&gt; RP: particle
#:&gt;     aboard about across along apart around aside at away back before behind
#:&gt;     by crop down ever fast for forth from go high i.e. in into just later
#:&gt;     low more off on open out over per pie raising start teeth that through
#:&gt;     under unto up up-pp upon whole with you
#:&gt; SYM: symbol
#:&gt;     % &amp; ' '' ''. ) ). * + ,. &lt; = &gt; @ A[fj] U.S U.S.S.R * ** ***
#:&gt; TO: "to" as preposition or infinitive marker
#:&gt;     to
#:&gt; UH: interjection
#:&gt;     Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen
#:&gt;     huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly
#:&gt;     man baby diddle hush sonuvabitch ...
#:&gt; VB: verb, base form
#:&gt;     ask assemble assess assign assume atone attention avoid bake balkanize
#:&gt;     bank begin behold believe bend benefit bevel beware bless boil bomb
#:&gt;     boost brace break bring broil brush build ...
#:&gt; VBD: verb, past tense
#:&gt;     dipped pleaded swiped regummed soaked tidied convened halted registered
#:&gt;     cushioned exacted snubbed strode aimed adopted belied figgered
#:&gt;     speculated wore appreciated contemplated ...
#:&gt; VBG: verb, present participle or gerund
#:&gt;     telegraphing stirring focusing angering judging stalling lactating
#:&gt;     hankerin' alleging veering capping approaching traveling besieging
#:&gt;     encrypting interrupting erasing wincing ...
#:&gt; VBN: verb, past participle
#:&gt;     multihulled dilapidated aerosolized chaired languished panelized used
#:&gt;     experimented flourished imitated reunifed factored condensed sheared
#:&gt;     unsettled primed dubbed desired ...
#:&gt; VBP: verb, present tense, not 3rd person singular
#:&gt;     predominate wrap resort sue twist spill cure lengthen brush terminate
#:&gt;     appear tend stray glisten obtain comprise detest tease attract
#:&gt;     emphasize mold postpone sever return wag ...
#:&gt; VBZ: verb, present tense, 3rd person singular
#:&gt;     bases reconstructs marks mixes displeases seals carps weaves snatches
#:&gt;     slumps stretches authorizes smolders pictures emerges stockpiles
#:&gt;     seduces fizzes uses bolsters slaps speaks pleads ...
#:&gt; WDT: WH-determiner
#:&gt;     that what whatever which whichever
#:&gt; WP: WH-pronoun
#:&gt;     that what whatever whatsoever which who whom whosoever
#:&gt; WP$: WH-pronoun, possessive
#:&gt;     whose
#:&gt; WRB: Wh-adverb
#:&gt;     how however whence whenever where whereby whereever wherein whereof why
#:&gt; ``: opening quotation mark
#:&gt;     ` ``</code></pre>
</div>
<div id="claws5-tagset" class="section level4" number="17.8.1.3">
<h4>
<span class="header-section-number">17.8.1.3</span> Claws5 Tagset<a class="anchor" aria-label="anchor" href="#claws5-tagset"><i class="fas fa-link"></i></a>
</h4>
<p><a href="https://www.sketchengine.eu/english-claws5-part-of-speech-tagset/">Claws5 POS Tagset</a></p>
<div class="sourceCode" id="cb1831"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1831-1"><a href="nlp.html#cb1831-1" aria-hidden="true" tabindex="-1"></a>nltk.<span class="bu">help</span>.claws5_tagset()</span></code></pre></div>
<pre><code>#:&gt; AJ0: adjective (unmarked)
#:&gt;     good, old
#:&gt; AJC: comparative adjective
#:&gt;     better, older
#:&gt; AJS: superlative adjective
#:&gt;     best, oldest
#:&gt; AT0: article
#:&gt;     THE, A, AN
#:&gt; AV0: adverb (unmarked)
#:&gt;     often, well, longer, furthest
#:&gt; AVP: adverb particle
#:&gt;     up, off, out
#:&gt; AVQ: wh-adverb
#:&gt;     when, how, why
#:&gt; CJC: coordinating conjunction
#:&gt;     and, or
#:&gt; CJS: subordinating conjunction
#:&gt;     although, when
#:&gt; CJT: the conjunction THAT
#:&gt;     that
#:&gt; CRD: cardinal numeral
#:&gt;     3, fifty-five, 6609 (excl one)
#:&gt; DPS: possessive determiner form
#:&gt;     your, their
#:&gt; DT0: general determiner
#:&gt;     these, some
#:&gt; DTQ: wh-determiner
#:&gt;     whose, which
#:&gt; EX0: existential THERE
#:&gt;     there
#:&gt; ITJ: interjection or other isolate
#:&gt;     oh, yes, mhm
#:&gt; NN0: noun (neutral for number)
#:&gt;     aircraft, data
#:&gt; NN1: singular noun
#:&gt;     pencil, goose
#:&gt; NN2: plural noun
#:&gt;     pencils, geese
#:&gt; NP0: proper noun
#:&gt;     London, Michael, Mars
#:&gt; NULL: the null tag (for items not to be tagged)
#:&gt; ORD: ordinal
#:&gt;     sixth, 77th, last
#:&gt; PNI: indefinite pronoun
#:&gt;     none, everything
#:&gt; PNP: personal pronoun
#:&gt;     you, them, ours
#:&gt; PNQ: wh-pronoun
#:&gt;     who, whoever
#:&gt; PNX: reflexive pronoun
#:&gt;     itself, ourselves
#:&gt; POS: the possessive (or genitive morpheme)
#:&gt;     's or '
#:&gt; PRF: the preposition OF
#:&gt;     of
#:&gt; PRP: preposition (except for OF)
#:&gt;     for, above, to
#:&gt; PUL: punctuation
#:&gt;     left bracket - ( or [ )
#:&gt; PUN: punctuation
#:&gt;     general mark - . ! , : ; - ? ...
#:&gt; PUQ: punctuation
#:&gt;     quotation mark - ` ' "
#:&gt; PUR: punctuation
#:&gt;     right bracket - ) or ]
#:&gt; TO0: infinitive marker TO
#:&gt;     to
#:&gt; UNC: "unclassified" items which are not words of the English lexicon
#:&gt; VBB: the "base forms" of the verb "BE" (except the infinitive)
#:&gt;     am, are
#:&gt; VBD: past form of the verb "BE"
#:&gt;     was, were
#:&gt; VBG: -ing form of the verb "BE"
#:&gt;     being
#:&gt; VBI: infinitive of the verb "BE"
#:&gt;     be
#:&gt; VBN: past participle of the verb "BE"
#:&gt;     been
#:&gt; VBZ: -s form of the verb "BE"
#:&gt;     is, 's
#:&gt; VDB: base form of the verb "DO" (except the infinitive)
#:&gt;     do
#:&gt; VDD: past form of the verb "DO"
#:&gt;     did
#:&gt; VDG: -ing form of the verb "DO"
#:&gt;     doing
#:&gt; VDI: infinitive of the verb "DO"
#:&gt;     do
#:&gt; VDN: past participle of the verb "DO"
#:&gt;     done
#:&gt; VDZ: -s form of the verb "DO"
#:&gt;     does
#:&gt; VHB: base form of the verb "HAVE" (except the infinitive)
#:&gt;     have
#:&gt; VHD: past tense form of the verb "HAVE"
#:&gt;     had, 'd
#:&gt; VHG: -ing form of the verb "HAVE"
#:&gt;     having
#:&gt; VHI: infinitive of the verb "HAVE"
#:&gt;     have
#:&gt; VHN: past participle of the verb "HAVE"
#:&gt;     had
#:&gt; VHZ: -s form of the verb "HAVE"
#:&gt;     has, 's
#:&gt; VM0: modal auxiliary verb
#:&gt;     can, could, will, 'll
#:&gt; VVB: base form of lexical verb (except the infinitive)
#:&gt;     take, live
#:&gt; VVD: past tense form of lexical verb
#:&gt;     took, lived
#:&gt; VVG: -ing form of lexical verb
#:&gt;     taking, living
#:&gt; VVI: infinitive of lexical verb
#:&gt;     take, live
#:&gt; VVN: past participle form of lex. verb
#:&gt;     taken, lived
#:&gt; VVZ: -s form of lexical verb
#:&gt;     takes, lives
#:&gt; XX0: the negative NOT or N'T
#:&gt;     not
#:&gt; ZZ0: alphabetical symbol
#:&gt;     A, B, c, d</code></pre>
</div>
<div id="brown-tagset" class="section level4" number="17.8.1.4">
<h4>
<span class="header-section-number">17.8.1.4</span> Brown Tagset<a class="anchor" aria-label="anchor" href="#brown-tagset"><i class="fas fa-link"></i></a>
</h4>
<p><a href="https://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used">Brown POS Tagset</a></p>
<div class="sourceCode" id="cb1833"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1833-1"><a href="nlp.html#cb1833-1" aria-hidden="true" tabindex="-1"></a>nltk.<span class="bu">help</span>.brown_tagset()</span></code></pre></div>
<pre><code>#:&gt; (: opening parenthesis
#:&gt;     (
#:&gt; ): closing parenthesis
#:&gt;     )
#:&gt; *: negator
#:&gt;     not n't
#:&gt; ,: comma
#:&gt;     ,
#:&gt; --: dash
#:&gt;     --
#:&gt; .: sentence terminator
#:&gt;     . ? ; ! :
#:&gt; :: colon
#:&gt;     :
#:&gt; ABL: determiner/pronoun, pre-qualifier
#:&gt;     quite such rather
#:&gt; ABN: determiner/pronoun, pre-quantifier
#:&gt;     all half many nary
#:&gt; ABX: determiner/pronoun, double conjunction or pre-quantifier
#:&gt;     both
#:&gt; AP: determiner/pronoun, post-determiner
#:&gt;     many other next more last former little several enough most least only
#:&gt;     very few fewer past same Last latter less single plenty 'nough lesser
#:&gt;     certain various manye next-to-last particular final previous present
#:&gt;     nuf
#:&gt; AP$: determiner/pronoun, post-determiner, genitive
#:&gt;     other's
#:&gt; AP+AP: determiner/pronoun, post-determiner, hyphenated pair
#:&gt;     many-much
#:&gt; AT: article
#:&gt;     the an no a every th' ever' ye
#:&gt; BE: verb 'to be', infinitive or imperative
#:&gt;     be
#:&gt; BED: verb 'to be', past tense, 2nd person singular or all persons plural
#:&gt;     were
#:&gt; BED*: verb 'to be', past tense, 2nd person singular or all persons plural, negated
#:&gt;     weren't
#:&gt; BEDZ: verb 'to be', past tense, 1st and 3rd person singular
#:&gt;     was
#:&gt; BEDZ*: verb 'to be', past tense, 1st and 3rd person singular, negated
#:&gt;     wasn't
#:&gt; BEG: verb 'to be', present participle or gerund
#:&gt;     being
#:&gt; BEM: verb 'to be', present tense, 1st person singular
#:&gt;     am
#:&gt; BEM*: verb 'to be', present tense, 1st person singular, negated
#:&gt;     ain't
#:&gt; BEN: verb 'to be', past participle
#:&gt;     been
#:&gt; BER: verb 'to be', present tense, 2nd person singular or all persons plural
#:&gt;     are art
#:&gt; BER*: verb 'to be', present tense, 2nd person singular or all persons plural, negated
#:&gt;     aren't ain't
#:&gt; BEZ: verb 'to be', present tense, 3rd person singular
#:&gt;     is
#:&gt; BEZ*: verb 'to be', present tense, 3rd person singular, negated
#:&gt;     isn't ain't
#:&gt; CC: conjunction, coordinating
#:&gt;     and or but plus &amp; either neither nor yet 'n' and/or minus an'
#:&gt; CD: numeral, cardinal
#:&gt;     two one 1 four 2 1913 71 74 637 1937 8 five three million 87-31 29-5
#:&gt;     seven 1,119 fifty-three 7.5 billion hundred 125,000 1,700 60 100 six
#:&gt;     ...
#:&gt; CD$: numeral, cardinal, genitive
#:&gt;     1960's 1961's .404's
#:&gt; CS: conjunction, subordinating
#:&gt;     that as after whether before while like because if since for than altho
#:&gt;     until so unless though providing once lest s'posin' till whereas
#:&gt;     whereupon supposing tho' albeit then so's 'fore
#:&gt; DO: verb 'to do', uninflected present tense, infinitive or imperative
#:&gt;     do dost
#:&gt; DO*: verb 'to do', uninflected present tense or imperative, negated
#:&gt;     don't
#:&gt; DO+PPSS: verb 'to do', past or present tense + pronoun, personal, nominative, not 3rd person singular
#:&gt;     d'you
#:&gt; DOD: verb 'to do', past tense
#:&gt;     did done
#:&gt; DOD*: verb 'to do', past tense, negated
#:&gt;     didn't
#:&gt; DOZ: verb 'to do', present tense, 3rd person singular
#:&gt;     does
#:&gt; DOZ*: verb 'to do', present tense, 3rd person singular, negated
#:&gt;     doesn't don't
#:&gt; DT: determiner/pronoun, singular
#:&gt;     this each another that 'nother
#:&gt; DT$: determiner/pronoun, singular, genitive
#:&gt;     another's
#:&gt; DT+BEZ: determiner/pronoun + verb 'to be', present tense, 3rd person singular
#:&gt;     that's
#:&gt; DT+MD: determiner/pronoun + modal auxillary
#:&gt;     that'll this'll
#:&gt; DTI: determiner/pronoun, singular or plural
#:&gt;     any some
#:&gt; DTS: determiner/pronoun, plural
#:&gt;     these those them
#:&gt; DTS+BEZ: pronoun, plural + verb 'to be', present tense, 3rd person singular
#:&gt;     them's
#:&gt; DTX: determiner, pronoun or double conjunction
#:&gt;     neither either one
#:&gt; EX: existential there
#:&gt;     there
#:&gt; EX+BEZ: existential there + verb 'to be', present tense, 3rd person singular
#:&gt;     there's
#:&gt; EX+HVD: existential there + verb 'to have', past tense
#:&gt;     there'd
#:&gt; EX+HVZ: existential there + verb 'to have', present tense, 3rd person singular
#:&gt;     there's
#:&gt; EX+MD: existential there + modal auxillary
#:&gt;     there'll there'd
#:&gt; FW-*: foreign word: negator
#:&gt;     pas non ne
#:&gt; FW-AT: foreign word: article
#:&gt;     la le el un die der ein keine eine das las les Il
#:&gt; FW-AT+NN: foreign word: article + noun, singular, common
#:&gt;     l'orchestre l'identite l'arcade l'ange l'assistance l'activite
#:&gt;     L'Universite l'independance L'Union L'Unita l'osservatore
#:&gt; FW-AT+NP: foreign word: article + noun, singular, proper
#:&gt;     L'Astree L'Imperiale
#:&gt; FW-BE: foreign word: verb 'to be', infinitive or imperative
#:&gt;     sit
#:&gt; FW-BER: foreign word: verb 'to be', present tense, 2nd person singular or all persons plural
#:&gt;     sind sunt etes
#:&gt; FW-BEZ: foreign word: verb 'to be', present tense, 3rd person singular
#:&gt;     ist est
#:&gt; FW-CC: foreign word: conjunction, coordinating
#:&gt;     et ma mais und aber och nec y
#:&gt; FW-CD: foreign word: numeral, cardinal
#:&gt;     une cinq deux sieben unam zwei
#:&gt; FW-CS: foreign word: conjunction, subordinating
#:&gt;     bevor quam ma
#:&gt; FW-DT: foreign word: determiner/pronoun, singular
#:&gt;     hoc
#:&gt; FW-DT+BEZ: foreign word: determiner + verb 'to be', present tense, 3rd person singular
#:&gt;     c'est
#:&gt; FW-DTS: foreign word: determiner/pronoun, plural
#:&gt;     haec
#:&gt; FW-HV: foreign word: verb 'to have', present tense, not 3rd person singular
#:&gt;     habe
#:&gt; FW-IN: foreign word: preposition
#:&gt;     ad de en a par con dans ex von auf super post sine sur sub avec per
#:&gt;     inter sans pour pendant in di
#:&gt; FW-IN+AT: foreign word: preposition + article
#:&gt;     della des du aux zur d'un del dell'
#:&gt; FW-IN+NN: foreign word: preposition + noun, singular, common
#:&gt;     d'etat d'hotel d'argent d'identite d'art
#:&gt; FW-IN+NP: foreign word: preposition + noun, singular, proper
#:&gt;     d'Yquem d'Eiffel
#:&gt; FW-JJ: foreign word: adjective
#:&gt;     avant Espagnol sinfonica Siciliana Philharmonique grand publique haute
#:&gt;     noire bouffe Douce meme humaine bel serieuses royaux anticus presto
#:&gt;     Sovietskaya Bayerische comique schwarzen ...
#:&gt; FW-JJR: foreign word: adjective, comparative
#:&gt;     fortiori
#:&gt; FW-JJT: foreign word: adjective, superlative
#:&gt;     optimo
#:&gt; FW-NN: foreign word: noun, singular, common
#:&gt;     ballet esprit ersatz mano chatte goutte sang Fledermaus oud def kolkhoz
#:&gt;     roi troika canto boite blutwurst carne muzyka bonheur monde piece force
#:&gt;     ...
#:&gt; FW-NN$: foreign word: noun, singular, common, genitive
#:&gt;     corporis intellectus arte's dei aeternitatis senioritatis curiae
#:&gt;     patronne's chambre's
#:&gt; FW-NNS: foreign word: noun, plural, common
#:&gt;     al culpas vopos boites haflis kolkhozes augen tyrannis alpha-beta-
#:&gt;     gammas metis banditos rata phis negociants crus Einsatzkommandos
#:&gt;     kamikaze wohaws sabinas zorrillas palazzi engages coureurs corroborees
#:&gt;     yori Ubermenschen ...
#:&gt; FW-NP: foreign word: noun, singular, proper
#:&gt;     Karshilama Dieu Rundfunk Afrique Espanol Afrika Spagna Gott Carthago
#:&gt;     deus
#:&gt; FW-NPS: foreign word: noun, plural, proper
#:&gt;     Svenskarna Atlantes Dieux
#:&gt; FW-NR: foreign word: noun, singular, adverbial
#:&gt;     heute morgen aujourd'hui hoy
#:&gt; FW-OD: foreign word: numeral, ordinal
#:&gt;     18e 17e quintus
#:&gt; FW-PN: foreign word: pronoun, nominal
#:&gt;     hoc
#:&gt; FW-PP$: foreign word: determiner, possessive
#:&gt;     mea mon deras vos
#:&gt; FW-PPL: foreign word: pronoun, singular, reflexive
#:&gt;     se
#:&gt; FW-PPL+VBZ: foreign word: pronoun, singular, reflexive + verb, present tense, 3rd person singular
#:&gt;     s'excuse s'accuse
#:&gt; FW-PPO: pronoun, personal, accusative
#:&gt;     lui me moi mi
#:&gt; FW-PPO+IN: foreign word: pronoun, personal, accusative + preposition
#:&gt;     mecum tecum
#:&gt; FW-PPS: foreign word: pronoun, personal, nominative, 3rd person singular
#:&gt;     il
#:&gt; FW-PPSS: foreign word: pronoun, personal, nominative, not 3rd person singular
#:&gt;     ich vous sie je
#:&gt; FW-PPSS+HV: foreign word: pronoun, personal, nominative, not 3rd person singular + verb 'to have', present tense, not 3rd person singular
#:&gt;     j'ai
#:&gt; FW-QL: foreign word: qualifier
#:&gt;     minus
#:&gt; FW-RB: foreign word: adverb
#:&gt;     bas assai deja um wiederum cito velociter vielleicht simpliciter non zu
#:&gt;     domi nuper sic forsan olim oui semper tout despues hors
#:&gt; FW-RB+CC: foreign word: adverb + conjunction, coordinating
#:&gt;     forisque
#:&gt; FW-TO+VB: foreign word: infinitival to + verb, infinitive
#:&gt;     d'entretenir
#:&gt; FW-UH: foreign word: interjection
#:&gt;     sayonara bien adieu arigato bonjour adios bueno tchalo ciao o
#:&gt; FW-VB: foreign word: verb, present tense, not 3rd person singular, imperative or infinitive
#:&gt;     nolo contendere vive fermate faciunt esse vade noli tangere dites duces
#:&gt;     meminisse iuvabit gosaimasu voulez habla ksu'u'peli'afo lacheln miuchi
#:&gt;     say allons strafe portant
#:&gt; FW-VBD: foreign word: verb, past tense
#:&gt;     stabat peccavi audivi
#:&gt; FW-VBG: foreign word: verb, present participle or gerund
#:&gt;     nolens volens appellant seq. obliterans servanda dicendi delenda
#:&gt; FW-VBN: foreign word: verb, past participle
#:&gt;     vue verstrichen rasa verboten engages
#:&gt; FW-VBZ: foreign word: verb, present tense, 3rd person singular
#:&gt;     gouverne sinkt sigue diapiace
#:&gt; FW-WDT: foreign word: WH-determiner
#:&gt;     quo qua quod que quok
#:&gt; FW-WPO: foreign word: WH-pronoun, accusative
#:&gt;     quibusdam
#:&gt; FW-WPS: foreign word: WH-pronoun, nominative
#:&gt;     qui
#:&gt; HV: verb 'to have', uninflected present tense, infinitive or imperative
#:&gt;     have hast
#:&gt; HV*: verb 'to have', uninflected present tense or imperative, negated
#:&gt;     haven't ain't
#:&gt; HV+TO: verb 'to have', uninflected present tense + infinitival to
#:&gt;     hafta
#:&gt; HVD: verb 'to have', past tense
#:&gt;     had
#:&gt; HVD*: verb 'to have', past tense, negated
#:&gt;     hadn't
#:&gt; HVG: verb 'to have', present participle or gerund
#:&gt;     having
#:&gt; HVN: verb 'to have', past participle
#:&gt;     had
#:&gt; HVZ: verb 'to have', present tense, 3rd person singular
#:&gt;     has hath
#:&gt; HVZ*: verb 'to have', present tense, 3rd person singular, negated
#:&gt;     hasn't ain't
#:&gt; IN: preposition
#:&gt;     of in for by considering to on among at through with under into
#:&gt;     regarding than since despite according per before toward against as
#:&gt;     after during including between without except upon out over ...
#:&gt; IN+IN: preposition, hyphenated pair
#:&gt;     f'ovuh
#:&gt; IN+PPO: preposition + pronoun, personal, accusative
#:&gt;     t'hi-im
#:&gt; JJ: adjective
#:&gt;     ecent over-all possible hard-fought favorable hard meager fit such
#:&gt;     widespread outmoded inadequate ambiguous grand clerical effective
#:&gt;     orderly federal foster general proportionate ...
#:&gt; JJ$: adjective, genitive
#:&gt;     Great's
#:&gt; JJ+JJ: adjective, hyphenated pair
#:&gt;     big-large long-far
#:&gt; JJR: adjective, comparative
#:&gt;     greater older further earlier later freer franker wider better deeper
#:&gt;     firmer tougher faster higher bigger worse younger lighter nicer slower
#:&gt;     happier frothier Greater newer Elder ...
#:&gt; JJR+CS: adjective + conjunction, coordinating
#:&gt;     lighter'n
#:&gt; JJS: adjective, semantically superlative
#:&gt;     top chief principal northernmost master key head main tops utmost
#:&gt;     innermost foremost uppermost paramount topmost
#:&gt; JJT: adjective, superlative
#:&gt;     best largest coolest calmest latest greatest earliest simplest
#:&gt;     strongest newest fiercest unhappiest worst youngest worthiest fastest
#:&gt;     hottest fittest lowest finest smallest staunchest ...
#:&gt; MD: modal auxillary
#:&gt;     should may might will would must can could shall ought need wilt
#:&gt; MD*: modal auxillary, negated
#:&gt;     cannot couldn't wouldn't can't won't shouldn't shan't mustn't musn't
#:&gt; MD+HV: modal auxillary + verb 'to have', uninflected form
#:&gt;     shouldda musta coulda must've woulda could've
#:&gt; MD+PPSS: modal auxillary + pronoun, personal, nominative, not 3rd person singular
#:&gt;     willya
#:&gt; MD+TO: modal auxillary + infinitival to
#:&gt;     oughta
#:&gt; NN: noun, singular, common
#:&gt;     failure burden court fire appointment awarding compensation Mayor
#:&gt;     interim committee fact effect airport management surveillance jail
#:&gt;     doctor intern extern night weekend duty legislation Tax Office ...
#:&gt; NN$: noun, singular, common, genitive
#:&gt;     season's world's player's night's chapter's golf's football's
#:&gt;     baseball's club's U.'s coach's bride's bridegroom's board's county's
#:&gt;     firm's company's superintendent's mob's Navy's ...
#:&gt; NN+BEZ: noun, singular, common + verb 'to be', present tense, 3rd person singular
#:&gt;     water's camera's sky's kid's Pa's heat's throat's father's money's
#:&gt;     undersecretary's granite's level's wife's fat's Knife's fire's name's
#:&gt;     hell's leg's sun's roulette's cane's guy's kind's baseball's ...
#:&gt; NN+HVD: noun, singular, common + verb 'to have', past tense
#:&gt;     Pa'd
#:&gt; NN+HVZ: noun, singular, common + verb 'to have', present tense, 3rd person singular
#:&gt;     guy's Knife's boat's summer's rain's company's
#:&gt; NN+IN: noun, singular, common + preposition
#:&gt;     buncha
#:&gt; NN+MD: noun, singular, common + modal auxillary
#:&gt;     cowhand'd sun'll
#:&gt; NN+NN: noun, singular, common, hyphenated pair
#:&gt;     stomach-belly
#:&gt; NNS: noun, plural, common
#:&gt;     irregularities presentments thanks reports voters laws legislators
#:&gt;     years areas adjustments chambers $100 bonds courts sales details raises
#:&gt;     sessions members congressmen votes polls calls ...
#:&gt; NNS$: noun, plural, common, genitive
#:&gt;     taxpayers' children's members' States' women's cutters' motorists'
#:&gt;     steelmakers' hours' Nations' lawyers' prisoners' architects' tourists'
#:&gt;     Employers' secretaries' Rogues' ...
#:&gt; NNS+MD: noun, plural, common + modal auxillary
#:&gt;     duds'd oystchers'll
#:&gt; NP: noun, singular, proper
#:&gt;     Fulton Atlanta September-October Durwood Pye Ivan Allen Jr. Jan.
#:&gt;     Alpharetta Grady William B. Hartsfield Pearl Williams Aug. Berry J. M.
#:&gt;     Cheshire Griffin Opelika Ala. E. Pelham Snodgrass ...
#:&gt; NP$: noun, singular, proper, genitive
#:&gt;     Green's Landis' Smith's Carreon's Allison's Boston's Spahn's Willie's
#:&gt;     Mickey's Milwaukee's Mays' Howsam's Mantle's Shaw's Wagner's Rickey's
#:&gt;     Shea's Palmer's Arnold's Broglio's ...
#:&gt; NP+BEZ: noun, singular, proper + verb 'to be', present tense, 3rd person singular
#:&gt;     W.'s Ike's Mack's Jack's Kate's Katharine's Black's Arthur's Seaton's
#:&gt;     Buckhorn's Breed's Penny's Rob's Kitty's Blackwell's Myra's Wally's
#:&gt;     Lucille's Springfield's Arlene's
#:&gt; NP+HVZ: noun, singular, proper + verb 'to have', present tense, 3rd person singular
#:&gt;     Bill's Guardino's Celie's Skolman's Crosson's Tim's Wally's
#:&gt; NP+MD: noun, singular, proper + modal auxillary
#:&gt;     Gyp'll John'll
#:&gt; NPS: noun, plural, proper
#:&gt;     Chases Aderholds Chapelles Armisteads Lockies Carbones French Marskmen
#:&gt;     Toppers Franciscans Romans Cadillacs Masons Blacks Catholics British
#:&gt;     Dixiecrats Mississippians Congresses ...
#:&gt; NPS$: noun, plural, proper, genitive
#:&gt;     Republicans' Orioles' Birds' Yanks' Redbirds' Bucs' Yankees' Stevenses'
#:&gt;     Geraghtys' Burkes' Wackers' Achaeans' Dresbachs' Russians' Democrats'
#:&gt;     Gershwins' Adventists' Negroes' Catholics' ...
#:&gt; NR: noun, singular, adverbial
#:&gt;     Friday home Wednesday Tuesday Monday Sunday Thursday yesterday tomorrow
#:&gt;     tonight West East Saturday west left east downtown north northeast
#:&gt;     southeast northwest North South right ...
#:&gt; NR$: noun, singular, adverbial, genitive
#:&gt;     Saturday's Monday's yesterday's tonight's tomorrow's Sunday's
#:&gt;     Wednesday's Friday's today's Tuesday's West's Today's South's
#:&gt; NR+MD: noun, singular, adverbial + modal auxillary
#:&gt;     today'll
#:&gt; NRS: noun, plural, adverbial
#:&gt;     Sundays Mondays Saturdays Wednesdays Souths Fridays
#:&gt; OD: numeral, ordinal
#:&gt;     first 13th third nineteenth 2d 61st second sixth eighth ninth twenty-
#:&gt;     first eleventh 50th eighteenth- Thirty-ninth 72nd 1/20th twentieth
#:&gt;     mid-19th thousandth 350th sixteenth 701st ...
#:&gt; PN: pronoun, nominal
#:&gt;     none something everything one anyone nothing nobody everybody everyone
#:&gt;     anybody anything someone no-one nothin
#:&gt; PN$: pronoun, nominal, genitive
#:&gt;     one's someone's anybody's nobody's everybody's anyone's everyone's
#:&gt; PN+BEZ: pronoun, nominal + verb 'to be', present tense, 3rd person singular
#:&gt;     nothing's everything's somebody's nobody's someone's
#:&gt; PN+HVD: pronoun, nominal + verb 'to have', past tense
#:&gt;     nobody'd
#:&gt; PN+HVZ: pronoun, nominal + verb 'to have', present tense, 3rd person singular
#:&gt;     nobody's somebody's one's
#:&gt; PN+MD: pronoun, nominal + modal auxillary
#:&gt;     someone'll somebody'll anybody'd
#:&gt; PP$: determiner, possessive
#:&gt;     our its his their my your her out thy mine thine
#:&gt; PP$$: pronoun, possessive
#:&gt;     ours mine his hers theirs yours
#:&gt; PPL: pronoun, singular, reflexive
#:&gt;     itself himself myself yourself herself oneself ownself
#:&gt; PPLS: pronoun, plural, reflexive
#:&gt;     themselves ourselves yourselves
#:&gt; PPO: pronoun, personal, accusative
#:&gt;     them it him me us you 'em her thee we'uns
#:&gt; PPS: pronoun, personal, nominative, 3rd person singular
#:&gt;     it he she thee
#:&gt; PPS+BEZ: pronoun, personal, nominative, 3rd person singular + verb 'to be', present tense, 3rd person singular
#:&gt;     it's he's she's
#:&gt; PPS+HVD: pronoun, personal, nominative, 3rd person singular + verb 'to have', past tense
#:&gt;     she'd he'd it'd
#:&gt; PPS+HVZ: pronoun, personal, nominative, 3rd person singular + verb 'to have', present tense, 3rd person singular
#:&gt;     it's he's she's
#:&gt; PPS+MD: pronoun, personal, nominative, 3rd person singular + modal auxillary
#:&gt;     he'll she'll it'll he'd it'd she'd
#:&gt; PPSS: pronoun, personal, nominative, not 3rd person singular
#:&gt;     they we I you ye thou you'uns
#:&gt; PPSS+BEM: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 1st person singular
#:&gt;     I'm Ahm
#:&gt; PPSS+BER: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 2nd person singular or all persons plural
#:&gt;     we're you're they're
#:&gt; PPSS+BEZ: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular
#:&gt;     you's
#:&gt; PPSS+BEZ*: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular, negated
#:&gt;     'tain't
#:&gt; PPSS+HV: pronoun, personal, nominative, not 3rd person singular + verb 'to have', uninflected present tense
#:&gt;     I've we've they've you've
#:&gt; PPSS+HVD: pronoun, personal, nominative, not 3rd person singular + verb 'to have', past tense
#:&gt;     I'd you'd we'd they'd
#:&gt; PPSS+MD: pronoun, personal, nominative, not 3rd person singular + modal auxillary
#:&gt;     you'll we'll I'll we'd I'd they'll they'd you'd
#:&gt; PPSS+VB: pronoun, personal, nominative, not 3rd person singular + verb 'to verb', uninflected present tense
#:&gt;     y'know
#:&gt; QL: qualifier, pre
#:&gt;     well less very most so real as highly fundamentally even how much
#:&gt;     remarkably somewhat more completely too thus ill deeply little overly
#:&gt;     halfway almost impossibly far severly such ...
#:&gt; QLP: qualifier, post
#:&gt;     indeed enough still 'nuff
#:&gt; RB: adverb
#:&gt;     only often generally also nevertheless upon together back newly no
#:&gt;     likely meanwhile near then heavily there apparently yet outright fully
#:&gt;     aside consistently specifically formally ever just ...
#:&gt; RB$: adverb, genitive
#:&gt;     else's
#:&gt; RB+BEZ: adverb + verb 'to be', present tense, 3rd person singular
#:&gt;     here's there's
#:&gt; RB+CS: adverb + conjunction, coordinating
#:&gt;     well's soon's
#:&gt; RBR: adverb, comparative
#:&gt;     further earlier better later higher tougher more harder longer sooner
#:&gt;     less faster easier louder farther oftener nearer cheaper slower tighter
#:&gt;     lower worse heavier quicker ...
#:&gt; RBR+CS: adverb, comparative + conjunction, coordinating
#:&gt;     more'n
#:&gt; RBT: adverb, superlative
#:&gt;     most best highest uppermost nearest brightest hardest fastest deepest
#:&gt;     farthest loudest ...
#:&gt; RN: adverb, nominal
#:&gt;     here afar then
#:&gt; RP: adverb, particle
#:&gt;     up out off down over on in about through across after
#:&gt; RP+IN: adverb, particle + preposition
#:&gt;     out'n outta
#:&gt; TO: infinitival to
#:&gt;     to t'
#:&gt; TO+VB: infinitival to + verb, infinitive
#:&gt;     t'jawn t'lah
#:&gt; UH: interjection
#:&gt;     Hurrah bang whee hmpf ah goodbye oops oh-the-pain-of-it ha crunch say
#:&gt;     oh why see well hello lo alas tarantara rum-tum-tum gosh hell keerist
#:&gt;     Jesus Keeeerist boy c'mon 'mon goddamn bah hoo-pig damn ...
#:&gt; VB: verb, base: uninflected present, imperative or infinitive
#:&gt;     investigate find act follow inure achieve reduce take remedy re-set
#:&gt;     distribute realize disable feel receive continue place protect
#:&gt;     eliminate elaborate work permit run enter force ...
#:&gt; VB+AT: verb, base: uninflected present or infinitive + article
#:&gt;     wanna
#:&gt; VB+IN: verb, base: uninflected present, imperative or infinitive + preposition
#:&gt;     lookit
#:&gt; VB+JJ: verb, base: uninflected present, imperative or infinitive + adjective
#:&gt;     die-dead
#:&gt; VB+PPO: verb, uninflected present tense + pronoun, personal, accusative
#:&gt;     let's lemme gimme
#:&gt; VB+RP: verb, imperative + adverbial particle
#:&gt;     g'ahn c'mon
#:&gt; VB+TO: verb, base: uninflected present, imperative or infinitive + infinitival to
#:&gt;     wanta wanna
#:&gt; VB+VB: verb, base: uninflected present, imperative or infinitive; hypenated pair
#:&gt;     say-speak
#:&gt; VBD: verb, past tense
#:&gt;     said produced took recommended commented urged found added praised
#:&gt;     charged listed became announced brought attended wanted voted defeated
#:&gt;     received got stood shot scheduled feared promised made ...
#:&gt; VBG: verb, present participle or gerund
#:&gt;     modernizing improving purchasing Purchasing lacking enabling pricing
#:&gt;     keeping getting picking entering voting warning making strengthening
#:&gt;     setting neighboring attending participating moving ...
#:&gt; VBG+TO: verb, present participle + infinitival to
#:&gt;     gonna
#:&gt; VBN: verb, past participle
#:&gt;     conducted charged won received studied revised operated accepted
#:&gt;     combined experienced recommended effected granted seen protected
#:&gt;     adopted retarded notarized selected composed gotten printed ...
#:&gt; VBN+TO: verb, past participle + infinitival to
#:&gt;     gotta
#:&gt; VBZ: verb, present tense, 3rd person singular
#:&gt;     deserves believes receives takes goes expires says opposes starts
#:&gt;     permits expects thinks faces votes teaches holds calls fears spends
#:&gt;     collects backs eliminates sets flies gives seeks reads ...
#:&gt; WDT: WH-determiner
#:&gt;     which what whatever whichever whichever-the-hell
#:&gt; WDT+BER: WH-determiner + verb 'to be', present tense, 2nd person singular or all persons plural
#:&gt;     what're
#:&gt; WDT+BER+PP: WH-determiner + verb 'to be', present, 2nd person singular or all persons plural + pronoun, personal, nominative, not 3rd person singular
#:&gt;     whaddya
#:&gt; WDT+BEZ: WH-determiner + verb 'to be', present tense, 3rd person singular
#:&gt;     what's
#:&gt; WDT+DO+PPS: WH-determiner + verb 'to do', uninflected present tense + pronoun, personal, nominative, not 3rd person singular
#:&gt;     whaddya
#:&gt; WDT+DOD: WH-determiner + verb 'to do', past tense
#:&gt;     what'd
#:&gt; WDT+HVZ: WH-determiner + verb 'to have', present tense, 3rd person singular
#:&gt;     what's
#:&gt; WP$: WH-pronoun, genitive
#:&gt;     whose whosever
#:&gt; WPO: WH-pronoun, accusative
#:&gt;     whom that who
#:&gt; WPS: WH-pronoun, nominative
#:&gt;     that who whoever whosoever what whatsoever
#:&gt; WPS+BEZ: WH-pronoun, nominative + verb 'to be', present, 3rd person singular
#:&gt;     that's who's
#:&gt; WPS+HVD: WH-pronoun, nominative + verb 'to have', past tense
#:&gt;     who'd
#:&gt; WPS+HVZ: WH-pronoun, nominative + verb 'to have', present tense, 3rd person singular
#:&gt;     who's that's
#:&gt; WPS+MD: WH-pronoun, nominative + modal auxillary
#:&gt;     who'll that'd who'd that'll
#:&gt; WQL: WH-qualifier
#:&gt;     however how
#:&gt; WRB: WH-adverb
#:&gt;     however when where why whereby wherever how whenever whereon wherein
#:&gt;     wherewith wheare wherefore whereof howsabout
#:&gt; WRB+BER: WH-adverb + verb 'to be', present, 2nd person singular or all persons plural
#:&gt;     where're
#:&gt; WRB+BEZ: WH-adverb + verb 'to be', present, 3rd person singular
#:&gt;     how's where's
#:&gt; WRB+DO: WH-adverb + verb 'to do', present, not 3rd person singular
#:&gt;     howda
#:&gt; WRB+DOD: WH-adverb + verb 'to do', past tense
#:&gt;     where'd how'd
#:&gt; WRB+DOD*: WH-adverb + verb 'to do', past tense, negated
#:&gt;     whyn't
#:&gt; WRB+DOZ: WH-adverb + verb 'to do', present tense, 3rd person singular
#:&gt;     how's
#:&gt; WRB+IN: WH-adverb + preposition
#:&gt;     why'n
#:&gt; WRB+MD: WH-adverb + modal auxillary
#:&gt;     where'd</code></pre>
</div>
</div>
<div id="tagging-techniques" class="section level3" number="17.8.2">
<h3>
<span class="header-section-number">17.8.2</span> Tagging Techniques<a class="anchor" aria-label="anchor" href="#tagging-techniques"><i class="fas fa-link"></i></a>
</h3>
<p>There are few types of tagging techniques:</p>
<ul>
<li>Lexical-based<br>
</li>
<li>Rule-based (Brill)</li>
<li>Probalistic/Stochastic-based (Conditional Random Fields-CRFs, Hidden Markov Models-HMM)</li>
<li>Neural network-based</li>
</ul>
<p>NLTK supports the below taggers:</p>
<pre><code>from nltk.tag.brill      import BrillTagger
from nltk.tag.hunpos     import HunposTagger
from nltk.tag.stanford   import StanfordTagger, StanfordPOSTagger, StanfordNERTagger
from nltk.tag.hmm        import HiddenMarkovModelTagger, HiddenMarkovModelTrainer
from nltk.tag.senna      import SennaTagger, SennaChunkTagger, SennaNERTagger
from nltk.tag.crf        import CRFTagger
from nltk.tag.perceptron import PerceptronTagger</code></pre>
<div id="nltk-perceptrontagger" class="section level4" number="17.8.2.1">
<h4>
<span class="header-section-number">17.8.2.1</span> nltk <code>PerceptronTagger</code><a class="anchor" aria-label="anchor" href="#nltk-perceptrontagger"><i class="fas fa-link"></i></a>
</h4>
<p>PerceptronTagger produce tags with <strong>Penn Treebank</strong> tagset</p>
<div class="sourceCode" id="cb1836"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1836-1"><a href="nlp.html#cb1836-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tag <span class="im">import</span> PerceptronTagger</span>
<span id="cb1836-2"><a href="nlp.html#cb1836-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1836-3"><a href="nlp.html#cb1836-3" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'averaged_perceptron_tagger'</span>)</span></code></pre></div>
<pre><code>#:&gt; True
#:&gt; 
#:&gt; [nltk_data] Downloading package averaged_perceptron_tagger to
#:&gt; [nltk_data]     /home/msfz751/nltk_data...
#:&gt; [nltk_data]   Package averaged_perceptron_tagger is already up-to-
#:&gt; [nltk_data]       date!</code></pre>
<div class="sourceCode" id="cb1838"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1838-1"><a href="nlp.html#cb1838-1" aria-hidden="true" tabindex="-1"></a>tagger <span class="op">=</span> PerceptronTagger()</span>
<span id="cb1838-2"><a href="nlp.html#cb1838-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Tagger Classes:'</span>, tagger.classes, </span>
<span id="cb1838-3"><a href="nlp.html#cb1838-3" aria-hidden="true" tabindex="-1"></a>      <span class="st">'</span><span class="ch">\n\n</span><span class="st"># Classes:'</span>, <span class="bu">len</span>(tagger.classes))</span></code></pre></div>
<pre><code>#:&gt; Tagger Classes: {'PRP', '(', 'PRP$', 'JJR', 'JJ', 'FW', ':', 'RBS', 'VB', 'RBR', '#', 'CD', ',', 'RB', '``', 'NNPS', ')', 'NN', 'WP', '.', 'TO', 'NNP', 'CC', 'PDT', "''", 'WP$', 'SYM', 'WDT', 'LS', 'IN', 'VBD', 'POS', 'JJS', 'VBP', 'UH', '$', 'DT', 'MD', 'WRB', 'VBG', 'RP', 'VBZ', 'NNS', 'VBN', 'EX'} 
#:&gt; 
#:&gt; # Classes: 45</code></pre>
</div>
</div>
<div id="performing-tagging-nltk.pos_tag" class="section level3" number="17.8.3">
<h3>
<span class="header-section-number">17.8.3</span> Performing Tagging <code>nltk.pos_tag()</code><a class="anchor" aria-label="anchor" href="#performing-tagging-nltk.pos_tag"><i class="fas fa-link"></i></a>
</h3>
<p>Tagging works sentence by sentence:</p>
<ul>
<li>Document fist must be splitted into sentences<br>
</li>
<li>Each sentence need to be tokenized into words<br>
</li>
<li>Default NTLK uses <code>PerceptronTagger</code>
</li>
</ul>
<div class="sourceCode" id="cb1840"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1840-1"><a href="nlp.html#cb1840-1" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('averaged_perceptron_tagger')</span></span>
<span id="cb1840-2"><a href="nlp.html#cb1840-2" aria-hidden="true" tabindex="-1"></a><span class="co">#import nltk</span></span>
<span id="cb1840-3"><a href="nlp.html#cb1840-3" aria-hidden="true" tabindex="-1"></a><span class="co">#from nltk.tokenize import word_tokenize, sent_tokenize </span></span>
<span id="cb1840-4"><a href="nlp.html#cb1840-4" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> <span class="st">'''Sukanya, Rajib and Naba are my good friends. Sukanya is getting married next year. Marriage is a big step in one's life. It is both exciting and frightening. But friendship is a sacred bond between people. It is a special kind of love between us. Many of you must have tried searching for a friend but never found the right one.'''</span></span>
<span id="cb1840-5"><a href="nlp.html#cb1840-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1840-6"><a href="nlp.html#cb1840-6" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> nltk.sent_tokenize(doc)</span>
<span id="cb1840-7"><a href="nlp.html#cb1840-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> sentence <span class="kw">in</span> sentences:</span>
<span id="cb1840-8"><a href="nlp.html#cb1840-8" aria-hidden="true" tabindex="-1"></a>  tokens <span class="op">=</span> nltk.word_tokenize(sentence)</span>
<span id="cb1840-9"><a href="nlp.html#cb1840-9" aria-hidden="true" tabindex="-1"></a>  tagged <span class="op">=</span> nltk.pos_tag(tokens)</span>
<span id="cb1840-10"><a href="nlp.html#cb1840-10" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(tagged)</span></code></pre></div>
<pre><code>#:&gt; [('Sukanya', 'NNP'), (',', ','), ('Rajib', 'NNP'), ('and', 'CC'), ('Naba', 'NNP'), ('are', 'VBP'), ('my', 'PRP$'), ('good', 'JJ'), ('friends', 'NNS'), ('.', '.')]
#:&gt; [('Sukanya', 'NNP'), ('is', 'VBZ'), ('getting', 'VBG'), ('married', 'VBN'), ('next', 'JJ'), ('year', 'NN'), ('.', '.')]
#:&gt; [('Marriage', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('big', 'JJ'), ('step', 'NN'), ('in', 'IN'), ('one', 'CD'), ("'s", 'POS'), ('life', 'NN'), ('.', '.')]
#:&gt; [('It', 'PRP'), ('is', 'VBZ'), ('both', 'DT'), ('exciting', 'VBG'), ('and', 'CC'), ('frightening', 'NN'), ('.', '.')]
#:&gt; [('But', 'CC'), ('friendship', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('sacred', 'JJ'), ('bond', 'NN'), ('between', 'IN'), ('people', 'NNS'), ('.', '.')]
#:&gt; [('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('special', 'JJ'), ('kind', 'NN'), ('of', 'IN'), ('love', 'NN'), ('between', 'IN'), ('us', 'PRP'), ('.', '.')]
#:&gt; [('Many', 'JJ'), ('of', 'IN'), ('you', 'PRP'), ('must', 'MD'), ('have', 'VB'), ('tried', 'VBN'), ('searching', 'VBG'), ('for', 'IN'), ('a', 'DT'), ('friend', 'NN'), ('but', 'CC'), ('never', 'RB'), ('found', 'VBD'), ('the', 'DT'), ('right', 'JJ'), ('one', 'NN'), ('.', '.')]</code></pre>
</div>
</div>
<div id="sentiment" class="section level2" number="17.9">
<h2>
<span class="header-section-number">17.9</span> Sentiment<a class="anchor" aria-label="anchor" href="#sentiment"><i class="fas fa-link"></i></a>
</h2>
<div id="nltk-and-senti-wordnet" class="section level3" number="17.9.1">
<h3>
<span class="header-section-number">17.9.1</span> NLTK and Senti-Wordnet<a class="anchor" aria-label="anchor" href="#nltk-and-senti-wordnet"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>SentiWordNet <strong>extends Wordnet Synsets</strong> with positive and negative sentiment scores<br>
</li>
<li>The extension was achieved via a complex mix of propagation methods and classifiers. It is thus not a gold standard resource like WordNet (which was compiled by humans), but it has proven useful in a wide range of tasks<br>
</li>
<li>It contains similar number of synsets as wordnet</li>
</ul>
<div class="sourceCode" id="cb1842"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1842-1"><a href="nlp.html#cb1842-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> sentiwordnet <span class="im">as</span> swn</span>
<span id="cb1842-2"><a href="nlp.html#cb1842-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'sentiwordnet'</span>)</span></code></pre></div>
<pre><code>#:&gt; True
#:&gt; 
#:&gt; [nltk_data] Downloading package sentiwordnet to
#:&gt; [nltk_data]     /home/msfz751/nltk_data...
#:&gt; [nltk_data]   Package sentiwordnet is already up-to-date!</code></pre>
<div class="sourceCode" id="cb1844"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1844-1"><a href="nlp.html#cb1844-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="bu">set</span>( swn.all_senti_synsets() )</span>
<span id="cb1844-2"><a href="nlp.html#cb1844-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Total synsets in senti-wordnet  : '</span> ,   <span class="bu">len</span>(s))</span></code></pre></div>
<pre><code>#:&gt; Total synsets in senti-wordnet  :  117659</code></pre>
<div id="senti-synset" class="section level4" number="17.9.1.1">
<h4>
<span class="header-section-number">17.9.1.1</span> Senti-Synset<a class="anchor" aria-label="anchor" href="#senti-synset"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>Senti-Wordnet extends wordnet with three(3) sentiment scores: positive, negative, objective<br>
</li>
<li>All three scores added up to value 1.0</li>
</ul>
<div class="sourceCode" id="cb1846"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1846-1"><a href="nlp.html#cb1846-1" aria-hidden="true" tabindex="-1"></a>breakdown <span class="op">=</span> swn.senti_synset(<span class="st">'breakdown.n.03'</span>)</span>
<span id="cb1846-2"><a href="nlp.html#cb1846-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1846-3"><a href="nlp.html#cb1846-3" aria-hidden="true" tabindex="-1"></a>  breakdown, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb1846-4"><a href="nlp.html#cb1846-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Positive:'</span>, breakdown.pos_score(), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1846-5"><a href="nlp.html#cb1846-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Negative:'</span>, breakdown.neg_score(), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1846-6"><a href="nlp.html#cb1846-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Objective:'</span>,breakdown.obj_score()</span>
<span id="cb1846-7"><a href="nlp.html#cb1846-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>#:&gt; &lt;breakdown.n.03: PosScore=0.0 NegScore=0.25&gt; 
#:&gt; Positive: 0.0 
#:&gt;  Negative: 0.25 
#:&gt;  Objective: 0.75</code></pre>
</div>
<div id="senti-synsets" class="section level4" number="17.9.1.2">
<h4>
<span class="header-section-number">17.9.1.2</span> Senti-Synsets<a class="anchor" aria-label="anchor" href="#senti-synsets"><i class="fas fa-link"></i></a>
</h4>
<p>Get all the synonmys, with and without the POS information</p>
<div class="sourceCode" id="cb1848"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1848-1"><a href="nlp.html#cb1848-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="bu">list</span>(swn.senti_synsets(<span class="st">'slow'</span>)), <span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>,  <span class="co">## without POS tag</span></span>
<span id="cb1848-2"><a href="nlp.html#cb1848-2" aria-hidden="true" tabindex="-1"></a>       <span class="bu">list</span>(swn.senti_synsets(<span class="st">'slow'</span>, <span class="st">'a'</span>)) )   <span class="co">## with POS tag</span></span></code></pre></div>
<pre><code>#:&gt; [SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')] 
#:&gt; 
#:&gt;  [SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08')]</code></pre>
<p>Get the score for first synset</p>
<div class="sourceCode" id="cb1850"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1850-1"><a href="nlp.html#cb1850-1" aria-hidden="true" tabindex="-1"></a>first_synset <span class="op">=</span> <span class="bu">list</span>(swn.senti_synsets(<span class="st">'slow'</span>,<span class="st">'a'</span>))[<span class="dv">0</span>]</span>
<span id="cb1850-2"><a href="nlp.html#cb1850-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1850-3"><a href="nlp.html#cb1850-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1850-4"><a href="nlp.html#cb1850-4" aria-hidden="true" tabindex="-1"></a>  first_synset, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1850-5"><a href="nlp.html#cb1850-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Positive:'</span>,  first_synset.pos_score(), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1850-6"><a href="nlp.html#cb1850-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Negative:'</span>,  first_synset.neg_score(), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1850-7"><a href="nlp.html#cb1850-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Objective:'</span>, first_synset.obj_score()</span>
<span id="cb1850-8"><a href="nlp.html#cb1850-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>#:&gt; &lt;slow.a.01: PosScore=0.0 NegScore=0.0&gt; 
#:&gt;  Positive: 0.0 
#:&gt;  Negative: 0.0 
#:&gt;  Objective: 1.0</code></pre>
</div>
<div id="converting-pos-tag-into-wordnet-pos-tag" class="section level4" number="17.9.1.3">
<h4>
<span class="header-section-number">17.9.1.3</span> Converting POS-tag into Wordnet POS-tag<a class="anchor" aria-label="anchor" href="#converting-pos-tag-into-wordnet-pos-tag"><i class="fas fa-link"></i></a>
</h4>
<p><strong>Using Function</strong></p>
<div class="sourceCode" id="cb1852"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1852-1"><a href="nlp.html#cb1852-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1852-2"><a href="nlp.html#cb1852-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb1852-3"><a href="nlp.html#cb1852-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet <span class="im">as</span> wn</span>
<span id="cb1852-4"><a href="nlp.html#cb1852-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1852-5"><a href="nlp.html#cb1852-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> penn_to_wn(tag):</span>
<span id="cb1852-6"><a href="nlp.html#cb1852-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1852-7"><a href="nlp.html#cb1852-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Convert between the PennTreebank tags to simple Wordnet tags</span></span>
<span id="cb1852-8"><a href="nlp.html#cb1852-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1852-9"><a href="nlp.html#cb1852-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> tag.startswith(<span class="st">'J'</span>):</span>
<span id="cb1852-10"><a href="nlp.html#cb1852-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> wn.ADJ</span>
<span id="cb1852-11"><a href="nlp.html#cb1852-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> tag.startswith(<span class="st">'N'</span>):</span>
<span id="cb1852-12"><a href="nlp.html#cb1852-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> wn.NOUN</span>
<span id="cb1852-13"><a href="nlp.html#cb1852-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> tag.startswith(<span class="st">'R'</span>):</span>
<span id="cb1852-14"><a href="nlp.html#cb1852-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> wn.ADV</span>
<span id="cb1852-15"><a href="nlp.html#cb1852-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> tag.startswith(<span class="st">'V'</span>):</span>
<span id="cb1852-16"><a href="nlp.html#cb1852-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> wn.VERB</span>
<span id="cb1852-17"><a href="nlp.html#cb1852-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb1852-18"><a href="nlp.html#cb1852-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1852-19"><a href="nlp.html#cb1852-19" aria-hidden="true" tabindex="-1"></a>wt <span class="op">=</span> word_tokenize(<span class="st">"Star Wars is a wonderful movie"</span>)</span>
<span id="cb1852-20"><a href="nlp.html#cb1852-20" aria-hidden="true" tabindex="-1"></a>penn_tags <span class="op">=</span> nltk.pos_tag(wt)</span>
<span id="cb1852-21"><a href="nlp.html#cb1852-21" aria-hidden="true" tabindex="-1"></a>wordnet_tags <span class="op">=</span> [ (x, penn_to_wn(y)) <span class="cf">for</span> (x,y) <span class="kw">in</span> penn_tags ]</span>
<span id="cb1852-22"><a href="nlp.html#cb1852-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1852-23"><a href="nlp.html#cb1852-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1852-24"><a href="nlp.html#cb1852-24" aria-hidden="true" tabindex="-1"></a><span class="st">'Penn Tags    :'</span>, penn_tags, </span>
<span id="cb1852-25"><a href="nlp.html#cb1852-25" aria-hidden="true" tabindex="-1"></a><span class="st">'</span><span class="ch">\n</span><span class="st">Wordnet Tags :'</span>, wordnet_tags)</span></code></pre></div>
<pre><code>#:&gt; Penn Tags    : [('Star', 'NNP'), ('Wars', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('wonderful', 'JJ'), ('movie', 'NN')] 
#:&gt; Wordnet Tags : [('Star', 'n'), ('Wars', 'n'), ('is', 'v'), ('a', None), ('wonderful', 'a'), ('movie', 'n')]</code></pre>
<p><strong>Using defaultdict</strong></p>
<div class="sourceCode" id="cb1854"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1854-1"><a href="nlp.html#cb1854-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1854-2"><a href="nlp.html#cb1854-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet <span class="im">as</span> wn</span>
<span id="cb1854-3"><a href="nlp.html#cb1854-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk <span class="im">import</span> word_tokenize, pos_tag</span>
<span id="cb1854-4"><a href="nlp.html#cb1854-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb1854-5"><a href="nlp.html#cb1854-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1854-6"><a href="nlp.html#cb1854-6" aria-hidden="true" tabindex="-1"></a>tag_map <span class="op">=</span> defaultdict(<span class="kw">lambda</span> : <span class="va">None</span>)</span>
<span id="cb1854-7"><a href="nlp.html#cb1854-7" aria-hidden="true" tabindex="-1"></a>tag_map[<span class="st">'J'</span>] <span class="op">=</span> wn.ADJ</span>
<span id="cb1854-8"><a href="nlp.html#cb1854-8" aria-hidden="true" tabindex="-1"></a>tag_map[<span class="st">'R'</span>] <span class="op">=</span> wn.ADV</span>
<span id="cb1854-9"><a href="nlp.html#cb1854-9" aria-hidden="true" tabindex="-1"></a>tag_map[<span class="st">'V'</span>] <span class="op">=</span> wn.VERB</span>
<span id="cb1854-10"><a href="nlp.html#cb1854-10" aria-hidden="true" tabindex="-1"></a>tag_map[<span class="st">'N'</span>] <span class="op">=</span> wn.NOUN</span>
<span id="cb1854-11"><a href="nlp.html#cb1854-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1854-12"><a href="nlp.html#cb1854-12" aria-hidden="true" tabindex="-1"></a>wt <span class="op">=</span> word_tokenize(<span class="st">"Star Wars is a wonderful movie"</span>)</span>
<span id="cb1854-13"><a href="nlp.html#cb1854-13" aria-hidden="true" tabindex="-1"></a>penn_tags <span class="op">=</span> nltk.pos_tag(wt)</span>
<span id="cb1854-14"><a href="nlp.html#cb1854-14" aria-hidden="true" tabindex="-1"></a>wordnet_tags <span class="op">=</span> [ (x, tag_map[y[<span class="dv">0</span>]]) <span class="cf">for</span> (x,y) <span class="kw">in</span> penn_tags ]</span>
<span id="cb1854-15"><a href="nlp.html#cb1854-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1854-16"><a href="nlp.html#cb1854-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1854-17"><a href="nlp.html#cb1854-17" aria-hidden="true" tabindex="-1"></a><span class="st">'Penn Tags    :'</span>, penn_tags, </span>
<span id="cb1854-18"><a href="nlp.html#cb1854-18" aria-hidden="true" tabindex="-1"></a><span class="st">'</span><span class="ch">\n</span><span class="st">Wordnet Tags :'</span>, wordnet_tags)</span></code></pre></div>
<pre><code>#:&gt; Penn Tags    : [('Star', 'NNP'), ('Wars', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('wonderful', 'JJ'), ('movie', 'NN')] 
#:&gt; Wordnet Tags : [('Star', 'n'), ('Wars', 'n'), ('is', 'v'), ('a', None), ('wonderful', 'a'), ('movie', 'n')]</code></pre>
</div>
</div>
<div id="vader" class="section level3" number="17.9.2">
<h3>
<span class="header-section-number">17.9.2</span> Vader<a class="anchor" aria-label="anchor" href="#vader"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>It is a rule based sentiment analyzer, contain 7503 lexicons</li>
<li>It is good for <strong>social media</strong> because lexicon contain <strong>emoji and short</strong> form text</li>
<li>Contain only <strong>3 n-gram</strong>
</li>
<li>Supported by NTLK or install vader seperately (pip install vaderSentiment)</li>
</ul>
<div id="vader-lexicon" class="section level4" number="17.9.2.1">
<h4>
<span class="header-section-number">17.9.2.1</span> Vader Lexicon<a class="anchor" aria-label="anchor" href="#vader-lexicon"><i class="fas fa-link"></i></a>
</h4>
<p>The lexicon is a dictionary. To make it iterable, need to convert into list:<br>
- Step 1: Convert <code>dict</code> to <code>dict_items</code>, which is a list containing items, each item is one dict<br>
- Step 2: Unpack <code>dict_items</code> to <code>list</code></p>
<div class="sourceCode" id="cb1856"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1856-1"><a href="nlp.html#cb1856-1" aria-hidden="true" tabindex="-1"></a><span class="co">#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer   ## seperate pip installed library</span></span>
<span id="cb1856-2"><a href="nlp.html#cb1856-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.sentiment.vader <span class="im">import</span> SentimentIntensityAnalyzer</span>
<span id="cb1856-3"><a href="nlp.html#cb1856-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1856-4"><a href="nlp.html#cb1856-4" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'vader_lexicon'</span>)</span></code></pre></div>
<pre><code>#:&gt; True
#:&gt; 
#:&gt; [nltk_data] Downloading package vader_lexicon to
#:&gt; [nltk_data]     /home/msfz751/nltk_data...
#:&gt; [nltk_data]   Package vader_lexicon is already up-to-date!</code></pre>
<div class="sourceCode" id="cb1858"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1858-1"><a href="nlp.html#cb1858-1" aria-hidden="true" tabindex="-1"></a>vader_lex  <span class="op">=</span> SentimentIntensityAnalyzer().lexicon  <span class="co"># get the lexicon dictionary</span></span>
<span id="cb1858-2"><a href="nlp.html#cb1858-2" aria-hidden="true" tabindex="-1"></a>vader_list <span class="op">=</span> <span class="bu">list</span>(vader_lex.items())               <span class="co"># convert to items then list</span></span>
<span id="cb1858-3"><a href="nlp.html#cb1858-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">'Total Vader Lexicon:'</span>, <span class="bu">len</span>(vader_lex),<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1858-4"><a href="nlp.html#cb1858-4" aria-hidden="true" tabindex="-1"></a>        vader_list[<span class="dv">1</span>:<span class="dv">10</span>], vader_list[<span class="dv">220</span>:<span class="dv">240</span>] )</span></code></pre></div>
<pre><code>#:&gt; Total Vader Lexicon: 7502 
#:&gt;  [('%)', -0.4), ('%-)', -1.5), ('&amp;-:', -0.4), ('&amp;:', -0.7), ("( '}{' )", 1.6), ('(%', -0.9), ("('-:", 2.2), ("(':", 2.3), ('((-:', 2.1)] [('b^d', 2.6), ('cwot', -2.3), ("d-':", -2.5), ('d8', -3.2), ('d:', 1.2), ('d:&lt;', -3.2), ('d;', -2.9), ('d=', 1.5), ('doa', -2.3), ('dx', -3.0), ('ez', 1.5), ('fav', 2.0), ('fcol', -1.8), ('ff', 1.8), ('ffs', -2.8), ('fkm', -2.4), ('foaf', 1.8), ('ftw', 2.0), ('fu', -3.7), ('fubar', -3.0)]</code></pre>
<p><strong>There is only four N-Gram in the lexicon</strong></p>
<div class="sourceCode" id="cb1860"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1860-1"><a href="nlp.html#cb1860-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'List of N-grams: '</span>)</span></code></pre></div>
<pre><code>#:&gt; List of N-grams:</code></pre>
<div class="sourceCode" id="cb1862"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1862-1"><a href="nlp.html#cb1862-1" aria-hidden="true" tabindex="-1"></a>[ (tok,score) <span class="cf">for</span> tok, score <span class="kw">in</span> vader_list <span class="cf">if</span> <span class="st">" "</span> <span class="kw">in</span> tok]</span></code></pre></div>
<pre><code>#:&gt; [("( '}{' )", 1.6), ("can't stand", -2.0), ('fed up', -1.8), ('screwed up', -1.5)]</code></pre>
<p>If stemming or lemmatization is used, stem/lemmatize the vader lexicon too</p>
<div class="sourceCode" id="cb1864"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1864-1"><a href="nlp.html#cb1864-1" aria-hidden="true" tabindex="-1"></a>[ (tok,score) <span class="cf">for</span> tok, score <span class="kw">in</span> vader_list <span class="cf">if</span> <span class="st">"lov"</span> <span class="kw">in</span> tok]</span></code></pre></div>
<pre><code>#:&gt; [('beloved', 2.3), ('lovable', 3.0), ('love', 3.2), ('loved', 2.9), ('lovelies', 2.2), ('lovely', 2.8), ('lover', 2.8), ('loverly', 2.8), ('lovers', 2.4), ('loves', 2.7), ('loving', 2.9), ('lovingly', 3.2), ('lovingness', 2.7), ('unlovable', -2.7), ('unloved', -1.9), ('unlovelier', -1.9), ('unloveliest', -1.9), ('unloveliness', -2.0), ('unlovely', -2.1), ('unloving', -2.3)]</code></pre>
</div>
<div id="polarity-scoring" class="section level4" number="17.9.2.2">
<h4>
<span class="header-section-number">17.9.2.2</span> Polarity Scoring<a class="anchor" aria-label="anchor" href="#polarity-scoring"><i class="fas fa-link"></i></a>
</h4>
<p>Scoring result is a dictionary of:</p>
<ul>
<li>neg</li>
<li>neu</li>
<li>pos</li>
<li>compound
<strong>neg, neu, pos adds up to 1.0</strong>
</li>
</ul>
<p>Example below shows polarity for two sentences:</p>
<div class="sourceCode" id="cb1866"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1866-1"><a href="nlp.html#cb1866-1" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [<span class="st">"Python is a very useful but hell difficult to learn"</span>,</span>
<span id="cb1866-2"><a href="nlp.html#cb1866-2" aria-hidden="true" tabindex="-1"></a>        <span class="st">":) :) :("</span>]</span>
<span id="cb1866-3"><a href="nlp.html#cb1866-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> corpus:</span>
<span id="cb1866-4"><a href="nlp.html#cb1866-4" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(doc, <span class="st">'--&gt;'</span>, <span class="st">"</span><span class="ch">\n</span><span class="st">:"</span>, SentimentIntensityAnalyzer().polarity_scores(doc) )</span></code></pre></div>
<pre><code>#:&gt; Python is a very useful but hell difficult to learn --&gt; 
#:&gt; : {'neg': 0.554, 'neu': 0.331, 'pos': 0.116, 'compound': -0.8735}
#:&gt; :) :) :( --&gt; 
#:&gt; : {'neg': 0.326, 'neu': 0.0, 'pos': 0.674, 'compound': 0.4767}</code></pre>
</div>
</div>
</div>
<div id="feature-representation" class="section level2" number="17.10">
<h2>
<span class="header-section-number">17.10</span> Feature Representation<a class="anchor" aria-label="anchor" href="#feature-representation"><i class="fas fa-link"></i></a>
</h2>
<div id="the-data-3" class="section level3" number="17.10.1">
<h3>
<span class="header-section-number">17.10.1</span> The Data<a class="anchor" aria-label="anchor" href="#the-data-3"><i class="fas fa-link"></i></a>
</h3>
<p>A corpus is a collection of multiple documents. In the below example, each document is represented by a sentence.</p>
<div class="sourceCode" id="cb1868"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1868-1"><a href="nlp.html#cb1868-1" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [</span>
<span id="cb1868-2"><a href="nlp.html#cb1868-2" aria-hidden="true" tabindex="-1"></a>   <span class="st">'This is the first document, :)'</span>,</span>
<span id="cb1868-3"><a href="nlp.html#cb1868-3" aria-hidden="true" tabindex="-1"></a>   <span class="st">'This document is the second document.'</span>,</span>
<span id="cb1868-4"><a href="nlp.html#cb1868-4" aria-hidden="true" tabindex="-1"></a>   <span class="st">'And this is a third one'</span>,</span>
<span id="cb1868-5"><a href="nlp.html#cb1868-5" aria-hidden="true" tabindex="-1"></a>   <span class="st">'Is this the first document?'</span>,</span>
<span id="cb1868-6"><a href="nlp.html#cb1868-6" aria-hidden="true" tabindex="-1"></a>]</span></code></pre></div>
</div>
<div id="frequency-count-1" class="section level3" number="17.10.2">
<h3>
<span class="header-section-number">17.10.2</span> Frequency Count<a class="anchor" aria-label="anchor" href="#frequency-count-1"><i class="fas fa-link"></i></a>
</h3>
<p>Using purely frequency count as a feature will obviously bias on long document (which contain a lot of words, hence words within the document will have very high frequency).</p>
<div id="tokenizer" class="section level4" number="17.10.2.1">
<h4>
<span class="header-section-number">17.10.2.1</span> + Tokenizer<a class="anchor" aria-label="anchor" href="#tokenizer"><i class="fas fa-link"></i></a>
</h4>
<p><strong>Default Tokenizer</strong><br>
By default, vectorizer apply tokenizer to select minimum <strong>2-chars alphanumeric words</strong>. Below <strong>train</strong> the vectorizer using <strong><code>fit_transform()</code></strong>.</p>
<div class="sourceCode" id="cb1869"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1869-1"><a href="nlp.html#cb1869-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb1869-2"><a href="nlp.html#cb1869-2" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> CountVectorizer()          <span class="co"># initialize the vectorizer</span></span>
<span id="cb1869-3"><a href="nlp.html#cb1869-3" aria-hidden="true" tabindex="-1"></a>X   <span class="op">=</span> vec.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></span>
<span id="cb1869-4"><a href="nlp.html#cb1869-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.DataFrame(X.toarray(), columns<span class="op">=</span>vec.get_feature_names()),<span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>,</span>
<span id="cb1869-5"><a href="nlp.html#cb1869-5" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Vocabulary: '</span>, vec.vocabulary_)</span></code></pre></div>
<pre><code>#:&gt;    and  document  first  is  one  second  the  third  this
#:&gt; 0    0         1      1   1    0       0    1      0     1
#:&gt; 1    0         2      0   1    0       1    1      0     1
#:&gt; 2    1         0      0   1    1       0    0      1     1
#:&gt; 3    0         1      1   1    0       0    1      0     1 
#:&gt; 
#:&gt;  Vocabulary:  {'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}</code></pre>
<p><strong>Custom Tokenizer</strong><br>
You can use a custom tokenizer, which is a <strong>function that return list of words</strong>. Example below uses nltk RegexpTokenizer function, which retains one or more alphanumeric characters.</p>
<div class="sourceCode" id="cb1871"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1871-1"><a href="nlp.html#cb1871-1" aria-hidden="true" tabindex="-1"></a>my_tokenizer <span class="op">=</span> RegexpTokenizer(<span class="vs">r'[a-zA-Z0-9\']+'</span>)  <span class="co">## Custom Tokenizer</span></span>
<span id="cb1871-2"><a href="nlp.html#cb1871-2" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> CountVectorizer(tokenizer<span class="op">=</span>my_tokenizer.tokenize) <span class="co">## custom tokenizer's function</span></span>
<span id="cb1871-3"><a href="nlp.html#cb1871-3" aria-hidden="true" tabindex="-1"></a>X2   <span class="op">=</span> vec2.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></span>
<span id="cb1871-4"><a href="nlp.html#cb1871-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.DataFrame(X2.toarray(), columns<span class="op">=</span>vec2.get_feature_names()),<span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>,</span>
<span id="cb1871-5"><a href="nlp.html#cb1871-5" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Vocabulary: '</span>, vec.vocabulary_)</span></code></pre></div>
<pre><code>#:&gt;    a  and  document  first  is  one  second  the  third  this
#:&gt; 0  0    0         1      1   1    0       0    1      0     1
#:&gt; 1  0    0         2      0   1    0       1    1      0     1
#:&gt; 2  1    1         0      0   1    1       0    0      1     1
#:&gt; 3  0    0         1      1   1    0       0    1      0     1 
#:&gt; 
#:&gt;  Vocabulary:  {'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}</code></pre>
<p><strong>1 and 2-Word-Gram Tokenizer</strong><br>
Use <code>ngram_range()</code> to specify range of grams needed.</p>
<div class="sourceCode" id="cb1873"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1873-1"><a href="nlp.html#cb1873-1" aria-hidden="true" tabindex="-1"></a>vec3 <span class="op">=</span> CountVectorizer(ngram_range<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">2</span>))          <span class="co"># initialize the vectorizer</span></span>
<span id="cb1873-2"><a href="nlp.html#cb1873-2" aria-hidden="true" tabindex="-1"></a>X3   <span class="op">=</span> vec3.fit_transform(corpus)     <span class="co"># FIT the vectorizer, return fitted data</span></span>
<span id="cb1873-3"><a href="nlp.html#cb1873-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.DataFrame(X3.toarray(), columns<span class="op">=</span>vec3.get_feature_names()),<span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>,</span>
<span id="cb1873-4"><a href="nlp.html#cb1873-4" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Vocabulary: '</span>, vec.vocabulary_)</span></code></pre></div>
<pre><code>#:&gt;    and  and this  document  document is  first  ...  third one  this  this document  \
#:&gt; 0    0         0         1            0      1  ...          0     1              0   
#:&gt; 1    0         0         2            1      0  ...          0     1              1   
#:&gt; 2    1         1         0            0      0  ...          1     1              0   
#:&gt; 3    0         0         1            0      1  ...          0     1              0   
#:&gt; 
#:&gt;    this is  this the  
#:&gt; 0        1         0  
#:&gt; 1        0         0  
#:&gt; 2        1         0  
#:&gt; 3        0         1  
#:&gt; 
#:&gt; [4 rows x 22 columns] 
#:&gt; 
#:&gt;  Vocabulary:  {'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}</code></pre>
<p><strong>Apply Trained Vectorizer</strong>
Once the vectorizer had been trained, you can apply them on new corpus. <strong>Tokens not in the vectorizer vocubulary are ignored</strong>.</p>
<div class="sourceCode" id="cb1875"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1875-1"><a href="nlp.html#cb1875-1" aria-hidden="true" tabindex="-1"></a>new_corpus <span class="op">=</span> [<span class="st">"My Name is Charlie Angel"</span>, <span class="st">"I love to watch Star Wars"</span>]</span>
<span id="cb1875-2"><a href="nlp.html#cb1875-2" aria-hidden="true" tabindex="-1"></a>XX <span class="op">=</span> vec.transform(new_corpus)</span>
<span id="cb1875-3"><a href="nlp.html#cb1875-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(XX.toarray(), columns<span class="op">=</span>vec.get_feature_names())</span></code></pre></div>
<pre><code>#:&gt;    and  document  first  is  one  second  the  third  this
#:&gt; 0    0         0      0   1    0       0    0      0     0
#:&gt; 1    0         0      0   0    0       0    0      0     0</code></pre>
</div>
<div id="stop-words" class="section level4" number="17.10.2.2">
<h4>
<span class="header-section-number">17.10.2.2</span> + Stop Words<a class="anchor" aria-label="anchor" href="#stop-words"><i class="fas fa-link"></i></a>
</h4>
<p>Vectorizer can optionally be use with stop words list. Use <code>stop_words=english</code> to apply filtering using sklearn built-in stop word. You can replace <code>english</code> with other word <strong>list object</strong>.</p>
<div class="sourceCode" id="cb1877"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1877-1"><a href="nlp.html#cb1877-1" aria-hidden="true" tabindex="-1"></a>vec4 <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">'english'</span>) <span class="co">## sklearn stopwords list</span></span>
<span id="cb1877-2"><a href="nlp.html#cb1877-2" aria-hidden="true" tabindex="-1"></a>X4 <span class="op">=</span> vec4.fit_transform(corpus)</span>
<span id="cb1877-3"><a href="nlp.html#cb1877-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(X4.toarray(), columns<span class="op">=</span>vec4.get_feature_names())</span></code></pre></div>
<pre><code>#:&gt;    document  second
#:&gt; 0         1       0
#:&gt; 1         2       1
#:&gt; 2         0       0
#:&gt; 3         1       0</code></pre>
</div>
</div>
<div id="tfidf" class="section level3" number="17.10.3">
<h3>
<span class="header-section-number">17.10.3</span> TFIDF<a class="anchor" aria-label="anchor" href="#tfidf"><i class="fas fa-link"></i></a>
</h3>
<div id="equation" class="section level4" number="17.10.3.1">
<h4>
<span class="header-section-number">17.10.3.1</span> Equation<a class="anchor" aria-label="anchor" href="#equation"><i class="fas fa-link"></i></a>
</h4>
<p><span class="math display">\[tf(t,d) = \text{occurances of term t in document t} \\
n     = \text{number of documents} \\
df(t) = \text{number of documents containing term t} \\
idf(t)  = log \frac{n}{df(t))} + 1 \\
idf(t)  = log \frac{1+n}{1+df(t))} + 1 \text{.... smoothing, prevent zero division} \\
tfidf(t) = tf(t) * idf(t,d)    \text{.... raw, no normalization on tf(t)} \\
tfidf(t) = \frac{tf(t,d)}{||V||_2} * idf(t)    \text{.... tf normalized with euclidean norm}\]</span></p>
</div>
<div id="tfidftransformer" class="section level4" number="17.10.3.2">
<h4>
<span class="header-section-number">17.10.3.2</span> <code>TfidfTransformer</code><a class="anchor" aria-label="anchor" href="#tfidftransformer"><i class="fas fa-link"></i></a>
</h4>
<p>To generate TFIDF vectors, first run <code>CountVectorizer</code> to get frequency vector matrix. Then take the output into this transformer.</p>
<div class="sourceCode" id="cb1879"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1879-1"><a href="nlp.html#cb1879-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfTransformer</span>
<span id="cb1879-2"><a href="nlp.html#cb1879-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1879-3"><a href="nlp.html#cb1879-3" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [</span>
<span id="cb1879-4"><a href="nlp.html#cb1879-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"apple apple apple apple apple banana"</span>,</span>
<span id="cb1879-5"><a href="nlp.html#cb1879-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"apple apple"</span>,</span>
<span id="cb1879-6"><a href="nlp.html#cb1879-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"apple apple apple banana"</span>,</span>
<span id="cb1879-7"><a href="nlp.html#cb1879-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"durian durian durian"</span>]</span>
<span id="cb1879-8"><a href="nlp.html#cb1879-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1879-9"><a href="nlp.html#cb1879-9" aria-hidden="true" tabindex="-1"></a>count_vec <span class="op">=</span> CountVectorizer()</span>
<span id="cb1879-10"><a href="nlp.html#cb1879-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> count_vec.fit_transform(corpus)</span>
<span id="cb1879-11"><a href="nlp.html#cb1879-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1879-12"><a href="nlp.html#cb1879-12" aria-hidden="true" tabindex="-1"></a>transformer1 <span class="op">=</span> TfidfTransformer(smooth_idf<span class="op">=</span><span class="va">False</span>,norm<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb1879-13"><a href="nlp.html#cb1879-13" aria-hidden="true" tabindex="-1"></a>transformer2 <span class="op">=</span> TfidfTransformer(smooth_idf<span class="op">=</span><span class="va">False</span>,norm<span class="op">=</span><span class="st">'l2'</span>)</span>
<span id="cb1879-14"><a href="nlp.html#cb1879-14" aria-hidden="true" tabindex="-1"></a>transformer3 <span class="op">=</span> TfidfTransformer(smooth_idf<span class="op">=</span><span class="va">True</span>,norm<span class="op">=</span><span class="st">'l2'</span>)</span>
<span id="cb1879-15"><a href="nlp.html#cb1879-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1879-16"><a href="nlp.html#cb1879-16" aria-hidden="true" tabindex="-1"></a>tfidf1 <span class="op">=</span> transformer1.fit_transform(X)</span>
<span id="cb1879-17"><a href="nlp.html#cb1879-17" aria-hidden="true" tabindex="-1"></a>tfidf2 <span class="op">=</span> transformer2.fit_transform(X)</span>
<span id="cb1879-18"><a href="nlp.html#cb1879-18" aria-hidden="true" tabindex="-1"></a>tfidf3 <span class="op">=</span> transformer3.fit_transform(X)</span>
<span id="cb1879-19"><a href="nlp.html#cb1879-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1879-20"><a href="nlp.html#cb1879-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1879-21"><a href="nlp.html#cb1879-21" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Frequency Count: </span><span class="ch">\n</span><span class="st">'</span>, pd.DataFrame(X.toarray(), columns<span class="op">=</span>count_vec.get_feature_names()),</span>
<span id="cb1879-22"><a href="nlp.html#cb1879-22" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n\n</span><span class="st">Vocabulary: '</span>, count_vec.vocabulary_,</span>
<span id="cb1879-23"><a href="nlp.html#cb1879-23" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n\n</span><span class="st">TFIDF Without Norm:</span><span class="ch">\n</span><span class="st">'</span>,tfidf1.toarray(), </span>
<span id="cb1879-24"><a href="nlp.html#cb1879-24" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n\n</span><span class="st">TFIDF with L2 Norm:</span><span class="ch">\n</span><span class="st">'</span>,tfidf2.toarray(),  </span>
<span id="cb1879-25"><a href="nlp.html#cb1879-25" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n\n</span><span class="st">TFIDF with L2 Norm (smooth):</span><span class="ch">\n</span><span class="st">'</span>,tfidf3.toarray())</span></code></pre></div>
<pre><code>#:&gt; Frequency Count: 
#:&gt;     apple  banana  durian
#:&gt; 0      5       1       0
#:&gt; 1      2       0       0
#:&gt; 2      3       1       0
#:&gt; 3      0       0       3 
#:&gt; 
#:&gt; Vocabulary:  {'apple': 0, 'banana': 1, 'durian': 2} 
#:&gt; 
#:&gt; TFIDF Without Norm:
#:&gt;  [[6.43841036 1.69314718 0.        ]
#:&gt;  [2.57536414 0.         0.        ]
#:&gt;  [3.86304622 1.69314718 0.        ]
#:&gt;  [0.         0.         7.15888308]] 
#:&gt; 
#:&gt; TFIDF with L2 Norm:
#:&gt;  [[0.96711783 0.25432874 0.        ]
#:&gt;  [1.         0.         0.        ]
#:&gt;  [0.91589033 0.40142857 0.        ]
#:&gt;  [0.         0.         1.        ]] 
#:&gt; 
#:&gt; TFIDF with L2 Norm (smooth):
#:&gt;  [[0.97081492 0.23982991 0.        ]
#:&gt;  [1.         0.         0.        ]
#:&gt;  [0.92468843 0.38072472 0.        ]
#:&gt;  [0.         0.         1.        ]]</code></pre>
</div>
<div id="tfidfvectorizer" class="section level4" number="17.10.3.3">
<h4>
<span class="header-section-number">17.10.3.3</span> <code>TfidfVectorizer</code><a class="anchor" aria-label="anchor" href="#tfidfvectorizer"><i class="fas fa-link"></i></a>
</h4>
<p>This vectorizer gives end to end processing from corpus into TFIDF vector matrix, including tokenization, stopwords.</p>
<div class="sourceCode" id="cb1881"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1881-1"><a href="nlp.html#cb1881-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1881-2"><a href="nlp.html#cb1881-2" aria-hidden="true" tabindex="-1"></a>my_tokenizer <span class="op">=</span> RegexpTokenizer(<span class="vs">r'[a-zA-Z0-9\']+'</span>)  <span class="co">## Custom Tokenizer</span></span>
<span id="cb1881-3"><a href="nlp.html#cb1881-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1881-4"><a href="nlp.html#cb1881-4" aria-hidden="true" tabindex="-1"></a>vec1 <span class="op">=</span> TfidfVectorizer(tokenizer<span class="op">=</span>my_tokenizer.tokenize,  stop_words<span class="op">=</span><span class="st">'english'</span>) <span class="co">#default smooth_idf=True, norm='l2'</span></span>
<span id="cb1881-5"><a href="nlp.html#cb1881-5" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> TfidfVectorizer(tokenizer<span class="op">=</span>my_tokenizer.tokenize, stop_words<span class="op">=</span><span class="st">'english'</span>,smooth_idf<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1881-6"><a href="nlp.html#cb1881-6" aria-hidden="true" tabindex="-1"></a>vec3 <span class="op">=</span> TfidfVectorizer(tokenizer<span class="op">=</span>my_tokenizer.tokenize, stop_words<span class="op">=</span><span class="st">'english'</span>, norm<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb1881-7"><a href="nlp.html#cb1881-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1881-8"><a href="nlp.html#cb1881-8" aria-hidden="true" tabindex="-1"></a>X1   <span class="op">=</span> vec1.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></span>
<span id="cb1881-9"><a href="nlp.html#cb1881-9" aria-hidden="true" tabindex="-1"></a>X2   <span class="op">=</span> vec2.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></span>
<span id="cb1881-10"><a href="nlp.html#cb1881-10" aria-hidden="true" tabindex="-1"></a>X3   <span class="op">=</span> vec3.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></span>
<span id="cb1881-11"><a href="nlp.html#cb1881-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1881-12"><a href="nlp.html#cb1881-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb1881-13"><a href="nlp.html#cb1881-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">'TFIDF Features (Default with Smooth and L2 Norm):</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1881-14"><a href="nlp.html#cb1881-14" aria-hidden="true" tabindex="-1"></a>  pd.DataFrame(X1.toarray().<span class="bu">round</span>(<span class="dv">3</span>), columns<span class="op">=</span>vec1.get_feature_names()),</span>
<span id="cb1881-15"><a href="nlp.html#cb1881-15" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n\n</span><span class="st">TFIDF Features (without Smoothing):</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1881-16"><a href="nlp.html#cb1881-16" aria-hidden="true" tabindex="-1"></a>  pd.DataFrame(X2.toarray().<span class="bu">round</span>(<span class="dv">3</span>), columns<span class="op">=</span>vec2.get_feature_names()),</span>
<span id="cb1881-17"><a href="nlp.html#cb1881-17" aria-hidden="true" tabindex="-1"></a>  <span class="st">'</span><span class="ch">\n\n</span><span class="st">TFIDF Features (without L2 Norm):</span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb1881-18"><a href="nlp.html#cb1881-18" aria-hidden="true" tabindex="-1"></a>  pd.DataFrame(X3.toarray().<span class="bu">round</span>(<span class="dv">3</span>), columns<span class="op">=</span>vec3.get_feature_names())</span>
<span id="cb1881-19"><a href="nlp.html#cb1881-19" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<pre><code>#:&gt; TFIDF Features (Default with Smooth and L2 Norm):
#:&gt;     apple  banana  durian
#:&gt; 0  0.971   0.240     0.0
#:&gt; 1  1.000   0.000     0.0
#:&gt; 2  0.925   0.381     0.0
#:&gt; 3  0.000   0.000     1.0 
#:&gt; 
#:&gt; TFIDF Features (without Smoothing):
#:&gt;     apple  banana  durian
#:&gt; 0  0.967   0.254     0.0
#:&gt; 1  1.000   0.000     0.0
#:&gt; 2  0.916   0.401     0.0
#:&gt; 3  0.000   0.000     1.0 
#:&gt; 
#:&gt; TFIDF Features (without L2 Norm):
#:&gt;     apple  banana  durian
#:&gt; 0  6.116   1.511   0.000
#:&gt; 1  2.446   0.000   0.000
#:&gt; 2  3.669   1.511   0.000
#:&gt; 3  0.000   0.000   5.749</code></pre>
</div>
</div>
</div>
<div id="appliction" class="section level2" number="17.11">
<h2>
<span class="header-section-number">17.11</span> Appliction<a class="anchor" aria-label="anchor" href="#appliction"><i class="fas fa-link"></i></a>
</h2>
<div id="document-similarity" class="section level3" number="17.11.1">
<h3>
<span class="header-section-number">17.11.1</span> Document Similarity<a class="anchor" aria-label="anchor" href="#document-similarity"><i class="fas fa-link"></i></a>
</h3>
<p>Document1 and Document 2 are mutiplicate of Document0, therefore their consine similarity is the same.</p>
<div class="sourceCode" id="cb1883"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1883-1"><a href="nlp.html#cb1883-1" aria-hidden="true" tabindex="-1"></a>documents <span class="op">=</span> (</span>
<span id="cb1883-2"><a href="nlp.html#cb1883-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"apple apple banana"</span>,</span>
<span id="cb1883-3"><a href="nlp.html#cb1883-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"apple apple banana apple apple banana"</span>,</span>
<span id="cb1883-4"><a href="nlp.html#cb1883-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"apple apple banana apple apple banana apple apple banana"</span>)</span>
<span id="cb1883-5"><a href="nlp.html#cb1883-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1883-6"><a href="nlp.html#cb1883-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1883-7"><a href="nlp.html#cb1883-7" aria-hidden="true" tabindex="-1"></a>tfidf_vec <span class="op">=</span> TfidfVectorizer()</span>
<span id="cb1883-8"><a href="nlp.html#cb1883-8" aria-hidden="true" tabindex="-1"></a>tfidf_matrix <span class="op">=</span> tfidf_vec.fit_transform(documents)</span>
<span id="cb1883-9"><a href="nlp.html#cb1883-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1883-10"><a href="nlp.html#cb1883-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb1883-11"><a href="nlp.html#cb1883-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Cosine Similarity betwen doc0 and doc1:</span><span class="ch">\n</span><span class="st">'</span>,cosine_similarity(tfidf_matrix[<span class="dv">0</span>], tfidf_matrix[<span class="dv">1</span>]))</span></code></pre></div>
<pre><code>#:&gt; Cosine Similarity betwen doc0 and doc1:
#:&gt;  [[1.]]</code></pre>
<div class="sourceCode" id="cb1885"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1885-1"><a href="nlp.html#cb1885-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Cosine Similarity betwen doc1 and doc2:</span><span class="ch">\n</span><span class="st">'</span>,cosine_similarity(tfidf_matrix[<span class="dv">1</span>], tfidf_matrix[<span class="dv">2</span>]))</span></code></pre></div>
<pre><code>#:&gt; Cosine Similarity betwen doc1 and doc2:
#:&gt;  [[1.]]</code></pre>
<div class="sourceCode" id="cb1887"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1887-1"><a href="nlp.html#cb1887-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Cosine Similarity betwen doc1 and doc2:</span><span class="ch">\n</span><span class="st">'</span>,cosine_similarity(tfidf_matrix[<span class="dv">0</span>], tfidf_matrix[<span class="dv">2</span>]))</span></code></pre></div>
<pre><code>#:&gt; Cosine Similarity betwen doc1 and doc2:
#:&gt;  [[1.]]</code></pre>
</div>
</div>
<div id="naive-bayes" class="section level2" number="17.12">
<h2>
<span class="header-section-number">17.12</span> Naive Bayes<a class="anchor" aria-label="anchor" href="#naive-bayes"><i class="fas fa-link"></i></a>
</h2>
<div id="libraries" class="section level3" number="17.12.1">
<h3>
<span class="header-section-number">17.12.1</span> Libraries<a class="anchor" aria-label="anchor" href="#libraries"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb1889"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1889-1"><a href="nlp.html#cb1889-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nlpia.data.loaders <span class="im">import</span> get_data</span>
<span id="cb1889-2"><a href="nlp.html#cb1889-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize.casual     <span class="im">import</span> casual_tokenize</span>
<span id="cb1889-3"><a href="nlp.html#cb1889-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span></code></pre></div>
</div>
<div id="the-data-4" class="section level3" number="17.12.2">
<h3>
<span class="header-section-number">17.12.2</span> The Data<a class="anchor" aria-label="anchor" href="#the-data-4"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb1890"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1890-1"><a href="nlp.html#cb1890-1" aria-hidden="true" tabindex="-1"></a>movies <span class="op">=</span> get_data(<span class="st">'hutto_movies'</span>)   <span class="co"># download data</span></span>
<span id="cb1890-2"><a href="nlp.html#cb1890-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(movies.head(), <span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>,</span>
<span id="cb1890-3"><a href="nlp.html#cb1890-3" aria-hidden="true" tabindex="-1"></a>      movies.describe())</span></code></pre></div>
<pre><code>#:&gt;     sentiment                                               text
#:&gt; id                                                              
#:&gt; 1    2.266667  The Rock is destined to be the 21st Century's ...
#:&gt; 2    3.533333  The gorgeously elaborate continuation of ''The...
#:&gt; 3   -0.600000                     Effective but too tepid biopic
#:&gt; 4    1.466667  If you sometimes like to go to the movies to h...
#:&gt; 5    1.733333  Emerges as something rare, an issue movie that... 
#:&gt; 
#:&gt;            sentiment
#:&gt; count  10605.000000
#:&gt; mean       0.004831
#:&gt; std        1.922050
#:&gt; min       -3.875000
#:&gt; 25%       -1.769231
#:&gt; 50%       -0.080000
#:&gt; 75%        1.833333
#:&gt; max        3.941176</code></pre>
</div>
<div id="bag-of-words" class="section level3" number="17.12.3">
<h3>
<span class="header-section-number">17.12.3</span> Bag of Words<a class="anchor" aria-label="anchor" href="#bag-of-words"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Tokenize each record, remove single character token, then convert into list of counters (words-frequency pair).<br>
</li>
<li>Each item in the list is a counter, which represent word frequency within the record</li>
</ul>
<div class="sourceCode" id="cb1892"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1892-1"><a href="nlp.html#cb1892-1" aria-hidden="true" tabindex="-1"></a>bag_of_words <span class="op">=</span> []</span>
<span id="cb1892-2"><a href="nlp.html#cb1892-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> movies.text:</span>
<span id="cb1892-3"><a href="nlp.html#cb1892-3" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> casual_tokenize(text, reduce_len<span class="op">=</span><span class="va">True</span>, strip_handles<span class="op">=</span><span class="va">True</span>)  <span class="co"># tokenize</span></span>
<span id="cb1892-4"><a href="nlp.html#cb1892-4" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> tokens <span class="cf">if</span> <span class="bu">len</span>(x)<span class="op">&gt;</span><span class="dv">1</span>]                  <span class="co">## remove single char token</span></span>
<span id="cb1892-5"><a href="nlp.html#cb1892-5" aria-hidden="true" tabindex="-1"></a>    bag_of_words.append( Counter(tokens, strip_handles<span class="op">=</span><span class="va">True</span>)  <span class="co">## add to our BoW</span></span>
<span id="cb1892-6"><a href="nlp.html#cb1892-6" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1892-7"><a href="nlp.html#cb1892-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1892-8"><a href="nlp.html#cb1892-8" aria-hidden="true" tabindex="-1"></a>unique_words <span class="op">=</span>  <span class="bu">list</span>( <span class="bu">set</span>([ y  <span class="cf">for</span> x <span class="kw">in</span> bag_of_words  <span class="cf">for</span> y <span class="kw">in</span> x.keys()]) )</span>
<span id="cb1892-9"><a href="nlp.html#cb1892-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1892-10"><a href="nlp.html#cb1892-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Total Rows: "</span>, <span class="bu">len</span>(bag_of_words),<span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>,</span>
<span id="cb1892-11"><a href="nlp.html#cb1892-11" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Row 1 BoW: '</span>,bag_of_words[:<span class="dv">1</span>],<span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>,    <span class="co"># see the first two records</span></span>
<span id="cb1892-12"><a href="nlp.html#cb1892-12" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Row 2 BoW: '</span>, bag_of_words[:<span class="dv">2</span>], <span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>,</span>
<span id="cb1892-13"><a href="nlp.html#cb1892-13" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Total Unique Words: '</span>, <span class="bu">len</span>(unique_words))</span></code></pre></div>
<pre><code>#:&gt; Total Rows:  10605 
#:&gt; 
#:&gt;  Row 1 BoW:  [Counter({'to': 2, 'The': 1, 'Rock': 1, 'is': 1, 'destined': 1, 'be': 1, 'the': 1, '21st': 1, "Century's": 1, 'new': 1, 'Conan': 1, 'and': 1, 'that': 1, "he's": 1, 'going': 1, 'make': 1, 'splash': 1, 'even': 1, 'greater': 1, 'than': 1, 'Arnold': 1, 'Schwarzenegger': 1, 'Jean': 1, 'Claud': 1, 'Van': 1, 'Damme': 1, 'or': 1, 'Steven': 1, 'Segal': 1, 'strip_handles': 1})] 
#:&gt; 
#:&gt;  Row 2 BoW:  [Counter({'to': 2, 'The': 1, 'Rock': 1, 'is': 1, 'destined': 1, 'be': 1, 'the': 1, '21st': 1, "Century's": 1, 'new': 1, 'Conan': 1, 'and': 1, 'that': 1, "he's": 1, 'going': 1, 'make': 1, 'splash': 1, 'even': 1, 'greater': 1, 'than': 1, 'Arnold': 1, 'Schwarzenegger': 1, 'Jean': 1, 'Claud': 1, 'Van': 1, 'Damme': 1, 'or': 1, 'Steven': 1, 'Segal': 1, 'strip_handles': 1}), Counter({'of': 4, 'The': 2, 'gorgeously': 1, 'elaborate': 1, 'continuation': 1, 'Lord': 1, 'the': 1, 'Rings': 1, 'trilogy': 1, 'is': 1, 'so': 1, 'huge': 1, 'that': 1, 'column': 1, 'words': 1, 'cannot': 1, 'adequately': 1, 'describe': 1, 'co': 1, 'writer': 1, 'director': 1, 'Peter': 1, "Jackson's": 1, 'expanded': 1, 'vision': 1, "Tolkien's": 1, 'Middle': 1, 'earth': 1, 'strip_handles': 1})] 
#:&gt; 
#:&gt;  Total Unique Words:  20686</code></pre>
<p><strong>Convert NaN into 0 then all features into integer</strong></p>
<div class="sourceCode" id="cb1894"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1894-1"><a href="nlp.html#cb1894-1" aria-hidden="true" tabindex="-1"></a>bows_df <span class="op">=</span> pd.DataFrame.from_records(bag_of_words)</span>
<span id="cb1894-2"><a href="nlp.html#cb1894-2" aria-hidden="true" tabindex="-1"></a>bows_df <span class="op">=</span> bows_df.fillna(<span class="dv">0</span>).astype(<span class="bu">int</span>)  <span class="co"># replace NaN with 0, change to integer</span></span>
<span id="cb1894-3"><a href="nlp.html#cb1894-3" aria-hidden="true" tabindex="-1"></a>bows_df.head()</span></code></pre></div>
<pre><code>#:&gt;    The  Rock  is  destined  to  ...  Bearable  Staggeringly  ve  muttering  dissing
#:&gt; 0    1     1   1         1   2  ...         0             0   0          0        0
#:&gt; 1    2     0   1         0   0  ...         0             0   0          0        0
#:&gt; 2    0     0   0         0   0  ...         0             0   0          0        0
#:&gt; 3    0     0   1         0   4  ...         0             0   0          0        0
#:&gt; 4    0     0   0         0   0  ...         0             0   0          0        0
#:&gt; 
#:&gt; [5 rows x 20686 columns]</code></pre>
</div>
<div id="build-the-model" class="section level3" number="17.12.4">
<h3>
<span class="header-section-number">17.12.4</span> Build The Model<a class="anchor" aria-label="anchor" href="#build-the-model"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb1896"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1896-1"><a href="nlp.html#cb1896-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb1896-2"><a href="nlp.html#cb1896-2" aria-hidden="true" tabindex="-1"></a>train_y  <span class="op">=</span> movies.sentiment<span class="op">&gt;</span><span class="dv">0</span>   <span class="co"># label</span></span>
<span id="cb1896-3"><a href="nlp.html#cb1896-3" aria-hidden="true" tabindex="-1"></a>train_X  <span class="op">=</span> bows_df              <span class="co"># features</span></span>
<span id="cb1896-4"><a href="nlp.html#cb1896-4" aria-hidden="true" tabindex="-1"></a>nb_model <span class="op">=</span> MultinomialNB().fit( train_X, train_y)</span></code></pre></div>
</div>
<div id="train-set-prediction" class="section level3" number="17.12.5">
<h3>
<span class="header-section-number">17.12.5</span> Train Set Prediction<a class="anchor" aria-label="anchor" href="#train-set-prediction"><i class="fas fa-link"></i></a>
</h3>
<p>First, make a prediction on training data, then compare to ground truth.</p>
<div class="sourceCode" id="cb1897"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1897-1"><a href="nlp.html#cb1897-1" aria-hidden="true" tabindex="-1"></a>train_predicted <span class="op">=</span> nb_model.predict(bows_df)</span>
<span id="cb1897-2"><a href="nlp.html#cb1897-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy: "</span>, np.mean(train_predicted<span class="op">==</span>train_y).<span class="bu">round</span>(<span class="dv">4</span>))</span></code></pre></div>
<pre><code>#:&gt; Accuracy:  0.9357</code></pre>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="sklearn.html"><span class="header-section-number">16</span> sklearn</a></div>
<div class="next"><a href="web-scrapping.html"><span class="header-section-number">18</span> Web Scrapping</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#nlp"><span class="header-section-number">17</span> NLP</a></li>
<li>
<a class="nav-link" href="#regular-expression"><span class="header-section-number">17.1</span> Regular Expression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#syntax"><span class="header-section-number">17.1.1</span> Syntax</a></li>
<li><a class="nav-link" href="#finding"><span class="header-section-number">17.1.2</span> Finding</a></li>
<li><a class="nav-link" href="#matching-condition"><span class="header-section-number">17.1.3</span> Matching Condition</a></li>
<li><a class="nav-link" href="#grouping-1"><span class="header-section-number">17.1.4</span> Grouping</a></li>
<li><a class="nav-link" href="#splittitng"><span class="header-section-number">17.1.5</span> Splittitng</a></li>
<li><a class="nav-link" href="#substitution-re.sub"><span class="header-section-number">17.1.6</span> Substitution re.sub()</a></li>
<li><a class="nav-link" href="#practical-examples"><span class="header-section-number">17.1.7</span> Practical Examples</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#word-tokenizer"><span class="header-section-number">17.2</span> Word Tokenizer</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#custom-tokenizer"><span class="header-section-number">17.2.1</span> Custom Tokenizer</a></li>
<li><a class="nav-link" href="#nltk.tokenize.word_tokenize"><span class="header-section-number">17.2.2</span> nltk.tokenize.word_tokenize()</a></li>
<li><a class="nav-link" href="#nltk.tokenize.casual.casual_tokenize"><span class="header-section-number">17.2.3</span> nltk.tokenize.casual.casual_tokenize()</a></li>
<li><a class="nav-link" href="#nltk.tokenize.treebank.treebankwordtokenizer.tokenize"><span class="header-section-number">17.2.4</span> nltk.tokenize.treebank.TreebankWordTokenizer().tokenize()</a></li>
<li><a class="nav-link" href="#corpus-token-extractor"><span class="header-section-number">17.2.5</span> Corpus Token Extractor</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sentence-tokenizer"><span class="header-section-number">17.3</span> Sentence Tokenizer</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sample-text"><span class="header-section-number">17.3.1</span> Sample Text</a></li>
<li><a class="nav-link" href="#nltk.tokenize.punkt.punktsentencetokenizer"><span class="header-section-number">17.3.2</span> ’nltk.tokenize.punkt.PunktSentenceTokenizer`</a></li>
<li><a class="nav-link" href="#nltk.tokenize.sent_tokenize"><span class="header-section-number">17.3.3</span> nltk.tokenize.sent_tokenize()</a></li>
</ul>
</li>
<li><a class="nav-link" href="#n-gram"><span class="header-section-number">17.4</span> N-Gram</a></li>
<li>
<a class="nav-link" href="#stopwords"><span class="header-section-number">17.5</span> Stopwords</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#custom-stop-words"><span class="header-section-number">17.5.1</span> Custom Stop Words</a></li>
<li><a class="nav-link" href="#nltk-stop-words"><span class="header-section-number">17.5.2</span> NLTK Stop Words</a></li>
<li><a class="nav-link" href="#sklearn-stop-words"><span class="header-section-number">17.5.3</span> SKLearn Stop Words</a></li>
<li><a class="nav-link" href="#combined-nltk-and-sklearn-stop-words"><span class="header-section-number">17.5.4</span> Combined NLTK and SKLearn Stop Words</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#normalizing"><span class="header-section-number">17.6</span> Normalizing</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#case-folding"><span class="header-section-number">17.6.1</span> Case Folding</a></li>
<li><a class="nav-link" href="#stemming"><span class="header-section-number">17.6.2</span> Stemming</a></li>
<li><a class="nav-link" href="#lemmatization"><span class="header-section-number">17.6.3</span> Lemmatization</a></li>
<li><a class="nav-link" href="#comparing-stemming-and-lemmatization"><span class="header-section-number">17.6.4</span> Comparing Stemming and Lemmatization</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#wordnet"><span class="header-section-number">17.7</span> Wordnet</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#nltk-and-wordnet"><span class="header-section-number">17.7.1</span> NLTK and Wordnet</a></li>
<li><a class="nav-link" href="#synset"><span class="header-section-number">17.7.2</span> Synset</a></li>
<li><a class="nav-link" href="#synsets"><span class="header-section-number">17.7.3</span> Synsets</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#part-of-speech-pos"><span class="header-section-number">17.8</span> Part Of Speech (POS)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#tag-sets"><span class="header-section-number">17.8.1</span> Tag Sets</a></li>
<li><a class="nav-link" href="#tagging-techniques"><span class="header-section-number">17.8.2</span> Tagging Techniques</a></li>
<li><a class="nav-link" href="#performing-tagging-nltk.pos_tag"><span class="header-section-number">17.8.3</span> Performing Tagging nltk.pos_tag()</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sentiment"><span class="header-section-number">17.9</span> Sentiment</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#nltk-and-senti-wordnet"><span class="header-section-number">17.9.1</span> NLTK and Senti-Wordnet</a></li>
<li><a class="nav-link" href="#vader"><span class="header-section-number">17.9.2</span> Vader</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#feature-representation"><span class="header-section-number">17.10</span> Feature Representation</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-data-3"><span class="header-section-number">17.10.1</span> The Data</a></li>
<li><a class="nav-link" href="#frequency-count-1"><span class="header-section-number">17.10.2</span> Frequency Count</a></li>
<li><a class="nav-link" href="#tfidf"><span class="header-section-number">17.10.3</span> TFIDF</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#appliction"><span class="header-section-number">17.11</span> Appliction</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#document-similarity"><span class="header-section-number">17.11.1</span> Document Similarity</a></li></ul>
</li>
<li>
<a class="nav-link" href="#naive-bayes"><span class="header-section-number">17.12</span> Naive Bayes</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#libraries"><span class="header-section-number">17.12.1</span> Libraries</a></li>
<li><a class="nav-link" href="#the-data-4"><span class="header-section-number">17.12.2</span> The Data</a></li>
<li><a class="nav-link" href="#bag-of-words"><span class="header-section-number">17.12.3</span> Bag of Words</a></li>
<li><a class="nav-link" href="#build-the-model"><span class="header-section-number">17.12.4</span> Build The Model</a></li>
<li><a class="nav-link" href="#train-set-prediction"><span class="header-section-number">17.12.5</span> Train Set Prediction</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com//f0nzie/yongks-python-rmarkdown-book/blob/master/06-nlp.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com//f0nzie/yongks-python-rmarkdown-book/edit/master/06-nlp.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Python Bookdown</strong>" was written by Yong Keh Soon. It was last built on 2020-11-20.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
