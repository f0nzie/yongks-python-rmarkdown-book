<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>18 NLP | Python Bookdown</title>
  <meta name="description" content="This is a python cookbook, written using RMarkdown Notebook. It is made possible by using reticulate R library as the bridge between R and Python." />
  <meta name="generator" content="bookdown 0.18.1 and GitBook 2.6.7" />

  <meta property="og:title" content="18 NLP | Python Bookdown" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a python cookbook, written using RMarkdown Notebook. It is made possible by using reticulate R library as the bridge between R and Python." />
  <meta name="github-repo" content="yongks/python_bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="18 NLP | Python Bookdown" />
  
  <meta name="twitter:description" content="This is a python cookbook, written using RMarkdown Notebook. It is made possible by using reticulate R library as the bridge between R and Python." />
  

<meta name="author" content="Yong Keh Soon" />


<meta name="date" content="2020-04-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sklearn.html"/>
<link rel="next" href="web-scrapping.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="custom.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Python Bookdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="1" data-path="fundamentals.html"><a href="fundamentals.html"><i class="fa fa-check"></i><b>1</b> Fundamentals</a><ul>
<li class="chapter" data-level="1.1" data-path="fundamentals.html"><a href="fundamentals.html#library-management"><i class="fa fa-check"></i><b>1.1</b> Library Management</a><ul>
<li class="chapter" data-level="1.1.1" data-path="fundamentals.html"><a href="fundamentals.html#built-in-libraries"><i class="fa fa-check"></i><b>1.1.1</b> Built-In Libraries</a></li>
<li class="chapter" data-level="1.1.2" data-path="fundamentals.html"><a href="fundamentals.html#common-external-libraries"><i class="fa fa-check"></i><b>1.1.2</b> Common External Libraries</a><ul>
<li class="chapter" data-level="1.1.2.1" data-path="fundamentals.html"><a href="fundamentals.html#numpy"><i class="fa fa-check"></i><b>1.1.2.1</b> numpy</a></li>
<li class="chapter" data-level="1.1.2.2" data-path="fundamentals.html"><a href="fundamentals.html#scipy"><i class="fa fa-check"></i><b>1.1.2.2</b> scipy</a></li>
<li class="chapter" data-level="1.1.2.3" data-path="fundamentals.html"><a href="fundamentals.html#pandas"><i class="fa fa-check"></i><b>1.1.2.3</b> Pandas</a></li>
<li class="chapter" data-level="1.1.2.4" data-path="fundamentals.html"><a href="fundamentals.html#scikit-learn"><i class="fa fa-check"></i><b>1.1.2.4</b> scikit-learn</a></li>
<li class="chapter" data-level="1.1.2.5" data-path="fundamentals.html"><a href="fundamentals.html#matplotlib"><i class="fa fa-check"></i><b>1.1.2.5</b> matplotlib</a></li>
</ul></li>
<li class="chapter" data-level="1.1.3" data-path="fundamentals.html"><a href="fundamentals.html#package-management"><i class="fa fa-check"></i><b>1.1.3</b> Package Management</a></li>
<li class="chapter" data-level="1.1.4" data-path="fundamentals.html"><a href="fundamentals.html#conda"><i class="fa fa-check"></i><b>1.1.4</b> Conda</a><ul>
<li class="chapter" data-level="1.1.4.1" data-path="fundamentals.html"><a href="fundamentals.html#conda-environment"><i class="fa fa-check"></i><b>1.1.4.1</b> Conda Environment</a></li>
<li class="chapter" data-level="1.1.4.2" data-path="fundamentals.html"><a href="fundamentals.html#package-version"><i class="fa fa-check"></i><b>1.1.4.2</b> Package Version</a></li>
<li class="chapter" data-level="1.1.4.3" data-path="fundamentals.html"><a href="fundamentals.html#package-installation"><i class="fa fa-check"></i><b>1.1.4.3</b> Package Installation</a></li>
</ul></li>
<li class="chapter" data-level="1.1.5" data-path="fundamentals.html"><a href="fundamentals.html#pip"><i class="fa fa-check"></i><b>1.1.5</b> PIP</a><ul>
<li class="chapter" data-level="1.1.5.1" data-path="fundamentals.html"><a href="fundamentals.html#package-version-1"><i class="fa fa-check"></i><b>1.1.5.1</b> Package Version</a></li>
<li class="chapter" data-level="1.1.5.2" data-path="fundamentals.html"><a href="fundamentals.html#package-installation-1"><i class="fa fa-check"></i><b>1.1.5.2</b> Package Installation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="fundamentals.html"><a href="fundamentals.html#everything-is-object"><i class="fa fa-check"></i><b>1.2</b> Everything Is Object</a></li>
<li class="chapter" data-level="1.3" data-path="fundamentals.html"><a href="fundamentals.html#assignment"><i class="fa fa-check"></i><b>1.3</b> Assignment</a><ul>
<li class="chapter" data-level="1.3.1" data-path="fundamentals.html"><a href="fundamentals.html#multiple-assignment"><i class="fa fa-check"></i><b>1.3.1</b> Multiple Assignment</a></li>
<li class="chapter" data-level="1.3.2" data-path="fundamentals.html"><a href="fundamentals.html#augmented-assignment"><i class="fa fa-check"></i><b>1.3.2</b> Augmented Assignment</a></li>
<li class="chapter" data-level="1.3.3" data-path="fundamentals.html"><a href="fundamentals.html#unpacking-assingment"><i class="fa fa-check"></i><b>1.3.3</b> Unpacking Assingment</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="built-in-data-types.html"><a href="built-in-data-types.html"><i class="fa fa-check"></i><b>2</b> Built-in Data Types</a><ul>
<li class="chapter" data-level="2.1" data-path="built-in-data-types.html"><a href="built-in-data-types.html#numbers"><i class="fa fa-check"></i><b>2.1</b> Numbers</a><ul>
<li class="chapter" data-level="2.1.1" data-path="built-in-data-types.html"><a href="built-in-data-types.html#integer"><i class="fa fa-check"></i><b>2.1.1</b> Integer</a></li>
<li class="chapter" data-level="2.1.2" data-path="built-in-data-types.html"><a href="built-in-data-types.html#float"><i class="fa fa-check"></i><b>2.1.2</b> Float</a></li>
<li class="chapter" data-level="2.1.3" data-path="built-in-data-types.html"><a href="built-in-data-types.html#number-operators"><i class="fa fa-check"></i><b>2.1.3</b> Number Operators</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="built-in-data-types.html"><a href="built-in-data-types.html#string"><i class="fa fa-check"></i><b>2.2</b> String</a><ul>
<li class="chapter" data-level="2.2.1" data-path="built-in-data-types.html"><a href="built-in-data-types.html#constructor"><i class="fa fa-check"></i><b>2.2.1</b> Constructor</a><ul>
<li class="chapter" data-level="2.2.1.1" data-path="built-in-data-types.html"><a href="built-in-data-types.html#classical-method"><i class="fa fa-check"></i><b>2.2.1.1</b> Classical Method</a></li>
<li class="chapter" data-level="2.2.1.2" data-path="built-in-data-types.html"><a href="built-in-data-types.html#shortcut-method"><i class="fa fa-check"></i><b>2.2.1.2</b> Shortcut Method</a></li>
<li class="chapter" data-level="2.2.1.3" data-path="built-in-data-types.html"><a href="built-in-data-types.html#multiline-method"><i class="fa fa-check"></i><b>2.2.1.3</b> Multiline Method</a></li>
<li class="chapter" data-level="2.2.1.4" data-path="built-in-data-types.html"><a href="built-in-data-types.html#immutability"><i class="fa fa-check"></i><b>2.2.1.4</b> Immutability</a></li>
</ul></li>
<li class="chapter" data-level="2.2.2" data-path="built-in-data-types.html"><a href="built-in-data-types.html#class-constants"><i class="fa fa-check"></i><b>2.2.2</b> Class Constants</a><ul>
<li class="chapter" data-level="2.2.2.1" data-path="built-in-data-types.html"><a href="built-in-data-types.html#letters"><i class="fa fa-check"></i><b>2.2.2.1</b> Letters</a></li>
<li class="chapter" data-level="2.2.2.2" data-path="built-in-data-types.html"><a href="built-in-data-types.html#digits"><i class="fa fa-check"></i><b>2.2.2.2</b> Digits</a></li>
<li class="chapter" data-level="2.2.2.3" data-path="built-in-data-types.html"><a href="built-in-data-types.html#white-spaces"><i class="fa fa-check"></i><b>2.2.2.3</b> White Spaces</a></li>
</ul></li>
<li class="chapter" data-level="2.2.3" data-path="built-in-data-types.html"><a href="built-in-data-types.html#instance-methods"><i class="fa fa-check"></i><b>2.2.3</b> Instance Methods</a><ul>
<li class="chapter" data-level="2.2.3.1" data-path="built-in-data-types.html"><a href="built-in-data-types.html#substitution-format"><i class="fa fa-check"></i><b>2.2.3.1</b> Substitution : <strong><code>format()</code></strong></a></li>
<li class="chapter" data-level="2.2.3.2" data-path="built-in-data-types.html"><a href="built-in-data-types.html#substitution-f-string"><i class="fa fa-check"></i><b>2.2.3.2</b> Substitution : <strong><code>f-string</code></strong></a></li>
<li class="chapter" data-level="2.2.3.3" data-path="built-in-data-types.html"><a href="built-in-data-types.html#conversion-upper-lower"><i class="fa fa-check"></i><b>2.2.3.3</b> Conversion: <code>upper() lower()</code></a></li>
<li class="chapter" data-level="2.2.3.4" data-path="built-in-data-types.html"><a href="built-in-data-types.html#find-pattern-position"><i class="fa fa-check"></i><b>2.2.3.4</b> <code>find()</code> pattern position</a></li>
<li class="chapter" data-level="2.2.3.5" data-path="built-in-data-types.html"><a href="built-in-data-types.html#strip-off-blank-spaces"><i class="fa fa-check"></i><b>2.2.3.5</b> <code>strip()</code> off blank spaces</a></li>
<li class="chapter" data-level="2.2.3.6" data-path="built-in-data-types.html"><a href="built-in-data-types.html#list-related-split"><i class="fa fa-check"></i><b>2.2.3.6</b> List Related: <code>split()</code></a></li>
<li class="chapter" data-level="2.2.3.7" data-path="built-in-data-types.html"><a href="built-in-data-types.html#list-related-join"><i class="fa fa-check"></i><b>2.2.3.7</b> List Related: <code>join()</code></a></li>
<li class="chapter" data-level="2.2.3.8" data-path="built-in-data-types.html"><a href="built-in-data-types.html#replacement-.replace"><i class="fa fa-check"></i><b>2.2.3.8</b> Replacement: <code>.replace()</code></a></li>
</ul></li>
<li class="chapter" data-level="2.2.4" data-path="built-in-data-types.html"><a href="built-in-data-types.html#operator"><i class="fa fa-check"></i><b>2.2.4</b> Operator</a><ul>
<li class="chapter" data-level="2.2.4.1" data-path="built-in-data-types.html"><a href="built-in-data-types.html#old-style-substitution"><i class="fa fa-check"></i><b>2.2.4.1</b> <code>%</code> Old Style Substitution</a></li>
<li class="chapter" data-level="2.2.4.2" data-path="built-in-data-types.html"><a href="built-in-data-types.html#concatenation"><i class="fa fa-check"></i><b>2.2.4.2</b> <code>+</code> Concatenation</a></li>
<li class="chapter" data-level="2.2.4.3" data-path="built-in-data-types.html"><a href="built-in-data-types.html#in-matching"><i class="fa fa-check"></i><b>2.2.4.3</b> <code>in</code> matching</a></li>
<li class="chapter" data-level="2.2.4.4" data-path="built-in-data-types.html"><a href="built-in-data-types.html#comparitor"><i class="fa fa-check"></i><b>2.2.4.4</b> Comparitor</a></li>
</ul></li>
<li class="chapter" data-level="2.2.5" data-path="built-in-data-types.html"><a href="built-in-data-types.html#iterations"><i class="fa fa-check"></i><b>2.2.5</b> Iterations</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="built-in-data-types.html"><a href="built-in-data-types.html#boolean"><i class="fa fa-check"></i><b>2.3</b> Boolean</a><ul>
<li class="chapter" data-level="2.3.1" data-path="built-in-data-types.html"><a href="built-in-data-types.html#what-is-considered-false"><i class="fa fa-check"></i><b>2.3.1</b> What is Considered False ?</a></li>
<li class="chapter" data-level="2.3.2" data-path="built-in-data-types.html"><a href="built-in-data-types.html#and-operator"><i class="fa fa-check"></i><b>2.3.2</b> <code>and</code> operator</a></li>
<li class="chapter" data-level="2.3.3" data-path="built-in-data-types.html"><a href="built-in-data-types.html#not-operator"><i class="fa fa-check"></i><b>2.3.3</b> <code>not</code> operator</a></li>
<li class="chapter" data-level="2.3.4" data-path="built-in-data-types.html"><a href="built-in-data-types.html#or-operator"><i class="fa fa-check"></i><b>2.3.4</b> <code>or</code> operator</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="built-in-data-types.html"><a href="built-in-data-types.html#none"><i class="fa fa-check"></i><b>2.4</b> None</a><ul>
<li class="chapter" data-level="2.4.1" data-path="built-in-data-types.html"><a href="built-in-data-types.html#none-is-an-object"><i class="fa fa-check"></i><b>2.4.1</b> None is an Object</a></li>
<li class="chapter" data-level="2.4.2" data-path="built-in-data-types.html"><a href="built-in-data-types.html#comparing-none"><i class="fa fa-check"></i><b>2.4.2</b> Comparing None</a></li>
<li class="chapter" data-level="2.4.3" data-path="built-in-data-types.html"><a href="built-in-data-types.html#operation-on-none"><i class="fa fa-check"></i><b>2.4.3</b> Operation on None</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html"><i class="fa fa-check"></i><b>3</b> Built-In Data Structure</a><ul>
<li class="chapter" data-level="3.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#tuple"><i class="fa fa-check"></i><b>3.1</b> Tuple</a><ul>
<li class="chapter" data-level="3.1.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#creating"><i class="fa fa-check"></i><b>3.1.1</b> Creating</a><ul>
<li class="chapter" data-level="3.1.1.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#constructor-1"><i class="fa fa-check"></i><b>3.1.1.1</b> Constructor</a></li>
<li class="chapter" data-level="3.1.1.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#assignment-1"><i class="fa fa-check"></i><b>3.1.1.2</b> Assignment</a></li>
</ul></li>
<li class="chapter" data-level="3.1.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#accessing"><i class="fa fa-check"></i><b>3.1.2</b> Accessing</a></li>
<li class="chapter" data-level="3.1.3" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#duplicating"><i class="fa fa-check"></i><b>3.1.3</b> Duplicating</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#list"><i class="fa fa-check"></i><b>3.2</b> List</a><ul>
<li class="chapter" data-level="3.2.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#creating-list"><i class="fa fa-check"></i><b>3.2.1</b> Creating List</a><ul>
<li class="chapter" data-level="3.2.1.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#empty-list"><i class="fa fa-check"></i><b>3.2.1.1</b> Empty List</a></li>
<li class="chapter" data-level="3.2.1.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#literal-assignment"><i class="fa fa-check"></i><b>3.2.1.2</b> Literal Assignment</a></li>
</ul></li>
<li class="chapter" data-level="3.2.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#accessing-items"><i class="fa fa-check"></i><b>3.2.2</b> Accessing Items</a></li>
<li class="chapter" data-level="3.2.3" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#methods"><i class="fa fa-check"></i><b>3.2.3</b> Methods</a><ul>
<li class="chapter" data-level="3.2.3.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#remove-items"><i class="fa fa-check"></i><b>3.2.3.1</b> Remove Item(s)</a></li>
<li class="chapter" data-level="3.2.3.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#appending-item-s"><i class="fa fa-check"></i><b>3.2.3.2</b> Appending Item (s)</a></li>
<li class="chapter" data-level="3.2.3.3" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#other-methods"><i class="fa fa-check"></i><b>3.2.3.3</b> Other Methods</a></li>
</ul></li>
<li class="chapter" data-level="3.2.4" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#operator-1"><i class="fa fa-check"></i><b>3.2.4</b> Operator</a><ul>
<li class="chapter" data-level="3.2.4.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#concatenation-1"><i class="fa fa-check"></i><b>3.2.4.1</b> Concatenation</a></li>
</ul></li>
<li class="chapter" data-level="3.2.5" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#list-is-mutable"><i class="fa fa-check"></i><b>3.2.5</b> List is Mutable</a></li>
<li class="chapter" data-level="3.2.6" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#duplicate-or-reference"><i class="fa fa-check"></i><b>3.2.6</b> Duplicate or Reference</a></li>
<li class="chapter" data-level="3.2.7" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#list-is-iterable"><i class="fa fa-check"></i><b>3.2.7</b> List Is Iterable</a><ul>
<li class="chapter" data-level="3.2.7.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#for-loop"><i class="fa fa-check"></i><b>3.2.7.1</b> For Loop</a></li>
<li class="chapter" data-level="3.2.7.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#list-comprehension"><i class="fa fa-check"></i><b>3.2.7.2</b> List Comprehension</a></li>
</ul></li>
<li class="chapter" data-level="3.2.8" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#conversion"><i class="fa fa-check"></i><b>3.2.8</b> Conversion</a></li>
<li class="chapter" data-level="3.2.9" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#built-in-functions-applicable-to-list"><i class="fa fa-check"></i><b>3.2.9</b> Built-In Functions Applicable To List</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#dictionaries"><i class="fa fa-check"></i><b>3.3</b> Dictionaries</a><ul>
<li class="chapter" data-level="3.3.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#creating-dict"><i class="fa fa-check"></i><b>3.3.1</b> Creating dict</a><ul>
<li class="chapter" data-level="3.3.1.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#from-literals"><i class="fa fa-check"></i><b>3.3.1.1</b> From Literals</a></li>
<li class="chapter" data-level="3.3.1.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#from-variables"><i class="fa fa-check"></i><b>3.3.1.2</b> From Variables</a></li>
</ul></li>
<li class="chapter" data-level="3.3.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#accessing-dict"><i class="fa fa-check"></i><b>3.3.2</b> Accessing dict</a><ul>
<li class="chapter" data-level="3.3.2.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#get-all-keys"><i class="fa fa-check"></i><b>3.3.2.1</b> Get All Keys</a></li>
<li class="chapter" data-level="3.3.2.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#get-all-values"><i class="fa fa-check"></i><b>3.3.2.2</b> Get All Values</a></li>
<li class="chapter" data-level="3.3.2.3" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#access-value-with-specific-key"><i class="fa fa-check"></i><b>3.3.2.3</b> Access value with Specific Key</a></li>
</ul></li>
<li class="chapter" data-level="3.3.3" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#dict-is-mutable"><i class="fa fa-check"></i><b>3.3.3</b> Dict Is Mutable</a><ul>
<li class="chapter" data-level="3.3.3.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#updateappend"><i class="fa fa-check"></i><b>3.3.3.1</b> Update/Append</a></li>
</ul></li>
<li class="chapter" data-level="3.3.4" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#iterating-elements"><i class="fa fa-check"></i><b>3.3.4</b> Iterating Elements</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#sets"><i class="fa fa-check"></i><b>3.4</b> Sets</a><ul>
<li class="chapter" data-level="3.4.1" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#creation"><i class="fa fa-check"></i><b>3.4.1</b> Creation</a></li>
<li class="chapter" data-level="3.4.2" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#membership-test"><i class="fa fa-check"></i><b>3.4.2</b> Membership Test</a></li>
<li class="chapter" data-level="3.4.3" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#subset-test"><i class="fa fa-check"></i><b>3.4.3</b> Subset Test</a></li>
<li class="chapter" data-level="3.4.4" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#union-using"><i class="fa fa-check"></i><b>3.4.4</b> Union using <code>|</code></a></li>
<li class="chapter" data-level="3.4.5" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#intersection-using"><i class="fa fa-check"></i><b>3.4.5</b> Intersection using <code>&amp;</code></a></li>
<li class="chapter" data-level="3.4.6" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#difference-using--"><i class="fa fa-check"></i><b>3.4.6</b> Difference using <code>-</code></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="built-in-data-structure.html"><a href="built-in-data-structure.html#range"><i class="fa fa-check"></i><b>3.5</b> range</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="control-and-loops.html"><a href="control-and-loops.html"><i class="fa fa-check"></i><b>4</b> Control and Loops</a><ul>
<li class="chapter" data-level="4.1" data-path="control-and-loops.html"><a href="control-and-loops.html#if-statement"><i class="fa fa-check"></i><b>4.1</b> If Statement</a><ul>
<li class="chapter" data-level="4.1.1" data-path="control-and-loops.html"><a href="control-and-loops.html#multiline-if..-statements"><i class="fa fa-check"></i><b>4.1.1</b> Multiline If.. Statements</a></li>
<li class="chapter" data-level="4.1.2" data-path="control-and-loops.html"><a href="control-and-loops.html#single-line-if-..-statement"><i class="fa fa-check"></i><b>4.1.2</b> Single Line If .. Statement</a><ul>
<li class="chapter" data-level="4.1.2.1" data-path="control-and-loops.html"><a href="control-and-loops.html#if-in-one-statement"><i class="fa fa-check"></i><b>4.1.2.1</b> if … In One Statement</a></li>
<li class="chapter" data-level="4.1.2.2" data-path="control-and-loops.html"><a href="control-and-loops.html#ternary-statemnt"><i class="fa fa-check"></i><b>4.1.2.2</b> Ternary Statemnt</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="control-and-loops.html"><a href="control-and-loops.html#for-loops"><i class="fa fa-check"></i><b>4.2</b> For Loops</a><ul>
<li class="chapter" data-level="4.2.1" data-path="control-and-loops.html"><a href="control-and-loops.html#for-..-else-construct"><i class="fa fa-check"></i><b>4.2.1</b> For .. Else Construct</a></li>
<li class="chapter" data-level="4.2.2" data-path="control-and-loops.html"><a href="control-and-loops.html#loop-thorugh-range"><i class="fa fa-check"></i><b>4.2.2</b> Loop thorugh ‘range’</a></li>
<li class="chapter" data-level="4.2.3" data-path="control-and-loops.html"><a href="control-and-loops.html#loop-through-list"><i class="fa fa-check"></i><b>4.2.3</b> Loop through ‘list’</a><ul>
<li class="chapter" data-level="4.2.3.1" data-path="control-and-loops.html"><a href="control-and-loops.html#standard-for-loop"><i class="fa fa-check"></i><b>4.2.3.1</b> Standard For Loop</a></li>
<li class="chapter" data-level="4.2.3.2" data-path="control-and-loops.html"><a href="control-and-loops.html#list-comprehension-1"><i class="fa fa-check"></i><b>4.2.3.2</b> List Comprehension</a></li>
</ul></li>
<li class="chapter" data-level="4.2.4" data-path="control-and-loops.html"><a href="control-and-loops.html#loop-through-dictionary"><i class="fa fa-check"></i><b>4.2.4</b> Loop Through ‘Dictionary’</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="control-and-loops.html"><a href="control-and-loops.html#generators"><i class="fa fa-check"></i><b>4.3</b> Generators</a><ul>
<li class="chapter" data-level="4.3.1" data-path="control-and-loops.html"><a href="control-and-loops.html#basic-generator-function"><i class="fa fa-check"></i><b>4.3.1</b> Basic Generator Function</a></li>
<li class="chapter" data-level="4.3.2" data-path="control-and-loops.html"><a href="control-and-loops.html#useful-generator-fuction"><i class="fa fa-check"></i><b>4.3.2</b> Useful Generator Fuction</a></li>
<li class="chapter" data-level="4.3.3" data-path="control-and-loops.html"><a href="control-and-loops.html#generator-expression"><i class="fa fa-check"></i><b>4.3.3</b> Generator Expression</a></li>
<li class="chapter" data-level="4.3.4" data-path="control-and-loops.html"><a href="control-and-loops.html#compare-to-iterator-class"><i class="fa fa-check"></i><b>4.3.4</b> Compare to Iterator Class</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="library-and-functions.html"><a href="library-and-functions.html"><i class="fa fa-check"></i><b>5</b> Library and Functions</a><ul>
<li class="chapter" data-level="5.1" data-path="library-and-functions.html"><a href="library-and-functions.html#package-source"><i class="fa fa-check"></i><b>5.1</b> Package Source</a><ul>
<li class="chapter" data-level="5.1.1" data-path="library-and-functions.html"><a href="library-and-functions.html#conda-1"><i class="fa fa-check"></i><b>5.1.1</b> Conda</a></li>
<li class="chapter" data-level="5.1.2" data-path="library-and-functions.html"><a href="library-and-functions.html#pip-1"><i class="fa fa-check"></i><b>5.1.2</b> PIP</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="library-and-functions.html"><a href="library-and-functions.html#importing-library"><i class="fa fa-check"></i><b>5.2</b> Importing Library</a><ul>
<li class="chapter" data-level="5.2.1" data-path="library-and-functions.html"><a href="library-and-functions.html#import-entire-library"><i class="fa fa-check"></i><b>5.2.1</b> Import Entire Library</a><ul>
<li class="chapter" data-level="5.2.1.1" data-path="library-and-functions.html"><a href="library-and-functions.html#import-into-standalone-namespace"><i class="fa fa-check"></i><b>5.2.1.1</b> Import Into Standalone Namespace</a></li>
<li class="chapter" data-level="5.2.1.2" data-path="library-and-functions.html"><a href="library-and-functions.html#import-into-global-name-space"><i class="fa fa-check"></i><b>5.2.1.2</b> Import Into Global Name Space</a></li>
</ul></li>
<li class="chapter" data-level="5.2.2" data-path="library-and-functions.html"><a href="library-and-functions.html#import-specific-function"><i class="fa fa-check"></i><b>5.2.2</b> Import Specific Function</a></li>
<li class="chapter" data-level="5.2.3" data-path="library-and-functions.html"><a href="library-and-functions.html#machine-learning-packages"><i class="fa fa-check"></i><b>5.2.3</b> Machine Learning Packages</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="library-and-functions.html"><a href="library-and-functions.html#define-function"><i class="fa fa-check"></i><b>5.3</b> Define Function</a><ul>
<li class="chapter" data-level="5.3.1" data-path="library-and-functions.html"><a href="library-and-functions.html#function-arguments"><i class="fa fa-check"></i><b>5.3.1</b> Function Arguments</a></li>
<li class="chapter" data-level="5.3.2" data-path="library-and-functions.html"><a href="library-and-functions.html#list-within-function"><i class="fa fa-check"></i><b>5.3.2</b> List Within Function</a></li>
<li class="chapter" data-level="5.3.3" data-path="library-and-functions.html"><a href="library-and-functions.html#return-statement"><i class="fa fa-check"></i><b>5.3.3</b> Return Statement</a></li>
<li class="chapter" data-level="5.3.4" data-path="library-and-functions.html"><a href="library-and-functions.html#no-return-statement"><i class="fa fa-check"></i><b>5.3.4</b> No Return Statement</a></li>
<li class="chapter" data-level="5.3.5" data-path="library-and-functions.html"><a href="library-and-functions.html#return-multiple-value"><i class="fa fa-check"></i><b>5.3.5</b> Return Multiple Value</a></li>
<li class="chapter" data-level="5.3.6" data-path="library-and-functions.html"><a href="library-and-functions.html#passing-function-as-argument"><i class="fa fa-check"></i><b>5.3.6</b> Passing Function as Argument</a></li>
<li class="chapter" data-level="5.3.7" data-path="library-and-functions.html"><a href="library-and-functions.html#arguments"><i class="fa fa-check"></i><b>5.3.7</b> Arguments</a><ul>
<li class="chapter" data-level="5.3.7.1" data-path="library-and-functions.html"><a href="library-and-functions.html#example-1"><i class="fa fa-check"></i><b>5.3.7.1</b> Example 1</a></li>
<li class="chapter" data-level="5.3.7.2" data-path="library-and-functions.html"><a href="library-and-functions.html#example-2"><i class="fa fa-check"></i><b>5.3.7.2</b> Example 2</a></li>
<li class="chapter" data-level="5.3.7.3" data-path="library-and-functions.html"><a href="library-and-functions.html#example-3"><i class="fa fa-check"></i><b>5.3.7.3</b> Example 3</a></li>
<li class="chapter" data-level="5.3.7.4" data-path="library-and-functions.html"><a href="library-and-functions.html#example-4"><i class="fa fa-check"></i><b>5.3.7.4</b> Example 4</a></li>
<li class="chapter" data-level="5.3.7.5" data-path="library-and-functions.html"><a href="library-and-functions.html#example-5"><i class="fa fa-check"></i><b>5.3.7.5</b> Example 5</a></li>
<li class="chapter" data-level="5.3.7.6" data-path="library-and-functions.html"><a href="library-and-functions.html#example-6-empty-args"><i class="fa fa-check"></i><b>5.3.7.6</b> Example 6 Empty args</a></li>
</ul></li>
<li class="chapter" data-level="5.3.8" data-path="library-and-functions.html"><a href="library-and-functions.html#keyword-arguments"><i class="fa fa-check"></i><b>5.3.8</b> keyword arguments</a><ul>
<li class="chapter" data-level="5.3.8.1" data-path="library-and-functions.html"><a href="library-and-functions.html#example-1-1"><i class="fa fa-check"></i><b>5.3.8.1</b> Example 1</a></li>
<li class="chapter" data-level="5.3.8.2" data-path="library-and-functions.html"><a href="library-and-functions.html#example-2-1"><i class="fa fa-check"></i><b>5.3.8.2</b> Example 2</a></li>
<li class="chapter" data-level="5.3.8.3" data-path="library-and-functions.html"><a href="library-and-functions.html#example-3-1"><i class="fa fa-check"></i><b>5.3.8.3</b> Example 3</a></li>
</ul></li>
<li class="chapter" data-level="5.3.9" data-path="library-and-functions.html"><a href="library-and-functions.html#mixing-args-kwargs"><i class="fa fa-check"></i><b>5.3.9</b> Mixing *args, **kwargs</a><ul>
<li class="chapter" data-level="5.3.9.1" data-path="library-and-functions.html"><a href="library-and-functions.html#example-1-2"><i class="fa fa-check"></i><b>5.3.9.1</b> Example 1</a></li>
<li class="chapter" data-level="5.3.9.2" data-path="library-and-functions.html"><a href="library-and-functions.html#example-2-2"><i class="fa fa-check"></i><b>5.3.9.2</b> Example 2</a></li>
</ul></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="exception-handling.html"><a href="exception-handling.html"><i class="fa fa-check"></i><b>6</b> Exception Handling</a><ul>
<li class="chapter" data-level="6.1" data-path="exception-handling.html"><a href="exception-handling.html#catching-error"><i class="fa fa-check"></i><b>6.1</b> Catching Error</a></li>
<li class="chapter" data-level="6.2" data-path="exception-handling.html"><a href="exception-handling.html#custom-exception"><i class="fa fa-check"></i><b>6.2</b> Custom Exception</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="object-oriented-programming.html"><a href="object-oriented-programming.html"><i class="fa fa-check"></i><b>7</b> Object Oriented Programming</a><ul>
<li class="chapter" data-level="7.1" data-path="object-oriented-programming.html"><a href="object-oriented-programming.html#defining-class"><i class="fa fa-check"></i><b>7.1</b> Defining Class</a></li>
<li class="chapter" data-level="7.2" data-path="object-oriented-programming.html"><a href="object-oriented-programming.html#constructor-2"><i class="fa fa-check"></i><b>7.2</b> Constructor</a></li>
<li class="chapter" data-level="7.3" data-path="object-oriented-programming.html"><a href="object-oriented-programming.html#calling-method"><i class="fa fa-check"></i><b>7.3</b> Calling Method</a></li>
<li class="chapter" data-level="7.4" data-path="object-oriented-programming.html"><a href="object-oriented-programming.html#getting-property"><i class="fa fa-check"></i><b>7.4</b> Getting Property</a></li>
<li class="chapter" data-level="7.5" data-path="object-oriented-programming.html"><a href="object-oriented-programming.html#setting-property"><i class="fa fa-check"></i><b>7.5</b> Setting Property</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="decorator.html"><a href="decorator.html"><i class="fa fa-check"></i><b>8</b> Decorator</a><ul>
<li class="chapter" data-level="8.1" data-path="decorator.html"><a href="decorator.html#definition"><i class="fa fa-check"></i><b>8.1</b> Definition</a></li>
<li class="chapter" data-level="8.2" data-path="decorator.html"><a href="decorator.html#examples"><i class="fa fa-check"></i><b>8.2</b> Examples</a><ul>
<li class="chapter" data-level="8.2.1" data-path="decorator.html"><a href="decorator.html#example-1---plain-decorator-function"><i class="fa fa-check"></i><b>8.2.1</b> Example 1 - Plain decorator function</a></li>
<li class="chapter" data-level="8.2.2" data-path="decorator.html"><a href="decorator.html#example-2---decorator-with-class"><i class="fa fa-check"></i><b>8.2.2</b> Example 2 - Decorator with Class</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html"><i class="fa fa-check"></i><b>9</b> datetime Standard Library</a><ul>
<li class="chapter" data-level="9.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#iso8601"><i class="fa fa-check"></i><b>9.1</b> ISO8601</a><ul>
<li class="chapter" data-level="9.1.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#date-time"><i class="fa fa-check"></i><b>9.1.1</b> Date Time</a></li>
<li class="chapter" data-level="9.1.2" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#date"><i class="fa fa-check"></i><b>9.1.2</b> Date</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#module-import"><i class="fa fa-check"></i><b>9.2</b> Module Import</a></li>
<li class="chapter" data-level="9.3" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#class"><i class="fa fa-check"></i><b>9.3</b> Class</a></li>
<li class="chapter" data-level="9.4" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#date-1"><i class="fa fa-check"></i><b>9.4</b> date</a><ul>
<li class="chapter" data-level="9.4.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#constructor-3"><i class="fa fa-check"></i><b>9.4.1</b> Constructor</a></li>
<li class="chapter" data-level="9.4.2" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#class-method"><i class="fa fa-check"></i><b>9.4.2</b> Class Method</a><ul>
<li class="chapter" data-level="9.4.2.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#today"><i class="fa fa-check"></i><b>9.4.2.1</b> <code>today</code></a></li>
<li class="chapter" data-level="9.4.2.2" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#convert-from-iso-fromisoformat"><i class="fa fa-check"></i><b>9.4.2.2</b> Convert From ISO <code>fromisoformat</code></a></li>
</ul></li>
<li class="chapter" data-level="9.4.3" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#instance-method"><i class="fa fa-check"></i><b>9.4.3</b> Instance Method</a><ul>
<li class="chapter" data-level="9.4.3.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#replace"><i class="fa fa-check"></i><b>9.4.3.1</b> <code>replace()</code></a></li>
<li class="chapter" data-level="9.4.3.2" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#weekday-isoweekday"><i class="fa fa-check"></i><b>9.4.3.2</b> <code>weekday(), isoweekday()</code></a></li>
<li class="chapter" data-level="9.4.3.3" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#formating-with-isoformat"><i class="fa fa-check"></i><b>9.4.3.3</b> Formating with <code>isoformat()</code></a></li>
<li class="chapter" data-level="9.4.3.4" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#formating-with-strftime"><i class="fa fa-check"></i><b>9.4.3.4</b> Formating with <code>strftime</code></a></li>
<li class="chapter" data-level="9.4.3.5" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#isocalendar"><i class="fa fa-check"></i><b>9.4.3.5</b> <code>isocalendar()</code></a></li>
</ul></li>
<li class="chapter" data-level="9.4.4" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#attributes"><i class="fa fa-check"></i><b>9.4.4</b> Attributes</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#date-and-datetime"><i class="fa fa-check"></i><b>9.5</b> date and datetime</a><ul>
<li class="chapter" data-level="9.5.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#constructor-4"><i class="fa fa-check"></i><b>9.5.1</b> Constructor</a></li>
<li class="chapter" data-level="9.5.2" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#class-method-1"><i class="fa fa-check"></i><b>9.5.2</b> Class Method</a><ul>
<li class="chapter" data-level="9.5.2.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#now-and-today"><i class="fa fa-check"></i><b>9.5.2.1</b> <code>now</code> and <code>today</code></a></li>
<li class="chapter" data-level="9.5.2.2" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#utcnow"><i class="fa fa-check"></i><b>9.5.2.2</b> <code>utcnow</code></a></li>
<li class="chapter" data-level="9.5.2.3" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#combine-date-and-time"><i class="fa fa-check"></i><b>9.5.2.3</b> <code>combine()</code> date and time</a></li>
<li class="chapter" data-level="9.5.2.4" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#convert-from-string-strptime"><i class="fa fa-check"></i><b>9.5.2.4</b> Convert from String <code>strptime()</code></a></li>
<li class="chapter" data-level="9.5.2.5" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#convert-from-iso-fromisoformat-1"><i class="fa fa-check"></i><b>9.5.2.5</b> Convert from ISO <code>fromisoformat</code></a></li>
</ul></li>
<li class="chapter" data-level="9.5.3" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#instance-method-1"><i class="fa fa-check"></i><b>9.5.3</b> Instance Method</a><ul>
<li class="chapter" data-level="9.5.3.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#weekday"><i class="fa fa-check"></i><b>9.5.3.1</b> <code>weekday</code></a></li>
<li class="chapter" data-level="9.5.3.2" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#replace-1"><i class="fa fa-check"></i><b>9.5.3.2</b> <code>replace</code></a></li>
<li class="chapter" data-level="9.5.3.3" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#convert-to-.time"><i class="fa fa-check"></i><b>9.5.3.3</b> convert to <code>.time()</code></a></li>
<li class="chapter" data-level="9.5.3.4" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#convert-to-.date"><i class="fa fa-check"></i><b>9.5.3.4</b> Convert to <code>.date()</code></a></li>
<li class="chapter" data-level="9.5.3.5" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#convert-to-string"><i class="fa fa-check"></i><b>9.5.3.5</b> Convert to String</a></li>
</ul></li>
<li class="chapter" data-level="9.5.4" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#attributes-1"><i class="fa fa-check"></i><b>9.5.4</b> Attributes</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#time"><i class="fa fa-check"></i><b>9.6</b> time</a><ul>
<li class="chapter" data-level="9.6.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#constructor-5"><i class="fa fa-check"></i><b>9.6.1</b> Constructor</a></li>
<li class="chapter" data-level="9.6.2" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#class-method-2"><i class="fa fa-check"></i><b>9.6.2</b> Class Method</a><ul>
<li class="chapter" data-level="9.6.2.1" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#now"><i class="fa fa-check"></i><b>9.6.2.1</b> <code>now()</code></a></li>
</ul></li>
<li class="chapter" data-level="9.6.3" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#attributes-2"><i class="fa fa-check"></i><b>9.6.3</b> Attributes</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="datetime-standard-library.html"><a href="datetime-standard-library.html#timedelta"><i class="fa fa-check"></i><b>9.7</b> timedelta</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="getting-external-data.html"><a href="getting-external-data.html"><i class="fa fa-check"></i><b>10</b> Getting External Data</a></li>
<li class="chapter" data-level="11" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html"><i class="fa fa-check"></i><b>11</b> Plydata (dplyr for Python)</a><ul>
<li class="chapter" data-level="11.1" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#sample-data"><i class="fa fa-check"></i><b>11.1</b> Sample Data</a></li>
<li class="chapter" data-level="11.2" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#column-manipulation"><i class="fa fa-check"></i><b>11.2</b> Column Manipulation</a><ul>
<li class="chapter" data-level="11.2.1" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#copy-column"><i class="fa fa-check"></i><b>11.2.1</b> Copy Column</a></li>
<li class="chapter" data-level="11.2.2" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#new-column-from-existing-column"><i class="fa fa-check"></i><b>11.2.2</b> New Column from existing Column</a></li>
<li class="chapter" data-level="11.2.3" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#select-columns"><i class="fa fa-check"></i><b>11.2.3</b> Select Column(s)</a><ul>
<li class="chapter" data-level="11.2.3.1" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#by-column-names"><i class="fa fa-check"></i><b>11.2.3.1</b> By Column Names</a></li>
<li class="chapter" data-level="11.2.3.2" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#specify-column-range"><i class="fa fa-check"></i><b>11.2.3.2</b> Specify Column Range</a></li>
</ul></li>
<li class="chapter" data-level="11.2.4" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#drop-columns"><i class="fa fa-check"></i><b>11.2.4</b> Drop Column(s)</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#sorting-arrange"><i class="fa fa-check"></i><b>11.3</b> Sorting (arrange)</a></li>
<li class="chapter" data-level="11.4" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#grouping"><i class="fa fa-check"></i><b>11.4</b> Grouping</a></li>
<li class="chapter" data-level="11.5" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#summarization"><i class="fa fa-check"></i><b>11.5</b> Summarization</a><ul>
<li class="chapter" data-level="11.5.1" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#simple-method"><i class="fa fa-check"></i><b>11.5.1</b> Simple Method</a></li>
<li class="chapter" data-level="11.5.2" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#specify-summarized-column-name"><i class="fa fa-check"></i><b>11.5.2</b> Specify Summarized Column Name</a></li>
<li class="chapter" data-level="11.5.3" data-path="plydata-dplyr-for-python.html"><a href="plydata-dplyr-for-python.html#number-of-rows-in-group"><i class="fa fa-check"></i><b>11.5.3</b> Number of Rows in Group</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="numpy-1.html"><a href="numpy-1.html"><i class="fa fa-check"></i><b>12</b> numpy</a><ul>
<li class="chapter" data-level="12.1" data-path="numpy-1.html"><a href="numpy-1.html#environment-setup"><i class="fa fa-check"></i><b>12.1</b> Environment Setup</a></li>
<li class="chapter" data-level="12.2" data-path="numpy-1.html"><a href="numpy-1.html#module-import-1"><i class="fa fa-check"></i><b>12.2</b> Module Import</a></li>
<li class="chapter" data-level="12.3" data-path="numpy-1.html"><a href="numpy-1.html#data-types"><i class="fa fa-check"></i><b>12.3</b> Data Types</a><ul>
<li class="chapter" data-level="12.3.1" data-path="numpy-1.html"><a href="numpy-1.html#numpy-data-types"><i class="fa fa-check"></i><b>12.3.1</b> NumPy Data Types</a></li>
<li class="chapter" data-level="12.3.2" data-path="numpy-1.html"><a href="numpy-1.html#int3264"><i class="fa fa-check"></i><b>12.3.2</b> int32/64</a></li>
<li class="chapter" data-level="12.3.3" data-path="numpy-1.html"><a href="numpy-1.html#float3264"><i class="fa fa-check"></i><b>12.3.3</b> float32/64</a></li>
<li class="chapter" data-level="12.3.4" data-path="numpy-1.html"><a href="numpy-1.html#bool"><i class="fa fa-check"></i><b>12.3.4</b> bool</a></li>
<li class="chapter" data-level="12.3.5" data-path="numpy-1.html"><a href="numpy-1.html#str"><i class="fa fa-check"></i><b>12.3.5</b> str</a></li>
<li class="chapter" data-level="12.3.6" data-path="numpy-1.html"><a href="numpy-1.html#datetime64"><i class="fa fa-check"></i><b>12.3.6</b> datetime64</a><ul>
<li class="chapter" data-level="12.3.6.1" data-path="numpy-1.html"><a href="numpy-1.html#constructor-6"><i class="fa fa-check"></i><b>12.3.6.1</b> Constructor</a></li>
<li class="chapter" data-level="12.3.6.2" data-path="numpy-1.html"><a href="numpy-1.html#instance-method-2"><i class="fa fa-check"></i><b>12.3.6.2</b> Instance Method</a></li>
</ul></li>
<li class="chapter" data-level="12.3.7" data-path="numpy-1.html"><a href="numpy-1.html#nan"><i class="fa fa-check"></i><b>12.3.7</b> nan</a><ul>
<li class="chapter" data-level="12.3.7.1" data-path="numpy-1.html"><a href="numpy-1.html#creating-nan"><i class="fa fa-check"></i><b>12.3.7.1</b> Creating NaN</a></li>
<li class="chapter" data-level="12.3.7.2" data-path="numpy-1.html"><a href="numpy-1.html#detecting-nan"><i class="fa fa-check"></i><b>12.3.7.2</b> Detecting NaN</a></li>
<li class="chapter" data-level="12.3.7.3" data-path="numpy-1.html"><a href="numpy-1.html#operation"><i class="fa fa-check"></i><b>12.3.7.3</b> Operation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="numpy-1.html"><a href="numpy-1.html#numpy-array"><i class="fa fa-check"></i><b>12.4</b> Numpy Array</a><ul>
<li class="chapter" data-level="12.4.1" data-path="numpy-1.html"><a href="numpy-1.html#concept"><i class="fa fa-check"></i><b>12.4.1</b> Concept</a></li>
<li class="chapter" data-level="12.4.2" data-path="numpy-1.html"><a href="numpy-1.html#constructor-7"><i class="fa fa-check"></i><b>12.4.2</b> Constructor</a><ul>
<li class="chapter" data-level="12.4.2.1" data-path="numpy-1.html"><a href="numpy-1.html#dtype-int-float"><i class="fa fa-check"></i><b>12.4.2.1</b> dType: int, float</a></li>
<li class="chapter" data-level="12.4.2.2" data-path="numpy-1.html"><a href="numpy-1.html#dtype-datetime64"><i class="fa fa-check"></i><b>12.4.2.2</b> dType: datetime64</a></li>
<li class="chapter" data-level="12.4.2.3" data-path="numpy-1.html"><a href="numpy-1.html#d-array"><i class="fa fa-check"></i><b>12.4.2.3</b> 2D Array</a></li>
</ul></li>
<li class="chapter" data-level="12.4.3" data-path="numpy-1.html"><a href="numpy-1.html#dimensions"><i class="fa fa-check"></i><b>12.4.3</b> Dimensions</a><ul>
<li class="chapter" data-level="12.4.3.1" data-path="numpy-1.html"><a href="numpy-1.html#differentiating-dimensions"><i class="fa fa-check"></i><b>12.4.3.1</b> Differentiating Dimensions</a></li>
<li class="chapter" data-level="12.4.3.2" data-path="numpy-1.html"><a href="numpy-1.html#d-array-1"><i class="fa fa-check"></i><b>12.4.3.2</b> 1-D Array</a></li>
<li class="chapter" data-level="12.4.3.3" data-path="numpy-1.html"><a href="numpy-1.html#d-array-2"><i class="fa fa-check"></i><b>12.4.3.3</b> 2-D Array</a></li>
<li class="chapter" data-level="12.4.3.4" data-path="numpy-1.html"><a href="numpy-1.html#d-array---single-row"><i class="fa fa-check"></i><b>12.4.3.4</b> 2-D Array - Single Row</a></li>
<li class="chapter" data-level="12.4.3.5" data-path="numpy-1.html"><a href="numpy-1.html#d-array-single-column"><i class="fa fa-check"></i><b>12.4.3.5</b> 2-D Array : Single Column</a></li>
</ul></li>
<li class="chapter" data-level="12.4.4" data-path="numpy-1.html"><a href="numpy-1.html#class-method-3"><i class="fa fa-check"></i><b>12.4.4</b> Class Method</a><ul>
<li class="chapter" data-level="12.4.4.1" data-path="numpy-1.html"><a href="numpy-1.html#arange"><i class="fa fa-check"></i><b>12.4.4.1</b> <code>arange()</code></a></li>
<li class="chapter" data-level="12.4.4.2" data-path="numpy-1.html"><a href="numpy-1.html#ones"><i class="fa fa-check"></i><b>12.4.4.2</b> <code>ones()</code></a></li>
<li class="chapter" data-level="12.4.4.3" data-path="numpy-1.html"><a href="numpy-1.html#zeros"><i class="fa fa-check"></i><b>12.4.4.3</b> <code>zeros()</code></a></li>
<li class="chapter" data-level="12.4.4.4" data-path="numpy-1.html"><a href="numpy-1.html#where"><i class="fa fa-check"></i><b>12.4.4.4</b> <code>where()</code></a></li>
<li class="chapter" data-level="12.4.4.5" data-path="numpy-1.html"><a href="numpy-1.html#logical-methods"><i class="fa fa-check"></i><b>12.4.4.5</b> Logical Methods</a></li>
</ul></li>
<li class="chapter" data-level="12.4.5" data-path="numpy-1.html"><a href="numpy-1.html#instance-method-3"><i class="fa fa-check"></i><b>12.4.5</b> Instance Method</a><ul>
<li class="chapter" data-level="12.4.5.1" data-path="numpy-1.html"><a href="numpy-1.html#astype-conversion"><i class="fa fa-check"></i><b>12.4.5.1</b> <code>astype()</code> conversion</a></li>
<li class="chapter" data-level="12.4.5.2" data-path="numpy-1.html"><a href="numpy-1.html#reshape"><i class="fa fa-check"></i><b>12.4.5.2</b> <code>reshape()</code></a></li>
</ul></li>
<li class="chapter" data-level="12.4.6" data-path="numpy-1.html"><a href="numpy-1.html#element-selection"><i class="fa fa-check"></i><b>12.4.6</b> Element Selection</a><ul>
<li class="chapter" data-level="12.4.6.1" data-path="numpy-1.html"><a href="numpy-1.html#sample-data-1"><i class="fa fa-check"></i><b>12.4.6.1</b> Sample Data</a></li>
<li class="chapter" data-level="12.4.6.2" data-path="numpy-1.html"><a href="numpy-1.html#dimension"><i class="fa fa-check"></i><b>12.4.6.2</b> 1-Dimension</a></li>
<li class="chapter" data-level="12.4.6.3" data-path="numpy-1.html"><a href="numpy-1.html#dimension-1"><i class="fa fa-check"></i><b>12.4.6.3</b> 2-Dimension</a></li>
</ul></li>
<li class="chapter" data-level="12.4.7" data-path="numpy-1.html"><a href="numpy-1.html#attributes-3"><i class="fa fa-check"></i><b>12.4.7</b> Attributes</a><ul>
<li class="chapter" data-level="12.4.7.1" data-path="numpy-1.html"><a href="numpy-1.html#dtype"><i class="fa fa-check"></i><b>12.4.7.1</b> <code>dtype</code></a></li>
<li class="chapter" data-level="12.4.7.2" data-path="numpy-1.html"><a href="numpy-1.html#dim"><i class="fa fa-check"></i><b>12.4.7.2</b> <code>dim</code></a></li>
<li class="chapter" data-level="12.4.7.3" data-path="numpy-1.html"><a href="numpy-1.html#shape"><i class="fa fa-check"></i><b>12.4.7.3</b> <code>shape</code></a></li>
</ul></li>
<li class="chapter" data-level="12.4.8" data-path="numpy-1.html"><a href="numpy-1.html#operations"><i class="fa fa-check"></i><b>12.4.8</b> Operations</a><ul>
<li class="chapter" data-level="12.4.8.1" data-path="numpy-1.html"><a href="numpy-1.html#arithmetic"><i class="fa fa-check"></i><b>12.4.8.1</b> Arithmetic</a></li>
<li class="chapter" data-level="12.4.8.2" data-path="numpy-1.html"><a href="numpy-1.html#comparison"><i class="fa fa-check"></i><b>12.4.8.2</b> Comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="numpy-1.html"><a href="numpy-1.html#random-numbers"><i class="fa fa-check"></i><b>12.5</b> Random Numbers</a><ul>
<li class="chapter" data-level="12.5.1" data-path="numpy-1.html"><a href="numpy-1.html#uniform-distribution"><i class="fa fa-check"></i><b>12.5.1</b> Uniform Distribution</a><ul>
<li class="chapter" data-level="12.5.1.1" data-path="numpy-1.html"><a href="numpy-1.html#random-integer-with-replacement"><i class="fa fa-check"></i><b>12.5.1.1</b> Random Integer (with Replacement)</a></li>
<li class="chapter" data-level="12.5.1.2" data-path="numpy-1.html"><a href="numpy-1.html#random-integer-with-or-without-replacement"><i class="fa fa-check"></i><b>12.5.1.2</b> Random Integer (with or without replacement)</a></li>
<li class="chapter" data-level="12.5.1.3" data-path="numpy-1.html"><a href="numpy-1.html#random-float"><i class="fa fa-check"></i><b>12.5.1.3</b> Random Float</a></li>
</ul></li>
<li class="chapter" data-level="12.5.2" data-path="numpy-1.html"><a href="numpy-1.html#normal-distribution"><i class="fa fa-check"></i><b>12.5.2</b> Normal Distribution</a><ul>
<li class="chapter" data-level="12.5.2.1" data-path="numpy-1.html"><a href="numpy-1.html#standard-normal-distribution"><i class="fa fa-check"></i><b>12.5.2.1</b> Standard Normal Distribution</a></li>
<li class="chapter" data-level="12.5.2.2" data-path="numpy-1.html"><a href="numpy-1.html#normal-distribution-non-standard"><i class="fa fa-check"></i><b>12.5.2.2</b> Normal Distribution (Non-Standard)</a></li>
<li class="chapter" data-level="12.5.2.3" data-path="numpy-1.html"><a href="numpy-1.html#linear-spacing"><i class="fa fa-check"></i><b>12.5.2.3</b> Linear Spacing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="numpy-1.html"><a href="numpy-1.html#sampling-integer"><i class="fa fa-check"></i><b>12.6</b> Sampling (Integer)</a></li>
<li class="chapter" data-level="12.7" data-path="numpy-1.html"><a href="numpy-1.html#nan-missing-numerical-data"><i class="fa fa-check"></i><b>12.7</b> NaN : Missing Numerical Data</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="pandas-1.html"><a href="pandas-1.html"><i class="fa fa-check"></i><b>13</b> pandas</a><ul>
<li class="chapter" data-level="13.1" data-path="pandas-1.html"><a href="pandas-1.html#modules-import"><i class="fa fa-check"></i><b>13.1</b> Modules Import</a></li>
<li class="chapter" data-level="13.2" data-path="pandas-1.html"><a href="pandas-1.html#pandas-objects"><i class="fa fa-check"></i><b>13.2</b> Pandas Objects</a><ul>
<li class="chapter" data-level="13.2.1" data-path="pandas-1.html"><a href="pandas-1.html#pandas-data-types"><i class="fa fa-check"></i><b>13.2.1</b> Pandas Data Types</a></li>
<li class="chapter" data-level="13.2.2" data-path="pandas-1.html"><a href="pandas-1.html#pandas-data-structure"><i class="fa fa-check"></i><b>13.2.2</b> Pandas Data Structure</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="pandas-1.html"><a href="pandas-1.html#class-method-4"><i class="fa fa-check"></i><b>13.3</b> Class Method</a><ul>
<li class="chapter" data-level="13.3.1" data-path="pandas-1.html"><a href="pandas-1.html#creating-timestamp-objects"><i class="fa fa-check"></i><b>13.3.1</b> Creating Timestamp Objects</a><ul>
<li class="chapter" data-level="13.3.1.1" data-path="pandas-1.html"><a href="pandas-1.html#from-list-to-datetimeindex"><i class="fa fa-check"></i><b>13.3.1.1</b> From List to <code>DateTimeIndex</code></a></li>
<li class="chapter" data-level="13.3.1.2" data-path="pandas-1.html"><a href="pandas-1.html#from-list-to-series-of-timestamps"><i class="fa fa-check"></i><b>13.3.1.2</b> From List to Series of Timestamps</a></li>
<li class="chapter" data-level="13.3.1.3" data-path="pandas-1.html"><a href="pandas-1.html#from-scalar-to-timestamp"><i class="fa fa-check"></i><b>13.3.1.3</b> From Scalar to Timestamp</a></li>
</ul></li>
<li class="chapter" data-level="13.3.2" data-path="pandas-1.html"><a href="pandas-1.html#generate-timestamp-sequence"><i class="fa fa-check"></i><b>13.3.2</b> Generate Timestamp Sequence</a><ul>
<li class="chapter" data-level="13.3.2.1" data-path="pandas-1.html"><a href="pandas-1.html#hourly"><i class="fa fa-check"></i><b>13.3.2.1</b> Hourly</a></li>
<li class="chapter" data-level="13.3.2.2" data-path="pandas-1.html"><a href="pandas-1.html#daily"><i class="fa fa-check"></i><b>13.3.2.2</b> Daily</a></li>
<li class="chapter" data-level="13.3.2.3" data-path="pandas-1.html"><a href="pandas-1.html#first-day-of-month"><i class="fa fa-check"></i><b>13.3.2.3</b> First Day Of Month</a></li>
<li class="chapter" data-level="13.3.2.4" data-path="pandas-1.html"><a href="pandas-1.html#last-day-of-month"><i class="fa fa-check"></i><b>13.3.2.4</b> Last Day of Month</a></li>
</ul></li>
<li class="chapter" data-level="13.3.3" data-path="pandas-1.html"><a href="pandas-1.html#frequency-table-crosstab"><i class="fa fa-check"></i><b>13.3.3</b> Frequency Table (crosstab)</a><ul>
<li class="chapter" data-level="13.3.3.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-2"><i class="fa fa-check"></i><b>13.3.3.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.3.3.2" data-path="pandas-1.html"><a href="pandas-1.html#one-dimensiontable"><i class="fa fa-check"></i><b>13.3.3.2</b> One DimensionTable</a></li>
<li class="chapter" data-level="13.3.3.3" data-path="pandas-1.html"><a href="pandas-1.html#two-dimension-table"><i class="fa fa-check"></i><b>13.3.3.3</b> Two Dimension Table</a></li>
<li class="chapter" data-level="13.3.3.4" data-path="pandas-1.html"><a href="pandas-1.html#higher-dimension-table"><i class="fa fa-check"></i><b>13.3.3.4</b> Higher Dimension Table</a></li>
<li class="chapter" data-level="13.3.3.5" data-path="pandas-1.html"><a href="pandas-1.html#getting-margin"><i class="fa fa-check"></i><b>13.3.3.5</b> Getting Margin</a></li>
<li class="chapter" data-level="13.3.3.6" data-path="pandas-1.html"><a href="pandas-1.html#getting-proportion"><i class="fa fa-check"></i><b>13.3.3.6</b> Getting Proportion</a></li>
</ul></li>
<li class="chapter" data-level="13.3.4" data-path="pandas-1.html"><a href="pandas-1.html#concatination"><i class="fa fa-check"></i><b>13.3.4</b> Concatination</a><ul>
<li class="chapter" data-level="13.3.4.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-3"><i class="fa fa-check"></i><b>13.3.4.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.3.4.2" data-path="pandas-1.html"><a href="pandas-1.html#column-wise"><i class="fa fa-check"></i><b>13.3.4.2</b> Column-Wise</a></li>
<li class="chapter" data-level="13.3.4.3" data-path="pandas-1.html"><a href="pandas-1.html#row-wise"><i class="fa fa-check"></i><b>13.3.4.3</b> Row-Wise</a></li>
</ul></li>
<li class="chapter" data-level="13.3.5" data-path="pandas-1.html"><a href="pandas-1.html#external-data"><i class="fa fa-check"></i><b>13.3.5</b> External Data</a><ul>
<li class="chapter" data-level="13.3.5.1" data-path="pandas-1.html"><a href="pandas-1.html#html_table-parser"><i class="fa fa-check"></i><b>13.3.5.1</b> <code>html_table</code> Parser</a></li>
<li class="chapter" data-level="13.3.5.2" data-path="pandas-1.html"><a href="pandas-1.html#csv-writing"><i class="fa fa-check"></i><b>13.3.5.2</b> CSV Writing</a></li>
<li class="chapter" data-level="13.3.5.3" data-path="pandas-1.html"><a href="pandas-1.html#csv-reading"><i class="fa fa-check"></i><b>13.3.5.3</b> CSV Reading</a></li>
</ul></li>
<li class="chapter" data-level="13.3.6" data-path="pandas-1.html"><a href="pandas-1.html#inspection"><i class="fa fa-check"></i><b>13.3.6</b> Inspection</a><ul>
<li class="chapter" data-level="13.3.6.1" data-path="pandas-1.html"><a href="pandas-1.html#structure-info"><i class="fa fa-check"></i><b>13.3.6.1</b> Structure <code>info</code></a></li>
<li class="chapter" data-level="13.3.6.2" data-path="pandas-1.html"><a href="pandas-1.html#head"><i class="fa fa-check"></i><b>13.3.6.2</b> <code>head</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="pandas-1.html"><a href="pandas-1.html#class-timestamp"><i class="fa fa-check"></i><b>13.4</b> class: Timestamp</a><ul>
<li class="chapter" data-level="13.4.1" data-path="pandas-1.html"><a href="pandas-1.html#constructor-8"><i class="fa fa-check"></i><b>13.4.1</b> Constructor</a><ul>
<li class="chapter" data-level="13.4.1.1" data-path="pandas-1.html"><a href="pandas-1.html#from-number"><i class="fa fa-check"></i><b>13.4.1.1</b> From Number</a></li>
<li class="chapter" data-level="13.4.1.2" data-path="pandas-1.html"><a href="pandas-1.html#from-string"><i class="fa fa-check"></i><b>13.4.1.2</b> From String</a></li>
<li class="chapter" data-level="13.4.1.3" data-path="pandas-1.html"><a href="pandas-1.html#from-standard-library-datetime-and-date-object"><i class="fa fa-check"></i><b>13.4.1.3</b> From Standard Library <code>datetime</code> and <code>date</code> Object</a></li>
</ul></li>
<li class="chapter" data-level="13.4.2" data-path="pandas-1.html"><a href="pandas-1.html#attributes-4"><i class="fa fa-check"></i><b>13.4.2</b> Attributes</a></li>
<li class="chapter" data-level="13.4.3" data-path="pandas-1.html"><a href="pandas-1.html#instance-methods-1"><i class="fa fa-check"></i><b>13.4.3</b> Instance Methods</a><ul>
<li class="chapter" data-level="13.4.3.1" data-path="pandas-1.html"><a href="pandas-1.html#atribute-like-methods"><i class="fa fa-check"></i><b>13.4.3.1</b> Atribute-like Methods</a></li>
<li class="chapter" data-level="13.4.3.2" data-path="pandas-1.html"><a href="pandas-1.html#timezones"><i class="fa fa-check"></i><b>13.4.3.2</b> Timezones</a></li>
<li class="chapter" data-level="13.4.3.3" data-path="pandas-1.html"><a href="pandas-1.html#formatting"><i class="fa fa-check"></i><b>13.4.3.3</b> Formatting</a></li>
<li class="chapter" data-level="13.4.3.4" data-path="pandas-1.html"><a href="pandas-1.html#type-conversion"><i class="fa fa-check"></i><b>13.4.3.4</b> Type Conversion</a></li>
<li class="chapter" data-level="13.4.3.5" data-path="pandas-1.html"><a href="pandas-1.html#ceil"><i class="fa fa-check"></i><b>13.4.3.5</b> <code>ceil</code></a></li>
<li class="chapter" data-level="13.4.3.6" data-path="pandas-1.html"><a href="pandas-1.html#updating"><i class="fa fa-check"></i><b>13.4.3.6</b> Updating</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="pandas-1.html"><a href="pandas-1.html#class-datetimeindex"><i class="fa fa-check"></i><b>13.5</b> class: DateTimeIndex</a><ul>
<li class="chapter" data-level="13.5.1" data-path="pandas-1.html"><a href="pandas-1.html#creating-1"><i class="fa fa-check"></i><b>13.5.1</b> Creating</a></li>
<li class="chapter" data-level="13.5.2" data-path="pandas-1.html"><a href="pandas-1.html#instance-method-4"><i class="fa fa-check"></i><b>13.5.2</b> Instance Method</a><ul>
<li class="chapter" data-level="13.5.2.1" data-path="pandas-1.html"><a href="pandas-1.html#data-type-conversion"><i class="fa fa-check"></i><b>13.5.2.1</b> Data Type Conversion</a></li>
<li class="chapter" data-level="13.5.2.2" data-path="pandas-1.html"><a href="pandas-1.html#structure-conversion"><i class="fa fa-check"></i><b>13.5.2.2</b> Structure Conversion</a></li>
</ul></li>
<li class="chapter" data-level="13.5.3" data-path="pandas-1.html"><a href="pandas-1.html#attributes-5"><i class="fa fa-check"></i><b>13.5.3</b> Attributes</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="pandas-1.html"><a href="pandas-1.html#class-series"><i class="fa fa-check"></i><b>13.6</b> class: Series</a><ul>
<li class="chapter" data-level="13.6.1" data-path="pandas-1.html"><a href="pandas-1.html#constructor-9"><i class="fa fa-check"></i><b>13.6.1</b> Constructor</a><ul>
<li class="chapter" data-level="13.6.1.1" data-path="pandas-1.html"><a href="pandas-1.html#empty-series"><i class="fa fa-check"></i><b>13.6.1.1</b> Empty Series</a></li>
<li class="chapter" data-level="13.6.1.2" data-path="pandas-1.html"><a href="pandas-1.html#from-scalar"><i class="fa fa-check"></i><b>13.6.1.2</b> From Scalar</a></li>
<li class="chapter" data-level="13.6.1.3" data-path="pandas-1.html"><a href="pandas-1.html#from-array-like"><i class="fa fa-check"></i><b>13.6.1.3</b> From array-like</a></li>
<li class="chapter" data-level="13.6.1.4" data-path="pandas-1.html"><a href="pandas-1.html#from-dictionary"><i class="fa fa-check"></i><b>13.6.1.4</b> From Dictionary</a></li>
<li class="chapter" data-level="13.6.1.5" data-path="pandas-1.html"><a href="pandas-1.html#specify-index"><i class="fa fa-check"></i><b>13.6.1.5</b> Specify Index</a></li>
<li class="chapter" data-level="13.6.1.6" data-path="pandas-1.html"><a href="pandas-1.html#mix-element-types"><i class="fa fa-check"></i><b>13.6.1.6</b> Mix Element Types</a></li>
<li class="chapter" data-level="13.6.1.7" data-path="pandas-1.html"><a href="pandas-1.html#specify-data-types"><i class="fa fa-check"></i><b>13.6.1.7</b> Specify Data Types</a></li>
</ul></li>
<li class="chapter" data-level="13.6.2" data-path="pandas-1.html"><a href="pandas-1.html#accessing-series"><i class="fa fa-check"></i><b>13.6.2</b> Accessing Series</a><ul>
<li class="chapter" data-level="13.6.2.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-4"><i class="fa fa-check"></i><b>13.6.2.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.6.2.2" data-path="pandas-1.html"><a href="pandas-1.html#by-row-numbers"><i class="fa fa-check"></i><b>13.6.2.2</b> by Row Number(s)</a></li>
<li class="chapter" data-level="13.6.2.3" data-path="pandas-1.html"><a href="pandas-1.html#by-indexes"><i class="fa fa-check"></i><b>13.6.2.3</b> by Index(es)</a></li>
<li class="chapter" data-level="13.6.2.4" data-path="pandas-1.html"><a href="pandas-1.html#filtering"><i class="fa fa-check"></i><b>13.6.2.4</b> Filtering</a></li>
</ul></li>
<li class="chapter" data-level="13.6.3" data-path="pandas-1.html"><a href="pandas-1.html#updating-series"><i class="fa fa-check"></i><b>13.6.3</b> Updating Series</a><ul>
<li class="chapter" data-level="13.6.3.1" data-path="pandas-1.html"><a href="pandas-1.html#by-row-numbers-1"><i class="fa fa-check"></i><b>13.6.3.1</b> by Row Number(s)</a></li>
<li class="chapter" data-level="13.6.3.2" data-path="pandas-1.html"><a href="pandas-1.html#by-indexes-1"><i class="fa fa-check"></i><b>13.6.3.2</b> by Index(es)</a></li>
</ul></li>
<li class="chapter" data-level="13.6.4" data-path="pandas-1.html"><a href="pandas-1.html#series-attributes"><i class="fa fa-check"></i><b>13.6.4</b> Series Attributes</a><ul>
<li class="chapter" data-level="13.6.4.1" data-path="pandas-1.html"><a href="pandas-1.html#the-data"><i class="fa fa-check"></i><b>13.6.4.1</b> The Data</a></li>
<li class="chapter" data-level="13.6.4.2" data-path="pandas-1.html"><a href="pandas-1.html#the-attributes"><i class="fa fa-check"></i><b>13.6.4.2</b> The Attributes</a></li>
</ul></li>
<li class="chapter" data-level="13.6.5" data-path="pandas-1.html"><a href="pandas-1.html#instance-methods-2"><i class="fa fa-check"></i><b>13.6.5</b> Instance Methods</a><ul>
<li class="chapter" data-level="13.6.5.1" data-path="pandas-1.html"><a href="pandas-1.html#index-manipulation"><i class="fa fa-check"></i><b>13.6.5.1</b> Index Manipulation</a></li>
<li class="chapter" data-level="13.6.5.2" data-path="pandas-1.html"><a href="pandas-1.html#structure-conversion-1"><i class="fa fa-check"></i><b>13.6.5.2</b> Structure Conversion</a></li>
<li class="chapter" data-level="13.6.5.3" data-path="pandas-1.html"><a href="pandas-1.html#datatype-conversion"><i class="fa fa-check"></i><b>13.6.5.3</b> DataType Conversion</a></li>
</ul></li>
<li class="chapter" data-level="13.6.6" data-path="pandas-1.html"><a href="pandas-1.html#series-operators"><i class="fa fa-check"></i><b>13.6.6</b> Series Operators</a><ul>
<li class="chapter" data-level="13.6.6.1" data-path="pandas-1.html"><a href="pandas-1.html#arithmetic-operator"><i class="fa fa-check"></i><b>13.6.6.1</b> Arithmetic Operator</a></li>
<li class="chapter" data-level="13.6.6.2" data-path="pandas-1.html"><a href="pandas-1.html#logic-operator"><i class="fa fa-check"></i><b>13.6.6.2</b> Logic Operator</a></li>
</ul></li>
<li class="chapter" data-level="13.6.7" data-path="pandas-1.html"><a href="pandas-1.html#series-.str-accesor"><i class="fa fa-check"></i><b>13.6.7</b> Series <code>.str</code> Accesor</a><ul>
<li class="chapter" data-level="13.6.7.1" data-path="pandas-1.html"><a href="pandas-1.html#regex-extractor"><i class="fa fa-check"></i><b>13.6.7.1</b> Regex Extractor</a></li>
<li class="chapter" data-level="13.6.7.2" data-path="pandas-1.html"><a href="pandas-1.html#character-extractor"><i class="fa fa-check"></i><b>13.6.7.2</b> Character Extractor</a></li>
<li class="chapter" data-level="13.6.7.3" data-path="pandas-1.html"><a href="pandas-1.html#splitting"><i class="fa fa-check"></i><b>13.6.7.3</b> Splitting</a></li>
<li class="chapter" data-level="13.6.7.4" data-path="pandas-1.html"><a href="pandas-1.html#case-conversion"><i class="fa fa-check"></i><b>13.6.7.4</b> Case Conversion</a></li>
<li class="chapter" data-level="13.6.7.5" data-path="pandas-1.html"><a href="pandas-1.html#number-of-characters"><i class="fa fa-check"></i><b>13.6.7.5</b> Number of Characters</a></li>
<li class="chapter" data-level="13.6.7.6" data-path="pandas-1.html"><a href="pandas-1.html#string-indexing"><i class="fa fa-check"></i><b>13.6.7.6</b> String Indexing</a></li>
<li class="chapter" data-level="13.6.7.7" data-path="pandas-1.html"><a href="pandas-1.html#series-substring-extraction"><i class="fa fa-check"></i><b>13.6.7.7</b> Series Substring Extraction</a></li>
</ul></li>
<li class="chapter" data-level="13.6.8" data-path="pandas-1.html"><a href="pandas-1.html#series-.dt-accessor"><i class="fa fa-check"></i><b>13.6.8</b> Series <code>.dt</code> Accessor</a><ul>
<li class="chapter" data-level="13.6.8.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-5"><i class="fa fa-check"></i><b>13.6.8.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.6.8.2" data-path="pandas-1.html"><a href="pandas-1.html#convert-to"><i class="fa fa-check"></i><b>13.6.8.2</b> Convert To</a></li>
<li class="chapter" data-level="13.6.8.3" data-path="pandas-1.html"><a href="pandas-1.html#timestamp-attributes"><i class="fa fa-check"></i><b>13.6.8.3</b> Timestamp Attributes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="pandas-1.html"><a href="pandas-1.html#class-dataframe"><i class="fa fa-check"></i><b>13.7</b> class: DataFrame</a><ul>
<li class="chapter" data-level="13.7.1" data-path="pandas-1.html"><a href="pandas-1.html#constructor-10"><i class="fa fa-check"></i><b>13.7.1</b> Constructor</a><ul>
<li class="chapter" data-level="13.7.1.1" data-path="pandas-1.html"><a href="pandas-1.html#empty-dataframe"><i class="fa fa-check"></i><b>13.7.1.1</b> Empty DataFrame</a></li>
<li class="chapter" data-level="13.7.1.2" data-path="pandas-1.html"><a href="pandas-1.html#from-row-oriented-data-list-of-lists"><i class="fa fa-check"></i><b>13.7.1.2</b> From Row Oriented Data (List of Lists)</a></li>
<li class="chapter" data-level="13.7.1.3" data-path="pandas-1.html"><a href="pandas-1.html#from-row-oriented-data-list-of-dictionary"><i class="fa fa-check"></i><b>13.7.1.3</b> From Row Oriented Data (List of Dictionary)</a></li>
<li class="chapter" data-level="13.7.1.4" data-path="pandas-1.html"><a href="pandas-1.html#from-column-oriented-data"><i class="fa fa-check"></i><b>13.7.1.4</b> From Column Oriented Data</a></li>
</ul></li>
<li class="chapter" data-level="13.7.2" data-path="pandas-1.html"><a href="pandas-1.html#operator-2"><i class="fa fa-check"></i><b>13.7.2</b> Operator</a><ul>
<li class="chapter" data-level="13.7.2.1" data-path="pandas-1.html"><a href="pandas-1.html#the-data-1"><i class="fa fa-check"></i><b>13.7.2.1</b> The Data</a></li>
<li class="chapter" data-level="13.7.2.2" data-path="pandas-1.html"><a href="pandas-1.html#addition"><i class="fa fa-check"></i><b>13.7.2.2</b> Addition</a></li>
<li class="chapter" data-level="13.7.2.3" data-path="pandas-1.html"><a href="pandas-1.html#substraction"><i class="fa fa-check"></i><b>13.7.2.3</b> Substraction</a></li>
</ul></li>
<li class="chapter" data-level="13.7.3" data-path="pandas-1.html"><a href="pandas-1.html#attributes-6"><i class="fa fa-check"></i><b>13.7.3</b> Attributes</a><ul>
<li class="chapter" data-level="13.7.3.1" data-path="pandas-1.html"><a href="pandas-1.html#dimensions-1"><i class="fa fa-check"></i><b>13.7.3.1</b> Dimensions</a></li>
<li class="chapter" data-level="13.7.3.2" data-path="pandas-1.html"><a href="pandas-1.html#index"><i class="fa fa-check"></i><b>13.7.3.2</b> Index</a></li>
<li class="chapter" data-level="13.7.3.3" data-path="pandas-1.html"><a href="pandas-1.html#columns"><i class="fa fa-check"></i><b>13.7.3.3</b> Columns</a></li>
<li class="chapter" data-level="13.7.3.4" data-path="pandas-1.html"><a href="pandas-1.html#values"><i class="fa fa-check"></i><b>13.7.3.4</b> Values</a></li>
</ul></li>
<li class="chapter" data-level="13.7.4" data-path="pandas-1.html"><a href="pandas-1.html#index-manipulation-1"><i class="fa fa-check"></i><b>13.7.4</b> Index Manipulation</a><ul>
<li class="chapter" data-level="13.7.4.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-6"><i class="fa fa-check"></i><b>13.7.4.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.7.4.2" data-path="pandas-1.html"><a href="pandas-1.html#convert-column-to-index"><i class="fa fa-check"></i><b>13.7.4.2</b> Convert Column To Index</a></li>
<li class="chapter" data-level="13.7.4.3" data-path="pandas-1.html"><a href="pandas-1.html#convert-index-back-to-column"><i class="fa fa-check"></i><b>13.7.4.3</b> Convert Index Back To Column</a></li>
<li class="chapter" data-level="13.7.4.4" data-path="pandas-1.html"><a href="pandas-1.html#updating-index-.index"><i class="fa fa-check"></i><b>13.7.4.4</b> Updating Index ( .index= )</a></li>
<li class="chapter" data-level="13.7.4.5" data-path="pandas-1.html"><a href="pandas-1.html#reordering-index-.-reindex"><i class="fa fa-check"></i><b>13.7.4.5</b> Reordering Index (. reindex )</a></li>
<li class="chapter" data-level="13.7.4.6" data-path="pandas-1.html"><a href="pandas-1.html#rename-index"><i class="fa fa-check"></i><b>13.7.4.6</b> Rename Index</a></li>
</ul></li>
<li class="chapter" data-level="13.7.5" data-path="pandas-1.html"><a href="pandas-1.html#subsetting-columns"><i class="fa fa-check"></i><b>13.7.5</b> Subsetting Columns</a><ul>
<li class="chapter" data-level="13.7.5.1" data-path="pandas-1.html"><a href="pandas-1.html#select-single-column"><i class="fa fa-check"></i><b>13.7.5.1</b> Select Single Column</a></li>
<li class="chapter" data-level="13.7.5.2" data-path="pandas-1.html"><a href="pandas-1.html#select-multiple-columns"><i class="fa fa-check"></i><b>13.7.5.2</b> Select Multiple Columns</a></li>
<li class="chapter" data-level="13.7.5.3" data-path="pandas-1.html"><a href="pandas-1.html#by-column-name-.filter"><i class="fa fa-check"></i><b>13.7.5.3</b> By Column Name (.filter)</a></li>
<li class="chapter" data-level="13.7.5.4" data-path="pandas-1.html"><a href="pandas-1.html#data-type-.select_dtypes"><i class="fa fa-check"></i><b>13.7.5.4</b> Data Type (.select_dtypes)</a></li>
</ul></li>
<li class="chapter" data-level="13.7.6" data-path="pandas-1.html"><a href="pandas-1.html#column-manipulation-1"><i class="fa fa-check"></i><b>13.7.6</b> Column Manipulation</a><ul>
<li class="chapter" data-level="13.7.6.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-7"><i class="fa fa-check"></i><b>13.7.6.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.7.6.2" data-path="pandas-1.html"><a href="pandas-1.html#renaming-columns"><i class="fa fa-check"></i><b>13.7.6.2</b> Renaming Columns</a></li>
<li class="chapter" data-level="13.7.6.3" data-path="pandas-1.html"><a href="pandas-1.html#reordering-columns"><i class="fa fa-check"></i><b>13.7.6.3</b> Reordering Columns</a></li>
<li class="chapter" data-level="13.7.6.4" data-path="pandas-1.html"><a href="pandas-1.html#duplicating-or-replacing-column"><i class="fa fa-check"></i><b>13.7.6.4</b> Duplicating or Replacing Column</a></li>
<li class="chapter" data-level="13.7.6.5" data-path="pandas-1.html"><a href="pandas-1.html#dropping-columns-.drop"><i class="fa fa-check"></i><b>13.7.6.5</b> Dropping Columns (.drop)</a></li>
</ul></li>
<li class="chapter" data-level="13.7.7" data-path="pandas-1.html"><a href="pandas-1.html#subsetting-rows"><i class="fa fa-check"></i><b>13.7.7</b> Subsetting Rows</a><ul>
<li class="chapter" data-level="13.7.7.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-8"><i class="fa fa-check"></i><b>13.7.7.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.7.7.2" data-path="pandas-1.html"><a href="pandas-1.html#by-index-or-boolean"><i class="fa fa-check"></i><b>13.7.7.2</b> By Index or Boolean</a></li>
<li class="chapter" data-level="13.7.7.3" data-path="pandas-1.html"><a href="pandas-1.html#by-row-number"><i class="fa fa-check"></i><b>13.7.7.3</b> By Row Number</a></li>
<li class="chapter" data-level="13.7.7.4" data-path="pandas-1.html"><a href="pandas-1.html#by-expression-.query"><i class="fa fa-check"></i><b>13.7.7.4</b> By Expression (.query)</a></li>
<li class="chapter" data-level="13.7.7.5" data-path="pandas-1.html"><a href="pandas-1.html#by-random-.sample"><i class="fa fa-check"></i><b>13.7.7.5</b> By Random (.sample)</a></li>
</ul></li>
<li class="chapter" data-level="13.7.8" data-path="pandas-1.html"><a href="pandas-1.html#row-manipulation"><i class="fa fa-check"></i><b>13.7.8</b> Row Manipulation</a><ul>
<li class="chapter" data-level="13.7.8.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-9"><i class="fa fa-check"></i><b>13.7.8.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.7.8.2" data-path="pandas-1.html"><a href="pandas-1.html#appending-rows"><i class="fa fa-check"></i><b>13.7.8.2</b> Appending Rows</a></li>
<li class="chapter" data-level="13.7.8.3" data-path="pandas-1.html"><a href="pandas-1.html#concatenate-rows"><i class="fa fa-check"></i><b>13.7.8.3</b> Concatenate Rows</a></li>
<li class="chapter" data-level="13.7.8.4" data-path="pandas-1.html"><a href="pandas-1.html#dropping-rows-.drop"><i class="fa fa-check"></i><b>13.7.8.4</b> Dropping Rows (.drop)</a></li>
</ul></li>
<li class="chapter" data-level="13.7.9" data-path="pandas-1.html"><a href="pandas-1.html#slicing"><i class="fa fa-check"></i><b>13.7.9</b> Slicing</a><ul>
<li class="chapter" data-level="13.7.9.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-10"><i class="fa fa-check"></i><b>13.7.9.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.7.9.2" data-path="pandas-1.html"><a href="pandas-1.html#getting-one-cell"><i class="fa fa-check"></i><b>13.7.9.2</b> Getting One Cell</a></li>
<li class="chapter" data-level="13.7.9.3" data-path="pandas-1.html"><a href="pandas-1.html#getting-multiple-cells"><i class="fa fa-check"></i><b>13.7.9.3</b> Getting Multiple Cells</a></li>
</ul></li>
<li class="chapter" data-level="13.7.10" data-path="pandas-1.html"><a href="pandas-1.html#chained-indexing"><i class="fa fa-check"></i><b>13.7.10</b> Chained Indexing</a></li>
<li class="chapter" data-level="13.7.11" data-path="pandas-1.html"><a href="pandas-1.html#cell-value-replacement"><i class="fa fa-check"></i><b>13.7.11</b> Cell Value Replacement</a><ul>
<li class="chapter" data-level="13.7.11.1" data-path="pandas-1.html"><a href="pandas-1.html#mask"><i class="fa fa-check"></i><b>13.7.11.1</b> <code>mask()</code></a></li>
<li class="chapter" data-level="13.7.11.2" data-path="pandas-1.html"><a href="pandas-1.html#where-1"><i class="fa fa-check"></i><b>13.7.11.2</b> <code>where()</code></a></li>
</ul></li>
<li class="chapter" data-level="13.7.12" data-path="pandas-1.html"><a href="pandas-1.html#iteration"><i class="fa fa-check"></i><b>13.7.12</b> Iteration</a><ul>
<li class="chapter" data-level="13.7.12.1" data-path="pandas-1.html"><a href="pandas-1.html#loop-through-rows-.iterrows"><i class="fa fa-check"></i><b>13.7.12.1</b> Loop Through Rows (.iterrows)</a></li>
<li class="chapter" data-level="13.7.12.2" data-path="pandas-1.html"><a href="pandas-1.html#loop-through-columns-.itemes"><i class="fa fa-check"></i><b>13.7.12.2</b> Loop Through Columns (.itemes)</a></li>
</ul></li>
<li class="chapter" data-level="13.7.13" data-path="pandas-1.html"><a href="pandas-1.html#data-structure"><i class="fa fa-check"></i><b>13.7.13</b> Data Structure</a><ul>
<li class="chapter" data-level="13.7.13.1" data-path="pandas-1.html"><a href="pandas-1.html#instance-methods---structure"><i class="fa fa-check"></i><b>13.7.13.1</b> Instance Methods - Structure</a></li>
<li class="chapter" data-level="13.7.13.2" data-path="pandas-1.html"><a href="pandas-1.html#conversion-to-other-format"><i class="fa fa-check"></i><b>13.7.13.2</b> Conversion To Other Format</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="pandas-1.html"><a href="pandas-1.html#class-multiindex"><i class="fa fa-check"></i><b>13.8</b> class: MultiIndex</a><ul>
<li class="chapter" data-level="13.8.1" data-path="pandas-1.html"><a href="pandas-1.html#the-data-2"><i class="fa fa-check"></i><b>13.8.1</b> The Data</a></li>
<li class="chapter" data-level="13.8.2" data-path="pandas-1.html"><a href="pandas-1.html#creating-multiindex-object"><i class="fa fa-check"></i><b>13.8.2</b> Creating MultiIndex Object</a><ul>
<li class="chapter" data-level="13.8.2.1" data-path="pandas-1.html"><a href="pandas-1.html#create-from-tuples"><i class="fa fa-check"></i><b>13.8.2.1</b> Create From Tuples</a></li>
</ul></li>
<li class="chapter" data-level="13.8.3" data-path="pandas-1.html"><a href="pandas-1.html#multiindex-object"><i class="fa fa-check"></i><b>13.8.3</b> MultiIndex Object</a><ul>
<li class="chapter" data-level="13.8.3.1" data-path="pandas-1.html"><a href="pandas-1.html#levels"><i class="fa fa-check"></i><b>13.8.3.1</b> Levels</a></li>
<li class="chapter" data-level="13.8.3.2" data-path="pandas-1.html"><a href="pandas-1.html#convert-multiindex-back-to-tuples"><i class="fa fa-check"></i><b>13.8.3.2</b> Convert MultiIndex Back To Tuples</a></li>
</ul></li>
<li class="chapter" data-level="13.8.4" data-path="pandas-1.html"><a href="pandas-1.html#selecting-columns"><i class="fa fa-check"></i><b>13.8.4</b> Selecting Column(s)</a><ul>
<li class="chapter" data-level="13.8.4.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-11"><i class="fa fa-check"></i><b>13.8.4.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.8.4.2" data-path="pandas-1.html"><a href="pandas-1.html#select-level0-headers"><i class="fa fa-check"></i><b>13.8.4.2</b> Select Level0 Header(s)</a></li>
<li class="chapter" data-level="13.8.4.3" data-path="pandas-1.html"><a href="pandas-1.html#selecting-level-1-headers"><i class="fa fa-check"></i><b>13.8.4.3</b> Selecting Level 1 Header(s)</a></li>
<li class="chapter" data-level="13.8.4.4" data-path="pandas-1.html"><a href="pandas-1.html#select-level-0-and-level1-headers"><i class="fa fa-check"></i><b>13.8.4.4</b> Select Level 0 and Level1 Headers</a></li>
<li class="chapter" data-level="13.8.4.5" data-path="pandas-1.html"><a href="pandas-1.html#select-single-l0l1-header"><i class="fa fa-check"></i><b>13.8.4.5</b> Select single L0,L1 Header</a></li>
</ul></li>
<li class="chapter" data-level="13.8.5" data-path="pandas-1.html"><a href="pandas-1.html#headers-ordering"><i class="fa fa-check"></i><b>13.8.5</b> Headers Ordering</a><ul>
<li class="chapter" data-level="13.8.5.1" data-path="pandas-1.html"><a href="pandas-1.html#sort-headers"><i class="fa fa-check"></i><b>13.8.5.1</b> Sort Headers</a></li>
<li class="chapter" data-level="13.8.5.2" data-path="pandas-1.html"><a href="pandas-1.html#rearranging-headers"><i class="fa fa-check"></i><b>13.8.5.2</b> Rearranging Headers</a></li>
</ul></li>
<li class="chapter" data-level="13.8.6" data-path="pandas-1.html"><a href="pandas-1.html#stacking-and-unstacking"><i class="fa fa-check"></i><b>13.8.6</b> Stacking and Unstacking</a><ul>
<li class="chapter" data-level="13.8.6.1" data-path="pandas-1.html"><a href="pandas-1.html#stacking-columns-to-rows"><i class="fa fa-check"></i><b>13.8.6.1</b> Stacking Columns to Rows</a></li>
</ul></li>
<li class="chapter" data-level="13.8.7" data-path="pandas-1.html"><a href="pandas-1.html#exploratory-analysis"><i class="fa fa-check"></i><b>13.8.7</b> Exploratory Analysis</a><ul>
<li class="chapter" data-level="13.8.7.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-12"><i class="fa fa-check"></i><b>13.8.7.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.8.7.2" data-path="pandas-1.html"><a href="pandas-1.html#all-stats-in-one---.describe"><i class="fa fa-check"></i><b>13.8.7.2</b> All Stats in One - .describe()</a></li>
<li class="chapter" data-level="13.8.7.3" data-path="pandas-1.html"><a href="pandas-1.html#minmaxmeanmedian"><i class="fa fa-check"></i><b>13.8.7.3</b> min/max/mean/median</a></li>
</ul></li>
<li class="chapter" data-level="13.8.8" data-path="pandas-1.html"><a href="pandas-1.html#plotting"><i class="fa fa-check"></i><b>13.8.8</b> Plotting</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="pandas-1.html"><a href="pandas-1.html#class-categories"><i class="fa fa-check"></i><b>13.9</b> class: Categories</a><ul>
<li class="chapter" data-level="13.9.1" data-path="pandas-1.html"><a href="pandas-1.html#creating-2"><i class="fa fa-check"></i><b>13.9.1</b> Creating</a><ul>
<li class="chapter" data-level="13.9.1.1" data-path="pandas-1.html"><a href="pandas-1.html#from-list"><i class="fa fa-check"></i><b>13.9.1.1</b> From List</a></li>
<li class="chapter" data-level="13.9.1.2" data-path="pandas-1.html"><a href="pandas-1.html#from-series"><i class="fa fa-check"></i><b>13.9.1.2</b> From Series</a></li>
<li class="chapter" data-level="13.9.1.3" data-path="pandas-1.html"><a href="pandas-1.html#ordering-category"><i class="fa fa-check"></i><b>13.9.1.3</b> Ordering Category</a></li>
</ul></li>
<li class="chapter" data-level="13.9.2" data-path="pandas-1.html"><a href="pandas-1.html#properties"><i class="fa fa-check"></i><b>13.9.2</b> Properties</a><ul>
<li class="chapter" data-level="13.9.2.1" data-path="pandas-1.html"><a href="pandas-1.html#categories"><i class="fa fa-check"></i><b>13.9.2.1</b> .categories</a></li>
<li class="chapter" data-level="13.9.2.2" data-path="pandas-1.html"><a href="pandas-1.html#codes"><i class="fa fa-check"></i><b>13.9.2.2</b> .codes</a></li>
</ul></li>
<li class="chapter" data-level="13.9.3" data-path="pandas-1.html"><a href="pandas-1.html#rename-category"><i class="fa fa-check"></i><b>13.9.3</b> Rename Category</a><ul>
<li class="chapter" data-level="13.9.3.1" data-path="pandas-1.html"><a href="pandas-1.html#renamce-to-new-category-object"><i class="fa fa-check"></i><b>13.9.3.1</b> Renamce To New Category Object</a></li>
<li class="chapter" data-level="13.9.3.2" data-path="pandas-1.html"><a href="pandas-1.html#rename-inplace"><i class="fa fa-check"></i><b>13.9.3.2</b> Rename Inplace</a></li>
</ul></li>
<li class="chapter" data-level="13.9.4" data-path="pandas-1.html"><a href="pandas-1.html#adding-new-category"><i class="fa fa-check"></i><b>13.9.4</b> Adding New Category</a></li>
<li class="chapter" data-level="13.9.5" data-path="pandas-1.html"><a href="pandas-1.html#removing-category"><i class="fa fa-check"></i><b>13.9.5</b> Removing Category</a><ul>
<li class="chapter" data-level="13.9.5.1" data-path="pandas-1.html"><a href="pandas-1.html#remove-specific-categories"><i class="fa fa-check"></i><b>13.9.5.1</b> Remove Specific Categor(ies)</a></li>
<li class="chapter" data-level="13.9.5.2" data-path="pandas-1.html"><a href="pandas-1.html#remove-unused-category"><i class="fa fa-check"></i><b>13.9.5.2</b> Remove Unused Category</a></li>
</ul></li>
<li class="chapter" data-level="13.9.6" data-path="pandas-1.html"><a href="pandas-1.html#add-and-remove-categories-in-one-step---set"><i class="fa fa-check"></i><b>13.9.6</b> Add and Remove Categories In One Step - Set()</a></li>
<li class="chapter" data-level="13.9.7" data-path="pandas-1.html"><a href="pandas-1.html#categorical-descriptive-analysis"><i class="fa fa-check"></i><b>13.9.7</b> Categorical Descriptive Analysis</a><ul>
<li class="chapter" data-level="13.9.7.1" data-path="pandas-1.html"><a href="pandas-1.html#at-one-glance"><i class="fa fa-check"></i><b>13.9.7.1</b> At One Glance</a></li>
<li class="chapter" data-level="13.9.7.2" data-path="pandas-1.html"><a href="pandas-1.html#frequency-count"><i class="fa fa-check"></i><b>13.9.7.2</b> Frequency Count</a></li>
<li class="chapter" data-level="13.9.7.3" data-path="pandas-1.html"><a href="pandas-1.html#least-frequent-category-most-frequent-category-and-most-frequent-category"><i class="fa fa-check"></i><b>13.9.7.3</b> Least Frequent Category, Most Frequent Category, and Most Frequent Category</a></li>
</ul></li>
<li class="chapter" data-level="13.9.8" data-path="pandas-1.html"><a href="pandas-1.html#other-methods-1"><i class="fa fa-check"></i><b>13.9.8</b> Other Methods</a><ul>
<li class="chapter" data-level="13.9.8.1" data-path="pandas-1.html"><a href="pandas-1.html#get_values"><i class="fa fa-check"></i><b>13.9.8.1</b> .get_values()</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="pandas-1.html"><a href="pandas-1.html#dummies"><i class="fa fa-check"></i><b>13.10</b> Dummies</a><ul>
<li class="chapter" data-level="13.10.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-13"><i class="fa fa-check"></i><b>13.10.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.10.2" data-path="pandas-1.html"><a href="pandas-1.html#dummies-on-array-like-data"><i class="fa fa-check"></i><b>13.10.2</b> Dummies on Array-Like Data</a></li>
<li class="chapter" data-level="13.10.3" data-path="pandas-1.html"><a href="pandas-1.html#dummies-on-dataframe-multiple-columns"><i class="fa fa-check"></i><b>13.10.3</b> Dummies on DataFrame (multiple columns)</a><ul>
<li class="chapter" data-level="13.10.3.1" data-path="pandas-1.html"><a href="pandas-1.html#all-columns"><i class="fa fa-check"></i><b>13.10.3.1</b> All Columns</a></li>
<li class="chapter" data-level="13.10.3.2" data-path="pandas-1.html"><a href="pandas-1.html#selected-columns"><i class="fa fa-check"></i><b>13.10.3.2</b> Selected Columns</a></li>
</ul></li>
<li class="chapter" data-level="13.10.4" data-path="pandas-1.html"><a href="pandas-1.html#dummies-with-na"><i class="fa fa-check"></i><b>13.10.4</b> Dummies with na</a></li>
<li class="chapter" data-level="13.10.5" data-path="pandas-1.html"><a href="pandas-1.html#specify-prefixes"><i class="fa fa-check"></i><b>13.10.5</b> Specify Prefixes</a></li>
<li class="chapter" data-level="13.10.6" data-path="pandas-1.html"><a href="pandas-1.html#dropping-first-column"><i class="fa fa-check"></i><b>13.10.6</b> Dropping First Column</a></li>
</ul></li>
<li class="chapter" data-level="13.11" data-path="pandas-1.html"><a href="pandas-1.html#dataframegroupby"><i class="fa fa-check"></i><b>13.11</b> DataFrameGroupBy</a><ul>
<li class="chapter" data-level="13.11.1" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-14"><i class="fa fa-check"></i><b>13.11.1</b> Sample Data</a></li>
<li class="chapter" data-level="13.11.2" data-path="pandas-1.html"><a href="pandas-1.html#creating-groups"><i class="fa fa-check"></i><b>13.11.2</b> Creating Groups</a></li>
<li class="chapter" data-level="13.11.3" data-path="pandas-1.html"><a href="pandas-1.html#properties-1"><i class="fa fa-check"></i><b>13.11.3</b> Properties</a><ul>
<li class="chapter" data-level="13.11.3.1" data-path="pandas-1.html"><a href="pandas-1.html#number-of-groups"><i class="fa fa-check"></i><b>13.11.3.1</b> Number of Groups</a></li>
<li class="chapter" data-level="13.11.3.2" data-path="pandas-1.html"><a href="pandas-1.html#row-numbers-associated-for-each-group"><i class="fa fa-check"></i><b>13.11.3.2</b> Row Numbers Associated For Each Group</a></li>
</ul></li>
<li class="chapter" data-level="13.11.4" data-path="pandas-1.html"><a href="pandas-1.html#methods-1"><i class="fa fa-check"></i><b>13.11.4</b> Methods</a><ul>
<li class="chapter" data-level="13.11.4.1" data-path="pandas-1.html"><a href="pandas-1.html#number-of-rows-in-each-group"><i class="fa fa-check"></i><b>13.11.4.1</b> Number of Rows In Each Group</a></li>
</ul></li>
<li class="chapter" data-level="13.11.5" data-path="pandas-1.html"><a href="pandas-1.html#retrieve-rows"><i class="fa fa-check"></i><b>13.11.5</b> Retrieve Rows</a><ul>
<li class="chapter" data-level="13.11.5.1" data-path="pandas-1.html"><a href="pandas-1.html#retrieve-n-th-row-of-each-grou"><i class="fa fa-check"></i><b>13.11.5.1</b> Retrieve n-th Row Of Each Grou</a></li>
<li class="chapter" data-level="13.11.5.2" data-path="pandas-1.html"><a href="pandas-1.html#retrieve-n-rows-of-each-groups"><i class="fa fa-check"></i><b>13.11.5.2</b> Retrieve N Rows Of Each Groups</a></li>
<li class="chapter" data-level="13.11.5.3" data-path="pandas-1.html"><a href="pandas-1.html#retrieve-all-rows-of-specific-group"><i class="fa fa-check"></i><b>13.11.5.3</b> Retrieve All Rows Of Specific Group</a></li>
</ul></li>
<li class="chapter" data-level="13.11.6" data-path="pandas-1.html"><a href="pandas-1.html#single-statistic-per-group"><i class="fa fa-check"></i><b>13.11.6</b> Single Statistic Per Group</a><ul>
<li class="chapter" data-level="13.11.6.1" data-path="pandas-1.html"><a href="pandas-1.html#count"><i class="fa fa-check"></i><b>13.11.6.1</b> <code>count()</code></a></li>
<li class="chapter" data-level="13.11.6.2" data-path="pandas-1.html"><a href="pandas-1.html#sum"><i class="fa fa-check"></i><b>13.11.6.2</b> <code>sum()</code></a></li>
<li class="chapter" data-level="13.11.6.3" data-path="pandas-1.html"><a href="pandas-1.html#mean"><i class="fa fa-check"></i><b>13.11.6.3</b> <code>mean()</code></a></li>
</ul></li>
<li class="chapter" data-level="13.11.7" data-path="pandas-1.html"><a href="pandas-1.html#multi-statistic-per-group"><i class="fa fa-check"></i><b>13.11.7</b> Multi Statistic Per Group</a><ul>
<li class="chapter" data-level="13.11.7.1" data-path="pandas-1.html"><a href="pandas-1.html#single-function-to-columns"><i class="fa fa-check"></i><b>13.11.7.1</b> Single Function To Column(s)</a></li>
<li class="chapter" data-level="13.11.7.2" data-path="pandas-1.html"><a href="pandas-1.html#multiple-function-to-columns"><i class="fa fa-check"></i><b>13.11.7.2</b> Multiple Function to Column(s)</a></li>
<li class="chapter" data-level="13.11.7.3" data-path="pandas-1.html"><a href="pandas-1.html#column-relabling"><i class="fa fa-check"></i><b>13.11.7.3</b> Column Relabling</a></li>
</ul></li>
<li class="chapter" data-level="13.11.8" data-path="pandas-1.html"><a href="pandas-1.html#iteration-1"><i class="fa fa-check"></i><b>13.11.8</b> Iteration</a></li>
<li class="chapter" data-level="13.11.9" data-path="pandas-1.html"><a href="pandas-1.html#transform"><i class="fa fa-check"></i><b>13.11.9</b> Transform</a></li>
</ul></li>
<li class="chapter" data-level="13.12" data-path="pandas-1.html"><a href="pandas-1.html#fundamental-analysis"><i class="fa fa-check"></i><b>13.12</b> Fundamental Analysis</a></li>
<li class="chapter" data-level="13.13" data-path="pandas-1.html"><a href="pandas-1.html#missing-data"><i class="fa fa-check"></i><b>13.13</b> Missing Data</a><ul>
<li class="chapter" data-level="13.13.1" data-path="pandas-1.html"><a href="pandas-1.html#what-is-considered-missing-data"><i class="fa fa-check"></i><b>13.13.1</b> What Is Considered Missing Data ?</a></li>
<li class="chapter" data-level="13.13.2" data-path="pandas-1.html"><a href="pandas-1.html#sample-data-15"><i class="fa fa-check"></i><b>13.13.2</b> Sample Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="matplotlib-1.html"><a href="matplotlib-1.html"><i class="fa fa-check"></i><b>14</b> matplotlib</a><ul>
<li class="chapter" data-level="14.1" data-path="matplotlib-1.html"><a href="matplotlib-1.html#library"><i class="fa fa-check"></i><b>14.1</b> Library</a></li>
<li class="chapter" data-level="14.2" data-path="matplotlib-1.html"><a href="matplotlib-1.html#sample-data-16"><i class="fa fa-check"></i><b>14.2</b> Sample Data</a></li>
<li class="chapter" data-level="14.3" data-path="matplotlib-1.html"><a href="matplotlib-1.html#matlab-like-api"><i class="fa fa-check"></i><b>14.3</b> MATLAB-like API</a><ul>
<li class="chapter" data-level="14.3.1" data-path="matplotlib-1.html"><a href="matplotlib-1.html#sample-data-17"><i class="fa fa-check"></i><b>14.3.1</b> Sample Data</a></li>
<li class="chapter" data-level="14.3.2" data-path="matplotlib-1.html"><a href="matplotlib-1.html#single-plot"><i class="fa fa-check"></i><b>14.3.2</b> Single Plot</a></li>
<li class="chapter" data-level="14.3.3" data-path="matplotlib-1.html"><a href="matplotlib-1.html#multiple-subplots"><i class="fa fa-check"></i><b>14.3.3</b> Multiple Subplots</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="matplotlib-1.html"><a href="matplotlib-1.html#object-oriented-api"><i class="fa fa-check"></i><b>14.4</b> Object-Oriented API</a><ul>
<li class="chapter" data-level="14.4.1" data-path="matplotlib-1.html"><a href="matplotlib-1.html#sample-data-18"><i class="fa fa-check"></i><b>14.4.1</b> Sample Data</a></li>
<li class="chapter" data-level="14.4.2" data-path="matplotlib-1.html"><a href="matplotlib-1.html#single-plot-1"><i class="fa fa-check"></i><b>14.4.2</b> Single Plot</a></li>
<li class="chapter" data-level="14.4.3" data-path="matplotlib-1.html"><a href="matplotlib-1.html#multiple-axes-in-one-plot"><i class="fa fa-check"></i><b>14.4.3</b> Multiple Axes In One Plot</a></li>
<li class="chapter" data-level="14.4.4" data-path="matplotlib-1.html"><a href="matplotlib-1.html#multiple-subplots-1"><i class="fa fa-check"></i><b>14.4.4</b> Multiple Subplots</a><ul>
<li class="chapter" data-level="14.4.4.1" data-path="matplotlib-1.html"><a href="matplotlib-1.html#simple-subplots---all-same-size"><i class="fa fa-check"></i><b>14.4.4.1</b> Simple Subplots - all same size</a></li>
<li class="chapter" data-level="14.4.4.2" data-path="matplotlib-1.html"><a href="matplotlib-1.html#complicated-subplots---different-size"><i class="fa fa-check"></i><b>14.4.4.2</b> Complicated Subplots - different size</a></li>
</ul></li>
<li class="chapter" data-level="14.4.5" data-path="matplotlib-1.html"><a href="matplotlib-1.html#figure-customization"><i class="fa fa-check"></i><b>14.4.5</b> Figure Customization</a><ul>
<li class="chapter" data-level="14.4.5.1" data-path="matplotlib-1.html"><a href="matplotlib-1.html#avoid-overlap---use-tight_layout"><i class="fa fa-check"></i><b>14.4.5.1</b> Avoid Overlap - Use tight_layout()</a></li>
<li class="chapter" data-level="14.4.5.2" data-path="matplotlib-1.html"><a href="matplotlib-1.html#avoid-overlap---change-figure-size"><i class="fa fa-check"></i><b>14.4.5.2</b> Avoid Overlap - Change Figure Size</a></li>
<li class="chapter" data-level="14.4.5.3" data-path="matplotlib-1.html"><a href="matplotlib-1.html#text-within-figure"><i class="fa fa-check"></i><b>14.4.5.3</b> Text Within Figure</a></li>
</ul></li>
<li class="chapter" data-level="14.4.6" data-path="matplotlib-1.html"><a href="matplotlib-1.html#axes-customization"><i class="fa fa-check"></i><b>14.4.6</b> Axes Customization</a><ul>
<li class="chapter" data-level="14.4.6.1" data-path="matplotlib-1.html"><a href="matplotlib-1.html#y-axis-limit"><i class="fa fa-check"></i><b>14.4.6.1</b> Y-Axis Limit</a></li>
<li class="chapter" data-level="14.4.6.2" data-path="matplotlib-1.html"><a href="matplotlib-1.html#text-within-axes"><i class="fa fa-check"></i><b>14.4.6.2</b> Text Within Axes</a></li>
<li class="chapter" data-level="14.4.6.3" data-path="matplotlib-1.html"><a href="matplotlib-1.html#share-y-axis-label"><i class="fa fa-check"></i><b>14.4.6.3</b> Share Y Axis Label</a></li>
<li class="chapter" data-level="14.4.6.4" data-path="matplotlib-1.html"><a href="matplotlib-1.html#create-subplot-individually"><i class="fa fa-check"></i><b>14.4.6.4</b> Create Subplot Individually</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="matplotlib-1.html"><a href="matplotlib-1.html#histogram"><i class="fa fa-check"></i><b>14.5</b> Histogram</a></li>
<li class="chapter" data-level="14.6" data-path="matplotlib-1.html"><a href="matplotlib-1.html#scatter-plot"><i class="fa fa-check"></i><b>14.6</b> Scatter Plot</a></li>
<li class="chapter" data-level="14.7" data-path="matplotlib-1.html"><a href="matplotlib-1.html#bar-chart"><i class="fa fa-check"></i><b>14.7</b> Bar Chart</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="seaborn.html"><a href="seaborn.html"><i class="fa fa-check"></i><b>15</b> seaborn</a><ul>
<li class="chapter" data-level="15.1" data-path="seaborn.html"><a href="seaborn.html#seaborn-and-matplotlib"><i class="fa fa-check"></i><b>15.1</b> Seaborn and Matplotlib</a></li>
<li class="chapter" data-level="15.2" data-path="seaborn.html"><a href="seaborn.html#sample-data-19"><i class="fa fa-check"></i><b>15.2</b> Sample Data</a></li>
<li class="chapter" data-level="15.3" data-path="seaborn.html"><a href="seaborn.html#scatter-plot-1"><i class="fa fa-check"></i><b>15.3</b> Scatter Plot</a><ul>
<li class="chapter" data-level="15.3.1" data-path="seaborn.html"><a href="seaborn.html#x-numeric"><i class="fa fa-check"></i><b>15.3.1</b> 2x Numeric</a></li>
<li class="chapter" data-level="15.3.2" data-path="seaborn.html"><a href="seaborn.html#xnumeric-1x-categorical"><i class="fa fa-check"></i><b>15.3.2</b> 2xNumeric + 1x Categorical</a></li>
<li class="chapter" data-level="15.3.3" data-path="seaborn.html"><a href="seaborn.html#xnumeric-2x-categorical"><i class="fa fa-check"></i><b>15.3.3</b> 2xNumeric + 2x Categorical</a></li>
<li class="chapter" data-level="15.3.4" data-path="seaborn.html"><a href="seaborn.html#xnumeric-3x-categorical"><i class="fa fa-check"></i><b>15.3.4</b> 2xNumeric + 3x Categorical</a></li>
<li class="chapter" data-level="15.3.5" data-path="seaborn.html"><a href="seaborn.html#customization"><i class="fa fa-check"></i><b>15.3.5</b> Customization</a><ul>
<li class="chapter" data-level="15.3.5.1" data-path="seaborn.html"><a href="seaborn.html#size"><i class="fa fa-check"></i><b>15.3.5.1</b> size</a></li>
<li class="chapter" data-level="15.3.5.2" data-path="seaborn.html"><a href="seaborn.html#col_wrap"><i class="fa fa-check"></i><b>15.3.5.2</b> col_wrap</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="seaborn.html"><a href="seaborn.html#histogram-1"><i class="fa fa-check"></i><b>15.4</b> Histogram</a><ul>
<li class="chapter" data-level="15.4.1" data-path="seaborn.html"><a href="seaborn.html#x-numeric-1"><i class="fa fa-check"></i><b>15.4.1</b> 1x Numeric</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="seaborn.html"><a href="seaborn.html#bar-chart-1"><i class="fa fa-check"></i><b>15.5</b> Bar Chart</a><ul>
<li class="chapter" data-level="15.5.1" data-path="seaborn.html"><a href="seaborn.html#x-categorical-1x-numeric"><i class="fa fa-check"></i><b>15.5.1</b> 1x Categorical, 1x Numeric</a></li>
<li class="chapter" data-level="15.5.2" data-path="seaborn.html"><a href="seaborn.html#customization-1"><i class="fa fa-check"></i><b>15.5.2</b> Customization</a><ul>
<li class="chapter" data-level="15.5.2.1" data-path="seaborn.html"><a href="seaborn.html#ordering"><i class="fa fa-check"></i><b>15.5.2.1</b> Ordering</a></li>
<li class="chapter" data-level="15.5.2.2" data-path="seaborn.html"><a href="seaborn.html#flipping-xy-axis"><i class="fa fa-check"></i><b>15.5.2.2</b> Flipping X/Y Axis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="seaborn.html"><a href="seaborn.html#faceting"><i class="fa fa-check"></i><b>15.6</b> Faceting</a><ul>
<li class="chapter" data-level="15.6.1" data-path="seaborn.html"><a href="seaborn.html#faceting-histogram"><i class="fa fa-check"></i><b>15.6.1</b> Faceting Histogram</a></li>
<li class="chapter" data-level="15.6.2" data-path="seaborn.html"><a href="seaborn.html#faceting-scatter-plot"><i class="fa fa-check"></i><b>15.6.2</b> Faceting Scatter Plot</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="seaborn.html"><a href="seaborn.html#pair-grid"><i class="fa fa-check"></i><b>15.7</b> Pair Grid</a><ul>
<li class="chapter" data-level="15.7.1" data-path="seaborn.html"><a href="seaborn.html#simple-pair-grid"><i class="fa fa-check"></i><b>15.7.1</b> Simple Pair Grid</a></li>
<li class="chapter" data-level="15.7.2" data-path="seaborn.html"><a href="seaborn.html#different-diag-and-offdiag"><i class="fa fa-check"></i><b>15.7.2</b> Different Diag and OffDiag</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="plotnine.html"><a href="plotnine.html"><i class="fa fa-check"></i><b>16</b> plotnine</a><ul>
<li class="chapter" data-level="16.1" data-path="plotnine.html"><a href="plotnine.html#histogram-2"><i class="fa fa-check"></i><b>16.1</b> Histogram</a><ul>
<li class="chapter" data-level="16.1.1" data-path="plotnine.html"><a href="plotnine.html#xnumeric"><i class="fa fa-check"></i><b>16.1.1</b> 1xNumeric</a></li>
<li class="chapter" data-level="16.1.2" data-path="plotnine.html"><a href="plotnine.html#xnumeric-1xcategorical"><i class="fa fa-check"></i><b>16.1.2</b> 1xNumeric + 1xCategorical</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="plotnine.html"><a href="plotnine.html#scatter-plot-2"><i class="fa fa-check"></i><b>16.2</b> Scatter Plot</a><ul>
<li class="chapter" data-level="16.2.1" data-path="plotnine.html"><a href="plotnine.html#x-numeric-2"><i class="fa fa-check"></i><b>16.2.1</b> 2x Numeric</a></li>
<li class="chapter" data-level="16.2.2" data-path="plotnine.html"><a href="plotnine.html#x-numeric-1x-categorical"><i class="fa fa-check"></i><b>16.2.2</b> 2x Numeric + 1x Categorical</a></li>
<li class="chapter" data-level="16.2.3" data-path="plotnine.html"><a href="plotnine.html#x-numeric-1x-numeric-1x-categorical"><i class="fa fa-check"></i><b>16.2.3</b> 2x Numeric + 1x Numeric + 1x Categorical</a></li>
<li class="chapter" data-level="16.2.4" data-path="plotnine.html"><a href="plotnine.html#overlay-smooth-line"><i class="fa fa-check"></i><b>16.2.4</b> Overlay Smooth Line</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="plotnine.html"><a href="plotnine.html#line-chart"><i class="fa fa-check"></i><b>16.3</b> Line Chart</a><ul>
<li class="chapter" data-level="16.3.1" data-path="plotnine.html"><a href="plotnine.html#x-numeric-data"><i class="fa fa-check"></i><b>16.3.1</b> 2x Numeric Data</a></li>
<li class="chapter" data-level="16.3.2" data-path="plotnine.html"><a href="plotnine.html#x-numeric-1x-categorical-1"><i class="fa fa-check"></i><b>16.3.2</b> 1x Numeric, 1x Categorical</a></li>
<li class="chapter" data-level="16.3.3" data-path="plotnine.html"><a href="plotnine.html#x-numeric-1x-categorical-2"><i class="fa fa-check"></i><b>16.3.3</b> 2x Numeric, 1x Categorical</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="plotnine.html"><a href="plotnine.html#bar-chart-2"><i class="fa fa-check"></i><b>16.4</b> Bar Chart</a><ul>
<li class="chapter" data-level="16.4.0.1" data-path="plotnine.html"><a href="plotnine.html#x-categorical"><i class="fa fa-check"></i><b>16.4.0.1</b> 1x Categorical</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="sklearn.html"><a href="sklearn.html"><i class="fa fa-check"></i><b>17</b> sklearn</a><ul>
<li class="chapter" data-level="17.1" data-path="sklearn.html"><a href="sklearn.html#setup-hidden"><i class="fa fa-check"></i><b>17.1</b> Setup (hidden)</a></li>
<li class="chapter" data-level="17.2" data-path="sklearn.html"><a href="sklearn.html#the-library"><i class="fa fa-check"></i><b>17.2</b> The Library</a></li>
<li class="chapter" data-level="17.3" data-path="sklearn.html"><a href="sklearn.html#model-fitting"><i class="fa fa-check"></i><b>17.3</b> Model Fitting</a><ul>
<li class="chapter" data-level="17.3.1" data-path="sklearn.html"><a href="sklearn.html#underfitting"><i class="fa fa-check"></i><b>17.3.1</b> Underfitting</a></li>
<li class="chapter" data-level="17.3.2" data-path="sklearn.html"><a href="sklearn.html#overfitting"><i class="fa fa-check"></i><b>17.3.2</b> Overfitting</a></li>
<li class="chapter" data-level="17.3.3" data-path="sklearn.html"><a href="sklearn.html#just-right"><i class="fa fa-check"></i><b>17.3.3</b> Just Right</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="sklearn.html"><a href="sklearn.html#model-tuning"><i class="fa fa-check"></i><b>17.4</b> Model Tuning</a></li>
<li class="chapter" data-level="17.5" data-path="sklearn.html"><a href="sklearn.html#high-level-ml-process"><i class="fa fa-check"></i><b>17.5</b> High Level ML Process</a></li>
<li class="chapter" data-level="17.6" data-path="sklearn.html"><a href="sklearn.html#built-in-datasets"><i class="fa fa-check"></i><b>17.6</b> Built-in Datasets</a><ul>
<li class="chapter" data-level="17.6.1" data-path="sklearn.html"><a href="sklearn.html#diabetes-regression"><i class="fa fa-check"></i><b>17.6.1</b> diabetes (regression)</a><ul>
<li class="chapter" data-level="17.6.1.1" data-path="sklearn.html"><a href="sklearn.html#load-dataset"><i class="fa fa-check"></i><b>17.6.1.1</b> Load Dataset</a></li>
<li class="chapter" data-level="17.6.1.2" data-path="sklearn.html"><a href="sklearn.html#keys"><i class="fa fa-check"></i><b>17.6.1.2</b> keys</a></li>
<li class="chapter" data-level="17.6.1.3" data-path="sklearn.html"><a href="sklearn.html#features-and-target"><i class="fa fa-check"></i><b>17.6.1.3</b> Features and Target</a></li>
<li class="chapter" data-level="17.6.1.4" data-path="sklearn.html"><a href="sklearn.html#load-with-xy-convenient-method"><i class="fa fa-check"></i><b>17.6.1.4</b> Load with X,y (Convenient Method)</a></li>
</ul></li>
<li class="chapter" data-level="17.6.2" data-path="sklearn.html"><a href="sklearn.html#digits-classification"><i class="fa fa-check"></i><b>17.6.2</b> digits (Classification)</a><ul>
<li class="chapter" data-level="17.6.2.1" data-path="sklearn.html"><a href="sklearn.html#data"><i class="fa fa-check"></i><b>17.6.2.1</b> data</a></li>
<li class="chapter" data-level="17.6.2.2" data-path="sklearn.html"><a href="sklearn.html#images"><i class="fa fa-check"></i><b>17.6.2.2</b> Images</a></li>
<li class="chapter" data-level="17.6.2.3" data-path="sklearn.html"><a href="sklearn.html#loading-into-xy-convenient-method"><i class="fa fa-check"></i><b>17.6.2.3</b> Loading Into X,y (Convenient Method)</a></li>
</ul></li>
<li class="chapter" data-level="17.6.3" data-path="sklearn.html"><a href="sklearn.html#iris-classification"><i class="fa fa-check"></i><b>17.6.3</b> iris (Classification)</a><ul>
<li class="chapter" data-level="17.6.3.1" data-path="sklearn.html"><a href="sklearn.html#feature-names"><i class="fa fa-check"></i><b>17.6.3.1</b> Feature Names</a></li>
<li class="chapter" data-level="17.6.3.2" data-path="sklearn.html"><a href="sklearn.html#target"><i class="fa fa-check"></i><b>17.6.3.2</b> target</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="sklearn.html"><a href="sklearn.html#train-test-data-splitting"><i class="fa fa-check"></i><b>17.7</b> Train Test Data Splitting</a><ul>
<li class="chapter" data-level="17.7.1" data-path="sklearn.html"><a href="sklearn.html#sample-data-20"><i class="fa fa-check"></i><b>17.7.1</b> Sample Data</a></li>
<li class="chapter" data-level="17.7.2" data-path="sklearn.html"><a href="sklearn.html#one-time-split"><i class="fa fa-check"></i><b>17.7.2</b> One Time Split</a><ul>
<li class="chapter" data-level="17.7.2.1" data-path="sklearn.html"><a href="sklearn.html#method-1-split-one-dataframe-into-two-train-test"><i class="fa fa-check"></i><b>17.7.2.1</b> Method 1: Split One Dataframe Into Two (Train &amp; Test)</a></li>
<li class="chapter" data-level="17.7.2.2" data-path="sklearn.html"><a href="sklearn.html#method-2-split-two-dataframe-xy-into-four-x_traintest-y_traintest"><i class="fa fa-check"></i><b>17.7.2.2</b> Method 2: Split Two DataFrame (X,Y) into Four x_train/test, y_train/test</a></li>
</ul></li>
<li class="chapter" data-level="17.7.3" data-path="sklearn.html"><a href="sklearn.html#k-fold"><i class="fa fa-check"></i><b>17.7.3</b> K-Fold</a></li>
<li class="chapter" data-level="17.7.4" data-path="sklearn.html"><a href="sklearn.html#leave-one-out"><i class="fa fa-check"></i><b>17.7.4</b> Leave One Out</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="sklearn.html"><a href="sklearn.html#polynomial-transform"><i class="fa fa-check"></i><b>17.8</b> Polynomial Transform</a><ul>
<li class="chapter" data-level="17.8.1" data-path="sklearn.html"><a href="sklearn.html#single-variable"><i class="fa fa-check"></i><b>17.8.1</b> Single Variable</a><ul>
<li class="chapter" data-level="17.8.1.1" data-path="sklearn.html"><a href="sklearn.html#sample-data-21"><i class="fa fa-check"></i><b>17.8.1.1</b> Sample Data</a></li>
<li class="chapter" data-level="17.8.1.2" data-path="sklearn.html"><a href="sklearn.html#degree-1"><i class="fa fa-check"></i><b>17.8.1.2</b> Degree 1</a></li>
<li class="chapter" data-level="17.8.1.3" data-path="sklearn.html"><a href="sklearn.html#degree-2"><i class="fa fa-check"></i><b>17.8.1.3</b> Degree 2</a></li>
<li class="chapter" data-level="17.8.1.4" data-path="sklearn.html"><a href="sklearn.html#degree-3"><i class="fa fa-check"></i><b>17.8.1.4</b> Degree 3</a></li>
<li class="chapter" data-level="17.8.1.5" data-path="sklearn.html"><a href="sklearn.html#degree-4"><i class="fa fa-check"></i><b>17.8.1.5</b> Degree 4</a></li>
</ul></li>
<li class="chapter" data-level="17.8.2" data-path="sklearn.html"><a href="sklearn.html#two-variables"><i class="fa fa-check"></i><b>17.8.2</b> Two Variables</a><ul>
<li class="chapter" data-level="17.8.2.1" data-path="sklearn.html"><a href="sklearn.html#sample-data-22"><i class="fa fa-check"></i><b>17.8.2.1</b> Sample Data</a></li>
<li class="chapter" data-level="17.8.2.2" data-path="sklearn.html"><a href="sklearn.html#degree-2-1"><i class="fa fa-check"></i><b>17.8.2.2</b> Degree 2</a></li>
<li class="chapter" data-level="17.8.2.3" data-path="sklearn.html"><a href="sklearn.html#degree-3-1"><i class="fa fa-check"></i><b>17.8.2.3</b> Degree 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17.9" data-path="sklearn.html"><a href="sklearn.html#imputation-of-missing-data"><i class="fa fa-check"></i><b>17.9</b> Imputation of Missing Data</a><ul>
<li class="chapter" data-level="17.9.1" data-path="sklearn.html"><a href="sklearn.html#sample-data-23"><i class="fa fa-check"></i><b>17.9.1</b> Sample Data</a></li>
<li class="chapter" data-level="17.9.2" data-path="sklearn.html"><a href="sklearn.html#imputer"><i class="fa fa-check"></i><b>17.9.2</b> Imputer</a><ul>
<li class="chapter" data-level="17.9.2.1" data-path="sklearn.html"><a href="sklearn.html#mean-strategy"><i class="fa fa-check"></i><b>17.9.2.1</b> mean strategy</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17.10" data-path="sklearn.html"><a href="sklearn.html#scaling"><i class="fa fa-check"></i><b>17.10</b> Scaling</a><ul>
<li class="chapter" data-level="17.10.1" data-path="sklearn.html"><a href="sklearn.html#sample-data-24"><i class="fa fa-check"></i><b>17.10.1</b> Sample Data</a></li>
<li class="chapter" data-level="17.10.2" data-path="sklearn.html"><a href="sklearn.html#minmax-scaler"><i class="fa fa-check"></i><b>17.10.2</b> MinMax Scaler</a></li>
<li class="chapter" data-level="17.10.3" data-path="sklearn.html"><a href="sklearn.html#standard-scaler"><i class="fa fa-check"></i><b>17.10.3</b> Standard Scaler</a></li>
</ul></li>
<li class="chapter" data-level="17.11" data-path="sklearn.html"><a href="sklearn.html#pipeline"><i class="fa fa-check"></i><b>17.11</b> Pipeline</a><ul>
<li class="chapter" data-level="17.11.1" data-path="sklearn.html"><a href="sklearn.html#sample-data-25"><i class="fa fa-check"></i><b>17.11.1</b> Sample Data</a></li>
<li class="chapter" data-level="17.11.2" data-path="sklearn.html"><a href="sklearn.html#create-pipeline"><i class="fa fa-check"></i><b>17.11.2</b> Create Pipeline</a></li>
<li class="chapter" data-level="17.11.3" data-path="sklearn.html"><a href="sklearn.html#executing-pipeline"><i class="fa fa-check"></i><b>17.11.3</b> Executing Pipeline</a></li>
</ul></li>
<li class="chapter" data-level="17.12" data-path="sklearn.html"><a href="sklearn.html#cross-validation"><i class="fa fa-check"></i><b>17.12</b> Cross Validation</a><ul>
<li class="chapter" data-level="17.12.1" data-path="sklearn.html"><a href="sklearn.html#load-data"><i class="fa fa-check"></i><b>17.12.1</b> Load Data</a></li>
<li class="chapter" data-level="17.12.2" data-path="sklearn.html"><a href="sklearn.html#choose-an-cross-validator"><i class="fa fa-check"></i><b>17.12.2</b> Choose An Cross Validator</a></li>
<li class="chapter" data-level="17.12.3" data-path="sklearn.html"><a href="sklearn.html#run-cross-validation"><i class="fa fa-check"></i><b>17.12.3</b> Run Cross Validation</a></li>
<li class="chapter" data-level="17.12.4" data-path="sklearn.html"><a href="sklearn.html#the-result"><i class="fa fa-check"></i><b>17.12.4</b> The Result</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="nlp.html"><a href="nlp.html"><i class="fa fa-check"></i><b>18</b> NLP</a><ul>
<li class="chapter" data-level="18.1" data-path="nlp.html"><a href="nlp.html#regular-expression"><i class="fa fa-check"></i><b>18.1</b> Regular Expression</a><ul>
<li class="chapter" data-level="18.1.1" data-path="nlp.html"><a href="nlp.html#syntax"><i class="fa fa-check"></i><b>18.1.1</b> Syntax</a></li>
<li class="chapter" data-level="18.1.2" data-path="nlp.html"><a href="nlp.html#finding"><i class="fa fa-check"></i><b>18.1.2</b> Finding</a><ul>
<li class="chapter" data-level="18.1.2.1" data-path="nlp.html"><a href="nlp.html#find-the-first-match"><i class="fa fa-check"></i><b>18.1.2.1</b> Find The First Match</a></li>
<li class="chapter" data-level="18.1.2.2" data-path="nlp.html"><a href="nlp.html#find-all-matches"><i class="fa fa-check"></i><b>18.1.2.2</b> Find All Matches</a></li>
</ul></li>
<li class="chapter" data-level="18.1.3" data-path="nlp.html"><a href="nlp.html#matching-condition"><i class="fa fa-check"></i><b>18.1.3</b> Matching Condition</a><ul>
<li class="chapter" data-level="18.1.3.1" data-path="nlp.html"><a href="nlp.html#meta-characters"><i class="fa fa-check"></i><b>18.1.3.1</b> Meta Characters</a></li>
<li class="chapter" data-level="18.1.3.2" data-path="nlp.html"><a href="nlp.html#special-sequence"><i class="fa fa-check"></i><b>18.1.3.2</b> Special Sequence</a></li>
<li class="chapter" data-level="18.1.3.3" data-path="nlp.html"><a href="nlp.html#repetition"><i class="fa fa-check"></i><b>18.1.3.3</b> Repetition</a></li>
<li class="chapter" data-level="18.1.3.4" data-path="nlp.html"><a href="nlp.html#greedy-vs-non-greedy"><i class="fa fa-check"></i><b>18.1.3.4</b> Greedy vs Non-Greedy</a></li>
</ul></li>
<li class="chapter" data-level="18.1.4" data-path="nlp.html"><a href="nlp.html#grouping-1"><i class="fa fa-check"></i><b>18.1.4</b> Grouping</a><ul>
<li class="chapter" data-level="18.1.4.1" data-path="nlp.html"><a href="nlp.html#capturing-group"><i class="fa fa-check"></i><b>18.1.4.1</b> Capturing Group</a></li>
<li class="chapter" data-level="18.1.4.2" data-path="nlp.html"><a href="nlp.html#non-capturing-group"><i class="fa fa-check"></i><b>18.1.4.2</b> Non-Capturing Group</a></li>
</ul></li>
<li class="chapter" data-level="18.1.5" data-path="nlp.html"><a href="nlp.html#splittitng"><i class="fa fa-check"></i><b>18.1.5</b> Splittitng</a><ul>
<li class="chapter" data-level="18.1.5.1" data-path="nlp.html"><a href="nlp.html#use-re.split"><i class="fa fa-check"></i><b>18.1.5.1</b> Use <code>re.split()</code></a></li>
<li class="chapter" data-level="18.1.5.2" data-path="nlp.html"><a href="nlp.html#use-re.compile.split"><i class="fa fa-check"></i><b>18.1.5.2</b> Use <code>re.compile().split()</code></a></li>
</ul></li>
<li class="chapter" data-level="18.1.6" data-path="nlp.html"><a href="nlp.html#substitution-re.sub"><i class="fa fa-check"></i><b>18.1.6</b> Substitution <code>re.sub()</code></a><ul>
<li class="chapter" data-level="18.1.6.1" data-path="nlp.html"><a href="nlp.html#found-match"><i class="fa fa-check"></i><b>18.1.6.1</b> Found Match</a></li>
<li class="chapter" data-level="18.1.6.2" data-path="nlp.html"><a href="nlp.html#no-match"><i class="fa fa-check"></i><b>18.1.6.2</b> No Match</a></li>
</ul></li>
<li class="chapter" data-level="18.1.7" data-path="nlp.html"><a href="nlp.html#practical-examples"><i class="fa fa-check"></i><b>18.1.7</b> Practical Examples</a><ul>
<li class="chapter" data-level="18.1.7.1" data-path="nlp.html"><a href="nlp.html#extracting-float"><i class="fa fa-check"></i><b>18.1.7.1</b> Extracting Float</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="nlp.html"><a href="nlp.html#word-tokenizer"><i class="fa fa-check"></i><b>18.2</b> Word Tokenizer</a><ul>
<li class="chapter" data-level="18.2.1" data-path="nlp.html"><a href="nlp.html#custom-tokenizer"><i class="fa fa-check"></i><b>18.2.1</b> Custom Tokenizer</a><ul>
<li class="chapter" data-level="18.2.1.1" data-path="nlp.html"><a href="nlp.html#split-by-regex-pattern"><i class="fa fa-check"></i><b>18.2.1.1</b> Split By Regex Pattern</a></li>
<li class="chapter" data-level="18.2.1.2" data-path="nlp.html"><a href="nlp.html#pick-by-regex-pattern-nltk.tokenize.regexptokenizer"><i class="fa fa-check"></i><b>18.2.1.2</b> Pick By Regex Pattern <code>nltk.tokenize.RegexpTokenizer</code></a></li>
</ul></li>
<li class="chapter" data-level="18.2.2" data-path="nlp.html"><a href="nlp.html#nltk.tokenize.word_tokenize"><i class="fa fa-check"></i><b>18.2.2</b> <code>nltk.tokenize.word_tokenize()</code></a></li>
<li class="chapter" data-level="18.2.3" data-path="nlp.html"><a href="nlp.html#nltk.tokenize.casual.casual_tokenize"><i class="fa fa-check"></i><b>18.2.3</b> <code>nltk.tokenize.casual.casual_tokenize()</code></a></li>
<li class="chapter" data-level="18.2.4" data-path="nlp.html"><a href="nlp.html#nltk.tokenize.treebank.treebankwordtokenizer.tokenize"><i class="fa fa-check"></i><b>18.2.4</b> <code>nltk.tokenize.treebank.TreebankWordTokenizer().tokenize()</code></a></li>
<li class="chapter" data-level="18.2.5" data-path="nlp.html"><a href="nlp.html#corpus-token-extractor"><i class="fa fa-check"></i><b>18.2.5</b> Corpus Token Extractor</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="nlp.html"><a href="nlp.html#sentence-tokenizer"><i class="fa fa-check"></i><b>18.3</b> Sentence Tokenizer</a><ul>
<li class="chapter" data-level="18.3.1" data-path="nlp.html"><a href="nlp.html#sample-text"><i class="fa fa-check"></i><b>18.3.1</b> Sample Text</a></li>
<li class="chapter" data-level="18.3.2" data-path="nlp.html"><a href="nlp.html#nltk.tokenize.punkt.punktsentencetokenizer"><i class="fa fa-check"></i><b>18.3.2</b> ’nltk.tokenize.punkt.PunktSentenceTokenizer`</a><ul>
<li class="chapter" data-level="18.3.2.1" data-path="nlp.html"><a href="nlp.html#default-behavior"><i class="fa fa-check"></i><b>18.3.2.1</b> Default Behavior</a></li>
<li class="chapter" data-level="18.3.2.2" data-path="nlp.html"><a href="nlp.html#pretrained-model---english-pickle"><i class="fa fa-check"></i><b>18.3.2.2</b> Pretrained Model - English Pickle</a></li>
<li class="chapter" data-level="18.3.2.3" data-path="nlp.html"><a href="nlp.html#adding-abbreviations"><i class="fa fa-check"></i><b>18.3.2.3</b> Adding Abbreviations</a></li>
</ul></li>
<li class="chapter" data-level="18.3.3" data-path="nlp.html"><a href="nlp.html#nltk.tokenize.sent_tokenize"><i class="fa fa-check"></i><b>18.3.3</b> <code>nltk.tokenize.sent_tokenize()</code></a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="nlp.html"><a href="nlp.html#n-gram"><i class="fa fa-check"></i><b>18.4</b> N-Gram</a></li>
<li class="chapter" data-level="18.5" data-path="nlp.html"><a href="nlp.html#stopwords"><i class="fa fa-check"></i><b>18.5</b> Stopwords</a><ul>
<li class="chapter" data-level="18.5.1" data-path="nlp.html"><a href="nlp.html#custom-stop-words"><i class="fa fa-check"></i><b>18.5.1</b> Custom Stop Words</a></li>
<li class="chapter" data-level="18.5.2" data-path="nlp.html"><a href="nlp.html#nltk-stop-words"><i class="fa fa-check"></i><b>18.5.2</b> NLTK Stop Words</a></li>
<li class="chapter" data-level="18.5.3" data-path="nlp.html"><a href="nlp.html#sklearn-stop-words"><i class="fa fa-check"></i><b>18.5.3</b> SKLearn Stop Words</a></li>
<li class="chapter" data-level="18.5.4" data-path="nlp.html"><a href="nlp.html#combined-nltk-and-sklearn-stop-words"><i class="fa fa-check"></i><b>18.5.4</b> Combined NLTK and SKLearn Stop Words</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="nlp.html"><a href="nlp.html#normalizing"><i class="fa fa-check"></i><b>18.6</b> Normalizing</a><ul>
<li class="chapter" data-level="18.6.1" data-path="nlp.html"><a href="nlp.html#case-folding"><i class="fa fa-check"></i><b>18.6.1</b> Case Folding</a></li>
<li class="chapter" data-level="18.6.2" data-path="nlp.html"><a href="nlp.html#stemming"><i class="fa fa-check"></i><b>18.6.2</b> Stemming</a></li>
<li class="chapter" data-level="18.6.3" data-path="nlp.html"><a href="nlp.html#lemmatization"><i class="fa fa-check"></i><b>18.6.3</b> Lemmatization</a></li>
<li class="chapter" data-level="18.6.4" data-path="nlp.html"><a href="nlp.html#comparing-stemming-and-lemmatization"><i class="fa fa-check"></i><b>18.6.4</b> Comparing Stemming and Lemmatization</a></li>
</ul></li>
<li class="chapter" data-level="18.7" data-path="nlp.html"><a href="nlp.html#wordnet"><i class="fa fa-check"></i><b>18.7</b> Wordnet</a><ul>
<li class="chapter" data-level="18.7.1" data-path="nlp.html"><a href="nlp.html#nltk-and-wordnet"><i class="fa fa-check"></i><b>18.7.1</b> NLTK and Wordnet</a></li>
<li class="chapter" data-level="18.7.2" data-path="nlp.html"><a href="nlp.html#synset"><i class="fa fa-check"></i><b>18.7.2</b> Synset</a><ul>
<li class="chapter" data-level="18.7.2.1" data-path="nlp.html"><a href="nlp.html#notation"><i class="fa fa-check"></i><b>18.7.2.1</b> Notation</a></li>
<li class="chapter" data-level="18.7.2.2" data-path="nlp.html"><a href="nlp.html#part-of-speech"><i class="fa fa-check"></i><b>18.7.2.2</b> Part of Speech</a></li>
<li class="chapter" data-level="18.7.2.3" data-path="nlp.html"><a href="nlp.html#synset-similarity"><i class="fa fa-check"></i><b>18.7.2.3</b> Synset Similarity</a></li>
</ul></li>
<li class="chapter" data-level="18.7.3" data-path="nlp.html"><a href="nlp.html#synsets"><i class="fa fa-check"></i><b>18.7.3</b> Synsets</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="nlp.html"><a href="nlp.html#part-of-speech-pos"><i class="fa fa-check"></i><b>18.8</b> Part Of Speech (POS)</a><ul>
<li class="chapter" data-level="18.8.1" data-path="nlp.html"><a href="nlp.html#tag-sets"><i class="fa fa-check"></i><b>18.8.1</b> Tag Sets</a><ul>
<li class="chapter" data-level="18.8.1.1" data-path="nlp.html"><a href="nlp.html#universal-tagset"><i class="fa fa-check"></i><b>18.8.1.1</b> Universal Tagset</a></li>
<li class="chapter" data-level="18.8.1.2" data-path="nlp.html"><a href="nlp.html#penn-treebank-tagset"><i class="fa fa-check"></i><b>18.8.1.2</b> Penn Treebank Tagset</a></li>
<li class="chapter" data-level="18.8.1.3" data-path="nlp.html"><a href="nlp.html#claws5-tagset"><i class="fa fa-check"></i><b>18.8.1.3</b> Claws5 Tagset</a></li>
<li class="chapter" data-level="18.8.1.4" data-path="nlp.html"><a href="nlp.html#brown-tagset"><i class="fa fa-check"></i><b>18.8.1.4</b> Brown Tagset</a></li>
</ul></li>
<li class="chapter" data-level="18.8.2" data-path="nlp.html"><a href="nlp.html#tagging-techniques"><i class="fa fa-check"></i><b>18.8.2</b> Tagging Techniques</a><ul>
<li class="chapter" data-level="18.8.2.1" data-path="nlp.html"><a href="nlp.html#nltk-perceptrontagger"><i class="fa fa-check"></i><b>18.8.2.1</b> nltk <code>PerceptronTagger</code></a></li>
</ul></li>
<li class="chapter" data-level="18.8.3" data-path="nlp.html"><a href="nlp.html#performing-tagging-nltk.pos_tag"><i class="fa fa-check"></i><b>18.8.3</b> Performing Tagging <code>nltk.pos_tag()</code></a></li>
</ul></li>
<li class="chapter" data-level="18.9" data-path="nlp.html"><a href="nlp.html#sentiment"><i class="fa fa-check"></i><b>18.9</b> Sentiment</a><ul>
<li class="chapter" data-level="18.9.1" data-path="nlp.html"><a href="nlp.html#nltk-and-senti-wordnet"><i class="fa fa-check"></i><b>18.9.1</b> NLTK and Senti-Wordnet</a><ul>
<li class="chapter" data-level="18.9.1.1" data-path="nlp.html"><a href="nlp.html#senti-synset"><i class="fa fa-check"></i><b>18.9.1.1</b> Senti-Synset</a></li>
<li class="chapter" data-level="18.9.1.2" data-path="nlp.html"><a href="nlp.html#senti-synsets"><i class="fa fa-check"></i><b>18.9.1.2</b> Senti-Synsets</a></li>
<li class="chapter" data-level="18.9.1.3" data-path="nlp.html"><a href="nlp.html#converting-pos-tag-into-wordnet-pos-tag"><i class="fa fa-check"></i><b>18.9.1.3</b> Converting POS-tag into Wordnet POS-tag</a></li>
</ul></li>
<li class="chapter" data-level="18.9.2" data-path="nlp.html"><a href="nlp.html#vader"><i class="fa fa-check"></i><b>18.9.2</b> Vader</a><ul>
<li class="chapter" data-level="18.9.2.1" data-path="nlp.html"><a href="nlp.html#vader-lexicon"><i class="fa fa-check"></i><b>18.9.2.1</b> Vader Lexicon</a></li>
<li class="chapter" data-level="18.9.2.2" data-path="nlp.html"><a href="nlp.html#polarity-scoring"><i class="fa fa-check"></i><b>18.9.2.2</b> Polarity Scoring</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18.10" data-path="nlp.html"><a href="nlp.html#feature-representation"><i class="fa fa-check"></i><b>18.10</b> Feature Representation</a><ul>
<li class="chapter" data-level="18.10.1" data-path="nlp.html"><a href="nlp.html#the-data-3"><i class="fa fa-check"></i><b>18.10.1</b> The Data</a></li>
<li class="chapter" data-level="18.10.2" data-path="nlp.html"><a href="nlp.html#frequency-count-1"><i class="fa fa-check"></i><b>18.10.2</b> Frequency Count</a><ul>
<li class="chapter" data-level="18.10.2.1" data-path="nlp.html"><a href="nlp.html#tokenizer"><i class="fa fa-check"></i><b>18.10.2.1</b> + Tokenizer</a></li>
<li class="chapter" data-level="18.10.2.2" data-path="nlp.html"><a href="nlp.html#stop-words"><i class="fa fa-check"></i><b>18.10.2.2</b> + Stop Words</a></li>
</ul></li>
<li class="chapter" data-level="18.10.3" data-path="nlp.html"><a href="nlp.html#tfidf"><i class="fa fa-check"></i><b>18.10.3</b> TFIDF</a><ul>
<li class="chapter" data-level="18.10.3.1" data-path="nlp.html"><a href="nlp.html#equation"><i class="fa fa-check"></i><b>18.10.3.1</b> Equation</a></li>
<li class="chapter" data-level="18.10.3.2" data-path="nlp.html"><a href="nlp.html#tfidftransformer"><i class="fa fa-check"></i><b>18.10.3.2</b> <code>TfidfTransformer</code></a></li>
<li class="chapter" data-level="18.10.3.3" data-path="nlp.html"><a href="nlp.html#tfidfvectorizer"><i class="fa fa-check"></i><b>18.10.3.3</b> <code>TfidfVectorizer</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18.11" data-path="nlp.html"><a href="nlp.html#appliction"><i class="fa fa-check"></i><b>18.11</b> Appliction</a><ul>
<li class="chapter" data-level="18.11.1" data-path="nlp.html"><a href="nlp.html#document-similarity"><i class="fa fa-check"></i><b>18.11.1</b> Document Similarity</a></li>
</ul></li>
<li class="chapter" data-level="18.12" data-path="nlp.html"><a href="nlp.html#naive-bayes"><i class="fa fa-check"></i><b>18.12</b> Naive Bayes</a><ul>
<li class="chapter" data-level="18.12.1" data-path="nlp.html"><a href="nlp.html#libraries"><i class="fa fa-check"></i><b>18.12.1</b> Libraries</a></li>
<li class="chapter" data-level="18.12.2" data-path="nlp.html"><a href="nlp.html#the-data-4"><i class="fa fa-check"></i><b>18.12.2</b> The Data</a></li>
<li class="chapter" data-level="18.12.3" data-path="nlp.html"><a href="nlp.html#bag-of-words"><i class="fa fa-check"></i><b>18.12.3</b> Bag of Words</a></li>
<li class="chapter" data-level="18.12.4" data-path="nlp.html"><a href="nlp.html#build-the-model"><i class="fa fa-check"></i><b>18.12.4</b> Build The Model</a></li>
<li class="chapter" data-level="18.12.5" data-path="nlp.html"><a href="nlp.html#train-set-prediction"><i class="fa fa-check"></i><b>18.12.5</b> Train Set Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="web-scrapping.html"><a href="web-scrapping.html"><i class="fa fa-check"></i><b>19</b> Web Scrapping</a><ul>
<li class="chapter" data-level="19.1" data-path="web-scrapping.html"><a href="web-scrapping.html#requests"><i class="fa fa-check"></i><b>19.1</b> <code>requests</code></a><ul>
<li class="chapter" data-level="19.1.1" data-path="web-scrapping.html"><a href="web-scrapping.html#creating-a-session"><i class="fa fa-check"></i><b>19.1.1</b> Creating A Session</a></li>
<li class="chapter" data-level="19.1.2" data-path="web-scrapping.html"><a href="web-scrapping.html#rotating-broswer"><i class="fa fa-check"></i><b>19.1.2</b> Rotating Broswer</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="web-scrapping.html"><a href="web-scrapping.html#beautifulsoup"><i class="fa fa-check"></i><b>19.2</b> <code>BeautifulSoup</code></a><ul>
<li class="chapter" data-level="19.2.1" data-path="web-scrapping.html"><a href="web-scrapping.html#module-import-2"><i class="fa fa-check"></i><b>19.2.1</b> Module Import</a></li>
<li class="chapter" data-level="19.2.2" data-path="web-scrapping.html"><a href="web-scrapping.html#html-tag-parsing"><i class="fa fa-check"></i><b>19.2.2</b> HTML Tag Parsing</a><ul>
<li class="chapter" data-level="19.2.2.1" data-path="web-scrapping.html"><a href="web-scrapping.html#sample-data-26"><i class="fa fa-check"></i><b>19.2.2.1</b> Sample Data</a></li>
<li class="chapter" data-level="19.2.2.2" data-path="web-scrapping.html"><a href="web-scrapping.html#first-match"><i class="fa fa-check"></i><b>19.2.2.2</b> First Match</a></li>
<li class="chapter" data-level="19.2.2.3" data-path="web-scrapping.html"><a href="web-scrapping.html#find-all-matches-1"><i class="fa fa-check"></i><b>19.2.2.3</b> Find All Matches</a></li>
</ul></li>
<li class="chapter" data-level="19.2.3" data-path="web-scrapping.html"><a href="web-scrapping.html#meta-parsing"><i class="fa fa-check"></i><b>19.2.3</b> Meta Parsing</a></li>
<li class="chapter" data-level="19.2.4" data-path="web-scrapping.html"><a href="web-scrapping.html#getting-content"><i class="fa fa-check"></i><b>19.2.4</b> Getting Content</a><ul>
<li class="chapter" data-level="19.2.4.1" data-path="web-scrapping.html"><a href="web-scrapping.html#get-content-get_textstrip-separator"><i class="fa fa-check"></i><b>19.2.4.1</b> Get Content <code>get_text(strip=, separator=)</code></a></li>
<li class="chapter" data-level="19.2.4.2" data-path="web-scrapping.html"><a href="web-scrapping.html#splitting-content"><i class="fa fa-check"></i><b>19.2.4.2</b> Splitting Content</a></li>
</ul></li>
<li class="chapter" data-level="19.2.5" data-path="web-scrapping.html"><a href="web-scrapping.html#traversing"><i class="fa fa-check"></i><b>19.2.5</b> Traversing</a><ul>
<li class="chapter" data-level="19.2.5.1" data-path="web-scrapping.html"><a href="web-scrapping.html#get-the-element"><i class="fa fa-check"></i><b>19.2.5.1</b> Get The Element</a></li>
<li class="chapter" data-level="19.2.5.2" data-path="web-scrapping.html"><a href="web-scrapping.html#traversing-children"><i class="fa fa-check"></i><b>19.2.5.2</b> Traversing Children</a></li>
<li class="chapter" data-level="19.2.5.3" data-path="web-scrapping.html"><a href="web-scrapping.html#traversing-to-parent-parent"><i class="fa fa-check"></i><b>19.2.5.3</b> Traversing To Parent <code>parent()</code></a></li>
<li class="chapter" data-level="19.2.5.4" data-path="web-scrapping.html"><a href="web-scrapping.html#get-the-sibling-findprevioussibling"><i class="fa fa-check"></i><b>19.2.5.4</b> Get The Sibling <code>findPreviousSibling()</code></a></li>
</ul></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="finance.html"><a href="finance.html"><i class="fa fa-check"></i><b>20</b> Finance</a><ul>
<li class="chapter" data-level="20.1" data-path="finance.html"><a href="finance.html#getting-data"><i class="fa fa-check"></i><b>20.1</b> Getting Data</a><ul>
<li class="chapter" data-level="20.1.1" data-path="finance.html"><a href="finance.html#pandas_datareder"><i class="fa fa-check"></i><b>20.1.1</b> <code>pandas_datareder</code></a><ul>
<li class="chapter" data-level="20.1.1.1" data-path="finance.html"><a href="finance.html#ohlc-eod-pricing"><i class="fa fa-check"></i><b>20.1.1.1</b> OHLC EOD Pricing</a></li>
<li class="chapter" data-level="20.1.1.2" data-path="finance.html"><a href="finance.html#splits-and-dividends"><i class="fa fa-check"></i><b>20.1.1.2</b> Splits and Dividends</a></li>
<li class="chapter" data-level="20.1.1.3" data-path="finance.html"><a href="finance.html#merging-ohlc-and-splitsdividends"><i class="fa fa-check"></i><b>20.1.1.3</b> Merging OHLC and Splits/Dividends</a></li>
<li class="chapter" data-level="20.1.1.4" data-path="finance.html"><a href="finance.html#query-multiple-stocks"><i class="fa fa-check"></i><b>20.1.1.4</b> Query Multiple Stocks</a></li>
</ul></li>
<li class="chapter" data-level="20.1.2" data-path="finance.html"><a href="finance.html#yfinance"><i class="fa fa-check"></i><b>20.1.2</b> <code>yfinance</code></a><ul>
<li class="chapter" data-level="20.1.2.1" data-path="finance.html"><a href="finance.html#stock-info"><i class="fa fa-check"></i><b>20.1.2.1</b> Stock Info</a></li>
<li class="chapter" data-level="20.1.2.2" data-path="finance.html"><a href="finance.html#ohlc-eod-pricing-1"><i class="fa fa-check"></i><b>20.1.2.2</b> OHLC EOD Pricing</a></li>
<li class="chapter" data-level="20.1.2.3" data-path="finance.html"><a href="finance.html#splits-and-dividends-1"><i class="fa fa-check"></i><b>20.1.2.3</b> Splits and Dividends</a></li>
<li class="chapter" data-level="20.1.2.4" data-path="finance.html"><a href="finance.html#query-using-periods"><i class="fa fa-check"></i><b>20.1.2.4</b> Query Using Periods</a></li>
<li class="chapter" data-level="20.1.2.5" data-path="finance.html"><a href="finance.html#query-multiple-stocks-1"><i class="fa fa-check"></i><b>20.1.2.5</b> Query Multiple Stocks</a></li>
</ul></li>
<li class="chapter" data-level="20.1.3" data-path="finance.html"><a href="finance.html#world-trading"><i class="fa fa-check"></i><b>20.1.3</b> <code>world trading</code></a><ul>
<li class="chapter" data-level="20.1.3.1" data-path="finance.html"><a href="finance.html#ohlc-eod-pricing-2"><i class="fa fa-check"></i><b>20.1.3.1</b> OHLC EOD Pricing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="finance.html"><a href="finance.html#charting"><i class="fa fa-check"></i><b>20.2</b> Charting</a><ul>
<li class="chapter" data-level="20.2.1" data-path="finance.html"><a href="finance.html#price-comparison"><i class="fa fa-check"></i><b>20.2.1</b> Price Comparison</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Python Bookdown</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nlp" class="section level1">
<h1><span class="header-section-number">18</span> NLP</h1>
<p>Natural Language Processing</p>
<div id="regular-expression" class="section level2">
<h2><span class="header-section-number">18.1</span> Regular Expression</h2>
<ul>
<li>Rgular expressions (called REs or regexes) is mandatory skill for NLP. The <code>re</code> is a **built-in* library<br />
</li>
<li>It is essentially a tiny, highly specialized programming language embedded inside Python and made available through the re module<br />
</li>
<li>Regular expression patterns are compiled into a series of bytecodes which are then executed by a matching engine written in C</li>
</ul>
<div id="syntax" class="section level3">
<h3><span class="header-section-number">18.1.1</span> Syntax</h3>
<p>There are two methods to emply re. Below method compile a regex first, then apply it multiple times in subsequent code.</p>
<div class="sourceCode" id="cb1796"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1796-1" title="1"><span class="im">import</span> re</a>
<a class="sourceLine" id="cb1796-2" title="2">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;put pattern here&#39;</span>)</a>
<a class="sourceLine" id="cb1796-3" title="3">pattern.match(<span class="st">&#39;put text here&#39;</span>)</a></code></pre></div>
<p>Second method below employ compile and match in single line. The pattern cannot be reused, therefore good for onetime usage only.</p>
<div class="sourceCode" id="cb1797"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1797-1" title="1"><span class="im">import</span> re</a>
<a class="sourceLine" id="cb1797-2" title="2">pattern <span class="op">=</span> (<span class="vs">r&#39;put pattern here&#39;</span>)</a>
<a class="sourceLine" id="cb1797-3" title="3">re.match(pattern, <span class="vs">r&#39;put text here&#39;</span>)  <span class="co"># compile and match in single line</span></a></code></pre></div>
</div>
<div id="finding" class="section level3">
<h3><span class="header-section-number">18.1.2</span> Finding</h3>
<div id="find-the-first-match" class="section level4">
<h4><span class="header-section-number">18.1.2.1</span> Find The First Match</h4>
<p>There are two ways to find the first match:<br />
- <strong><code>re.search</code></strong> find first match anywhere in text, including multiline<br />
- <strong><code>re.match</code></strong> find first match at the BEGINNING of text, similar to <code>re.search</code>with <code>^</code><br />
- Both returns first match, return <strong>MatchObject</strong><br />
- Both returns <strong>None</strong> if no match is found</p>
<div class="sourceCode" id="cb1798"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1798-1" title="1">pattern1 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="st">&#39;123&#39;</span>) </a>
<a class="sourceLine" id="cb1798-2" title="2">pattern2 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="st">&#39;123&#39;</span>)</a>
<a class="sourceLine" id="cb1798-3" title="3">pattern3 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="st">&#39;^123&#39;</span>)  <span class="co"># equivalent to above</span></a>
<a class="sourceLine" id="cb1798-4" title="4">text <span class="op">=</span> <span class="st">&#39;abc123xyz&#39;</span></a>
<a class="sourceLine" id="cb1798-5" title="5"></a>
<a class="sourceLine" id="cb1798-6" title="6"><span class="co">## Single Line Text Example</span></a>
<a class="sourceLine" id="cb1798-7" title="7"><span class="bu">print</span>( <span class="st">&#39;re.search found a match somewhere:</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1798-8" title="8">       pattern1.search(text), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>, <span class="co">## found</span></a>
<a class="sourceLine" id="cb1798-9" title="9">       <span class="st">&#39;</span><span class="ch">\n</span><span class="st">re.match did not find anything at the beginning:</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1798-10" title="10">       pattern2.match(text), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1798-11" title="11">       <span class="st">&#39;</span><span class="ch">\n</span><span class="st">re.search did not find anything at beginning too:</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1798-12" title="12">       pattern3.search(text))        <span class="co">## None</span></a></code></pre></div>
<pre><code>## re.search found a match somewhere:
##  &lt;re.Match object; span=(3, 6), match=&#39;123&#39;&gt; 
##  
## re.match did not find anything at the beginning:
##  None 
##  
## re.search did not find anything at beginning too:
##  None</code></pre>
<p>Returned <strong>MatchObject</strong> provides useful information about the matched string.</p>
<div class="sourceCode" id="cb1800"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1800-1" title="1">age_pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;\d+&#39;</span>)</a>
<a class="sourceLine" id="cb1800-2" title="2">age_text    <span class="op">=</span> <span class="st">&#39;Ali is my teacher. He is 109 years old. his kid is 40 years old.&#39;</span></a>
<a class="sourceLine" id="cb1800-3" title="3">first_found <span class="op">=</span> age_pattern.search(age_text)</a>
<a class="sourceLine" id="cb1800-4" title="4"></a>
<a class="sourceLine" id="cb1800-5" title="5"><span class="bu">print</span>(<span class="st">&#39;Found Object:           &#39;</span>, first_found,</a>
<a class="sourceLine" id="cb1800-6" title="6">      <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Input Text:             &#39;</span>, first_found.string,</a>
<a class="sourceLine" id="cb1800-7" title="7">      <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Input Pattern:          &#39;</span>, first_found.re,</a>
<a class="sourceLine" id="cb1800-8" title="8">      <span class="st">&#39;</span><span class="ch">\n</span><span class="st">First Found string:     &#39;</span>, first_found.group(),</a>
<a class="sourceLine" id="cb1800-9" title="9">      <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Found Start Position:   &#39;</span>, first_found.start(),</a>
<a class="sourceLine" id="cb1800-10" title="10">      <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Found End Position:     &#39;</span>, first_found.end(),</a>
<a class="sourceLine" id="cb1800-11" title="11">      <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Found Span:             &#39;</span>, first_found.span(),)</a></code></pre></div>
<pre><code>## Found Object:            &lt;re.Match object; span=(25, 28), match=&#39;109&#39;&gt; 
## Input Text:              Ali is my teacher. He is 109 years old. his kid is 40 years old. 
## Input Pattern:           re.compile(&#39;\\d+&#39;) 
## First Found string:      109 
## Found Start Position:    25 
## Found End Position:      28 
## Found Span:              (25, 28)</code></pre>
</div>
<div id="find-all-matches" class="section level4">
<h4><span class="header-section-number">18.1.2.2</span> Find All Matches</h4>
<p><strong><code>findall()</code></strong> returns all matching string as <strong>list</strong>. If no matches found, it return an empty list.</p>
<div class="sourceCode" id="cb1802"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1802-1" title="1"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb1802-2" title="2">  <span class="st">&#39;Finding Two Digits:&#39;</span>,</a>
<a class="sourceLine" id="cb1802-3" title="3">  re.findall(<span class="vs">r&#39;\d\d&#39;</span>,<span class="st">&#39;abc123xyz456&#39;</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1802-4" title="4">  <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Found Nothing:&#39;</span>,</a>
<a class="sourceLine" id="cb1802-5" title="5">  re.findall(<span class="vs">r&#39;\d\d&#39;</span>,<span class="st">&#39;abcxyz&#39;</span>))</a></code></pre></div>
<pre><code>## Finding Two Digits: [&#39;12&#39;, &#39;45&#39;] 
##  
## Found Nothing: []</code></pre>
</div>
</div>
<div id="matching-condition" class="section level3">
<h3><span class="header-section-number">18.1.3</span> Matching Condition</h3>
<div id="meta-characters" class="section level4">
<h4><span class="header-section-number">18.1.3.1</span> Meta Characters</h4>
<pre><code>[]     match any single character within the bracket
[1234] is the same as [1-4]
[0-39] is the same as [01239]
[a-e]  is the same as [abcde]
[^abc] means any character except a,b,c
[^0-9] means any character except 0-9
a|b:   a or b
{n,m}  at least n repetition, but maximum m repetition
()     grouping</code></pre>
<div class="sourceCode" id="cb1805"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1805-1" title="1">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;[a-z]+&#39;</span>)</a>
<a class="sourceLine" id="cb1805-2" title="2">text1 <span class="op">=</span> <span class="st">&quot;tempo&quot;</span></a>
<a class="sourceLine" id="cb1805-3" title="3">text2 <span class="op">=</span> <span class="st">&quot;tempo1&quot;</span></a>
<a class="sourceLine" id="cb1805-4" title="4">text3 <span class="op">=</span> <span class="st">&quot;123 tempo1&quot;</span></a>
<a class="sourceLine" id="cb1805-5" title="5">text4 <span class="op">=</span> <span class="st">&quot; tempo&quot;</span></a>
<a class="sourceLine" id="cb1805-6" title="6"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb1805-7" title="7">  <span class="st">&#39;Matching Text1:&#39;</span>, pattern.match(text1),</a>
<a class="sourceLine" id="cb1805-8" title="8">  <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Matching Text2:&#39;</span>, pattern.match(text2),</a>
<a class="sourceLine" id="cb1805-9" title="9">  <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Matching Text3:&#39;</span>, pattern.match(text3),</a>
<a class="sourceLine" id="cb1805-10" title="10">  <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Matching Text4:&#39;</span>, pattern.match(text4))</a></code></pre></div>
<pre><code>## Matching Text1: &lt;re.Match object; span=(0, 5), match=&#39;tempo&#39;&gt; 
## Matching Text2: &lt;re.Match object; span=(0, 5), match=&#39;tempo&#39;&gt; 
## Matching Text3: None 
## Matching Text4: None</code></pre>
</div>
<div id="special-sequence" class="section level4">
<h4><span class="header-section-number">18.1.3.2</span> Special Sequence</h4>
<pre><code>. : [^\n]
\d: [0-9]              \D: [^0-9]
\s: [ \t\n\r\f\v]      \S: [^ \t\n\r\f\v]
\w: [a-zA-Z0-9_]       \W: [^a-zA-Z0-9_]
\t: tab
\n: newline
\b: word boundry (delimited by space, \t, \n)</code></pre>
<p><strong>Word Boundry Using <code>\b</code></strong>:</p>
<ul>
<li><code>\bABC</code> match if specified characters at the beginning of word (delimited by space,  ), or beginning of newline<br />
</li>
<li><code>ABC\b</code> match if specified characters at the end of word (delimited by space,  ), or end of the line</li>
</ul>
<div class="sourceCode" id="cb1808"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1808-1" title="1">text <span class="op">=</span> <span class="st">&quot;ABCD ABC XYZABC&quot;</span></a>
<a class="sourceLine" id="cb1808-2" title="2">pattern1 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;\bABC&#39;</span>)</a>
<a class="sourceLine" id="cb1808-3" title="3">pattern2 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;ABC\b&#39;</span>)</a>
<a class="sourceLine" id="cb1808-4" title="4">pattern3 <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;\bABC\b&#39;</span>)</a>
<a class="sourceLine" id="cb1808-5" title="5"></a>
<a class="sourceLine" id="cb1808-6" title="6"><span class="bu">print</span>(<span class="st">&#39;Match word that begins ABC:&#39;</span>,</a>
<a class="sourceLine" id="cb1808-7" title="7">  pattern1.findall(text), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1808-8" title="8">  <span class="st">&#39;Match word that ends with ABC:&#39;</span>,</a>
<a class="sourceLine" id="cb1808-9" title="9">  pattern2.findall(text),<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1808-10" title="10">  <span class="st">&#39;Match isolated word with ABC:&#39;</span>,</a>
<a class="sourceLine" id="cb1808-11" title="11">  pattern3.findall(text))</a></code></pre></div>
<pre><code>## Match word that begins ABC: [&#39;ABC&#39;, &#39;ABC&#39;] 
##  Match word that ends with ABC: [&#39;ABC&#39;, &#39;ABC&#39;] 
##  Match isolated word with ABC: [&#39;ABC&#39;]</code></pre>
</div>
<div id="repetition" class="section level4">
<h4><span class="header-section-number">18.1.3.3</span> Repetition</h4>
<p>When repetition is used, re will be <strong>greedy</strong>; it try to repeat as many times as possible. If <strong>later portions of the pattern don’t match</strong>, the matching engine will then <strong>back up and try again</strong> with fewer repetitions.</p>
<pre><code>?:    zero or 1 occurance
*:    zero or more occurance
+:    one  or more occurance</code></pre>
<p><strong><code>?</code> Zero or 1 Occurance</strong></p>
<div class="sourceCode" id="cb1811"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1811-1" title="1">text <span class="op">=</span> <span class="st">&#39;abcbcdd&#39;</span></a>
<a class="sourceLine" id="cb1811-2" title="2">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;a[bcd]?b&#39;</span>)</a>
<a class="sourceLine" id="cb1811-3" title="3">pattern.findall(text)</a></code></pre></div>
<pre><code>## [&#39;ab&#39;]</code></pre>
<p><strong><code>+</code> At Least One Occurance</strong></p>
<div class="sourceCode" id="cb1813"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1813-1" title="1">text <span class="op">=</span> <span class="st">&#39;abcbcdd&#39;</span></a>
<a class="sourceLine" id="cb1813-2" title="2">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;a[bcd]+b&#39;</span>)</a>
<a class="sourceLine" id="cb1813-3" title="3">pattern.findall(text)</a></code></pre></div>
<pre><code>## [&#39;abcb&#39;]</code></pre>
<p><strong><code>*</code> Zero Or More Occurance Occurance</strong></p>
<div class="sourceCode" id="cb1815"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1815-1" title="1">text <span class="op">=</span> <span class="st">&#39;abcbcdd&#39;</span></a>
<a class="sourceLine" id="cb1815-2" title="2">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;a[bcd]*b&#39;</span>)</a>
<a class="sourceLine" id="cb1815-3" title="3">pattern.findall(text)</a></code></pre></div>
<pre><code>## [&#39;abcb&#39;]</code></pre>
</div>
<div id="greedy-vs-non-greedy" class="section level4">
<h4><span class="header-section-number">18.1.3.4</span> Greedy vs Non-Greedy</h4>
<ul>
<li>The <code>*</code>, <code>+</code>, and <code>?</code> qualifiers are all greedy; they match as much text as possible<br />
</li>
<li>If the <code>&lt;.*&gt;</code> is matched against <code>&lt;a&gt; b &lt;c&gt;</code>, it will match the entire string, and not just <code>&lt;a&gt;</code><br />
</li>
<li>Adding <strong><code>?</code></strong> after the qualifier makes it perform the match in non-greedy; as few characters as possible will be matched. Using the RE &lt;.*?&gt; will match only ‘<a>’</li>
</ul>
<div class="sourceCode" id="cb1817"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1817-1" title="1">text <span class="op">=</span> <span class="st">&#39;&lt;a&gt; ali baba &lt;c&gt;&#39;</span></a>
<a class="sourceLine" id="cb1817-2" title="2">greedy_pattern     <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;&lt;.*&gt;&#39;</span>)</a>
<a class="sourceLine" id="cb1817-3" title="3">non_greedy_pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;&lt;.*?&gt;&#39;</span>)</a>
<a class="sourceLine" id="cb1817-4" title="4"><span class="bu">print</span>( <span class="st">&#39;Greedy:      &#39;</span> ,        greedy_pattern.findall(text), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1817-5" title="5">       <span class="st">&#39;Non Greedy: &#39;</span>, non_greedy_pattern.findall(text) )</a></code></pre></div>
<pre><code>## Greedy:       [&#39;&lt;a&gt; ali baba &lt;c&gt;&#39;] 
##  Non Greedy:  [&#39;&lt;a&gt;&#39;, &#39;&lt;c&gt;&#39;]</code></pre>
</div>
</div>
<div id="grouping-1" class="section level3">
<h3><span class="header-section-number">18.1.4</span> Grouping</h3>
<p>When <code>()</code> is used in the pattern, retrive the grouping components in MatchObject with <code>.groups()</code>. Result is in list. Example below extract hours, minutes and am/pm into a list.</p>
<div id="capturing-group" class="section level4">
<h4><span class="header-section-number">18.1.4.1</span> Capturing Group</h4>
<div class="sourceCode" id="cb1819"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1819-1" title="1">text <span class="op">=</span> <span class="st">&#39;Today at Wednesday, 10:50pm, we go for a walk&#39;</span></a>
<a class="sourceLine" id="cb1819-2" title="2">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;(\d\d):(\d\d)(am|pm)&#39;</span>)</a>
<a class="sourceLine" id="cb1819-3" title="3">m <span class="op">=</span> pattern.search(text)</a>
<a class="sourceLine" id="cb1819-4" title="4"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb1819-5" title="5">  <span class="st">&#39;All Gropus: &#39;</span>, m.groups(), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1819-6" title="6">  <span class="st">&#39;Group 1: &#39;</span>, m.group(<span class="dv">1</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1819-7" title="7">  <span class="st">&#39;Group 2: &#39;</span>, m.group(<span class="dv">2</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1819-8" title="8">  <span class="st">&#39;Group 3: &#39;</span>, m.group(<span class="dv">3</span>) )</a></code></pre></div>
<pre><code>## All Gropus:  (&#39;10&#39;, &#39;50&#39;, &#39;pm&#39;) 
##  Group 1:  10 
##  Group 2:  50 
##  Group 3:  pm</code></pre>
</div>
<div id="non-capturing-group" class="section level4">
<h4><span class="header-section-number">18.1.4.2</span> Non-Capturing Group</h4>
<p>Having <code>(:? )</code> means don’t capture this group</p>
<div class="sourceCode" id="cb1821"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1821-1" title="1">text <span class="op">=</span> <span class="st">&#39;Today at Wednesday, 10:50pm, we go for a walk&#39;</span></a>
<a class="sourceLine" id="cb1821-2" title="2">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;(:?\d\d):(?:\d\d)(am|pm)&#39;</span>)</a>
<a class="sourceLine" id="cb1821-3" title="3">m <span class="op">=</span> pattern.search(text)</a>
<a class="sourceLine" id="cb1821-4" title="4"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb1821-5" title="5">  <span class="st">&#39;All Gropus: &#39;</span>, m.groups(), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1821-6" title="6">  <span class="st">&#39;Group 1: &#39;</span>, m.group(<span class="dv">1</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1821-7" title="7">  <span class="st">&#39;Group 2: &#39;</span>, m.group(<span class="dv">2</span>) )</a></code></pre></div>
<pre><code>## All Gropus:  (&#39;10&#39;, &#39;pm&#39;) 
##  Group 1:  10 
##  Group 2:  pm</code></pre>
</div>
</div>
<div id="splittitng" class="section level3">
<h3><span class="header-section-number">18.1.5</span> Splittitng</h3>
<p>Pattern is used to match <strong>delimters</strong>.</p>
<div id="use-re.split" class="section level4">
<h4><span class="header-section-number">18.1.5.1</span> Use <code>re.split()</code></h4>
<div class="sourceCode" id="cb1823"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1823-1" title="1"><span class="bu">print</span>( re.split(<span class="st">&#39;@&#39;</span>,  <span class="st">&quot;aa@bb @ cc &quot;</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1823-2" title="2">       re.split(<span class="st">&#39;\|&#39;</span>, <span class="st">&quot;aa|bb | cc &quot;</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1823-3" title="3">       re.split(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>, <span class="st">&quot;sentence1</span><span class="ch">\n</span><span class="st">sentence2</span><span class="ch">\n</span><span class="st">sentence3&quot;</span>) )</a></code></pre></div>
<pre><code>## [&#39;aa&#39;, &#39;bb &#39;, &#39; cc &#39;] 
##  [&#39;aa&#39;, &#39;bb &#39;, &#39; cc &#39;] 
##  [&#39;sentence1&#39;, &#39;sentence2&#39;, &#39;sentence3&#39;]</code></pre>
</div>
<div id="use-re.compile.split" class="section level4">
<h4><span class="header-section-number">18.1.5.2</span> Use <code>re.compile().split()</code></h4>
<div class="sourceCode" id="cb1825"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1825-1" title="1">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&quot;\|&quot;</span>)</a>
<a class="sourceLine" id="cb1825-2" title="2">pattern.split(<span class="st">&quot;aa|bb | cc &quot;</span>)</a></code></pre></div>
<pre><code>## [&#39;aa&#39;, &#39;bb &#39;, &#39; cc &#39;]</code></pre>
</div>
</div>
<div id="substitution-re.sub" class="section level3">
<h3><span class="header-section-number">18.1.6</span> Substitution <code>re.sub()</code></h3>
<div id="found-match" class="section level4">
<h4><span class="header-section-number">18.1.6.1</span> Found Match</h4>
<p>Example below repalce anything within <code>{{.*}}</code></p>
<div class="sourceCode" id="cb1827"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1827-1" title="1">re.sub(<span class="vs">r&#39;(</span><span class="sc">{{</span><span class="vs">.*</span><span class="sc">}}</span><span class="vs">)&#39;</span>, <span class="st">&#39;Durian&#39;</span>, <span class="st">&#39;I like to eat </span><span class="sc">{{</span><span class="st">Food</span><span class="sc">}}</span><span class="st">.&#39;</span>, flags<span class="op">=</span>re.IGNORECASE)</a></code></pre></div>
<pre><code>## &#39;I like to eat Durian.&#39;</code></pre>
<p>Replace <code>AND</code> with <code>&amp;</code>. This does not require <code>()</code> grouping</p>
<div class="sourceCode" id="cb1829"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1829-1" title="1">re.sub(<span class="vs">r&#39;\sAND\s&#39;</span>, <span class="st">&#39; &amp; &#39;</span>, <span class="st">&#39;Baked Beans And Spam&#39;</span>, flags<span class="op">=</span>re.IGNORECASE)</a></code></pre></div>
<pre><code>## &#39;Baked Beans &amp; Spam&#39;</code></pre>
</div>
<div id="no-match" class="section level4">
<h4><span class="header-section-number">18.1.6.2</span> No Match</h4>
<p>If not pattern not found, return the original text.</p>
<div class="sourceCode" id="cb1831"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1831-1" title="1">re.sub(<span class="vs">r&#39;(</span><span class="sc">{{</span><span class="vs">.*</span><span class="sc">}}</span><span class="vs">)&#39;</span>, <span class="st">&#39;Durian&#39;</span>, <span class="st">&#39;I like to eat &lt;Food&gt;.&#39;</span>, flags<span class="op">=</span>re.IGNORECASE)</a></code></pre></div>
<pre><code>## &#39;I like to eat &lt;Food&gt;.&#39;</code></pre>
</div>
</div>
<div id="practical-examples" class="section level3">
<h3><span class="header-section-number">18.1.7</span> Practical Examples</h3>
<div id="extracting-float" class="section level4">
<h4><span class="header-section-number">18.1.7.1</span> Extracting Float</h4>
<div class="sourceCode" id="cb1833"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1833-1" title="1">re_float <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&#39;\d+(\.\d+)?&#39;</span>)</a>
<a class="sourceLine" id="cb1833-2" title="2"><span class="kw">def</span> extract_float(x):</a>
<a class="sourceLine" id="cb1833-3" title="3">    money <span class="op">=</span> x.replace(<span class="st">&#39;,&#39;</span>,<span class="st">&#39;&#39;</span>)</a>
<a class="sourceLine" id="cb1833-4" title="4">    result <span class="op">=</span> re_float.search(money)</a>
<a class="sourceLine" id="cb1833-5" title="5">    <span class="cf">return</span> <span class="bu">float</span>(result.group()) <span class="cf">if</span> result <span class="cf">else</span> <span class="bu">float</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb1833-6" title="6"></a>
<a class="sourceLine" id="cb1833-7" title="7"><span class="bu">print</span>( extract_float(<span class="st">&#39;123,456.78&#39;</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1833-8" title="8">       extract_float(<span class="st">&#39;rm 123.78 (30%)&#39;</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1833-9" title="9">       extract_float(<span class="st">&#39;rm 123,456.78 (30%)&#39;</span>) )</a></code></pre></div>
<pre><code>## 123456.78 
##  123.78 
##  123456.78</code></pre>
</div>
</div>
</div>
<div id="word-tokenizer" class="section level2">
<h2><span class="header-section-number">18.2</span> Word Tokenizer</h2>
<div id="custom-tokenizer" class="section level3">
<h3><span class="header-section-number">18.2.1</span> Custom Tokenizer</h3>
<div id="split-by-regex-pattern" class="section level4">
<h4><span class="header-section-number">18.2.1.1</span> Split By Regex Pattern</h4>
<p>Use <strong>regex</strong> to split words based on <strong>specific punctuation as delimeter</strong>.<br />
The rule is: split input text when any one or more continuous occurances of specified character.</p>
<div class="sourceCode" id="cb1835"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1835-1" title="1"><span class="im">import</span> re</a>
<a class="sourceLine" id="cb1835-2" title="2">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&quot;[-\s.,;!?]+&quot;</span>)</a>
<a class="sourceLine" id="cb1835-3" title="3">pattern.split(<span class="st">&quot;hi @ali--baba, you are aweeeeeesome! isn&#39;t it. Believe it.:)&quot;</span>)</a></code></pre></div>
<pre><code>## [&#39;hi&#39;, &#39;@ali&#39;, &#39;baba&#39;, &#39;you&#39;, &#39;are&#39;, &#39;aweeeeeesome&#39;, &quot;isn&#39;t&quot;, &#39;it&#39;, &#39;Believe&#39;, &#39;it&#39;, &#39;:)&#39;]</code></pre>
</div>
<div id="pick-by-regex-pattern-nltk.tokenize.regexptokenizer" class="section level4">
<h4><span class="header-section-number">18.2.1.2</span> Pick By Regex Pattern <code>nltk.tokenize.RegexpTokenizer</code></h4>
<p>Any sequence of chars fall within the bracket are considered tokens. Any chars not within the bracket are removed.</p>
<div class="sourceCode" id="cb1837"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1837-1" title="1"><span class="im">from</span> nltk.tokenize <span class="im">import</span> RegexpTokenizer</a>
<a class="sourceLine" id="cb1837-2" title="2">my_tokenizer <span class="op">=</span> RegexpTokenizer(<span class="vs">r&#39;[a-zA-Z0-9\&#39;]+&#39;</span>)</a>
<a class="sourceLine" id="cb1837-3" title="3">my_tokenizer.tokenize(<span class="st">&quot;hi @ali--baba, you are aweeeeeesome! isn&#39;t it. Believe it.:&quot;</span>)</a></code></pre></div>
<pre><code>## [&#39;hi&#39;, &#39;ali&#39;, &#39;baba&#39;, &#39;you&#39;, &#39;are&#39;, &#39;aweeeeeesome&#39;, &quot;isn&#39;t&quot;, &#39;it&#39;, &#39;Believe&#39;, &#39;it&#39;]</code></pre>
</div>
</div>
<div id="nltk.tokenize.word_tokenize" class="section level3">
<h3><span class="header-section-number">18.2.2</span> <code>nltk.tokenize.word_tokenize()</code></h3>
<p>Words and punctuations are considered as tokens!</p>
<div class="sourceCode" id="cb1839"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1839-1" title="1"><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</a>
<a class="sourceLine" id="cb1839-2" title="2"><span class="bu">print</span>( word_tokenize(<span class="st">&quot;hi @ali-baba, you are aweeeeeesome! isn&#39;t it. Believe it.:)&quot;</span>) )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mpunkt[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;punkt&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mtokenizers/punkt/english.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 144, in word_tokenize
##     sentences = [text] if preserve_line else sent_tokenize(text, language)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 105, in sent_tokenize
##     tokenizer = load(&#39;tokenizers/punkt/{0}.pickle&#39;.format(language))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
</div>
<div id="nltk.tokenize.casual.casual_tokenize" class="section level3">
<h3><span class="header-section-number">18.2.3</span> <code>nltk.tokenize.casual.casual_tokenize()</code></h3>
<ul>
<li>Support emoji</li>
<li>Support reduction of repetition chars</li>
<li>Support removing userid (<span class="citation">(<span class="citeproc-not-found" data-reference-id="someone"><strong>???</strong></span>)</span>)</li>
<li>Good for social media text</li>
<li>Punctuations are tokens!</li>
</ul>
<div class="sourceCode" id="cb1841"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1841-1" title="1"><span class="im">from</span> nltk.tokenize.casual     <span class="im">import</span> casual_tokenize</a>
<a class="sourceLine" id="cb1841-2" title="2"><span class="bu">print</span>( casual_tokenize(<span class="st">&quot;hi @ali-baba, you are aweeeeeesome! isn&#39;t it. Believe it. :)&quot;</span>) )  </a></code></pre></div>
<pre><code>## [&#39;hi&#39;, &#39;@ali&#39;, &#39;-&#39;, &#39;baba&#39;, &#39;,&#39;, &#39;you&#39;, &#39;are&#39;, &#39;aweeeeeesome&#39;, &#39;!&#39;, &quot;isn&#39;t&quot;, &#39;it&#39;, &#39;.&#39;, &#39;Believe&#39;, &#39;it&#39;, &#39;.&#39;, &#39;:)&#39;]</code></pre>
<p>Example below shorten repeating chars, notice aweeeeeesome becomes aweeesome</p>
<div class="sourceCode" id="cb1843"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1843-1" title="1"><span class="co">## shorten repeated chars</span></a>
<a class="sourceLine" id="cb1843-2" title="2"><span class="bu">print</span>( casual_tokenize(<span class="st">&quot;hi @ali-baba, you are aweeeeeesome! isn&#39;t it. Believe it.:)&quot;</span>, </a>
<a class="sourceLine" id="cb1843-3" title="3">          reduce_len<span class="op">=</span><span class="va">True</span>))     </a></code></pre></div>
<pre><code>## [&#39;hi&#39;, &#39;@ali&#39;, &#39;-&#39;, &#39;baba&#39;, &#39;,&#39;, &#39;you&#39;, &#39;are&#39;, &#39;aweeesome&#39;, &#39;!&#39;, &quot;isn&#39;t&quot;, &#39;it&#39;, &#39;.&#39;, &#39;Believe&#39;, &#39;it&#39;, &#39;.&#39;, &#39;:)&#39;]</code></pre>
<p>Stripping off User ID</p>
<div class="sourceCode" id="cb1845"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1845-1" title="1"><span class="co">## shorten repeated chars, stirp usernames</span></a>
<a class="sourceLine" id="cb1845-2" title="2"><span class="bu">print</span>( casual_tokenize(<span class="st">&quot;hi @ali-baba, you are aweeeeeesome! isn&#39;t it. Believe it.:)&quot;</span>, </a>
<a class="sourceLine" id="cb1845-3" title="3">          reduce_len<span class="op">=</span><span class="va">True</span>,      </a>
<a class="sourceLine" id="cb1845-4" title="4">          strip_handles<span class="op">=</span><span class="va">True</span>))  </a></code></pre></div>
<pre><code>## [&#39;hi&#39;, &#39;-&#39;, &#39;baba&#39;, &#39;,&#39;, &#39;you&#39;, &#39;are&#39;, &#39;aweeesome&#39;, &#39;!&#39;, &quot;isn&#39;t&quot;, &#39;it&#39;, &#39;.&#39;, &#39;Believe&#39;, &#39;it&#39;, &#39;.&#39;, &#39;:)&#39;]</code></pre>
</div>
<div id="nltk.tokenize.treebank.treebankwordtokenizer.tokenize" class="section level3">
<h3><span class="header-section-number">18.2.4</span> <code>nltk.tokenize.treebank.TreebankWordTokenizer().tokenize()</code></h3>
<p>Treebank assume input text is <strong>A sentence</strong>, hence any period combined with word is treated as token.</p>
<div class="sourceCode" id="cb1847"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1847-1" title="1"><span class="im">from</span> nltk.tokenize.treebank   <span class="im">import</span> TreebankWordTokenizer</a>
<a class="sourceLine" id="cb1847-2" title="2">TreebankWordTokenizer().tokenize(<span class="st">&quot;hi @ali-baba, you are aweeeeeesome! isn&#39;t it. Believe it.:)&quot;</span>)</a></code></pre></div>
<pre><code>## [&#39;hi&#39;, &#39;@&#39;, &#39;ali-baba&#39;, &#39;,&#39;, &#39;you&#39;, &#39;are&#39;, &#39;aweeeeeesome&#39;, &#39;!&#39;, &#39;is&#39;, &quot;n&#39;t&quot;, &#39;it.&#39;, &#39;Believe&#39;, &#39;it.&#39;, &#39;:&#39;, &#39;)&#39;]</code></pre>
</div>
<div id="corpus-token-extractor" class="section level3">
<h3><span class="header-section-number">18.2.5</span> Corpus Token Extractor</h3>
<p>A corpus is a collection of documents (list of documents).
A document is a text string containing one or many sentences.</p>
<div class="sourceCode" id="cb1849"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1849-1" title="1"><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</a>
<a class="sourceLine" id="cb1849-2" title="2"><span class="im">from</span> nlpia.data.loaders <span class="im">import</span> harry_docs <span class="im">as</span> corpus</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;nlpia&#39;
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1851"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1851-1" title="1"><span class="co">## Tokenize each doc to list, then add to a bigger list</span></a>
<a class="sourceLine" id="cb1851-2" title="2">doc_tokens<span class="op">=</span>[]</a>
<a class="sourceLine" id="cb1851-3" title="3"><span class="cf">for</span> doc <span class="kw">in</span> corpus:</a>
<a class="sourceLine" id="cb1851-4" title="4">  doc_tokens <span class="op">+=</span> [word_tokenize(doc.lower())]</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;corpus&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1853"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1853-1" title="1"><span class="bu">print</span>(<span class="st">&#39;Corpus (Contain 3 Documents):</span><span class="ch">\n</span><span class="st">&#39;</span>,corpus,<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1853-2" title="2">      <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Tokenized result for each document:&#39;</span>,<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,doc_tokens)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;corpus&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Unpack list of token lists from above using sum. To get the <strong>vocabulary</strong> (unique tokens), <strong>convert list to set</strong>.</p>
<div class="sourceCode" id="cb1855"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1855-1" title="1"><span class="co">## unpack list of list to list</span></a>
<a class="sourceLine" id="cb1855-2" title="2">vocab <span class="op">=</span> <span class="bu">sum</span>(doc_tokens,[])</a>
<a class="sourceLine" id="cb1855-3" title="3"><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Corpus Vacabulary (Unique Tokens):</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1855-4" title="4">       <span class="bu">sorted</span>(<span class="bu">set</span>(vocab)))</a></code></pre></div>
<pre><code>## 
## Corpus Vacabulary (Unique Tokens):
##  []</code></pre>
</div>
</div>
<div id="sentence-tokenizer" class="section level2">
<h2><span class="header-section-number">18.3</span> Sentence Tokenizer</h2>
<p>This is about detecting sentence boundry and split text into list of sentences</p>
<div id="sample-text" class="section level3">
<h3><span class="header-section-number">18.3.1</span> Sample Text</h3>
<div class="sourceCode" id="cb1857"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1857-1" title="1">text <span class="op">=</span> <span class="st">&#39;&#39;&#39;</span></a>
<a class="sourceLine" id="cb1857-2" title="2"><span class="st">Hello Mr. Smith, how are you doing today?</span></a>
<a class="sourceLine" id="cb1857-3" title="3"><span class="st">The weather is great, and city is awesome.</span></a>
<a class="sourceLine" id="cb1857-4" title="4"><span class="st">The sky is pinkish-blue, Dr. Alba would agree.</span></a>
<a class="sourceLine" id="cb1857-5" title="5"><span class="st">You shouldn&#39;t eat hard things i.e. cardboard, stones and bushes</span></a>
<a class="sourceLine" id="cb1857-6" title="6"><span class="st">&#39;&#39;&#39;</span></a></code></pre></div>
</div>
<div id="nltk.tokenize.punkt.punktsentencetokenizer" class="section level3">
<h3><span class="header-section-number">18.3.2</span> ’nltk.tokenize.punkt.PunktSentenceTokenizer`</h3>
<ul>
<li>The <code>PunktSentenceTokenizer</code> is an sentence boundary detection algorithm. It is an unsupervised trainable model. This means it can be trained on unlabeled data, aka text that is not split into sentences<br />
</li>
<li>PunkSentneceTokenizer is based on work published on this paepr: <a href="https://www.mitpressjournals.org/doi/abs/10.1162/coli.2006.32.4.485#.V2ouLXUrLeQ">Unsupervised Multilingual Sentence Boundary Detection</a></li>
</ul>
<div id="default-behavior" class="section level4">
<h4><span class="header-section-number">18.3.2.1</span> Default Behavior</h4>
<p>Vanila tokenizer splits sentences on period <code>.</code>, which is not desirable</p>
<div class="sourceCode" id="cb1858"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1858-1" title="1"><span class="im">from</span> nltk.tokenize.punkt <span class="im">import</span> PunktSentenceTokenizer, PunktTrainer</a>
<a class="sourceLine" id="cb1858-2" title="2"><span class="co">#nltk.download(&#39;punkt&#39;)</span></a>
<a class="sourceLine" id="cb1858-3" title="3">tokenizer <span class="op">=</span> PunktSentenceTokenizer()</a>
<a class="sourceLine" id="cb1858-4" title="4">tokenized_text <span class="op">=</span> tokenizer.tokenize(text) </a>
<a class="sourceLine" id="cb1858-5" title="5"><span class="cf">for</span> x <span class="kw">in</span> tokenized_text:</a>
<a class="sourceLine" id="cb1858-6" title="6">  <span class="bu">print</span>(x) </a></code></pre></div>
<pre><code>## 
## Hello Mr.
## Smith, how are you doing today?
## The weather is great, and city is awesome.
## The sky is pinkish-blue, Dr.
## Alba would agree.
## You shouldn&#39;t eat hard things i.e.
## cardboard, stones and bushes</code></pre>
</div>
<div id="pretrained-model---english-pickle" class="section level4">
<h4><span class="header-section-number">18.3.2.2</span> Pretrained Model - English Pickle</h4>
<p>NLTK already includes a pre-trained version of the PunktSentenceTokenizer for English, as you can see, it is quite good</p>
<div class="sourceCode" id="cb1860"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1860-1" title="1">tokenizer      <span class="op">=</span> nltk.data.load(<span class="st">&#39;tokenizers/punkt/english.pickle&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;nltk&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1862"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1862-1" title="1">tokenized_text <span class="op">=</span> tokenizer.tokenize(text) </a>
<a class="sourceLine" id="cb1862-2" title="2"><span class="cf">for</span> x <span class="kw">in</span> tokenized_text:</a>
<a class="sourceLine" id="cb1862-3" title="3">  <span class="bu">print</span>(x) </a></code></pre></div>
<pre><code>## 
## Hello Mr.
## Smith, how are you doing today?
## The weather is great, and city is awesome.
## The sky is pinkish-blue, Dr.
## Alba would agree.
## You shouldn&#39;t eat hard things i.e.
## cardboard, stones and bushes</code></pre>
</div>
<div id="adding-abbreviations" class="section level4">
<h4><span class="header-section-number">18.3.2.3</span> Adding Abbreviations</h4>
<ul>
<li>The pretrained tokenizer is not perfect, it wrongly detected ‘i.e.’ as sentence boundary<br />
</li>
<li>Let’s <strong>teach</strong> Punkt by adding the abbreviation to its parameter</li>
</ul>
<p><strong>Adding Single Abbreviation</strong></p>
<div class="sourceCode" id="cb1864"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1864-1" title="1"></a>
<a class="sourceLine" id="cb1864-2" title="2">tokenizer      <span class="op">=</span> nltk.data.load(<span class="st">&#39;tokenizers/punkt/english.pickle&#39;</span>)</a>
<a class="sourceLine" id="cb1864-3" title="3"></a>
<a class="sourceLine" id="cb1864-4" title="4"><span class="co">## Add apprevaitions to Tokenizer</span></a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;nltk&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1866"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1866-1" title="1">tokenizer._params.abbrev_types.add(<span class="st">&#39;i.e&#39;</span>)</a>
<a class="sourceLine" id="cb1866-2" title="2"></a>
<a class="sourceLine" id="cb1866-3" title="3">tokenized_text <span class="op">=</span> tokenizer.tokenize(text) </a>
<a class="sourceLine" id="cb1866-4" title="4"><span class="cf">for</span> x <span class="kw">in</span> tokenized_text:</a>
<a class="sourceLine" id="cb1866-5" title="5">  <span class="bu">print</span>(x)</a></code></pre></div>
<pre><code>## 
## Hello Mr.
## Smith, how are you doing today?
## The weather is great, and city is awesome.
## The sky is pinkish-blue, Dr.
## Alba would agree.
## You shouldn&#39;t eat hard things i.e. cardboard, stones and bushes</code></pre>
<p><strong>Add List of Abbreviations</strong></p>
<p>If you have more than one abbreviations, use <code>update()</code> with the list of abbreviations</p>
<div class="sourceCode" id="cb1868"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1868-1" title="1"><span class="im">from</span> nltk.tokenize.punkt <span class="im">import</span> PunktSentenceTokenizer, PunktParameters</a>
<a class="sourceLine" id="cb1868-2" title="2"></a>
<a class="sourceLine" id="cb1868-3" title="3"><span class="co">## Add Abbreviations to Tokenizer</span></a>
<a class="sourceLine" id="cb1868-4" title="4">tokenizer <span class="op">=</span>  nltk.data.load(<span class="st">&#39;tokenizers/punkt/english.pickle&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;nltk&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1870"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1870-1" title="1">tokenizer._params.abbrev_types.update([<span class="st">&#39;dr&#39;</span>, <span class="st">&#39;vs&#39;</span>, <span class="st">&#39;mr&#39;</span>, <span class="st">&#39;mrs&#39;</span>, <span class="st">&#39;prof&#39;</span>, <span class="st">&#39;inc&#39;</span>, <span class="st">&#39;i.e&#39;</span>])</a>
<a class="sourceLine" id="cb1870-2" title="2"></a>
<a class="sourceLine" id="cb1870-3" title="3">sentences <span class="op">=</span> tokenizer.tokenize(text) </a>
<a class="sourceLine" id="cb1870-4" title="4"><span class="cf">for</span> x <span class="kw">in</span> sentences:</a>
<a class="sourceLine" id="cb1870-5" title="5">  <span class="bu">print</span>(x) </a></code></pre></div>
<pre><code>## 
## Hello Mr. Smith, how are you doing today?
## The weather is great, and city is awesome.
## The sky is pinkish-blue, Dr. Alba would agree.
## You shouldn&#39;t eat hard things i.e. cardboard, stones and bushes</code></pre>
</div>
</div>
<div id="nltk.tokenize.sent_tokenize" class="section level3">
<h3><span class="header-section-number">18.3.3</span> <code>nltk.tokenize.sent_tokenize()</code></h3>
<p>The <code>sent_tokenize</code> function uses an instance of <strong>PunktSentenceTokenizer</strong>, which is already been trained and thus very well knows to mark the end and begining of sentence at what characters and punctuation.</p>
<div class="sourceCode" id="cb1872"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1872-1" title="1"><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize</a>
<a class="sourceLine" id="cb1872-2" title="2"></a>
<a class="sourceLine" id="cb1872-3" title="3">sentences <span class="op">=</span> sent_tokenize(text)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mpunkt[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;punkt&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mtokenizers/punkt/english.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 105, in sent_tokenize
##     tokenizer = load(&#39;tokenizers/punkt/{0}.pickle&#39;.format(language))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1874"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1874-1" title="1"><span class="cf">for</span> x <span class="kw">in</span> sentences:</a>
<a class="sourceLine" id="cb1874-2" title="2">  <span class="bu">print</span>(x) </a></code></pre></div>
<pre><code>## 
## Hello Mr. Smith, how are you doing today?
## The weather is great, and city is awesome.
## The sky is pinkish-blue, Dr. Alba would agree.
## You shouldn&#39;t eat hard things i.e. cardboard, stones and bushes</code></pre>
</div>
</div>
<div id="n-gram" class="section level2">
<h2><span class="header-section-number">18.4</span> N-Gram</h2>
<p>To create n-gram, first create 1-gram token</p>
<div class="sourceCode" id="cb1876"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1876-1" title="1"><span class="im">from</span> nltk.util <span class="im">import</span> ngrams </a>
<a class="sourceLine" id="cb1876-2" title="2"><span class="im">import</span> re</a>
<a class="sourceLine" id="cb1876-3" title="3">sentence <span class="op">=</span> <span class="st">&quot;Thomas Jefferson began building the city, at the age of 25&quot;</span></a>
<a class="sourceLine" id="cb1876-4" title="4">pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&quot;[-\s.,;!?]+&quot;</span>)</a>
<a class="sourceLine" id="cb1876-5" title="5">tokens <span class="op">=</span> pattern.split(sentence)</a>
<a class="sourceLine" id="cb1876-6" title="6"><span class="bu">print</span>(tokens)</a></code></pre></div>
<pre><code>## [&#39;Thomas&#39;, &#39;Jefferson&#39;, &#39;began&#39;, &#39;building&#39;, &#39;the&#39;, &#39;city&#39;, &#39;at&#39;, &#39;the&#39;, &#39;age&#39;, &#39;of&#39;, &#39;25&#39;]</code></pre>
<p><strong>ngrams()</strong> is a generator, therefore, use <strong>list()</strong> to convert into full list</p>
<div class="sourceCode" id="cb1878"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1878-1" title="1">ngrams(tokens,<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## &lt;generator object ngrams at 0x0000000046D9A7C8&gt;</code></pre>
<p>Convert 1-gram to 2-Gram, wrap into list</p>
<div class="sourceCode" id="cb1880"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1880-1" title="1">grammy <span class="op">=</span> <span class="bu">list</span>( ngrams(tokens,<span class="dv">2</span>) )</a>
<a class="sourceLine" id="cb1880-2" title="2"><span class="bu">print</span>(grammy)</a></code></pre></div>
<pre><code>## [(&#39;Thomas&#39;, &#39;Jefferson&#39;), (&#39;Jefferson&#39;, &#39;began&#39;), (&#39;began&#39;, &#39;building&#39;), (&#39;building&#39;, &#39;the&#39;), (&#39;the&#39;, &#39;city&#39;), (&#39;city&#39;, &#39;at&#39;), (&#39;at&#39;, &#39;the&#39;), (&#39;the&#39;, &#39;age&#39;), (&#39;age&#39;, &#39;of&#39;), (&#39;of&#39;, &#39;25&#39;)]</code></pre>
<p>Combine each 2-gram into a string object</p>
<div class="sourceCode" id="cb1882"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1882-1" title="1">[ <span class="st">&quot; &quot;</span>.join(x) <span class="cf">for</span> x <span class="kw">in</span> grammy]</a></code></pre></div>
<pre><code>## [&#39;Thomas Jefferson&#39;, &#39;Jefferson began&#39;, &#39;began building&#39;, &#39;building the&#39;, &#39;the city&#39;, &#39;city at&#39;, &#39;at the&#39;, &#39;the age&#39;, &#39;age of&#39;, &#39;of 25&#39;]</code></pre>
</div>
<div id="stopwords" class="section level2">
<h2><span class="header-section-number">18.5</span> Stopwords</h2>
<div id="custom-stop-words" class="section level3">
<h3><span class="header-section-number">18.5.1</span> Custom Stop Words</h3>
<p>Build the custom stop words dictionary.</p>
<div class="sourceCode" id="cb1884"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1884-1" title="1">stop_words <span class="op">=</span> [<span class="st">&#39;a&#39;</span>,<span class="st">&#39;an&#39;</span>,<span class="st">&#39;the&#39;</span>,<span class="st">&#39;on&#39;</span>,<span class="st">&#39;of&#39;</span>,<span class="st">&#39;off&#39;</span>,<span class="st">&#39;this&#39;</span>,<span class="st">&#39;is&#39;</span>,<span class="st">&#39;at&#39;</span>]</a></code></pre></div>
<p>Tokenize text and remove stop words</p>
<div class="sourceCode" id="cb1885"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1885-1" title="1">sentence <span class="op">=</span> <span class="st">&quot;The house is on fire&quot;</span></a>
<a class="sourceLine" id="cb1885-2" title="2">tokens   <span class="op">=</span> word_tokenize(sentence)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mpunkt[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;punkt&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mtokenizers/punkt/english.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 144, in word_tokenize
##     sentences = [text] if preserve_line else sent_tokenize(text, language)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 105, in sent_tokenize
##     tokenizer = load(&#39;tokenizers/punkt/{0}.pickle&#39;.format(language))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1887"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1887-1" title="1">tokens_without_stopwords <span class="op">=</span> [ x <span class="cf">for</span> x <span class="kw">in</span> tokens <span class="cf">if</span> x <span class="kw">not</span> <span class="kw">in</span> stop_words ]</a>
<a class="sourceLine" id="cb1887-2" title="2"></a>
<a class="sourceLine" id="cb1887-3" title="3"><span class="bu">print</span>(<span class="st">&#39; Original Tokens  : &#39;</span>, tokens, <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1887-4" title="4">      <span class="st">&#39;Removed Stopwords: &#39;</span>,tokens_without_stopwords)</a></code></pre></div>
<pre><code>##  Original Tokens  :  [&#39;Thomas&#39;, &#39;Jefferson&#39;, &#39;began&#39;, &#39;building&#39;, &#39;the&#39;, &#39;city&#39;, &#39;at&#39;, &#39;the&#39;, &#39;age&#39;, &#39;of&#39;, &#39;25&#39;] 
##  Removed Stopwords:  [&#39;Thomas&#39;, &#39;Jefferson&#39;, &#39;began&#39;, &#39;building&#39;, &#39;city&#39;, &#39;age&#39;, &#39;25&#39;]</code></pre>
</div>
<div id="nltk-stop-words" class="section level3">
<h3><span class="header-section-number">18.5.2</span> NLTK Stop Words</h3>
<p>Contain 179 words, in a list form</p>
<div class="sourceCode" id="cb1889"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1889-1" title="1"><span class="im">import</span> nltk</a>
<a class="sourceLine" id="cb1889-2" title="2"><span class="co">#nltk.download(&#39;stopwords&#39;)</span></a>
<a class="sourceLine" id="cb1889-3" title="3">nltk_stop_words <span class="op">=</span> nltk.corpus.stopwords.words(<span class="st">&#39;english&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mstopwords[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;stopwords&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/stopwords[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1891"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1891-1" title="1"><span class="bu">print</span>(<span class="st">&#39;Total NLTK Stopwords: &#39;</span>, <span class="bu">len</span>(nltk_stop_words),<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1891-2" title="2">      nltk_stop_words)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;nltk_stop_words&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
<div id="sklearn-stop-words" class="section level3">
<h3><span class="header-section-number">18.5.3</span> SKLearn Stop Words</h3>
<p>Contain 318 stop words, in frozenset form</p>
<div class="sourceCode" id="cb1893"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1893-1" title="1"><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> ENGLISH_STOP_WORDS <span class="im">as</span> sklearn_stop_words</a>
<a class="sourceLine" id="cb1893-2" title="2"><span class="bu">print</span>(<span class="st">&#39; Total Sklearn Stopwords: &#39;</span>, <span class="bu">len</span>(sklearn_stop_words),<span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1893-3" title="3">       sklearn_stop_words)</a></code></pre></div>
<pre><code>##  Total Sklearn Stopwords:  318 
## 
##  frozenset({&#39;via&#39;, &#39;eleven&#39;, &#39;too&#39;, &#39;i&#39;, &#39;any&#39;, &#39;for&#39;, &#39;bill&#39;, &#39;fire&#39;, &#39;some&#39;, &#39;whatever&#39;, &#39;throughout&#39;, &#39;somehow&#39;, &#39;few&#39;, &#39;indeed&#39;, &#39;of&#39;, &#39;yourselves&#39;, &#39;sincere&#39;, &#39;cannot&#39;, &#39;system&#39;, &#39;above&#39;, &#39;wherever&#39;, &#39;many&#39;, &#39;already&#39;, &#39;co&#39;, &#39;if&#39;, &#39;into&#39;, &#39;still&#39;, &#39;take&#39;, &#39;never&#39;, &#39;otherwise&#39;, &#39;ie&#39;, &#39;in&#39;, &#39;find&#39;, &#39;others&#39;, &#39;hers&#39;, &#39;fifty&#39;, &#39;or&#39;, &#39;myself&#39;, &#39;namely&#39;, &#39;describe&#39;, &#39;whither&#39;, &#39;anyhow&#39;, &#39;except&#39;, &#39;noone&#39;, &#39;been&#39;, &#39;may&#39;, &#39;towards&#39;, &#39;sometime&#39;, &#39;but&#39;, &#39;etc&#39;, &#39;amongst&#39;, &#39;none&#39;, &#39;made&#39;, &#39;always&#39;, &#39;thereby&#39;, &#39;cry&#39;, &#39;which&#39;, &#39;go&#39;, &#39;could&#39;, &#39;its&#39;, &#39;become&#39;, &#39;cant&#39;, &#39;so&#39;, &#39;over&#39;, &#39;ourselves&#39;, &#39;sometimes&#39;, &#39;during&#39;, &#39;my&#39;, &#39;bottom&#39;, &#39;two&#39;, &#39;anyway&#39;, &#39;every&#39;, &#39;eight&#39;, &#39;her&#39;, &#39;something&#39;, &#39;should&#39;, &#39;do&#39;, &#39;beyond&#39;, &#39;hereafter&#39;, &#39;this&#39;, &#39;whole&#39;, &#39;as&#39;, &#39;mill&#39;, &#39;four&#39;, &#39;another&#39;, &#39;de&#39;, &#39;those&#39;, &#39;same&#39;, &#39;himself&#39;, &#39;almost&#39;, &#39;down&#39;, &#39;while&#39;, &#39;them&#39;, &#39;latter&#39;, &#39;from&#39;, &#39;around&#39;, &#39;everyone&#39;, &#39;see&#39;, &#39;afterwards&#39;, &#39;not&#39;, &#39;further&#39;, &#39;she&#39;, &#39;amount&#39;, &#39;seemed&#39;, &#39;very&#39;, &#39;con&#39;, &#39;name&#39;, &#39;each&#39;, &#39;against&#39;, &#39;when&#39;, &#39;next&#39;, &#39;although&#39;, &#39;side&#39;, &#39;ours&#39;, &#39;again&#39;, &#39;detail&#39;, &#39;empty&#39;, &#39;thin&#39;, &#39;off&#39;, &#39;mostly&#39;, &#39;perhaps&#39;, &#39;front&#39;, &#39;re&#39;, &#39;thereupon&#39;, &#39;since&#39;, &#39;became&#39;, &#39;whence&#39;, &#39;meanwhile&#39;, &#39;we&#39;, &#39;therein&#39;, &#39;herself&#39;, &#39;thereafter&#39;, &#39;has&#39;, &#39;top&#39;, &#39;found&#39;, &#39;else&#39;, &#39;whether&#39;, &#39;how&#39;, &#39;full&#39;, &#39;more&#39;, &#39;nobody&#39;, &#39;besides&#39;, &#39;under&#39;, &#39;such&#39;, &#39;before&#39;, &#39;have&#39;, &#39;across&#39;, &#39;call&#39;, &#39;ltd&#39;, &#39;thence&#39;, &#39;our&#39;, &#39;at&#39;, &#39;whereafter&#39;, &#39;be&#39;, &#39;wherein&#39;, &#39;enough&#39;, &#39;third&#39;, &#39;yet&#39;, &#39;had&#39;, &#39;through&#39;, &#39;and&#39;, &#39;no&#39;, &#39;it&#39;, &#39;he&#39;, &#39;what&#39;, &#39;once&#39;, &#39;eg&#39;, &#39;here&#39;, &#39;him&#39;, &#39;by&#39;, &#39;toward&#39;, &#39;beside&#39;, &#39;per&#39;, &#39;mine&#39;, &#39;less&#39;, &#39;move&#39;, &#39;sixty&#39;, &#39;their&#39;, &#39;where&#39;, &#39;behind&#39;, &#39;us&#39;, &#39;within&#39;, &#39;is&#39;, &#39;whereupon&#39;, &#39;yourself&#39;, &#39;alone&#39;, &#39;other&#39;, &#39;a&#39;, &#39;rather&#39;, &#39;latterly&#39;, &#39;former&#39;, &#39;must&#39;, &#39;inc&#39;, &#39;hereupon&#39;, &#39;about&#39;, &#39;elsewhere&#39;, &#39;back&#39;, &#39;might&#39;, &#39;nothing&#39;, &#39;were&#39;, &#39;anyone&#39;, &#39;was&#39;, &#39;someone&#39;, &#39;themselves&#39;, &#39;along&#39;, &#39;whereby&#39;, &#39;nowhere&#39;, &#39;even&#39;, &#39;because&#39;, &#39;everywhere&#39;, &#39;however&#39;, &#39;three&#39;, &#39;the&#39;, &#39;whenever&#39;, &#39;up&#39;, &#39;after&#39;, &#39;most&#39;, &#39;onto&#39;, &#39;nor&#39;, &#39;formerly&#39;, &#39;itself&#39;, &#39;keep&#39;, &#39;then&#39;, &#39;hundred&#39;, &#39;part&#39;, &#39;becomes&#39;, &#39;seeming&#39;, &#39;get&#39;, &#39;beforehand&#39;, &#39;an&#39;, &#39;below&#39;, &#39;also&#39;, &#39;six&#39;, &#39;due&#39;, &#39;now&#39;, &#39;therefore&#39;, &#39;can&#39;, &#39;twelve&#39;, &#39;am&#39;, &#39;please&#39;, &#39;nevertheless&#39;, &#39;yours&#39;, &#39;five&#39;, &#39;thru&#39;, &#39;being&#39;, &#39;herein&#39;, &#39;both&#39;, &#39;me&#39;, &#39;why&#39;, &#39;forty&#39;, &#39;often&#39;, &#39;with&#39;, &#39;thick&#39;, &#39;nine&#39;, &#39;somewhere&#39;, &#39;on&#39;, &#39;neither&#39;, &#39;anything&#39;, &#39;becoming&#39;, &#39;well&#39;, &#39;whoever&#39;, &#39;to&#39;, &#39;will&#39;, &#39;first&#39;, &#39;whereas&#39;, &#39;put&#39;, &#39;least&#39;, &#39;all&#39;, &#39;though&#39;, &#39;upon&#39;, &#39;seem&#39;, &#39;his&#39;, &#39;are&#39;, &#39;between&#39;, &#39;moreover&#39;, &#39;until&#39;, &#39;anywhere&#39;, &#39;interest&#39;, &#39;than&#39;, &#39;you&#39;, &#39;ever&#39;, &#39;seems&#39;, &#39;your&#39;, &#39;together&#39;, &#39;couldnt&#39;, &#39;done&#39;, &#39;amoungst&#39;, &#39;several&#39;, &#39;hereby&#39;, &#39;that&#39;, &#39;give&#39;, &#39;ten&#39;, &#39;hasnt&#39;, &#39;own&#39;, &#39;they&#39;, &#39;serious&#39;, &#39;last&#39;, &#39;twenty&#39;, &#39;whom&#39;, &#39;would&#39;, &#39;these&#39;, &#39;fill&#39;, &#39;only&#39;, &#39;much&#39;, &#39;there&#39;, &#39;out&#39;, &#39;among&#39;, &#39;without&#39;, &#39;hence&#39;, &#39;one&#39;, &#39;whose&#39;, &#39;un&#39;, &#39;who&#39;, &#39;show&#39;, &#39;fifteen&#39;, &#39;either&#39;, &#39;thus&#39;, &#39;everything&#39;})</code></pre>
</div>
<div id="combined-nltk-and-sklearn-stop-words" class="section level3">
<h3><span class="header-section-number">18.5.4</span> Combined NLTK and SKLearn Stop Words</h3>
<div class="sourceCode" id="cb1895"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1895-1" title="1">combined_stop_words <span class="op">=</span> <span class="bu">list</span>( <span class="bu">set</span>(nltk_stop_words) <span class="op">|</span> <span class="bu">set</span>(sklearn_stop_words) )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;nltk_stop_words&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1897"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1897-1" title="1"><span class="bu">print</span>(<span class="st">&#39;Total combined NLTK and SKLearn Stopwords:&#39;</span>, <span class="bu">len</span>( combined_stop_words ),<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span></a>
<a class="sourceLine" id="cb1897-2" title="2">      <span class="st">&#39;Stopwords shared among NLTK and SKlearn  :&#39;</span>, <span class="bu">len</span>( <span class="bu">list</span>( <span class="bu">set</span>(nltk_stop_words) <span class="op">&amp;</span> <span class="bu">set</span>(sklearn_stop_words)) ))</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;combined_stop_words&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
</div>
<div id="normalizing" class="section level2">
<h2><span class="header-section-number">18.6</span> Normalizing</h2>
<p>Similar things are combined into single normalized form. This will reduced the vocabulary.</p>
<div id="case-folding" class="section level3">
<h3><span class="header-section-number">18.6.1</span> Case Folding</h3>
<p>If tokens aren’t cap normalized, you will end up with large word list.
However, some information is often communicated by capitalization of word, such as name of places. If names are important, consider using proper noun.</p>
<div class="sourceCode" id="cb1899"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1899-1" title="1">tokens <span class="op">=</span> [<span class="st">&#39;House&#39;</span>,<span class="st">&#39;Visitor&#39;</span>,<span class="st">&#39;Center&#39;</span>]</a>
<a class="sourceLine" id="cb1899-2" title="2">[ x.lower() <span class="cf">for</span> x <span class="kw">in</span> tokens]</a></code></pre></div>
<pre><code>## [&#39;house&#39;, &#39;visitor&#39;, &#39;center&#39;]</code></pre>
</div>
<div id="stemming" class="section level3">
<h3><span class="header-section-number">18.6.2</span> Stemming</h3>
<ul>
<li>Output of a stemmer is <strong>not necessary a proper word</strong></li>
<li>Automatically convert words to <strong>lower cap</strong></li>
<li><strong>Porter stemmer</strong> is a lifetime refinement with 300 lines of python code<br />
</li>
<li>Stemming is faster then Lemmatization</li>
</ul>
<div class="sourceCode" id="cb1901"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1901-1" title="1"><span class="im">from</span> nltk.stem.porter <span class="im">import</span> PorterStemmer</a>
<a class="sourceLine" id="cb1901-2" title="2">stemmer <span class="op">=</span> PorterStemmer()</a>
<a class="sourceLine" id="cb1901-3" title="3">tokens <span class="op">=</span> (<span class="st">&#39;house&#39;</span>,<span class="st">&#39;Housing&#39;</span>,<span class="st">&#39;hOuses&#39;</span>, <span class="st">&#39;Malicious&#39;</span>,<span class="st">&#39;goodness&#39;</span>)</a>
<a class="sourceLine" id="cb1901-4" title="4">[stemmer.stem(x) <span class="cf">for</span> x <span class="kw">in</span> tokens ]</a></code></pre></div>
<pre><code>## [&#39;hous&#39;, &#39;hous&#39;, &#39;hous&#39;, &#39;malici&#39;, &#39;good&#39;]</code></pre>
</div>
<div id="lemmatization" class="section level3">
<h3><span class="header-section-number">18.6.3</span> Lemmatization</h3>
<p>NLTK uses connections within <strong>princeton WordNet</strong> graph for word meanings.</p>
<div class="sourceCode" id="cb1903"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1903-1" title="1"><span class="co">#nltk.download(&#39;wordnet&#39;)</span></a>
<a class="sourceLine" id="cb1903-2" title="2"><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</a>
<a class="sourceLine" id="cb1903-3" title="3">lemmatizer <span class="op">=</span> WordNetLemmatizer()</a>
<a class="sourceLine" id="cb1903-4" title="4"></a>
<a class="sourceLine" id="cb1903-5" title="5"><span class="bu">print</span>( lemmatizer.lemmatize(<span class="st">&quot;better&quot;</span>, pos <span class="op">=</span><span class="st">&#39;a&#39;</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1903-6" title="6">       lemmatizer.lemmatize(<span class="st">&quot;better&quot;</span>, pos <span class="op">=</span><span class="st">&#39;n&#39;</span>) )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\stem\wordnet.py&quot;, line 41, in lemmatize
##     lemmas = wordnet._morphy(word, pos)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1905"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1905-1" title="1"><span class="bu">print</span>( lemmatizer.lemmatize(<span class="st">&quot;good&quot;</span>, pos <span class="op">=</span><span class="st">&#39;a&#39;</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1905-2" title="2">       lemmatizer.lemmatize(<span class="st">&quot;good&quot;</span>, pos <span class="op">=</span><span class="st">&#39;n&#39;</span>) )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\stem\wordnet.py&quot;, line 41, in lemmatize
##     lemmas = wordnet._morphy(word, pos)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
</div>
<div id="comparing-stemming-and-lemmatization" class="section level3">
<h3><span class="header-section-number">18.6.4</span> Comparing Stemming and Lemmatization</h3>
<ul>
<li>Lemmatization is slower than stemming
= Lemmatization is better at retaining meanings</li>
<li>Lemmatization produce valid english word</li>
<li>Stemming not necessary produce valid english word</li>
<li>Both reduce vocabulary size, but increase ambiguity</li>
<li>For search engine application, stemming and lemmatization will improve recall as it associate more documents with the same query words, however with the cost of reducing precision and accuracy.</li>
</ul>
<p>For search-based chatbot where accuracy is more important, it should first search with unnormalzied words.</p>
</div>
</div>
<div id="wordnet" class="section level2">
<h2><span class="header-section-number">18.7</span> Wordnet</h2>
<p>WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations.</p>
<p>WordNet superficially resembles a thesaurus, in that it groups words together based on their meanings. However, there are some important distinctions:<br />
- WordNet interlinks not just word forms—strings of letters—but specific senses of words. As a result, words that are found in close proximity to one another in the network are semantically disambiguated<br />
- WordNet labels the semantic relations among words, whereas the groupings of words in a thesaurus does not follow any explicit pattern other than meaning similarity</p>
<p><a href="https://wordnet.princeton.edu">Wordnet Princeton</a></p>
<p><a href="http://wordnetweb.princeton.edu/perl/webwn">Wordnet Online Browser</a></p>
<div id="nltk-and-wordnet" class="section level3">
<h3><span class="header-section-number">18.7.1</span> NLTK and Wordnet</h3>
<p>NLTK (version 3.7.6) includes the English WordNet (147,307 words and 117,659 synonym sets)</p>
<div class="sourceCode" id="cb1907"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1907-1" title="1"><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet <span class="im">as</span> wn</a>
<a class="sourceLine" id="cb1907-2" title="2"></a>
<a class="sourceLine" id="cb1907-3" title="3">s <span class="op">=</span> <span class="bu">set</span>( wn.all_synsets() )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1909"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1909-1" title="1">w <span class="op">=</span> <span class="bu">set</span>(wn.words())</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1911"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1911-1" title="1"><span class="bu">print</span>(<span class="st">&#39;Total words in wordnet  : &#39;</span> ,   <span class="bu">len</span>(w),</a>
<a class="sourceLine" id="cb1911-2" title="2">      <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Total synsets in wordnet: &#39;</span> , <span class="bu">len</span>(s) )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;w&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
<div id="synset" class="section level3">
<h3><span class="header-section-number">18.7.2</span> Synset</h3>
<div id="notation" class="section level4">
<h4><span class="header-section-number">18.7.2.1</span> Notation</h4>
<p>A synset is the basic construct of a word in wordnet. It contains the <strong>Word</strong> itself, with its <strong>POS</strong> tag and <strong>Usage</strong>: <strong><code>word.pos.nn</code></strong></p>
<div class="sourceCode" id="cb1913"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1913-1" title="1">wn.synset(<span class="st">&#39;breakdown.n.03&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<p>Breaking down the construct:</p>
<pre><code>&#39;breakdown&#39; = Word
&#39;n&#39;         = Part of Speech
&#39;03&#39;        = Usage (01 for most common usage and a higher number would indicate lesser common usages)</code></pre>
</div>
<div id="part-of-speech" class="section level4">
<h4><span class="header-section-number">18.7.2.2</span> Part of Speech</h4>
<p>Wordnet support five POS tags</p>
<pre><code>n - NOUN
v - VERB
a - ADJECTIVE
s - ADJECTIVE SATELLITE
r - ADVERB</code></pre>
<div class="sourceCode" id="cb1917"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1917-1" title="1"><span class="bu">print</span>(wn.ADJ, wn.ADJ_SAT, wn.ADV, wn.NOUN, wn.VERB)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
</div>
<div id="synset-similarity" class="section level4">
<h4><span class="header-section-number">18.7.2.3</span> Synset Similarity</h4>
<p>Let’s see how similar are the below two nouns</p>
<div class="sourceCode" id="cb1919"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1919-1" title="1">w1 <span class="op">=</span> wn.synset(<span class="st">&#39;dog.n.01&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1921"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1921-1" title="1">w2 <span class="op">=</span> wn.synset(<span class="st">&#39;ship.n.01&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1923"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1923-1" title="1"><span class="bu">print</span>(w1.wup_similarity(w2))</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;w1&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1925"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1925-1" title="1">w1 <span class="op">=</span> wn.synset(<span class="st">&#39;ship.n.01&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1927"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1927-1" title="1">w2 <span class="op">=</span> wn.synset(<span class="st">&#39;boat.n.01&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1929"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1929-1" title="1"><span class="bu">print</span>(w1.wup_similarity(w2))</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;w1&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
</div>
<div id="synsets" class="section level3">
<h3><span class="header-section-number">18.7.3</span> Synsets</h3>
<ul>
<li>Synsets is a collection of synsets, which are synonyms that share a common meaning<br />
</li>
<li>A synset (member of Synsets) is identified with a 3-part name of the form:</li>
<li>A synset can contain one or more lemmas, which represent a specific sense of a specific word<br />
</li>
<li>A synset can contain one or more <strong>Hyponyms and Hypernyms</strong>. These are specific and generalized concepts respectively. For example, ‘beach house’ and ‘guest house’ are hyponyms of ‘house’. They are more specific concepts of ‘house’. And ‘house’ is a hypernym of ‘guest house’ because it is the general concept<br />
</li>
<li><strong>Hyponyms and Hypernyms</strong> are also called lexical relations</li>
</ul>
<div class="sourceCode" id="cb1931"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1931-1" title="1">dogs <span class="op">=</span> wn.synsets(<span class="st">&#39;dog&#39;</span>) <span class="co"># get all synsets for word &#39;dog&#39;</span></a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1933"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1933-1" title="1"><span class="cf">for</span> d <span class="kw">in</span> dogs:  <span class="co">## iterate through each Synset</span></a>
<a class="sourceLine" id="cb1933-2" title="2">  <span class="bu">print</span>(d,<span class="st">&#39;:</span><span class="ch">\n</span><span class="st">Definition:&#39;</span>, d.definition(),</a>
<a class="sourceLine" id="cb1933-3" title="3">           <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Example:&#39;</span>,    d.examples(),</a>
<a class="sourceLine" id="cb1933-4" title="4">           <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Lemmas:&#39;</span>,     d.lemma_names(),</a>
<a class="sourceLine" id="cb1933-5" title="5">           <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Hyponyms:&#39;</span>,   d.hyponyms(), </a>
<a class="sourceLine" id="cb1933-6" title="6">           <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Hypernyms:&#39;</span>,  d.hypernyms(), <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;dogs&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
</div>
<div id="part-of-speech-pos" class="section level2">
<h2><span class="header-section-number">18.8</span> Part Of Speech (POS)</h2>
<ul>
<li>In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called <strong>grammatical tagging</strong> or <strong>word-category disambiguation</strong>, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context—i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph<br />
</li>
<li>This is useful for Information Retrieval, Text to Speech, Word Sense Disambiguation<br />
</li>
<li>The primary target of Part-of-Speech(POS) tagging is to identify the grammatical group of a given word. Whether it is a NOUN, PRONOUN, ADJECTIVE, VERB, ADVERBS, etc. based on the context<br />
</li>
<li>A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc</li>
</ul>
<div id="tag-sets" class="section level3">
<h3><span class="header-section-number">18.8.1</span> Tag Sets</h3>
<ul>
<li>Schools commonly teach that there are 9 parts of speech in English: noun, verb, article, adjective, preposition, pronoun, adverb, conjunction, and interjection<br />
</li>
<li>However, there are clearly many more categories and sub-categories</li>
</ul>
<div class="sourceCode" id="cb1935"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1935-1" title="1"> nltk.download(<span class="st">&#39;universal_tagset&#39;</span>)</a></code></pre></div>
<div id="universal-tagset" class="section level4">
<h4><span class="header-section-number">18.8.1.1</span> Universal Tagset</h4>
<p>This tagset contains <strong>12</strong> coarse tags</p>
<pre><code>VERB - verbs (all tenses and modes)
NOUN - nouns (common and proper)
PRON - pronouns
ADJ - adjectives
ADV - adverbs
ADP - adpositions (prepositions and postpositions)
CONJ - conjunctions
DET - determiners
NUM - cardinal numbers
PRT - particles or other function words
X - other: foreign words, typos, abbreviations
. - punctuation</code></pre>
</div>
<div id="penn-treebank-tagset" class="section level4">
<h4><span class="header-section-number">18.8.1.2</span> Penn Treebank Tagset</h4>
<ul>
<li>This is the most popular “tag set” for American English, developed in the Penn Treebank project<br />
</li>
<li>It has <strong>36 POS tags plus 12</strong> others for punctuations and special symbols</li>
</ul>
<p><a href="https://www.sketchengine.eu/penn-treebank-tagset/">PENN POS Tagset</a></p>
<div class="sourceCode" id="cb1937"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1937-1" title="1">nltk.<span class="bu">help</span>.upenn_tagset()</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mtagsets[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;tagsets&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mhelp/tagsets/upenn_tagset.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\help.py&quot;, line 28, in upenn_tagset
##     _format_tagset(&quot;upenn_tagset&quot;, tagpattern)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\help.py&quot;, line 47, in _format_tagset
##     tagdict = load(&quot;help/tagsets/&quot; + tagset + &quot;.pickle&quot;)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
</div>
<div id="claws5-tagset" class="section level4">
<h4><span class="header-section-number">18.8.1.3</span> Claws5 Tagset</h4>
<p><a href="https://www.sketchengine.eu/english-claws5-part-of-speech-tagset/">Claws5 POS Tagset</a></p>
<div class="sourceCode" id="cb1939"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1939-1" title="1">nltk.<span class="bu">help</span>.claws5_tagset()</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mtagsets[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;tagsets&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mhelp/tagsets/claws5_tagset.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\help.py&quot;, line 24, in claws5_tagset
##     _format_tagset(&quot;claws5_tagset&quot;, tagpattern)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\help.py&quot;, line 47, in _format_tagset
##     tagdict = load(&quot;help/tagsets/&quot; + tagset + &quot;.pickle&quot;)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
</div>
<div id="brown-tagset" class="section level4">
<h4><span class="header-section-number">18.8.1.4</span> Brown Tagset</h4>
<p><a href="https://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used">Brown POS Tagset</a></p>
<div class="sourceCode" id="cb1941"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1941-1" title="1">nltk.<span class="bu">help</span>.brown_tagset()</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mtagsets[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;tagsets&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mhelp/tagsets/brown_tagset.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\help.py&quot;, line 20, in brown_tagset
##     _format_tagset(&quot;brown_tagset&quot;, tagpattern)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\help.py&quot;, line 47, in _format_tagset
##     tagdict = load(&quot;help/tagsets/&quot; + tagset + &quot;.pickle&quot;)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
</div>
</div>
<div id="tagging-techniques" class="section level3">
<h3><span class="header-section-number">18.8.2</span> Tagging Techniques</h3>
<p>There are few types of tagging techniques:</p>
<ul>
<li>Lexical-based<br />
</li>
<li>Rule-based (Brill)</li>
<li>Probalistic/Stochastic-based (Conditional Random Fields-CRFs, Hidden Markov Models-HMM)</li>
<li>Neural network-based</li>
</ul>
<p>NLTK supports the below taggers:</p>
<pre><code>from nltk.tag.brill      import BrillTagger
from nltk.tag.hunpos     import HunposTagger
from nltk.tag.stanford   import StanfordTagger, StanfordPOSTagger, StanfordNERTagger
from nltk.tag.hmm        import HiddenMarkovModelTagger, HiddenMarkovModelTrainer
from nltk.tag.senna      import SennaTagger, SennaChunkTagger, SennaNERTagger
from nltk.tag.crf        import CRFTagger
from nltk.tag.perceptron import PerceptronTagger</code></pre>
<div id="nltk-perceptrontagger" class="section level4">
<h4><span class="header-section-number">18.8.2.1</span> nltk <code>PerceptronTagger</code></h4>
<p>PerceptronTagger produce tags with <strong>Penn Treebank</strong> tagset</p>
<div class="sourceCode" id="cb1944"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1944-1" title="1"><span class="im">from</span> nltk.tag <span class="im">import</span> PerceptronTagger</a>
<a class="sourceLine" id="cb1944-2" title="2">tagger <span class="op">=</span> PerceptronTagger()</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93maveraged_perceptron_tagger[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;averaged_perceptron_tagger&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tag\perceptron.py&quot;, line 162, in __init__
##     find(&#39;taggers/averaged_perceptron_tagger/&#39; + PICKLE)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1946"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1946-1" title="1"><span class="bu">print</span>(<span class="st">&#39;Tagger Classes:&#39;</span>, tagger.classes, </a>
<a class="sourceLine" id="cb1946-2" title="2">      <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st"># Classes:&#39;</span>, <span class="bu">len</span>(tagger.classes))</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;tagger&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
</div>
<div id="performing-tagging-nltk.pos_tag" class="section level3">
<h3><span class="header-section-number">18.8.3</span> Performing Tagging <code>nltk.pos_tag()</code></h3>
<p>Tagging works sentence by sentence:</p>
<ul>
<li>Document fist must be splitted into sentences<br />
</li>
<li>Each sentence need to be tokenized into words<br />
</li>
<li>Default NTLK uses <code>PerceptronTagger</code></li>
</ul>
<div class="sourceCode" id="cb1948"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1948-1" title="1"><span class="co">#nltk.download(&#39;averaged_perceptron_tagger&#39;)</span></a>
<a class="sourceLine" id="cb1948-2" title="2"><span class="co">#import nltk</span></a>
<a class="sourceLine" id="cb1948-3" title="3"><span class="co">#from nltk.tokenize import word_tokenize, sent_tokenize </span></a>
<a class="sourceLine" id="cb1948-4" title="4">doc <span class="op">=</span> <span class="st">&#39;&#39;&#39;Sukanya, Rajib and Naba are my good friends. Sukanya is getting married next year. Marriage is a big step in one&#39;s life. It is both exciting and frightening. But friendship is a sacred bond between people. It is a special kind of love between us. Many of you must have tried searching for a friend but never found the right one.&#39;&#39;&#39;</span></a>
<a class="sourceLine" id="cb1948-5" title="5"></a>
<a class="sourceLine" id="cb1948-6" title="6">sentences <span class="op">=</span> nltk.sent_tokenize(doc)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mpunkt[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;punkt&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mtokenizers/punkt/english.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 105, in sent_tokenize
##     tokenizer = load(&#39;tokenizers/punkt/{0}.pickle&#39;.format(language))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1950"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1950-1" title="1"><span class="cf">for</span> sentence <span class="kw">in</span> sentences:</a>
<a class="sourceLine" id="cb1950-2" title="2">  tokens <span class="op">=</span> nltk.word_tokenize(sentence)</a>
<a class="sourceLine" id="cb1950-3" title="3">  tagged <span class="op">=</span> nltk.pos_tag(tokens)</a>
<a class="sourceLine" id="cb1950-4" title="4">  <span class="bu">print</span>(tagged)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mpunkt[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;punkt&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mtokenizers/punkt/english.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 2, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 144, in word_tokenize
##     sentences = [text] if preserve_line else sent_tokenize(text, language)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 105, in sent_tokenize
##     tokenizer = load(&#39;tokenizers/punkt/{0}.pickle&#39;.format(language))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
</div>
</div>
<div id="sentiment" class="section level2">
<h2><span class="header-section-number">18.9</span> Sentiment</h2>
<div id="nltk-and-senti-wordnet" class="section level3">
<h3><span class="header-section-number">18.9.1</span> NLTK and Senti-Wordnet</h3>
<ul>
<li>SentiWordNet <strong>extends Wordnet Synsets</strong> with positive and negative sentiment scores<br />
</li>
<li>The extension was achieved via a complex mix of propagation methods and classifiers. It is thus not a gold standard resource like WordNet (which was compiled by humans), but it has proven useful in a wide range of tasks<br />
</li>
<li>It contains similar number of synsets as wordnet</li>
</ul>
<div class="sourceCode" id="cb1952"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1952-1" title="1"><span class="im">from</span> nltk.corpus <span class="im">import</span> sentiwordnet <span class="im">as</span> swn</a>
<a class="sourceLine" id="cb1952-2" title="2">nltk.download(<span class="st">&#39;sentiwordnet&#39;</span>)</a></code></pre></div>
<pre><code>## True
## 
## [nltk_data] Downloading package sentiwordnet to C:\Users\keh-
## [nltk_data]     soon.yong\AppData\Roaming\nltk_data...
## [nltk_data]   Package sentiwordnet is already up-to-date!</code></pre>
<div class="sourceCode" id="cb1954"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1954-1" title="1">s <span class="op">=</span> <span class="bu">set</span>( swn.all_senti_synsets() )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\reader\sentiwordnet.py&quot;, line 108, in all_senti_synsets
##     synset = wn.synset_from_pos_and_offset(pos, offset)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1956"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1956-1" title="1"><span class="bu">print</span>(<span class="st">&#39;Total synsets in senti-wordnet  : &#39;</span> ,   <span class="bu">len</span>(s))</a></code></pre></div>
<pre><code>## Total synsets in senti-wordnet  :  5</code></pre>
<div id="senti-synset" class="section level4">
<h4><span class="header-section-number">18.9.1.1</span> Senti-Synset</h4>
<ul>
<li>Senti-Wordnet extends wordnet with three(3) sentiment scores: positive, negative, objective<br />
</li>
<li>All three scores added up to value 1.0</li>
</ul>
<div class="sourceCode" id="cb1958"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1958-1" title="1">breakdown <span class="op">=</span> swn.senti_synset(<span class="st">&#39;breakdown.n.03&#39;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\reader\sentiwordnet.py&quot;, line 81, in senti_synset
##     synset = wn.synset(vals[0])
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1960"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1960-1" title="1"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb1960-2" title="2">  breakdown, <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span></a>
<a class="sourceLine" id="cb1960-3" title="3">  <span class="st">&#39;Positive:&#39;</span>, breakdown.pos_score(), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1960-4" title="4">  <span class="st">&#39;Negative:&#39;</span>, breakdown.neg_score(), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1960-5" title="5">  <span class="st">&#39;Objective:&#39;</span>,breakdown.obj_score()</a>
<a class="sourceLine" id="cb1960-6" title="6">)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;breakdown&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 2, in &lt;module&gt;</code></pre>
</div>
<div id="senti-synsets" class="section level4">
<h4><span class="header-section-number">18.9.1.2</span> Senti-Synsets</h4>
<p>Get all the synonmys, with and without the POS information</p>
<div class="sourceCode" id="cb1962"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1962-1" title="1"><span class="bu">print</span>( <span class="bu">list</span>(swn.senti_synsets(<span class="st">&#39;slow&#39;</span>)), <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>,  <span class="co">## without POS tag</span></a>
<a class="sourceLine" id="cb1962-2" title="2">       <span class="bu">list</span>(swn.senti_synsets(<span class="st">&#39;slow&#39;</span>, <span class="st">&#39;a&#39;</span>)) )   <span class="co">## with POS tag</span></a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\reader\sentiwordnet.py&quot;, line 96, in senti_synsets
##     synset_list = wn.synsets(string, pos)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<p>Get the score for first synset</p>
<div class="sourceCode" id="cb1964"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1964-1" title="1">first_synset <span class="op">=</span> <span class="bu">list</span>(swn.senti_synsets(<span class="st">&#39;slow&#39;</span>,<span class="st">&#39;a&#39;</span>))[<span class="dv">0</span>]</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\reader\sentiwordnet.py&quot;, line 96, in senti_synsets
##     synset_list = wn.synsets(string, pos)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1966"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1966-1" title="1"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb1966-2" title="2">  first_synset, <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1966-3" title="3">  <span class="st">&#39;Positive:&#39;</span>,  first_synset.pos_score(), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1966-4" title="4">  <span class="st">&#39;Negative:&#39;</span>,  first_synset.neg_score(), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1966-5" title="5">  <span class="st">&#39;Objective:&#39;</span>, first_synset.obj_score()</a>
<a class="sourceLine" id="cb1966-6" title="6">)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;first_synset&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 2, in &lt;module&gt;</code></pre>
</div>
<div id="converting-pos-tag-into-wordnet-pos-tag" class="section level4">
<h4><span class="header-section-number">18.9.1.3</span> Converting POS-tag into Wordnet POS-tag</h4>
<p><strong>Using Function</strong></p>
<div class="sourceCode" id="cb1968"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1968-1" title="1"><span class="im">import</span> nltk</a>
<a class="sourceLine" id="cb1968-2" title="2"><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</a>
<a class="sourceLine" id="cb1968-3" title="3"><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet <span class="im">as</span> wn</a>
<a class="sourceLine" id="cb1968-4" title="4"></a>
<a class="sourceLine" id="cb1968-5" title="5"><span class="kw">def</span> penn_to_wn(tag):</a>
<a class="sourceLine" id="cb1968-6" title="6">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb1968-7" title="7"><span class="co">    Convert between the PennTreebank tags to simple Wordnet tags</span></a>
<a class="sourceLine" id="cb1968-8" title="8"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb1968-9" title="9">    <span class="cf">if</span> tag.startswith(<span class="st">&#39;J&#39;</span>):</a>
<a class="sourceLine" id="cb1968-10" title="10">        <span class="cf">return</span> wn.ADJ</a>
<a class="sourceLine" id="cb1968-11" title="11">    <span class="cf">elif</span> tag.startswith(<span class="st">&#39;N&#39;</span>):</a>
<a class="sourceLine" id="cb1968-12" title="12">        <span class="cf">return</span> wn.NOUN</a>
<a class="sourceLine" id="cb1968-13" title="13">    <span class="cf">elif</span> tag.startswith(<span class="st">&#39;R&#39;</span>):</a>
<a class="sourceLine" id="cb1968-14" title="14">        <span class="cf">return</span> wn.ADV</a>
<a class="sourceLine" id="cb1968-15" title="15">    <span class="cf">elif</span> tag.startswith(<span class="st">&#39;V&#39;</span>):</a>
<a class="sourceLine" id="cb1968-16" title="16">        <span class="cf">return</span> wn.VERB</a>
<a class="sourceLine" id="cb1968-17" title="17">    <span class="cf">return</span> <span class="va">None</span></a>
<a class="sourceLine" id="cb1968-18" title="18"></a>
<a class="sourceLine" id="cb1968-19" title="19">wt <span class="op">=</span> word_tokenize(<span class="st">&quot;Star Wars is a wonderful movie&quot;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mpunkt[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;punkt&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mtokenizers/punkt/english.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 144, in word_tokenize
##     sentences = [text] if preserve_line else sent_tokenize(text, language)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 105, in sent_tokenize
##     tokenizer = load(&#39;tokenizers/punkt/{0}.pickle&#39;.format(language))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1970"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1970-1" title="1">penn_tags <span class="op">=</span> nltk.pos_tag(wt)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;wt&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1972"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1972-1" title="1">wordnet_tags <span class="op">=</span> [ (x, penn_to_wn(y)) <span class="cf">for</span> (x,y) <span class="kw">in</span> penn_tags ]</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;penn_tags&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1974"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1974-1" title="1"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb1974-2" title="2"><span class="st">&#39;Penn Tags    :&#39;</span>, penn_tags, </a>
<a class="sourceLine" id="cb1974-3" title="3"><span class="st">&#39;</span><span class="ch">\n</span><span class="st">Wordnet Tags :&#39;</span>, wordnet_tags)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;penn_tags&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 2, in &lt;module&gt;</code></pre>
<p><strong>Using defaultdict</strong></p>
<div class="sourceCode" id="cb1976"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1976-1" title="1"><span class="im">import</span> nltk</a>
<a class="sourceLine" id="cb1976-2" title="2"><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet <span class="im">as</span> wn</a>
<a class="sourceLine" id="cb1976-3" title="3"><span class="im">from</span> nltk <span class="im">import</span> word_tokenize, pos_tag</a>
<a class="sourceLine" id="cb1976-4" title="4"><span class="im">from</span> collections <span class="im">import</span> defaultdict</a>
<a class="sourceLine" id="cb1976-5" title="5"></a>
<a class="sourceLine" id="cb1976-6" title="6">tag_map <span class="op">=</span> defaultdict(<span class="kw">lambda</span> : <span class="va">None</span>)</a>
<a class="sourceLine" id="cb1976-7" title="7">tag_map[<span class="st">&#39;J&#39;</span>] <span class="op">=</span> wn.ADJ</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1978"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1978-1" title="1">tag_map[<span class="st">&#39;R&#39;</span>] <span class="op">=</span> wn.ADV</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1980"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1980-1" title="1">tag_map[<span class="st">&#39;V&#39;</span>] <span class="op">=</span> wn.VERB</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1982"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1982-1" title="1">tag_map[<span class="st">&#39;N&#39;</span>] <span class="op">=</span> wn.NOUN</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mwordnet[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mcorpora/wordnet[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 123, in __getattr__
##     self.__load()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 88, in __load
##     raise e
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py&quot;, line 83, in __load
##     root = nltk.data.find(&#39;{}/{}&#39;.format(self.subdir, self.__name))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1984"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1984-1" title="1">wt <span class="op">=</span> word_tokenize(<span class="st">&quot;Star Wars is a wonderful movie&quot;</span>)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mpunkt[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;punkt&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93mtokenizers/punkt/english.pickle[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 144, in word_tokenize
##     sentences = [text] if preserve_line else sent_tokenize(text, language)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\tokenize\__init__.py&quot;, line 105, in sent_tokenize
##     tokenizer = load(&#39;tokenizers/punkt/{0}.pickle&#39;.format(language))
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1986"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1986-1" title="1">penn_tags <span class="op">=</span> nltk.pos_tag(wt)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;wt&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1988"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1988-1" title="1">wordnet_tags <span class="op">=</span> [ (x, tag_map[y[<span class="dv">0</span>]]) <span class="cf">for</span> (x,y) <span class="kw">in</span> penn_tags ]</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;penn_tags&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1990"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1990-1" title="1"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb1990-2" title="2"><span class="st">&#39;Penn Tags    :&#39;</span>, penn_tags, </a>
<a class="sourceLine" id="cb1990-3" title="3"><span class="st">&#39;</span><span class="ch">\n</span><span class="st">Wordnet Tags :&#39;</span>, wordnet_tags)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;penn_tags&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 2, in &lt;module&gt;</code></pre>
</div>
</div>
<div id="vader" class="section level3">
<h3><span class="header-section-number">18.9.2</span> Vader</h3>
<ul>
<li>It is a rule based sentiment analyzer, contain 7503 lexicons</li>
<li>It is good for <strong>social media</strong> because lexicon contain <strong>emoji and short</strong> form text</li>
<li>Contain only <strong>3 n-gram</strong></li>
<li>Supported by NTLK or install vader seperately (pip install vaderSentiment)</li>
</ul>
<div id="vader-lexicon" class="section level4">
<h4><span class="header-section-number">18.9.2.1</span> Vader Lexicon</h4>
<p>The lexicon is a dictionary. To make it iterable, need to convert into list:<br />
- Step 1: Convert <code>dict</code> to <code>dict_items</code>, which is a list containing items, each item is one dict<br />
- Step 2: Unpack <code>dict_items</code> to <code>list</code></p>
<div class="sourceCode" id="cb1992"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1992-1" title="1"><span class="co">#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer   ## seperate pip installed library</span></a>
<a class="sourceLine" id="cb1992-2" title="2"><span class="im">from</span> nltk.sentiment.vader <span class="im">import</span> SentimentIntensityAnalyzer</a>
<a class="sourceLine" id="cb1992-3" title="3">vader_lex  <span class="op">=</span> SentimentIntensityAnalyzer().lexicon  <span class="co"># get the lexicon dictionary</span></a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mvader_lexicon[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;vader_lexicon&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\sentiment\vader.py&quot;, line 334, in __init__
##     self.lexicon_file = nltk.data.load(lexicon_file)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
<div class="sourceCode" id="cb1994"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1994-1" title="1">vader_list <span class="op">=</span> <span class="bu">list</span>(vader_lex.items())               <span class="co"># convert to items then list</span></a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;vader_lex&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb1996"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1996-1" title="1"><span class="bu">print</span>( <span class="st">&#39;Total Vader Lexicon:&#39;</span>, <span class="bu">len</span>(vader_lex),<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb1996-2" title="2">        vader_list[<span class="dv">1</span>:<span class="dv">10</span>], vader_list[<span class="dv">220</span>:<span class="dv">240</span>] )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;vader_lex&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p><strong>There is only four N-Gram in the lexicon</strong></p>
<div class="sourceCode" id="cb1998"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1998-1" title="1"><span class="bu">print</span>(<span class="st">&#39;List of N-grams: &#39;</span>)</a></code></pre></div>
<pre><code>## List of N-grams:</code></pre>
<div class="sourceCode" id="cb2000"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2000-1" title="1">[ (tok,score) <span class="cf">for</span> tok, score <span class="kw">in</span> vader_list <span class="cf">if</span> <span class="st">&quot; &quot;</span> <span class="kw">in</span> tok]</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;vader_list&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>If stemming or lemmatization is used, stem/lemmatize the vader lexicon too</p>
<div class="sourceCode" id="cb2002"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2002-1" title="1">[ (tok,score) <span class="cf">for</span> tok, score <span class="kw">in</span> vader_list <span class="cf">if</span> <span class="st">&quot;lov&quot;</span> <span class="kw">in</span> tok]</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;vader_list&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
<div id="polarity-scoring" class="section level4">
<h4><span class="header-section-number">18.9.2.2</span> Polarity Scoring</h4>
<p>Scoring result is a dictionary of:</p>
<ul>
<li>neg</li>
<li>neu</li>
<li>pos</li>
<li>compound
<strong>neg, neu, pos adds up to 1.0</strong></li>
</ul>
<p>Example below shows polarity for two sentences:</p>
<div class="sourceCode" id="cb2004"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2004-1" title="1">corpus <span class="op">=</span> [<span class="st">&quot;Python is a very useful but hell difficult to learn&quot;</span>,</a>
<a class="sourceLine" id="cb2004-2" title="2">        <span class="st">&quot;:) :) :(&quot;</span>]</a>
<a class="sourceLine" id="cb2004-3" title="3"><span class="cf">for</span> doc <span class="kw">in</span> corpus:</a>
<a class="sourceLine" id="cb2004-4" title="4">  <span class="bu">print</span>(doc, <span class="st">&#39;--&gt;&#39;</span>, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">:&quot;</span>, SentimentIntensityAnalyzer().polarity_scores(doc) )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): LookupError: 
## **********************************************************************
##   Resource [93mvader_lexicon[0m not found.
##   Please use the NLTK Downloader to obtain the resource:
## 
##   [31m&gt;&gt;&gt; import nltk
##   &gt;&gt;&gt; nltk.download(&#39;vader_lexicon&#39;)
##   [0m
##   For more information see: https://www.nltk.org/data.html
## 
##   Attempted to load [93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt[0m
## 
##   Searched in:
##     - &#39;C:\\Users\\keh-soon.yong\\Documents/nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\share\\nltk_data&#39;
##     - &#39;C:/ProgramData/Anaconda3\\lib\\nltk_data&#39;
##     - &#39;C:\\Users\\keh-soon.yong\\AppData\\Roaming\\nltk_data&#39;
##     - &#39;C:\\nltk_data&#39;
##     - &#39;D:\\nltk_data&#39;
##     - &#39;E:\\nltk_data&#39;
##     - &#39;&#39;
## **********************************************************************
## 
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 2, in &lt;module&gt;
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\sentiment\vader.py&quot;, line 334, in __init__
##     self.lexicon_file = nltk.data.load(lexicon_file)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 868, in load
##     opened_resource = _open(resource_url)
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 993, in _open
##     return find(path_, path + [&#39;&#39;]).open()
##   File &quot;C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py&quot;, line 701, in find
##     raise LookupError(resource_not_found)</code></pre>
</div>
</div>
</div>
<div id="feature-representation" class="section level2">
<h2><span class="header-section-number">18.10</span> Feature Representation</h2>
<div id="the-data-3" class="section level3">
<h3><span class="header-section-number">18.10.1</span> The Data</h3>
<p>A corpus is a collection of multiple documents. In the below example, each document is represented by a sentence.</p>
<div class="sourceCode" id="cb2006"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2006-1" title="1">corpus <span class="op">=</span> [</a>
<a class="sourceLine" id="cb2006-2" title="2">   <span class="st">&#39;This is the first document, :)&#39;</span>,</a>
<a class="sourceLine" id="cb2006-3" title="3">   <span class="st">&#39;This document is the second document.&#39;</span>,</a>
<a class="sourceLine" id="cb2006-4" title="4">   <span class="st">&#39;And this is a third one&#39;</span>,</a>
<a class="sourceLine" id="cb2006-5" title="5">   <span class="st">&#39;Is this the first document?&#39;</span>,</a>
<a class="sourceLine" id="cb2006-6" title="6">]</a></code></pre></div>
</div>
<div id="frequency-count-1" class="section level3">
<h3><span class="header-section-number">18.10.2</span> Frequency Count</h3>
<p>Using purely frequency count as a feature will obviously bias on long document (which contain a lot of words, hence words within the document will have very high frequency).</p>
<div id="tokenizer" class="section level4">
<h4><span class="header-section-number">18.10.2.1</span> + Tokenizer</h4>
<p><strong>Default Tokenizer</strong><br />
By default, vectorizer apply tokenizer to select minimum <strong>2-chars alphanumeric words</strong>. Below <strong>train</strong> the vectorizer using <strong><code>fit_transform()</code></strong>.</p>
<div class="sourceCode" id="cb2007"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2007-1" title="1"><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</a>
<a class="sourceLine" id="cb2007-2" title="2">vec <span class="op">=</span> CountVectorizer()          <span class="co"># initialize the vectorizer</span></a>
<a class="sourceLine" id="cb2007-3" title="3">X   <span class="op">=</span> vec.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></a>
<a class="sourceLine" id="cb2007-4" title="4"><span class="bu">print</span>(pd.DataFrame(X.toarray(), columns<span class="op">=</span>vec.get_feature_names()),<span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb2007-5" title="5">      <span class="st">&#39;Vocabulary: &#39;</span>, vec.vocabulary_)</a></code></pre></div>
<pre><code>##    and  document  first  is  one  second  the  third  this
## 0    0         1      1   1    0       0    1      0     1
## 1    0         2      0   1    0       1    1      0     1
## 2    1         0      0   1    1       0    0      1     1
## 3    0         1      1   1    0       0    1      0     1 
## 
##  Vocabulary:  {&#39;this&#39;: 8, &#39;is&#39;: 3, &#39;the&#39;: 6, &#39;first&#39;: 2, &#39;document&#39;: 1, &#39;second&#39;: 5, &#39;and&#39;: 0, &#39;third&#39;: 7, &#39;one&#39;: 4}</code></pre>
<p><strong>Custom Tokenizer</strong><br />
You can use a custom tokenizer, which is a <strong>function that return list of words</strong>. Example below uses nltk RegexpTokenizer function, which retains one or more alphanumeric characters.</p>
<div class="sourceCode" id="cb2009"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2009-1" title="1">my_tokenizer <span class="op">=</span> RegexpTokenizer(<span class="vs">r&#39;[a-zA-Z0-9\&#39;]+&#39;</span>)  <span class="co">## Custom Tokenizer</span></a>
<a class="sourceLine" id="cb2009-2" title="2">vec2 <span class="op">=</span> CountVectorizer(tokenizer<span class="op">=</span>my_tokenizer.tokenize) <span class="co">## custom tokenizer&#39;s function</span></a>
<a class="sourceLine" id="cb2009-3" title="3">X2   <span class="op">=</span> vec2.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></a>
<a class="sourceLine" id="cb2009-4" title="4"><span class="bu">print</span>(pd.DataFrame(X2.toarray(), columns<span class="op">=</span>vec2.get_feature_names()),<span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb2009-5" title="5">      <span class="st">&#39;Vocabulary: &#39;</span>, vec.vocabulary_)</a></code></pre></div>
<pre><code>##    a  and  document  first  is  one  second  the  third  this
## 0  0    0         1      1   1    0       0    1      0     1
## 1  0    0         2      0   1    0       1    1      0     1
## 2  1    1         0      0   1    1       0    0      1     1
## 3  0    0         1      1   1    0       0    1      0     1 
## 
##  Vocabulary:  {&#39;this&#39;: 8, &#39;is&#39;: 3, &#39;the&#39;: 6, &#39;first&#39;: 2, &#39;document&#39;: 1, &#39;second&#39;: 5, &#39;and&#39;: 0, &#39;third&#39;: 7, &#39;one&#39;: 4}</code></pre>
<p><strong>1 and 2-Word-Gram Tokenizer</strong><br />
Use <code>ngram_range()</code> to specify range of grams needed.</p>
<div class="sourceCode" id="cb2011"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2011-1" title="1">vec3 <span class="op">=</span> CountVectorizer(ngram_range<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">2</span>))          <span class="co"># initialize the vectorizer</span></a>
<a class="sourceLine" id="cb2011-2" title="2">X3   <span class="op">=</span> vec3.fit_transform(corpus)     <span class="co"># FIT the vectorizer, return fitted data</span></a>
<a class="sourceLine" id="cb2011-3" title="3"><span class="bu">print</span>(pd.DataFrame(X3.toarray(), columns<span class="op">=</span>vec3.get_feature_names()),<span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb2011-4" title="4">      <span class="st">&#39;Vocabulary: &#39;</span>, vec.vocabulary_)</a></code></pre></div>
<pre><code>##    and  and this  document  document is  first  ...  third one  this  this document  \
## 0    0         0         1            0      1  ...          0     1              0   
## 1    0         0         2            1      0  ...          0     1              1   
## 2    1         1         0            0      0  ...          1     1              0   
## 3    0         0         1            0      1  ...          0     1              0   
## 
##    this is  this the  
## 0        1         0  
## 1        0         0  
## 2        1         0  
## 3        0         1  
## 
## [4 rows x 22 columns] 
## 
##  Vocabulary:  {&#39;this&#39;: 8, &#39;is&#39;: 3, &#39;the&#39;: 6, &#39;first&#39;: 2, &#39;document&#39;: 1, &#39;second&#39;: 5, &#39;and&#39;: 0, &#39;third&#39;: 7, &#39;one&#39;: 4}</code></pre>
<p><strong>Apply Trained Vectorizer</strong>
Once the vectorizer had been trained, you can apply them on new corpus. <strong>Tokens not in the vectorizer vocubulary are ignored</strong>.</p>
<div class="sourceCode" id="cb2013"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2013-1" title="1">new_corpus <span class="op">=</span> [<span class="st">&quot;My Name is Charlie Angel&quot;</span>, <span class="st">&quot;I love to watch Star Wars&quot;</span>]</a>
<a class="sourceLine" id="cb2013-2" title="2">XX <span class="op">=</span> vec.transform(new_corpus)</a>
<a class="sourceLine" id="cb2013-3" title="3">pd.DataFrame(XX.toarray(), columns<span class="op">=</span>vec.get_feature_names())</a></code></pre></div>
<pre><code>##    and  document  first  is  one  second  the  third  this
## 0    0         0      0   1    0       0    0      0     0
## 1    0         0      0   0    0       0    0      0     0</code></pre>
</div>
<div id="stop-words" class="section level4">
<h4><span class="header-section-number">18.10.2.2</span> + Stop Words</h4>
<p>Vectorizer can optionally be use with stop words list. Use <code>stop_words=english</code> to apply filtering using sklearn built-in stop word. You can replace <code>english</code> with other word <strong>list object</strong>.</p>
<div class="sourceCode" id="cb2015"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2015-1" title="1">vec4 <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">&#39;english&#39;</span>) <span class="co">## sklearn stopwords list</span></a>
<a class="sourceLine" id="cb2015-2" title="2">X4 <span class="op">=</span> vec4.fit_transform(corpus)</a>
<a class="sourceLine" id="cb2015-3" title="3">pd.DataFrame(X4.toarray(), columns<span class="op">=</span>vec4.get_feature_names())</a></code></pre></div>
<pre><code>##    document  second
## 0         1       0
## 1         2       1
## 2         0       0
## 3         1       0</code></pre>
</div>
</div>
<div id="tfidf" class="section level3">
<h3><span class="header-section-number">18.10.3</span> TFIDF</h3>
<div id="equation" class="section level4">
<h4><span class="header-section-number">18.10.3.1</span> Equation</h4>
<p><span class="math display">\[tf(t,d) = \text{occurances of term t in document t} \\
n     = \text{number of documents} \\
df(t) = \text{number of documents containing term t} \\
idf(t)  = log \frac{n}{df(t))} + 1 \\
idf(t)  = log \frac{1+n}{1+df(t))} + 1 \text{.... smoothing, prevent zero division} \\
tfidf(t) = tf(t) * idf(t,d)    \text{.... raw, no normalization on tf(t)} \\
tfidf(t) = \frac{tf(t,d)}{||V||_2} * idf(t)    \text{.... tf normalized with euclidean norm}\]</span></p>
</div>
<div id="tfidftransformer" class="section level4">
<h4><span class="header-section-number">18.10.3.2</span> <code>TfidfTransformer</code></h4>
<p>To generate TFIDF vectors, first run <code>CountVectorizer</code> to get frequency vector matrix. Then take the output into this transformer.</p>
<div class="sourceCode" id="cb2017"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2017-1" title="1"><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfTransformer</a>
<a class="sourceLine" id="cb2017-2" title="2"></a>
<a class="sourceLine" id="cb2017-3" title="3">corpus <span class="op">=</span> [</a>
<a class="sourceLine" id="cb2017-4" title="4">    <span class="st">&quot;apple apple apple apple apple banana&quot;</span>,</a>
<a class="sourceLine" id="cb2017-5" title="5">    <span class="st">&quot;apple apple&quot;</span>,</a>
<a class="sourceLine" id="cb2017-6" title="6">    <span class="st">&quot;apple apple apple banana&quot;</span>,</a>
<a class="sourceLine" id="cb2017-7" title="7">    <span class="st">&quot;durian durian durian&quot;</span>]</a>
<a class="sourceLine" id="cb2017-8" title="8">    </a>
<a class="sourceLine" id="cb2017-9" title="9">count_vec <span class="op">=</span> CountVectorizer()</a>
<a class="sourceLine" id="cb2017-10" title="10">X <span class="op">=</span> count_vec.fit_transform(corpus)</a>
<a class="sourceLine" id="cb2017-11" title="11"></a>
<a class="sourceLine" id="cb2017-12" title="12">transformer1 <span class="op">=</span> TfidfTransformer(smooth_idf<span class="op">=</span><span class="va">False</span>,norm<span class="op">=</span><span class="va">None</span>)</a>
<a class="sourceLine" id="cb2017-13" title="13">transformer2 <span class="op">=</span> TfidfTransformer(smooth_idf<span class="op">=</span><span class="va">False</span>,norm<span class="op">=</span><span class="st">&#39;l2&#39;</span>)</a>
<a class="sourceLine" id="cb2017-14" title="14">transformer3 <span class="op">=</span> TfidfTransformer(smooth_idf<span class="op">=</span><span class="va">True</span>,norm<span class="op">=</span><span class="st">&#39;l2&#39;</span>)</a>
<a class="sourceLine" id="cb2017-15" title="15"></a>
<a class="sourceLine" id="cb2017-16" title="16">tfidf1 <span class="op">=</span> transformer1.fit_transform(X)</a>
<a class="sourceLine" id="cb2017-17" title="17">tfidf2 <span class="op">=</span> transformer2.fit_transform(X)</a>
<a class="sourceLine" id="cb2017-18" title="18">tfidf3 <span class="op">=</span> transformer3.fit_transform(X)</a>
<a class="sourceLine" id="cb2017-19" title="19"></a>
<a class="sourceLine" id="cb2017-20" title="20"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb2017-21" title="21">  <span class="st">&#39;Frequency Count: </span><span class="ch">\n</span><span class="st">&#39;</span>, pd.DataFrame(X.toarray(), columns<span class="op">=</span>count_vec.get_feature_names()),</a>
<a class="sourceLine" id="cb2017-22" title="22">  <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">Vocabulary: &#39;</span>, count_vec.vocabulary_,</a>
<a class="sourceLine" id="cb2017-23" title="23">  <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">TFIDF Without Norm:</span><span class="ch">\n</span><span class="st">&#39;</span>,tfidf1.toarray(), </a>
<a class="sourceLine" id="cb2017-24" title="24">  <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">TFIDF with L2 Norm:</span><span class="ch">\n</span><span class="st">&#39;</span>,tfidf2.toarray(),  </a>
<a class="sourceLine" id="cb2017-25" title="25">  <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">TFIDF with L2 Norm (smooth):</span><span class="ch">\n</span><span class="st">&#39;</span>,tfidf3.toarray())</a></code></pre></div>
<pre><code>## Frequency Count: 
##     apple  banana  durian
## 0      5       1       0
## 1      2       0       0
## 2      3       1       0
## 3      0       0       3 
## 
## Vocabulary:  {&#39;apple&#39;: 0, &#39;banana&#39;: 1, &#39;durian&#39;: 2} 
## 
## TFIDF Without Norm:
##  [[6.43841036 1.69314718 0.        ]
##  [2.57536414 0.         0.        ]
##  [3.86304622 1.69314718 0.        ]
##  [0.         0.         7.15888308]] 
## 
## TFIDF with L2 Norm:
##  [[0.96711783 0.25432874 0.        ]
##  [1.         0.         0.        ]
##  [0.91589033 0.40142857 0.        ]
##  [0.         0.         1.        ]] 
## 
## TFIDF with L2 Norm (smooth):
##  [[0.97081492 0.23982991 0.        ]
##  [1.         0.         0.        ]
##  [0.92468843 0.38072472 0.        ]
##  [0.         0.         1.        ]]</code></pre>
</div>
<div id="tfidfvectorizer" class="section level4">
<h4><span class="header-section-number">18.10.3.3</span> <code>TfidfVectorizer</code></h4>
<p>This vectorizer gives end to end processing from corpus into TFIDF vector matrix, including tokenization, stopwords.</p>
<div class="sourceCode" id="cb2019"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2019-1" title="1"><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</a>
<a class="sourceLine" id="cb2019-2" title="2">my_tokenizer <span class="op">=</span> RegexpTokenizer(<span class="vs">r&#39;[a-zA-Z0-9\&#39;]+&#39;</span>)  <span class="co">## Custom Tokenizer</span></a>
<a class="sourceLine" id="cb2019-3" title="3"></a>
<a class="sourceLine" id="cb2019-4" title="4">vec1 <span class="op">=</span> TfidfVectorizer(tokenizer<span class="op">=</span>my_tokenizer.tokenize,  stop_words<span class="op">=</span><span class="st">&#39;english&#39;</span>) <span class="co">#default smooth_idf=True, norm=&#39;l2&#39;</span></a>
<a class="sourceLine" id="cb2019-5" title="5">vec2 <span class="op">=</span> TfidfVectorizer(tokenizer<span class="op">=</span>my_tokenizer.tokenize, stop_words<span class="op">=</span><span class="st">&#39;english&#39;</span>,smooth_idf<span class="op">=</span><span class="va">False</span>)</a>
<a class="sourceLine" id="cb2019-6" title="6">vec3 <span class="op">=</span> TfidfVectorizer(tokenizer<span class="op">=</span>my_tokenizer.tokenize, stop_words<span class="op">=</span><span class="st">&#39;english&#39;</span>, norm<span class="op">=</span><span class="va">None</span>)</a>
<a class="sourceLine" id="cb2019-7" title="7"></a>
<a class="sourceLine" id="cb2019-8" title="8">X1   <span class="op">=</span> vec1.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></a>
<a class="sourceLine" id="cb2019-9" title="9">X2   <span class="op">=</span> vec2.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></a>
<a class="sourceLine" id="cb2019-10" title="10">X3   <span class="op">=</span> vec3.fit_transform(corpus)  <span class="co"># FIT the vectorizer, return fitted data</span></a>
<a class="sourceLine" id="cb2019-11" title="11"></a>
<a class="sourceLine" id="cb2019-12" title="12"><span class="bu">print</span>(</a>
<a class="sourceLine" id="cb2019-13" title="13">  <span class="st">&#39;TFIDF Features (Default with Smooth and L2 Norm):</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb2019-14" title="14">  pd.DataFrame(X1.toarray().<span class="bu">round</span>(<span class="dv">3</span>), columns<span class="op">=</span>vec1.get_feature_names()),</a>
<a class="sourceLine" id="cb2019-15" title="15">  <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">TFIDF Features (without Smoothing):</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb2019-16" title="16">  pd.DataFrame(X2.toarray().<span class="bu">round</span>(<span class="dv">3</span>), columns<span class="op">=</span>vec2.get_feature_names()),</a>
<a class="sourceLine" id="cb2019-17" title="17">  <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">TFIDF Features (without L2 Norm):</span><span class="ch">\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb2019-18" title="18">  pd.DataFrame(X3.toarray().<span class="bu">round</span>(<span class="dv">3</span>), columns<span class="op">=</span>vec3.get_feature_names())</a>
<a class="sourceLine" id="cb2019-19" title="19">  )</a></code></pre></div>
<pre><code>## TFIDF Features (Default with Smooth and L2 Norm):
##     apple  banana  durian
## 0  0.971   0.240     0.0
## 1  1.000   0.000     0.0
## 2  0.925   0.381     0.0
## 3  0.000   0.000     1.0 
## 
## TFIDF Features (without Smoothing):
##     apple  banana  durian
## 0  0.967   0.254     0.0
## 1  1.000   0.000     0.0
## 2  0.916   0.401     0.0
## 3  0.000   0.000     1.0 
## 
## TFIDF Features (without L2 Norm):
##     apple  banana  durian
## 0  6.116   1.511   0.000
## 1  2.446   0.000   0.000
## 2  3.669   1.511   0.000
## 3  0.000   0.000   5.749</code></pre>
</div>
</div>
</div>
<div id="appliction" class="section level2">
<h2><span class="header-section-number">18.11</span> Appliction</h2>
<div id="document-similarity" class="section level3">
<h3><span class="header-section-number">18.11.1</span> Document Similarity</h3>
<p>Document1 and Document 2 are mutiplicate of Document0, therefore their consine similarity is the same.</p>
<div class="sourceCode" id="cb2021"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2021-1" title="1">documents <span class="op">=</span> (</a>
<a class="sourceLine" id="cb2021-2" title="2">    <span class="st">&quot;apple apple banana&quot;</span>,</a>
<a class="sourceLine" id="cb2021-3" title="3">    <span class="st">&quot;apple apple banana apple apple banana&quot;</span>,</a>
<a class="sourceLine" id="cb2021-4" title="4">    <span class="st">&quot;apple apple banana apple apple banana apple apple banana&quot;</span>)</a>
<a class="sourceLine" id="cb2021-5" title="5">    </a>
<a class="sourceLine" id="cb2021-6" title="6"><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</a>
<a class="sourceLine" id="cb2021-7" title="7">tfidf_vec <span class="op">=</span> TfidfVectorizer()</a>
<a class="sourceLine" id="cb2021-8" title="8">tfidf_matrix <span class="op">=</span> tfidf_vec.fit_transform(documents)</a>
<a class="sourceLine" id="cb2021-9" title="9"></a>
<a class="sourceLine" id="cb2021-10" title="10"><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</a>
<a class="sourceLine" id="cb2021-11" title="11"><span class="bu">print</span>(<span class="st">&#39;Cosine Similarity betwen doc0 and doc1:</span><span class="ch">\n</span><span class="st">&#39;</span>,cosine_similarity(tfidf_matrix[<span class="dv">0</span>], tfidf_matrix[<span class="dv">1</span>]))</a></code></pre></div>
<pre><code>## Cosine Similarity betwen doc0 and doc1:
##  [[1.]]</code></pre>
<div class="sourceCode" id="cb2023"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2023-1" title="1"><span class="bu">print</span>(<span class="st">&#39;Cosine Similarity betwen doc1 and doc2:</span><span class="ch">\n</span><span class="st">&#39;</span>,cosine_similarity(tfidf_matrix[<span class="dv">1</span>], tfidf_matrix[<span class="dv">2</span>]))</a></code></pre></div>
<pre><code>## Cosine Similarity betwen doc1 and doc2:
##  [[1.]]</code></pre>
<div class="sourceCode" id="cb2025"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2025-1" title="1"><span class="bu">print</span>(<span class="st">&#39;Cosine Similarity betwen doc1 and doc2:</span><span class="ch">\n</span><span class="st">&#39;</span>,cosine_similarity(tfidf_matrix[<span class="dv">0</span>], tfidf_matrix[<span class="dv">2</span>]))</a></code></pre></div>
<pre><code>## Cosine Similarity betwen doc1 and doc2:
##  [[1.]]</code></pre>
</div>
</div>
<div id="naive-bayes" class="section level2">
<h2><span class="header-section-number">18.12</span> Naive Bayes</h2>
<div id="libraries" class="section level3">
<h3><span class="header-section-number">18.12.1</span> Libraries</h3>
<div class="sourceCode" id="cb2027"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2027-1" title="1"><span class="im">from</span> nlpia.data.loaders <span class="im">import</span> get_data</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;nlpia&#39;
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb2029"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2029-1" title="1"><span class="im">from</span> nltk.tokenize.casual     <span class="im">import</span> casual_tokenize</a>
<a class="sourceLine" id="cb2029-2" title="2"><span class="im">from</span> collections <span class="im">import</span> Counter</a></code></pre></div>
</div>
<div id="the-data-4" class="section level3">
<h3><span class="header-section-number">18.12.2</span> The Data</h3>
<div class="sourceCode" id="cb2030"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2030-1" title="1">movies <span class="op">=</span> get_data(<span class="st">&#39;hutto_movies&#39;</span>)   <span class="co"># download data</span></a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;get_data&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb2032"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2032-1" title="1"><span class="bu">print</span>(movies.head(), <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb2032-2" title="2">      movies.describe())</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;movies&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
<div id="bag-of-words" class="section level3">
<h3><span class="header-section-number">18.12.3</span> Bag of Words</h3>
<ul>
<li>Tokenize each record, remove single character token, then convert into list of counters (words-frequency pair).<br />
</li>
<li>Each item in the list is a counter, which represent word frequency within the record</li>
</ul>
<div class="sourceCode" id="cb2034"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2034-1" title="1">bag_of_words <span class="op">=</span> []</a>
<a class="sourceLine" id="cb2034-2" title="2"><span class="cf">for</span> text <span class="kw">in</span> movies.text:</a>
<a class="sourceLine" id="cb2034-3" title="3">    tokens <span class="op">=</span> casual_tokenize(text, reduce_len<span class="op">=</span><span class="va">True</span>, strip_handles<span class="op">=</span><span class="va">True</span>)  <span class="co"># tokenize</span></a>
<a class="sourceLine" id="cb2034-4" title="4">    tokens <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> tokens <span class="cf">if</span> <span class="bu">len</span>(x)<span class="op">&gt;</span><span class="dv">1</span>]                  <span class="co">## remove single char token</span></a>
<a class="sourceLine" id="cb2034-5" title="5">    bag_of_words.append( Counter(tokens, strip_handles<span class="op">=</span><span class="va">True</span>)  <span class="co">## add to our BoW</span></a>
<a class="sourceLine" id="cb2034-6" title="6">    )</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;movies&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb2036"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2036-1" title="1">unique_words <span class="op">=</span>  <span class="bu">list</span>( <span class="bu">set</span>([ y  <span class="cf">for</span> x <span class="kw">in</span> bag_of_words  <span class="cf">for</span> y <span class="kw">in</span> x.keys()]) )</a>
<a class="sourceLine" id="cb2036-2" title="2"></a>
<a class="sourceLine" id="cb2036-3" title="3"><span class="bu">print</span>(<span class="st">&quot;Total Rows: &quot;</span>, <span class="bu">len</span>(bag_of_words),<span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb2036-4" title="4">      <span class="st">&#39;Row 1 BoW: &#39;</span>,bag_of_words[:<span class="dv">1</span>],<span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>,    <span class="co"># see the first two records</span></a>
<a class="sourceLine" id="cb2036-5" title="5">      <span class="st">&#39;Row 2 BoW: &#39;</span>, bag_of_words[:<span class="dv">2</span>], <span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>,</a>
<a class="sourceLine" id="cb2036-6" title="6">      <span class="st">&#39;Total Unique Words: &#39;</span>, <span class="bu">len</span>(unique_words))</a></code></pre></div>
<pre><code>## Total Rows:  0 
## 
##  Row 1 BoW:  [] 
## 
##  Row 2 BoW:  [] 
## 
##  Total Unique Words:  0</code></pre>
<p><strong>Convert NaN into 0 then all features into integer</strong></p>
<div class="sourceCode" id="cb2038"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2038-1" title="1">bows_df <span class="op">=</span> pd.DataFrame.from_records(bag_of_words)</a>
<a class="sourceLine" id="cb2038-2" title="2">bows_df <span class="op">=</span> bows_df.fillna(<span class="dv">0</span>).astype(<span class="bu">int</span>)  <span class="co"># replace NaN with 0, change to integer</span></a>
<a class="sourceLine" id="cb2038-3" title="3">bows_df.head()</a></code></pre></div>
<pre><code>## Empty DataFrame
## Columns: []
## Index: []</code></pre>
</div>
<div id="build-the-model" class="section level3">
<h3><span class="header-section-number">18.12.4</span> Build The Model</h3>
<div class="sourceCode" id="cb2040"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2040-1" title="1"><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</a>
<a class="sourceLine" id="cb2040-2" title="2">train_y  <span class="op">=</span> movies.sentiment<span class="op">&gt;</span><span class="dv">0</span>   <span class="co"># label</span></a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;movies&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb2042"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2042-1" title="1">train_X  <span class="op">=</span> bows_df              <span class="co"># features</span></a>
<a class="sourceLine" id="cb2042-2" title="2">nb_model <span class="op">=</span> MultinomialNB().fit( train_X, train_y)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;train_y&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
<div id="train-set-prediction" class="section level3">
<h3><span class="header-section-number">18.12.5</span> Train Set Prediction</h3>
<p>First, make a prediction on training data, then compare to ground truth.</p>
<div class="sourceCode" id="cb2044"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2044-1" title="1">train_predicted <span class="op">=</span> nb_model.predict(bows_df)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;nb_model&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb2046"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2046-1" title="1"><span class="bu">print</span>(<span class="st">&quot;Accuracy: &quot;</span>, np.mean(train_predicted<span class="op">==</span>train_y).<span class="bu">round</span>(<span class="dv">4</span>))</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;train_predicted&#39; is not defined
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sklearn.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="web-scrapping.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"],
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "Sep;ia",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yongks/python_bookdown/edit/master/06-nlp.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
