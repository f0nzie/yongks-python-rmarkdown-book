[{"path":"index.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"Following text added Alfonso R. Reyes","code":""},{"path":"index.html","id":"main-sections-of-the-book","chapter":"Introduction","heading":"Main sections of the book","text":"FundamentalsnumpypandasVisualizationsklearnNatural Language ProcessingWeb scrappingFinance","code":""},{"path":"index.html","id":"python-environment","chapter":"Introduction","heading":"Python environment","text":"may need create Python environment covers packages dependencies building book. Anaconda3 installed computer, creating Python environment easy. Go tterminal run:Anaconda read file listing core dependencies, install following package version specified. inside environment.yml:","code":"conda env create -f environment.ymlname: python_book\nchannels:\n  - anaconda\n  - conda-forge\n  - defaults\ndependencies:\n  - python=3.7\n  - beautifulsoup4=4.9.3\n  - matplotlib=3.3.1\n  - nltk=3.5\n  - numpy=1.19.1\n  - pandas=1.1.3\n  - pandas-datareader=0.9.0\n  - pip=20.2.4\n  - requests=2.24.0\n  - scikit-learn=0.23.2\n  - seaborn=0.11.0\n  - urllib3=1.25.11\n  - pip:\n    - cufflinks\n    - h5py==2.10.0\n    - nlpia==0.5.2\n    - plotnine==0.7\n    - plydata==0.4.2\n    - yfinance==0.1.55\nprefix: /home/msfz751/anaconda3/envs/python_book"},{"path":"index.html","id":"automating-the-builds-with-a-makefile","chapter":"Introduction","heading":"Automating the builds with a Makefile","text":"","code":""},{"path":"index.html","id":"rules-for-building-the-book","chapter":"Introduction","heading":"Rules for building the book","text":"couple rules Makefile:","code":"# knit the book and then open it in the browser\n.PHONY: gitbook1 gitbook2\ngitbook1: build_book1 open_book\n\ngitbook2: build_book2 open_book\n\n# use rstudio pandoc\n# this rule sets the PANDOC environment variable from the shell\nbuild_book1:\n    export RSTUDIO_PANDOC=\"/usr/lib/rstudio/bin/pandoc\";\\\n    Rscript -e 'bookdown::render_book(\"index.Rmd\", \"bookdown::gitbook\")'\n\n# use rstudio pandoc\n# this rule sets the environment variable from R using multilines\nbuild_book2:\n    Rscript -e \"\\\n    Sys.setenv(RSTUDIO_PANDOC='/usr/lib/rstudio/bin/pandoc');\\\n    bookdown::render_book('index.Rmd', 'bookdown::gitbook')\""},{"path":"index.html","id":"clean-up-the-bookdown-project-folder","chapter":"Introduction","heading":"Clean up the bookdown project folder","text":"two rules occasionally tidy clean intermediate files bookdown project folder:","code":".PHONY: clean\nclean: tidy\n        find $(OUTPUT_DIR) -maxdepth 1 -name \\*.tex -not -name 'preamble.tex' -delete\n        $(RM) -rf $(BOOKDOWN_FILES_DIRS)\n        $(RM) -rf $(DEFAULT_PUBLISH_BOOK_DIRS)\n        if [ -d ${PUBLISH_BOOK_DIR} ]; then rm -rf ${PUBLISH_BOOK_DIR};fi\n        if [ -d ${CHECKPOINTS} ]; then rm -rf ${CHECKPOINTS};fi\n\n\n# delete unwanted files and folders in bookdown folder\n.PHONY: tidy\ntidy:\n        find $(OUTPUT_DIR) -maxdepth 1 -name \\*.md -not -name 'README.md' -delete\n        find $(OUTPUT_DIR) -maxdepth 1 -name \\*-book.html -delete\n        find $(OUTPUT_DIR) -maxdepth 1 -name \\*.png -delete\n        find $(OUTPUT_DIR) -maxdepth 1 -name \\*.log -delete\n        find $(OUTPUT_DIR) -maxdepth 1 -name \\*.rds -delete\n        find $(OUTPUT_DIR) -maxdepth 1 -name \\*.ckpt -delete\n        find $(OUTPUT_DIR) -maxdepth 1 -name \\*.nb.html -delete\n        find $(OUTPUT_DIR) -maxdepth 1 -name _main.Rmd -delete\n        find $(OUTPUT_DIR) -maxdepth 1 -name now.json -delete       "},{"path":"fundamentals.html","id":"fundamentals","chapter":"1 Fundamentals","heading":"1 Fundamentals","text":"","code":""},{"path":"fundamentals.html","id":"library-management","chapter":"1 Fundamentals","heading":"1.1 Library Management","text":"","code":""},{"path":"fundamentals.html","id":"built-in-libraries","chapter":"1 Fundamentals","heading":"1.1.1 Built-In Libraries","text":"","code":"import string\nimport datetime as dt"},{"path":"fundamentals.html","id":"common-external-libraries","chapter":"1 Fundamentals","heading":"1.1.2 Common External Libraries","text":"","code":"import numpy as np\nimport pandas as pd\nimport datetime as dt\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom plydata import define, query, select, group_by, summarize, arrange, head, rename\nimport plotnine\nfrom plotnine import *"},{"path":"fundamentals.html","id":"numpy","chapter":"1 Fundamentals","heading":"1.1.2.1 numpy","text":"Large multi-dimensional array matricesHigh level mathematical funcitons operate themEfficient array computation, modeled matlabSupport vectorized array math functions (built C, hence faster python loop list)","code":""},{"path":"fundamentals.html","id":"scipy","chapter":"1 Fundamentals","heading":"1.1.2.2 scipy","text":"Collection mathematical algorithms convenience functions built numpy extensionBuilt upon numpy","code":""},{"path":"fundamentals.html","id":"pandas","chapter":"1 Fundamentals","heading":"1.1.2.3 Pandas","text":"Data manipulation analysisOffer data structures operations manipulating numerical tables time seriesGood analyzing tabular dataUse exploratory data analysis, data pre-processing, statistics visualizationBuilt upon numpy","code":""},{"path":"fundamentals.html","id":"scikit-learn","chapter":"1 Fundamentals","heading":"1.1.2.4 scikit-learn","text":"Machine learning functionsBuilt top scipy","code":""},{"path":"fundamentals.html","id":"matplotlib","chapter":"1 Fundamentals","heading":"1.1.2.5 matplotlib","text":"Data Visualization","code":""},{"path":"fundamentals.html","id":"package-management","chapter":"1 Fundamentals","heading":"1.1.3 Package Management","text":"","code":""},{"path":"fundamentals.html","id":"conda","chapter":"1 Fundamentals","heading":"1.1.4 Conda","text":"","code":""},{"path":"fundamentals.html","id":"conda-environment","chapter":"1 Fundamentals","heading":"1.1.4.1 Conda Environment","text":"","code":"\nsystem(\"conda info\")"},{"path":"fundamentals.html","id":"package-version","chapter":"1 Fundamentals","heading":"1.1.4.2 Package Version","text":"","code":"\nsystem(\"conda list\") "},{"path":"fundamentals.html","id":"package-installation","chapter":"1 Fundamentals","heading":"1.1.4.3 Package Installation","text":"Conda recommended distribution.install official conda channel:install conda-forge community channel:","code":"conda install <package_name>  # always install latest\nconda install <package_name=version_number>\n\n## Example: Install From conda official channel\nconda install numpy\nconda install scipy\nconda install pandas\nconda install matpotlib\nconda install scikit-learn\nconda install seaborn\nconda install pipconda install -c conda-forge <package_name>\nconda install -c conda-forge <package_name=version_number>\n\n## Example: Install From conda community:\nconda install -c conda-forge plotnine"},{"path":"fundamentals.html","id":"pip","chapter":"1 Fundamentals","heading":"1.1.5 PIP","text":"PIP python open repository (part conda). Use pip package available conda.","code":""},{"path":"fundamentals.html","id":"package-version-1","chapter":"1 Fundamentals","heading":"1.1.5.1 Package Version","text":"","code":"\nsystem(\"pip list\")"},{"path":"fundamentals.html","id":"package-installation-1","chapter":"1 Fundamentals","heading":"1.1.5.2 Package Installation","text":"","code":"pip install <package_name>\n## Example: pip install plydata"},{"path":"fundamentals.html","id":"everything-is-object","chapter":"1 Fundamentals","heading":"1.2 Everything Is Object","text":"Every varibales python objectsEvery variable assginment reference based, , object value reference memory block dataIn exmaple, , b c  refer memory location:\n- Notice object assigned another object, refer memory location\n- two variable refers value, refer memory locationChanging data value (using assignment) changes reference","code":"a = 123\nb = 123  \nc = a\nprint ('Data of a =',  a,\n       '\\nData of b =',b,\n       '\\nData of c =',c,\n       '\\nID of a = ', id(a),\n       '\\nID of b = ', id(b),\n       '\\nID of c = ', id(c)\n)#:> Data of a = 123 \n#:> Data of b = 123 \n#:> Data of c = 123 \n#:> ID of a =  139904208751072 \n#:> ID of b =  139904208751072 \n#:> ID of c =  139904208751072a = 123\nb = a\na = 456  # reassignemnt changed a memory reference\n         # b memory reference not changed\nprint ('Data of a =',a,\n     '\\nData of b =',b,\n     '\\nID of a = ', id(a),\n     '\\nID of b = ', id(b)\n)#:> Data of a = 456 \n#:> Data of b = 123 \n#:> ID of a =  139903753613424 \n#:> ID of b =  139904208751072"},{"path":"fundamentals.html","id":"assignment","chapter":"1 Fundamentals","heading":"1.3 Assignment","text":"","code":""},{"path":"fundamentals.html","id":"multiple-assignment","chapter":"1 Fundamentals","heading":"1.3.1 Multiple Assignment","text":"Assign multiple variable time value. Note object created using method refer memory location.","code":"x = y = 'same mem loc'\nprint ('x = ', x,\n     '\\ny = ', y,\n     '\\nid(x) = ', id(x), \n     '\\nid(y) = ', id(y)\n)#:> x =  same mem loc \n#:> y =  same mem loc \n#:> id(x) =  139903753599600 \n#:> id(y) =  139903753599600"},{"path":"fundamentals.html","id":"augmented-assignment","chapter":"1 Fundamentals","heading":"1.3.2 Augmented Assignment","text":"","code":"x = 1\ny = x + 1\ny += 1\nprint ('y = ', y)#:> y =  3"},{"path":"fundamentals.html","id":"unpacking-assingment","chapter":"1 Fundamentals","heading":"1.3.3 Unpacking Assingment","text":"Assign multiple value multiple variabels time.","code":"x,y = 1,3\nprint (x,y)#:> 1 3"},{"path":"built-in-data-types.html","id":"built-in-data-types","chapter":"2 Built-in Data Types","heading":"2 Built-in Data Types","text":"","code":""},{"path":"built-in-data-types.html","id":"numbers","chapter":"2 Built-in Data Types","heading":"2.1 Numbers","text":"Two types built-number type, integer float.","code":""},{"path":"built-in-data-types.html","id":"integer","chapter":"2 Built-in Data Types","heading":"2.1.1 Integer","text":"","code":"n = 123\ntype (n)#:> <class 'int'>"},{"path":"built-in-data-types.html","id":"float","chapter":"2 Built-in Data Types","heading":"2.1.2 Float","text":"","code":"f = 123.4\ntype (f)#:> <class 'float'>"},{"path":"built-in-data-types.html","id":"number-operators","chapter":"2 Built-in Data Types","heading":"2.1.3 Number Operators","text":"general, operation potentially return float, result float type. Otherwise return integer.Division always return floatInteger Division integer return inter. Integer division float return float.Remainder integer return integer.\nRemainder float return floatPower return int float","code":"print(4/2)  # return float#:> 2.0type(4/2)#:> <class 'float'>print (8//3,'\\n',    # return int\n       8//3.2)       # return float#:> 2 \n#:>  2.0print (8%3, '\\n',    # return int\n       8%3.2)        # return float#:> 2 \n#:>  1.5999999999999996print (2**3)    # return int#:> 8print (2.1**3)  # return float#:> 9.261000000000001print (2**3.1)  # return float#:> 8.574187700290345"},{"path":"built-in-data-types.html","id":"string","chapter":"2 Built-in Data Types","heading":"2.2 String","text":"String object class ‘str.’ ordered collection letters, array object type str","code":"import string\ns = 'abcde'\nprint( '\\nvar type  = ', type(s),\n       '\\nelems     = ',s[0], s[1], s[2],\n       '\\nlen       = ', len(s),\n       '\\nelem type = ',type(s[1]))#:> \n#:> var type  =  <class 'str'> \n#:> elems     =  a b c \n#:> len       =  5 \n#:> elem type =  <class 'str'>"},{"path":"built-in-data-types.html","id":"constructor","chapter":"2 Built-in Data Types","heading":"2.2.1 Constructor","text":"","code":""},{"path":"built-in-data-types.html","id":"classical-method","chapter":"2 Built-in Data Types","heading":"2.2.1.1 Classical Method","text":"class str(object='')class str(object=b'', encoding='utf-8', errors='strict')","code":"my_string = str()        ## empty stringmy_string = str('abc')"},{"path":"built-in-data-types.html","id":"shortcut-method","chapter":"2 Built-in Data Types","heading":"2.2.1.2 Shortcut Method","text":"","code":"my_string = 'abc'"},{"path":"built-in-data-types.html","id":"multiline-method","chapter":"2 Built-in Data Types","heading":"2.2.1.3 Multiline Method","text":"Note variable contain \\n front end string.","code":"my_string = '''\nThis is me.\nYong Keh Soon\n'''\nprint(my_string)#:> \n#:> This is me.\n#:> Yong Keh Soonmy_string#:> '\\nThis is me.\\nYong Keh Soon\\n'"},{"path":"built-in-data-types.html","id":"immutability","chapter":"2 Built-in Data Types","heading":"2.2.1.4 Immutability","text":"String immuatable. Changing content result errorChanging variable completley change reference (new object)","code":"s = 'abcde'\nprint ('s : ', id(s))\n#s[1] = 'z'               # immutable, result in error#:> s :  139903753637552s = 'efgh'\nprint ('s : ', id(s))#:> s :  139903753596272"},{"path":"built-in-data-types.html","id":"class-constants","chapter":"2 Built-in Data Types","heading":"2.2.2 Class Constants","text":"","code":""},{"path":"built-in-data-types.html","id":"letters","chapter":"2 Built-in Data Types","heading":"2.2.2.1 Letters","text":"","code":"print( 'letters = ', string.ascii_letters,\n        '\\nlowercase = ',string.ascii_lowercase,\n        '\\nuppercase = ',string.ascii_uppercase )#:> letters =  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ \n#:> lowercase =  abcdefghijklmnopqrstuvwxyz \n#:> uppercase =  ABCDEFGHIJKLMNOPQRSTUVWXYZ"},{"path":"built-in-data-types.html","id":"digits","chapter":"2 Built-in Data Types","heading":"2.2.2.2 Digits","text":"","code":"string.digits#:> '0123456789'"},{"path":"built-in-data-types.html","id":"white-spaces","chapter":"2 Built-in Data Types","heading":"2.2.2.3 White Spaces","text":"","code":"string.whitespace#:> ' \\t\\n\\r\\x0b\\x0c'"},{"path":"built-in-data-types.html","id":"instance-methods","chapter":"2 Built-in Data Types","heading":"2.2.3 Instance Methods","text":"","code":""},{"path":"built-in-data-types.html","id":"substitution-format","chapter":"2 Built-in Data Types","heading":"2.2.3.1 Substitution : format()","text":"PositionalBy NameBy Dictionary NameFormatting NumberFloatInteger, PercentageAlignment","code":"print( '{} + {} = {}'.format('a', 'b', 'c'),         # auto sequence\n       '\\n{0} + {1} = {2}'.format('aa', 'bb', 'cc')) # manual sequence#:> a + b = c \n#:> aa + bb = cc'Coordinates: {latitude}, {longitude}'.format(latitude='37.24N', longitude='-115.81W') ## constant#:> 'Coordinates: 37.24N, -115.81W'coord = {'latitude': '37.24N', 'longitude': '-115.81W'} ## dictionary key/value\n'Coordinates: {latitude}, {longitude}'.format(**coord)#:> 'Coordinates: 37.24N, -115.81W''{:+f}; {:+f}'.format(3.14, -3.14)  # show it always#:> '+3.140000; -3.140000''{: f}; {: f}'.format(3.14, -3.14)  # show a space for positive numbers#:> ' 3.140000; -3.140000''Correct answers: {:.2f}'.format(55676.345345)#:> 'Correct answers: 55676.35''{0:,}   {0:.2%}   {0:,.2%}'.format(1234567890.4455)#:> '1,234,567,890.4455   123456789044.55%   123,456,789,044.55%''{0:<20}   {0:<<20}'.format('left aligned')#:> 'left aligned           left aligned<<<<<<<<''{0:>20}  {0:$>20}'.format('right aligned')#:> '       right aligned  $$$$$$$right aligned''{:^30}'.format('centered')  # use '*' as a fill char#:> '           centered           '"},{"path":"built-in-data-types.html","id":"substitution-f-string","chapter":"2 Built-in Data Types","heading":"2.2.3.2 Substitution : f-string","text":"","code":"my_name = 'Yong Keh Soon'\nsalary  = 11123.346\nf'Hello, {my_name}, your salary is {salary:,.2f} !'#:> 'Hello, Yong Keh Soon, your salary is 11,123.35 !'"},{"path":"built-in-data-types.html","id":"conversion-upper-lower","chapter":"2 Built-in Data Types","heading":"2.2.3.3 Conversion: upper() lower()","text":"","code":"'myEXEel.xls'.upper()#:> 'MYEXEEL.XLS''myEXEel.xls'.lower()#:> 'myexeel.xls'"},{"path":"built-in-data-types.html","id":"find-pattern-position","chapter":"2 Built-in Data Types","heading":"2.2.3.4 find() pattern position","text":"","code":"string.find() return position of first occurance. -1 if not founds='I love karaoke, I know you love it oo'\nprint (s.find('lov'))#:> 2print (s.find('kemuning'))#:> -1"},{"path":"built-in-data-types.html","id":"strip-off-blank-spaces","chapter":"2 Built-in Data Types","heading":"2.2.3.5 strip() off blank spaces","text":"","code":"filename = '  myexce l.   xls   '\nfilename.strip()#:> 'myexce l.   xls'"},{"path":"built-in-data-types.html","id":"list-related-split","chapter":"2 Built-in Data Types","heading":"2.2.3.6 List Related: split()","text":"Splitting delimeter specified. Observe empty spaces conserved result array","code":"animals = 'a1,a2 ,a3, a4'\nanimals.split(',')#:> ['a1', 'a2 ', 'a3', ' a4']"},{"path":"built-in-data-types.html","id":"list-related-join","chapter":"2 Built-in Data Types","heading":"2.2.3.7 List Related: join()","text":"","code":"'-'.join(['1', '2', '3', '4'])#:> '1-2-3-4'"},{"path":"built-in-data-types.html","id":"replacement-.replace","chapter":"2 Built-in Data Types","heading":"2.2.3.8 Replacement: .replace()","text":"","code":"string = \"geeks for geeks geeks geeks geeks\" \n   \n# Prints the string by replacing geeks by Geeks  \nprint(string.replace(\"geeks\", \"Geeks\"))  \n  \n# Prints the string by replacing only 3 occurrence of Geeks   #:> Geeks for Geeks Geeks Geeks Geeksprint(string.replace(\"geeks\", \"GeeksforGeeks\", 3)) #:> GeeksforGeeks for GeeksforGeeks GeeksforGeeks geeks geeks"},{"path":"built-in-data-types.html","id":"operator","chapter":"2 Built-in Data Types","heading":"2.2.4 Operator","text":"","code":""},{"path":"built-in-data-types.html","id":"old-style-substitution","chapter":"2 Built-in Data Types","heading":"2.2.4.1 % Old Style Substitution","text":"https://docs.python.org/3/library/stdtypes.html#old-string-formatting","code":"my_name = 'Yong Keh Soon'\nsalary  = 11123.346\n'Hello, %s, your salary is %.2f !' %(my_name, salary)#:> 'Hello, Yong Keh Soon, your salary is 11123.35 !'"},{"path":"built-in-data-types.html","id":"concatenation","chapter":"2 Built-in Data Types","heading":"2.2.4.2 + Concatenation","text":"","code":"'this is ' + 'awesome'#:> 'this is awesome'"},{"path":"built-in-data-types.html","id":"in-matching","chapter":"2 Built-in Data Types","heading":"2.2.4.3 in matching","text":"single string, partial matchFor list strings, exact match (even though one element list).\npartial match, workaround convert list single string","code":"print( 'abc' in '123abcdefg' )#:> Trueprint( 'abc' in ['abcdefg'],             # false\n       'abc' in ['abcdefg','123'],       # fakse\n       'abc' in ['123','abc','def'],     # true\n       'abc' in str(['123','abcdefg']))  # true#:> False False True True"},{"path":"built-in-data-types.html","id":"comparitor","chapter":"2 Built-in Data Types","heading":"2.2.4.4 Comparitor","text":"Comparitor compares memory address.","code":"a='abc'\nb='abc'\nprint('id(a) = ', id(a), \n      '\\nid(b) = ', id(b),\n      '\\na == b  ', a==b)#:> id(a) =  139904199793840 \n#:> id(b) =  139904199793840 \n#:> a == b   True"},{"path":"built-in-data-types.html","id":"iterations","chapter":"2 Built-in Data Types","heading":"2.2.5 Iterations","text":"step negative (reverse), end value must lower start value","code":"string[start:end:step]  # default start:0, end:last, step:1s = 'abcdefghijk'\nprint (s[0])       # first later#:> aprint (s[:3])      # first 3 letters#:> abcprint (s[2:8 :2])  # stepping#:> cegprint (s[-1])      # last letter#:> kprint (s[-3:])     # last three letters#:> ijkprint (s[:   :-1]) # reverse everything#:> kjihgfedcbaprint (s[8:2 :-1])#:> ihgfedprint (s[8:2])     # return NOTHING"},{"path":"built-in-data-types.html","id":"boolean","chapter":"2 Built-in Data Types","heading":"2.3 Boolean","text":"","code":"b = False\n\nif (b):\n    print ('It is true')\nelse:\n    print ('It is fake')#:> It is fake"},{"path":"built-in-data-types.html","id":"what-is-considered-false","chapter":"2 Built-in Data Types","heading":"2.3.1 What is Considered False ?","text":"Everything false, anything else true","code":"print ( bool(0),      # zero\n        bool(None),  # none\n        bool(''),    # empty string\n        bool([]),    # empty list\n        bool(()),    # empty tupple\n        bool(False), # False\n        bool(2-2))    # expression that return any value above#:> False False False False False False False"},{"path":"built-in-data-types.html","id":"and-operator","chapter":"2 Built-in Data Types","heading":"2.3.2 and operator","text":"BEWARE !can return different data typesIf evaluated result True, last True Value returned (python need evaluate last value)evaluated result False, first False Value returned (python return immediately detecting False value)","code":"print (123 and 2 and 1,\n       123 and [] and 2)#:> 1 []"},{"path":"built-in-data-types.html","id":"not-operator","chapter":"2 Built-in Data Types","heading":"2.3.3 not operator","text":"","code":"not (True)#:> Falsenot (True or False)#:> Falsenot (False)#:> Truenot (True and False)#:> True~(False)#:> -1"},{"path":"built-in-data-types.html","id":"or-operator","chapter":"2 Built-in Data Types","heading":"2.3.4 or operator","text":"can return different data typeIf evaluated result True, first True Value returned (right hand side value need evaluated)evaluated result False, last Fasle Value returned (need evalute items concluding False)","code":"print (1 or 2)#:> 1print (0 or 1 or 1)#:> 1print (0 or () or [])#:> []"},{"path":"built-in-data-types.html","id":"none","chapter":"2 Built-in Data Types","heading":"2.4 None","text":"","code":""},{"path":"built-in-data-types.html","id":"none-is-an-object","chapter":"2 Built-in Data Types","heading":"2.4.1 None is an Object","text":"None Python object NonTypeAny operation None object result errorFor array data None elements, verification required check iteration determine item None. computaionaly heavy","code":"type(None)#:> <class 'NoneType'>t1 = np.array([1, 2, 3, 4, 5])\nt2= np.array([1, 2, 3, None, 4, 5])\nprint( t1.dtype  , '\\n\\n',    # it's an object\n       t2.dtype)#:> int64 \n#:> \n#:>  object"},{"path":"built-in-data-types.html","id":"comparing-none","chapter":"2 Built-in Data Types","heading":"2.4.2 Comparing None","text":"Prefered MethodPrefered","code":"null_variable = None\nprint( null_variable == None )#:> Trueprint( null_variable is None )#:> Trueprint( null_variable is not None )#:> False"},{"path":"built-in-data-types.html","id":"operation-on-none","chapter":"2 Built-in Data Types","heading":"2.4.3 Operation on None","text":"operator (except ) None results error.","code":"None & None#:> Error in py_call_impl(callable, dots$args, dots$keywords): TypeError: unsupported operand type(s) for &: 'NoneType' and 'NoneType'\n#:> \n#:> Detailed traceback: \n#:>   File \"<string>\", line 1, in <module>"},{"path":"built-in-data-structure.html","id":"built-in-data-structure","chapter":"3 Built-In Data Structure","heading":"3 Built-In Data Structure","text":"","code":""},{"path":"built-in-data-structure.html","id":"tuple","chapter":"3 Built-In Data Structure","heading":"3.1 Tuple","text":"Tuple immutable list. attempt change/update tuple return error. can contain different types object.Benefits tuple List :\n- Faster list\n- Protects data accidental change\n- Can used key dictionaries, list can’t","code":""},{"path":"built-in-data-structure.html","id":"creating","chapter":"3 Built-In Data Structure","heading":"3.1.1 Creating","text":"","code":""},{"path":"built-in-data-structure.html","id":"constructor-1","chapter":"3 Built-In Data Structure","heading":"3.1.1.1 Constructor","text":"","code":"# mylist = [1,2,3]\n# print(tuple(mylist))"},{"path":"built-in-data-structure.html","id":"assignment-1","chapter":"3 Built-In Data Structure","heading":"3.1.1.2 Assignment","text":"Without () formal syntax defining tuple, items inside ( ) notation. Assignment although works without (), recommended.","code":"t1 = (1,2,3,'o','apple')\nt2 = 1,2,3,'o','apple'\n\nprint(type(t1), type(t2))#:> <class 'tuple'> <class 'tuple'>"},{"path":"built-in-data-structure.html","id":"accessing","chapter":"3 Built-In Data Structure","heading":"3.1.2 Accessing","text":"","code":"print( t[1], t[1:3] )"},{"path":"built-in-data-structure.html","id":"duplicating","chapter":"3 Built-In Data Structure","heading":"3.1.3 Duplicating","text":"Use normal assignment = duplicate. Reference memory address copied. Data actually duplicated memory.copy original memory location.","code":"original = (1,2,3,4,5)\ncopy_test = original\nprint(original)#:> (1, 2, 3, 4, 5)print(copy_test)#:> (1, 2, 3, 4, 5)print('Original ID: ', id(original))#:> Original ID:  139903753534832print('Copy ID:     ', id(copy_test))#:> Copy ID:      139903753534832"},{"path":"built-in-data-structure.html","id":"list","chapter":"3 Built-In Data Structure","heading":"3.2 List","text":"List collection ordered items, items can different data typesYou can pack list items placing []List mutable","code":""},{"path":"built-in-data-structure.html","id":"creating-list","chapter":"3 Built-In Data Structure","heading":"3.2.1 Creating List","text":"","code":""},{"path":"built-in-data-structure.html","id":"empty-list","chapter":"3 Built-In Data Structure","heading":"3.2.1.1 Empty List","text":"","code":"empty = []      # literal assignment method\nempty = list()  # constructor method\nprint (empty)#:> []"},{"path":"built-in-data-structure.html","id":"literal-assignment","chapter":"3 Built-In Data Structure","heading":"3.2.1.2 Literal Assignment","text":"Multiple data types allowed listConstructorNote list(string) split string letters","code":"[123,'abc',456, None]#:> [123, 'abc', 456, None]list('hello')#:> ['h', 'e', 'l', 'l', 'o']"},{"path":"built-in-data-structure.html","id":"accessing-items","chapter":"3 Built-In Data Structure","heading":"3.2.2 Accessing Items","text":"Access specific index numberAccess range indexes","code":"food = ['bread', 'noodle', 'rice', 'biscuit','jelly','cake']\nprint (food[2])  # 3rd item#:> riceprint (food[-1]) # last item#:> cakeprint (food[:4])     # first 3 items#:> ['bread', 'noodle', 'rice', 'biscuit']print (food[-3:])    # last 3 items#:> ['biscuit', 'jelly', 'cake']print (food[1:5])    # item 1 to 4#:> ['noodle', 'rice', 'biscuit', 'jelly']print (food[5:2:-1]) # item 3 to 5, reverse order#:> ['cake', 'jelly', 'biscuit']print (food[::-1])   # reverse order#:> ['cake', 'jelly', 'biscuit', 'rice', 'noodle', 'bread']"},{"path":"built-in-data-structure.html","id":"methods","chapter":"3 Built-In Data Structure","heading":"3.2.3 Methods","text":"","code":""},{"path":"built-in-data-structure.html","id":"remove-items","chapter":"3 Built-In Data Structure","heading":"3.2.3.1 Remove Item(s)","text":"Removal non-existance item result errorSearch remove first matching itemRemove last itemRemove item specific position","code":"food = list(['bread', 'noodle', 'rice', 'biscuit','jelly','cake','noodle'])\nfood.remove('noodle')\nprint (food)#:> ['bread', 'rice', 'biscuit', 'jelly', 'cake', 'noodle']food.pop()#:> 'noodle'print (food)#:> ['bread', 'rice', 'biscuit', 'jelly', 'cake']food.pop(1)  # counter start from 0#:> 'rice'print(food)#:> ['bread', 'biscuit', 'jelly', 'cake']food.remove('jelly')\nprint(food)#:> ['bread', 'biscuit', 'cake']"},{"path":"built-in-data-structure.html","id":"appending-item-s","chapter":"3 Built-In Data Structure","heading":"3.2.3.2 Appending Item (s)","text":"Append One ItemAppend Multiple Items extend() expand list/tupple argument append multiple items","code":"food.append('jelly')\nprint (food)#:> ['bread', 'biscuit', 'cake', 'jelly']food.extend(['nand','puff'])\nprint (food)#:> ['bread', 'biscuit', 'cake', 'jelly', 'nand', 'puff']"},{"path":"built-in-data-structure.html","id":"other-methods","chapter":"3 Built-In Data Structure","heading":"3.2.3.3 Other Methods","text":"Reversing order itemsLocating Index Number ItemCount occuranceSorting Order Items","code":"food.reverse()\nfood#:> ['puff', 'nand', 'jelly', 'cake', 'biscuit', 'bread']food.index('biscuit')#:> 4test = ['a','a','a','b','c']\ntest.count('a')#:> 3food.sort()\nprint (food)#:> ['biscuit', 'bread', 'cake', 'jelly', 'nand', 'puff']"},{"path":"built-in-data-structure.html","id":"operator-1","chapter":"3 Built-In Data Structure","heading":"3.2.4 Operator","text":"","code":""},{"path":"built-in-data-structure.html","id":"concatenation-1","chapter":"3 Built-In Data Structure","heading":"3.2.4.1 Concatenation","text":"Concatenating ListsTwo lists can concatenanted using ‘+’ operator.","code":"['dog','cat','horse'] + ['elephant','tiger'] + ['sheep']#:> ['dog', 'cat', 'horse', 'elephant', 'tiger', 'sheep']"},{"path":"built-in-data-structure.html","id":"list-is-mutable","chapter":"3 Built-In Data Structure","heading":"3.2.5 List is Mutable","text":"reference list variable won’t change adding/removing itemA function actually object, reference never change, hence mutable","code":"food = ['cake','jelly','roti','noodle']\nprint ('food : ',id(food))#:> food :  139903753597728food += ['salad','chicken']\nprint ('food : ',id(food))#:> food :  139903753597728def spam (elem, some_list=['a','b']):\n    some_list.append(elem)\n    return some_list\n\nprint (spam(1,['x']))#:> ['x', 1]print (spam(2)) ## second parameter is not passed#:> ['a', 'b', 2]print (spam(3)) ##  notice the default was remembered#:> ['a', 'b', 2, 3]"},{"path":"built-in-data-structure.html","id":"duplicate-or-reference","chapter":"3 Built-In Data Structure","heading":"3.2.6 Duplicate or Reference","text":"Use = : just copy refernce. IDs similarDuplicate List Object copy(). Resulting IDs differentPassing Function Reference","code":"original = [1,2,3,4,5]\ncopy_test = original\nprint('Original ID: ', id(original))#:> Original ID:  139903753598368print('Copy ID:     ', id(copy_test))                          #:> Copy ID:      139903753598368original[0]=999   ## change original\nprint(original)#:> [999, 2, 3, 4, 5]print(copy_test)  ## copy affected#:> [999, 2, 3, 4, 5]original = [1,2,3,4,5]\ncopy_test = original.copy()\nprint(original)#:> [1, 2, 3, 4, 5]print(copy_test)#:> [1, 2, 3, 4, 5]print('Original ID: ', id(original))#:> Original ID:  139903753608240print('Copy ID:     ', id(copy_test))#:> Copy ID:      139903914202208original[0] = 999  ## change original\nprint(original)    #:> [999, 2, 3, 4, 5]print(copy_test)   ## copy not affected#:> [1, 2, 3, 4, 5]def func(x):\n    print (x)\n    print('ID in Function:      ', id(x))\n    x.append(6)    ## modify the refrence\n    \nmy_list = [1,2,3,4,5]\nprint('ID outside Function: ', id(my_list))#:> ID outside Function:  139903914209360func(my_list)  ## call the function, pass the reference#:> [1, 2, 3, 4, 5]\n#:> ID in Function:       139903914209360print(my_list) ## content was altered#:> [1, 2, 3, 4, 5, 6]"},{"path":"built-in-data-structure.html","id":"list-is-iterable","chapter":"3 Built-In Data Structure","heading":"3.2.7 List Is Iterable","text":"","code":""},{"path":"built-in-data-structure.html","id":"for-loop","chapter":"3 Built-In Data Structure","heading":"3.2.7.1 For Loop","text":"","code":"s = ['abc','abcd','bcde','bcdee','cdefg']\nfor x in s:\n    if 'abc' in x:\n        print (x)#:> abc\n#:> abcd"},{"path":"built-in-data-structure.html","id":"list-comprehension","chapter":"3 Built-In Data Structure","heading":"3.2.7.2 List Comprehension","text":"code shorform method loop .Compare traditional version code :","code":"old_list = ['abc','abcd','bcde','bcdee','cdefg']\n[x for x in old_list if 'abc' in x]#:> ['abc', 'abcd']new_list = []\nold_list = ['abc','abcd','bcde','bcdee','cdefg']\nfor x in old_list:\n    if 'abc' in x:\n        new_list.append(x)\n        \nprint( new_list )#:> ['abc', 'abcd']"},{"path":"built-in-data-structure.html","id":"conversion","chapter":"3 Built-In Data Structure","heading":"3.2.8 Conversion","text":"Convert mutable list immutable tuple tuple()","code":"original = [1,2,3]\noriginal_tuple = tuple(original)\nprint( id(original),\n       id(original_tuple))#:> 139903753700928 139903753630976"},{"path":"built-in-data-structure.html","id":"built-in-functions-applicable-to-list","chapter":"3 Built-In Data Structure","heading":"3.2.9 Built-In Functions Applicable To List","text":"Number ElementsMax Value","code":"len(food)#:> 6test = [1,2,3,5,5,3,2,1]\nm = max(test)\ntest.index(m)  ## only first occurance is found#:> 3"},{"path":"built-in-data-structure.html","id":"dictionaries","chapter":"3 Built-In Data Structure","heading":"3.3 Dictionaries","text":"Dictionary list index-value items.","code":""},{"path":"built-in-data-structure.html","id":"creating-dict","chapter":"3 Built-In Data Structure","heading":"3.3.1 Creating dict","text":"","code":""},{"path":"built-in-data-structure.html","id":"from-literals","chapter":"3 Built-In Data Structure","heading":"3.3.1.1 From Literals","text":"Simple DictionaryDictionary list","code":"animal_counts = { 'cats' : 2, 'dogs' : 5, 'horses':4}\nprint (animal_counts)#:> {'cats': 2, 'dogs': 5, 'horses': 4}print( type(animal_counts) )#:> <class 'dict'>animal_names = {'cats':   ['Walter','Ra'],\n                'dogs':   ['Jim','Roy','John','Lucky','Row'],\n                'horses': ['Sax','Jack','Ann','Jeep']\n               }\nanimal_names#:> {'cats': ['Walter', 'Ra'], 'dogs': ['Jim', 'Roy', 'John', 'Lucky', 'Row'], 'horses': ['Sax', 'Jack', 'Ann', 'Jeep']}"},{"path":"built-in-data-structure.html","id":"from-variables","chapter":"3 Built-In Data Structure","heading":"3.3.1.2 From Variables","text":"","code":"cat_names = ['Walter','Ra','Jim']\ndog_names = ['Jim','Roy','John','Lucky','Row']\nhorse_names= ['Sax','Jack','Ann','Jeep']\nanimal_names = {'cats': cat_names, 'dogs': dog_names, 'horses': horse_names}\nanimal_names#:> {'cats': ['Walter', 'Ra', 'Jim'], 'dogs': ['Jim', 'Roy', 'John', 'Lucky', 'Row'], 'horses': ['Sax', 'Jack', 'Ann', 'Jeep']}"},{"path":"built-in-data-structure.html","id":"accessing-dict","chapter":"3 Built-In Data Structure","heading":"3.3.2 Accessing dict","text":"","code":""},{"path":"built-in-data-structure.html","id":"get-all-keys","chapter":"3 Built-In Data Structure","heading":"3.3.2.1 Get All Keys","text":"","code":"print (animal_names.keys())#:> dict_keys(['cats', 'dogs', 'horses'])print (sorted(animal_names.keys()))#:> ['cats', 'dogs', 'horses']"},{"path":"built-in-data-structure.html","id":"get-all-values","chapter":"3 Built-In Data Structure","heading":"3.3.2.2 Get All Values","text":"","code":"print (animal_names.values())#:> dict_values([['Walter', 'Ra', 'Jim'], ['Jim', 'Roy', 'John', 'Lucky', 'Row'], ['Sax', 'Jack', 'Ann', 'Jeep']])print (sorted(animal_names.values()))#:> [['Jim', 'Roy', 'John', 'Lucky', 'Row'], ['Sax', 'Jack', 'Ann', 'Jeep'], ['Walter', 'Ra', 'Jim']]"},{"path":"built-in-data-structure.html","id":"access-value-with-specific-key","chapter":"3 Built-In Data Structure","heading":"3.3.2.3 Access value with Specific Key","text":"Use [ key ] notation. However, return Error key existUse get( key ) notation. return None key exist","code":"animal_names['dogs']#:> ['Jim', 'Roy', 'John', 'Lucky', 'Row']print (animal_counts.get('cow'))#:> None"},{"path":"built-in-data-structure.html","id":"dict-is-mutable","chapter":"3 Built-In Data Structure","heading":"3.3.3 Dict Is Mutable","text":"","code":""},{"path":"built-in-data-structure.html","id":"updateappend","chapter":"3 Built-In Data Structure","heading":"3.3.3.1 Update/Append","text":"Use [key] notation update o append content element.Use clear() erase elements","code":"animal_names['dogs'] = ['Ali','Abu','Bakar']\nanimal_names#:> {'cats': ['Walter', 'Ra', 'Jim'], 'dogs': ['Ali', 'Abu', 'Bakar'], 'horses': ['Sax', 'Jack', 'Ann', 'Jeep']}animal_names.clear()"},{"path":"built-in-data-structure.html","id":"iterating-elements","chapter":"3 Built-In Data Structure","heading":"3.3.4 Iterating Elements","text":"Loop .items()","code":"animal_dict = { 'cats' : 2, 'dogs' : 5, 'horses':4}\n\nfor key,val in animal_dict.items():\n  print( key, val )#:> cats 2\n#:> dogs 5\n#:> horses 4"},{"path":"built-in-data-structure.html","id":"sets","chapter":"3 Built-In Data Structure","heading":"3.4 Sets","text":"Set unordered collection unique items. Set mutable","code":""},{"path":"built-in-data-structure.html","id":"creation","chapter":"3 Built-In Data Structure","heading":"3.4.1 Creation","text":"Set can declared {}, unlike list creation uses ‘[].’Set can created list, converted back list","code":"myset = {'a','b','c','d','a','b','e','f','g'}\nprint (myset) # notice no repetition values#:> {'c', 'e', 'b', 'f', 'g', 'd', 'a'}mylist = ['a','b','c','d','a','b','e','f','g']\nmyset = set(mylist)\nmy_unique_list = list(myset)\nprint (\n  'Original List       : ', mylist,\n  '\\nConvert to set      : ', myset,\n  '\\nConvert back to list: ', my_unique_list) # notice no repetition values#:> Original List       :  ['a', 'b', 'c', 'd', 'a', 'b', 'e', 'f', 'g'] \n#:> Convert to set      :  {'c', 'e', 'b', 'f', 'g', 'd', 'a'} \n#:> Convert back to list:  ['c', 'e', 'b', 'f', 'g', 'd', 'a']"},{"path":"built-in-data-structure.html","id":"membership-test","chapter":"3 Built-In Data Structure","heading":"3.4.2 Membership Test","text":"","code":"print ('a' in myset)      # is member ?#:> Trueprint ('f' not in myset)  # is not member ?#:> False"},{"path":"built-in-data-structure.html","id":"subset-test","chapter":"3 Built-In Data Structure","heading":"3.4.3 Subset Test","text":"Subset Test : <=\nProper Subset Test : <Proper Subset test master set contain least one element subset","code":"mysubset = {'d','g'}\nmysubset <= myset#:> Truemysubset = {'b','a','d','c','e','f','g'}\nprint ('Is Subset : ', mysubset <= myset)#:> Is Subset :  Trueprint ('Is Proper Subet : ', mysubset < myset)#:> Is Proper Subet :  False"},{"path":"built-in-data-structure.html","id":"union-using","chapter":"3 Built-In Data Structure","heading":"3.4.4 Union using |","text":"","code":"{'a','b','c'} | {'a','e','f'}#:> {'c', 'e', 'b', 'f', 'a'}"},{"path":"built-in-data-structure.html","id":"intersection-using","chapter":"3 Built-In Data Structure","heading":"3.4.5 Intersection using &","text":"elments exist left right set","code":"{'a','b','c','d'} & {'c','d','e','f'}#:> {'d', 'c'}"},{"path":"built-in-data-structure.html","id":"difference-using--","chapter":"3 Built-In Data Structure","heading":"3.4.6 Difference using -","text":"Remove right left","code":"{'a','b','c','d'} - {'c','d','e','f'}#:> {'b', 'a'}"},{"path":"built-in-data-structure.html","id":"range","chapter":"3 Built-In Data Structure","heading":"3.5 range","text":"range(X) generates sequence integer objectUse list() convert order view actual sequence dataMore Examples","code":"range (lower_bound, upper_bound, step_size)  \n# lower bound is optional, default = 0\n# upper bound is not included in result\n# step is optional, default = 1r = range(10)     # default lower bound =0, step =1\nprint (type (r))#:> <class 'range'>print (r)#:> range(0, 10)print (list(r))#:> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]print (list(range(2,8)))    # step not specified, default 1#:> [2, 3, 4, 5, 6, 7]print ('Odds Number : ' , list(range(1,10,2))) # generate odds number#:> Odds Number :  [1, 3, 5, 7, 9]"},{"path":"control-and-loops.html","id":"control-and-loops","chapter":"4 Control and Loops","heading":"4 Control and Loops","text":"","code":""},{"path":"control-and-loops.html","id":"if-statement","chapter":"4 Control and Loops","heading":"4.1 If Statement","text":"","code":""},{"path":"control-and-loops.html","id":"multiline-if..-statements","chapter":"4 Control and Loops","heading":"4.1.1 Multiline If.. Statements","text":"","code":"price = 102\nif price <100:\n    print ('buy')\nelif price < 110:\n    print ('hold')\nelif price < 120:\n    print ('think about it')\nelse:\n    print ('sell')#:> holdprint('end of programming')#:> end of programming"},{"path":"control-and-loops.html","id":"single-line-if-..-statement","chapter":"4 Control and Loops","heading":"4.1.2 Single Line If .. Statement","text":"","code":""},{"path":"control-and-loops.html","id":"if-in-one-statement","chapter":"4 Control and Loops","heading":"4.1.2.1 if … In One Statement","text":"","code":"price = 70\nif price<80: print('buy')#:> buy"},{"path":"control-and-loops.html","id":"ternary-statemnt","chapter":"4 Control and Loops","heading":"4.1.2.2 Ternary Statemnt","text":"statement return value simple condition","code":"price = 85\n'buy' if (price<80) else 'dont buy'#:> 'dont buy'"},{"path":"control-and-loops.html","id":"for-loops","chapter":"4 Control and Loops","heading":"4.2 For Loops","text":"","code":""},{"path":"control-and-loops.html","id":"for-..-else-construct","chapter":"4 Control and Loops","heading":"4.2.1 For .. Else Construct","text":"else executed loop completed cyclesIn exmaple, loop encountered break, hence else section executed.","code":"\nmylist = [1,2,3,4,5]\n\nfor i in mylist:\n  print (i)\nelse:\n  print('Hooray, the loop is completed successfully')#:> 1\n#:> 2\n#:> 3\n#:> 4\n#:> 5\n#:> Hooray, the loop is completed successfullyfor i in mylist:\n  if i < 4:\n    print (i)\n  else:\n    print('Oops, I am breaking out half way in the loop')\n    break\nelse:\n  print('Hooray, the loop is completed successfully')#:> 1\n#:> 2\n#:> 3\n#:> Oops, I am breaking out half way in the loop"},{"path":"control-and-loops.html","id":"loop-thorugh-range","chapter":"4 Control and Loops","heading":"4.2.2 Loop thorugh ‘range’","text":"","code":"for i in range (1,10,2):\n    print ('Odds Number : ',i) #:> Odds Number :  1\n#:> Odds Number :  3\n#:> Odds Number :  5\n#:> Odds Number :  7\n#:> Odds Number :  9"},{"path":"control-and-loops.html","id":"loop-through-list","chapter":"4 Control and Loops","heading":"4.2.3 Loop through ‘list’","text":"","code":""},{"path":"control-and-loops.html","id":"standard-for-loop","chapter":"4 Control and Loops","heading":"4.2.3.1 Standard For Loop","text":"","code":"letters = ['a','b','c','d']\nfor e in letters:\n    print ('Letter : ',e)#:> Letter :  a\n#:> Letter :  b\n#:> Letter :  c\n#:> Letter :  d"},{"path":"control-and-loops.html","id":"list-comprehension-1","chapter":"4 Control and Loops","heading":"4.2.3.2 List Comprehension","text":"Iterate existing list, build new list based conditionnew_list = [expression() old_list]Extend list comprehension can extended condition**new_list = [expression() old_list filter()]","code":"s = ['abc','abcd','bcde','bcdee','cdefg']\n[x.upper() for x in s]#:> ['ABC', 'ABCD', 'BCDE', 'BCDEE', 'CDEFG']old_list    = ['abc','abcd','bcde','bcdee','cdefg']\nmatching = [ x.upper() for x in old_list if 'bcd' in x ]\nprint( matching )#:> ['ABCD', 'BCDE', 'BCDEE']"},{"path":"control-and-loops.html","id":"loop-through-dictionary","chapter":"4 Control and Loops","heading":"4.2.4 Loop Through ‘Dictionary’","text":"Looping dict picup key","code":"d = {\"x\": 1, \"y\": 2}\nfor key in d:\n    print (key, d[key])#:> x 1\n#:> y 2"},{"path":"control-and-loops.html","id":"generators","chapter":"4 Control and Loops","heading":"4.3 Generators","text":"Generator lazy, produce items asked , hence memory efficientGenerator function ‘yield’ instead ‘return’Generator contains one yields statementWhen called, returns object (iterator) start execution immediatelyMethods like iter() next() implemented automatically. can iterate items using next()function yields, function paused control transferred callerLocal variables states remembered successive callsFinally, function terminates, StopIteration raised automatically calls","code":""},{"path":"control-and-loops.html","id":"basic-generator-function","chapter":"4 Control and Loops","heading":"4.3.1 Basic Generator Function","text":"example give clear understanding generator works","code":"def my_gen():\n    n = 1\n    print('This is printed first')\n    # Generator function contains yield statements\n    yield n\n\n    n += 1\n    print('This is printed second')\n    yield n\n\n    n += 1\n    print('This is printed at last')\n    yield na = my_gen()\ntype(a)#:> <class 'generator'>next(a)#:> This is printed first\n#:> 1next(a)#:> This is printed second\n#:> 2"},{"path":"control-and-loops.html","id":"useful-generator-fuction","chapter":"4 Control and Loops","heading":"4.3.2 Useful Generator Fuction","text":"Generator useful uses -loop\n- -loop within generator\n- -loop iterate generator","code":"def rev_str(my_str):\n    length = len(my_str)\n    for i in range(length - 1,-1,-1):\n        yield my_str[i]for c in rev_str(\"hello\"):\n     print(c)#:> o\n#:> l\n#:> l\n#:> e\n#:> h"},{"path":"control-and-loops.html","id":"generator-expression","chapter":"4 Control and Loops","heading":"4.3.3 Generator Expression","text":"Use () create annonymous generator function","code":"my_list = [1, 3, 6, 10]\na = (x**2 for x in my_list)next(a)#:> 1next(a)#:> 9sum(a) # sum the power of 6,10#:> 136"},{"path":"control-and-loops.html","id":"compare-to-iterator-class","chapter":"4 Control and Loops","heading":"4.3.4 Compare to Iterator Class","text":"Obviously, Generator concise cleaner","code":"class PowTwo:\n    def __init__(self, max = 0):\n        self.max = max\n\n    def __iter__(self):\n        self.n = 0\n        return self\n\n    def __next__(self):\n        if self.n > self.max:\n            raise StopIteration\n\n        result = 2 ** self.n\n        self.n += 1\n        return resultdef PowTwoGen(max = 0):\n    n = 0\n    while n < max:\n        yield 2 ** n\n        n += 1"},{"path":"library-and-functions.html","id":"library-and-functions","chapter":"5 Library and Functions","heading":"5 Library and Functions","text":"Library group functions","code":""},{"path":"library-and-functions.html","id":"package-source","chapter":"5 Library and Functions","heading":"5.1 Package Source","text":"","code":""},{"path":"library-and-functions.html","id":"conda-1","chapter":"5 Library and Functions","heading":"5.1.1 Conda","text":"Package manager languageInstall binaries","code":""},{"path":"library-and-functions.html","id":"pip-1","chapter":"5 Library and Functions","heading":"5.1.2 PIP","text":"Package manager python onlyCompile sourceStands Pip Installs PackagesPython’s officially-sanctioned package manager, commonly used install packages published Python Package Index (PyPI)pip PyPI governed supported Python Packaging Authority (PyPA).","code":""},{"path":"library-and-functions.html","id":"importing-library","chapter":"5 Library and Functions","heading":"5.2 Importing Library","text":"two methods import library functions:Standalone NamespaceGlobal Namespace","code":"- import <libName>                        # access function through: libName.functionName\n- import <libName> as <shortName>         # access function through: shortName.functionName- from   <libName> import *               # all functions available at global namespace\n- from   <libName> import <functionName>  # access function through: functionName    \n- from   <libName> import <functionName> as <shortFunctionName>  # access function through shortFunctionName"},{"path":"library-and-functions.html","id":"import-entire-library","chapter":"5 Library and Functions","heading":"5.2.1 Import Entire Library","text":"","code":""},{"path":"library-and-functions.html","id":"import-into-standalone-namespace","chapter":"5 Library and Functions","heading":"5.2.1.1 Import Into Standalone Namespace","text":"Use aliasing library name. useful conflicting library name","code":"import math\nmath.sqrt(9)#:> 3.0import math as m\nm.sqrt(9)#:> 3.0"},{"path":"library-and-functions.html","id":"import-into-global-name-space","chapter":"5 Library and Functions","heading":"5.2.1.2 Import Into Global Name Space","text":"functions library accessible global namespace","code":"from <libName> import *"},{"path":"library-and-functions.html","id":"import-specific-function","chapter":"5 Library and Functions","heading":"5.2.2 Import Specific Function","text":"Use aliasing function name","code":"from math import sqrt\nprint (sqrt(9))#:> 3.0from math import sqrt as sq\nprint (sq(9))#:> 3.0"},{"path":"library-and-functions.html","id":"machine-learning-packages","chapter":"5 Library and Functions","heading":"5.2.3 Machine Learning Packages","text":"alt text","code":""},{"path":"library-and-functions.html","id":"define-function","chapter":"5 Library and Functions","heading":"5.3 Define Function","text":"","code":""},{"path":"library-and-functions.html","id":"function-arguments","chapter":"5 Library and Functions","heading":"5.3.1 Function Arguments","text":"default, arguments assigned function left rightHowever, can also specify argument assigment function callFunction can default argement value","code":"def myfun(x,y):\n    print ('x:',x)\n    print ('y:',y)\n    \nmyfun(5,8)#:> x: 5\n#:> y: 8myfun (y=8,x=5)#:> x: 5\n#:> y: 8def myfun(x=1,y=1):  # default argument value is 1\n    print ('x:',x)\n    print ('y:',y)\n    \nmyfun(5)  # pass only one argument#:> x: 5\n#:> y: 1"},{"path":"library-and-functions.html","id":"list-within-function","chapter":"5 Library and Functions","heading":"5.3.2 List Within Function","text":"Consider function object, variable (some_list) immutable hence reference won’t change, even data changes","code":"def spam (elem, some_list=[]):\n    some_list.append(elem)\n    return some_list\n\nprint (spam(1))#:> [1]print (spam(2))#:> [1, 2]print (spam(3))#:> [1, 2, 3]"},{"path":"library-and-functions.html","id":"return-statement","chapter":"5 Library and Functions","heading":"5.3.3 Return Statement","text":"","code":"def bigger(x,y):\n    if (x>y):\n        return x\n    else:\n        return y\n    \nprint (bigger(5,8))#:> 8"},{"path":"library-and-functions.html","id":"no-return-statement","chapter":"5 Library and Functions","heading":"5.3.4 No Return Statement","text":"return statement, python return None","code":"def dummy():\n    print ('This is a dummy function, return no value')\n\ndummy()#:> This is a dummy function, return no value"},{"path":"library-and-functions.html","id":"return-multiple-value","chapter":"5 Library and Functions","heading":"5.3.5 Return Multiple Value","text":"Multiple value returned tuple. Use multiple assignment assign multiple variable","code":"def minmax(x,y,z):\n    return min(x,y,z), max(x,y,z)\n\na,b = minmax(7,8,9)     # multiple assignment\nc   = minmax(7,8,9)     # tuple\n\nprint (a,b)#:> 7 9print (c)    #:> (7, 9)"},{"path":"library-and-functions.html","id":"passing-function-as-argument","chapter":"5 Library and Functions","heading":"5.3.6 Passing Function as Argument","text":"can pass function name argument function","code":"def myfun(x,y,f):\n    f(x,y)\n\nmyfun('hello',54,print)#:> hello 54"},{"path":"library-and-functions.html","id":"arguments","chapter":"5 Library and Functions","heading":"5.3.7 Arguments","text":"args tuple","code":""},{"path":"library-and-functions.html","id":"example-1","chapter":"5 Library and Functions","heading":"5.3.7.1 Example 1","text":"Error example, many parameters passed function","code":""},{"path":"library-and-functions.html","id":"example-2","chapter":"5 Library and Functions","heading":"5.3.7.2 Example 2","text":"First argument goes x, remaining goes args tuple","code":"def myfun(x,*args):\n    print (x)\n    print (args)     #tuple\n    \nmyfun(1,2,3,4,5,'abc')#:> 1\n#:> (2, 3, 4, 5, 'abc')"},{"path":"library-and-functions.html","id":"example-3","chapter":"5 Library and Functions","heading":"5.3.7.3 Example 3","text":"First argument goes x, second argument goest y, remaining goes args","code":"def myfun(x,y,*args):\n    print (x)\n    print (y)\n    print (args)     #tuple\n    \nmyfun(1,2,3)#:> 1\n#:> 2\n#:> (3,)"},{"path":"library-and-functions.html","id":"example-4","chapter":"5 Library and Functions","heading":"5.3.7.4 Example 4","text":"","code":"def myfun(x,*args, y=9):\n    print (x)\n    print (y)\n    print (args)     #tuple\n    \nmyfun(1,2,3,4,5)#:> 1\n#:> 9\n#:> (2, 3, 4, 5)"},{"path":"library-and-functions.html","id":"example-5","chapter":"5 Library and Functions","heading":"5.3.7.5 Example 5","text":"goes args","code":"def myfun(*args):\n    print (args)     #tuple\n    \nmyfun(1,2,3,4,5)#:> (1, 2, 3, 4, 5)"},{"path":"library-and-functions.html","id":"example-6-empty-args","chapter":"5 Library and Functions","heading":"5.3.7.6 Example 6 Empty args","text":"","code":"def myfun(x,y,*args):\n    print (x)\n    print (y)\n    print (args)\n    \nmyfun(1,2)#:> 1\n#:> 2\n#:> ()"},{"path":"library-and-functions.html","id":"keyword-arguments","chapter":"5 Library and Functions","heading":"5.3.8 keyword arguments","text":"kwargs dictionary","code":""},{"path":"library-and-functions.html","id":"example-1-1","chapter":"5 Library and Functions","heading":"5.3.8.1 Example 1","text":"","code":"def foo(**kwargs):\n    print(kwargs)\n    \nfoo(a=1,b=2,c=3)#:> {'a': 1, 'b': 2, 'c': 3}"},{"path":"library-and-functions.html","id":"example-2-1","chapter":"5 Library and Functions","heading":"5.3.8.2 Example 2","text":"","code":"def foo(x,**kwargs):\n    print(x)\n    print(kwargs)\n    \nfoo(9,a=1,b=2,c=3)#:> 9\n#:> {'a': 1, 'b': 2, 'c': 3}foo(9) #empty dictionary#:> 9\n#:> {}"},{"path":"library-and-functions.html","id":"example-3-1","chapter":"5 Library and Functions","heading":"5.3.8.3 Example 3","text":"","code":"def foo(a,b,c,d=1):\n    print(a)\n    print(b)\n    print(c)\n    print(d)\n    \nfoo(**{\"a\":2,\"b\":3,\"c\":4})#:> 2\n#:> 3\n#:> 4\n#:> 1"},{"path":"library-and-functions.html","id":"mixing-args-kwargs","chapter":"5 Library and Functions","heading":"5.3.9 Mixing *args, **kwargs","text":"Always put args kwargs","code":""},{"path":"library-and-functions.html","id":"example-1-2","chapter":"5 Library and Functions","heading":"5.3.9.1 Example 1","text":"","code":"def foo(x,y=1,**kwargs):\n    print (x)\n    print (y)\n    print (kwargs)\n    \nfoo(1,2,c=3,d=4)#:> 1\n#:> 2\n#:> {'c': 3, 'd': 4}"},{"path":"library-and-functions.html","id":"example-2-2","chapter":"5 Library and Functions","heading":"5.3.9.2 Example 2","text":"","code":"def foo(x,y=2,*args,**kwargs):\n    print (x)\n    print (y)\n    print (args)\n    print (kwargs)\n    \nfoo(1,2,3,4,5,c=6,d=7)#:> 1\n#:> 2\n#:> (3, 4, 5)\n#:> {'c': 6, 'd': 7}"},{"path":"exception-handling.html","id":"exception-handling","chapter":"6 Exception Handling","heading":"6 Exception Handling","text":"try statement works follows:\n- First, try clause (statement(s) try except keywords) executed\n- exception occurs, except clause skipped execution try statement finished\n- exception occurs execution try clause, rest clause skipped. type matches exception named except keyword, except clause executed, execution continues try statement\n- exception occurs match exception named except clause, passed outer try statements; handler found, unhandled exception execution stops message shown aboveA try statement may one except clause, specify handlers different exceptions.","code":""},{"path":"exception-handling.html","id":"catching-error","chapter":"6 Exception Handling","heading":"6.1 Catching Error","text":"Different exception object different attributes.","code":"try:\n  a = 1 + 'a'\n  \n## known error  \nexcept TypeError as err:\n  print('I know this error !!!!',\n        '\\n Error: ', err,\n        '\\n Args:  ', err.args,\n        '\\n Type:  ', type(err))\n\n## all other error\nexcept Exception as err:\n  print( 'Error: ', err,\n         '\\nArgs:  ', err.args,\n         '\\nType:  ', type(err))#:> I know this error !!!! \n#:>  Error:  unsupported operand type(s) for +: 'int' and 'str' \n#:>  Args:   (\"unsupported operand type(s) for +: 'int' and 'str'\",) \n#:>  Type:   <class 'TypeError'>"},{"path":"exception-handling.html","id":"custom-exception","chapter":"6 Exception Handling","heading":"6.2 Custom Exception","text":"","code":"try:\n  raise Exception('bloody', 'hell')  #simulate exception\nexcept Exception as err:\n  print( 'Error: ', err,\n         '\\nArgs:  ', err.args,\n         '\\nType:  ', type(err))#:> Error:  ('bloody', 'hell') \n#:> Args:   ('bloody', 'hell') \n#:> Type:   <class 'Exception'>"},{"path":"object-oriented-programming.html","id":"object-oriented-programming","chapter":"7 Object Oriented Programming","heading":"7 Object Oriented Programming","text":"","code":""},{"path":"object-oriented-programming.html","id":"defining-class","chapter":"7 Object Oriented Programming","heading":"7.1 Defining Class","text":"Every function within class must least one parameter - selfUse init constructor function. init optional","code":"class Person:\n  wallet = 0  # \n  def __init__(self, myname,money=0):   # constructor\n      self.name = myname\n      self.wallet=money\n      print('I\\'m in Person Constructor: {}'.format(myname))\n  def say_hi(self):\n      print('Hello, my name is : ', self.name)\n  def say_bye(self):\n      print('Goodbye', Person.ID)\n  def take(self,amount):\n      self.wallet+=amount\n  def balance(self):\n      print('Wallet Balance:',self.wallet)\n  def MakeCry(self):\n      self.Cry()\n      \nclass Kid(Person):\n  def __init__(self, myname, money=0):\n      print('I\\'m in Kid Constructor: {}'.format(myname))\n      super().__init__(myname=myname, money=money)\n  def Cry(self):\n      print('Kid is crying')"},{"path":"object-oriented-programming.html","id":"constructor-2","chapter":"7 Object Oriented Programming","heading":"7.2 Constructor","text":"","code":"p1 = Person('Yong')  #:> I'm in Person Constructor: Yongp2 = Person('Gan',200)#:> I'm in Person Constructor: Ganp3 = Kid('Jolin',50)#:> I'm in Kid Constructor: Jolin\n#:> I'm in Person Constructor: Jolin"},{"path":"object-oriented-programming.html","id":"calling-method","chapter":"7 Object Oriented Programming","heading":"7.3 Calling Method","text":"","code":"p1.say_hi()#:> Hello, my name is :  Yongp1.balance()#:> Wallet Balance: 0p3.Cry()#:> Kid is cryingp3.MakeCry()#:> Kid is cryingp2.say_hi()#:> Hello, my name is :  Ganp2.balance()#:> Wallet Balance: 200"},{"path":"object-oriented-programming.html","id":"getting-property","chapter":"7 Object Oriented Programming","heading":"7.4 Getting Property","text":"","code":"p1.wallet#:> 0p2.wallet#:> 200"},{"path":"object-oriented-programming.html","id":"setting-property","chapter":"7 Object Oriented Programming","heading":"7.5 Setting Property","text":"","code":"p1.wallet = 900\np1.wallet#:> 900"},{"path":"decorator.html","id":"decorator","chapter":"8 Decorator","heading":"8 Decorator","text":"","code":""},{"path":"decorator.html","id":"definition","chapter":"8 Decorator","heading":"8.1 Definition","text":"Decorator function accept callable argumentThe main purpose decarator enhance program decorated functionIt returns callable","code":""},{"path":"decorator.html","id":"examples","chapter":"8 Decorator","heading":"8.2 Examples","text":"","code":""},{"path":"decorator.html","id":"example-1---plain-decorator-function","chapter":"8 Decorator","heading":"8.2.1 Example 1 - Plain decorator function","text":"Many times, useful register function elsewhere - example, registering task task runner, functin signal handlerregister decarator, accept decorated argumentfoo() bar() decorated function register","code":"registry = []\n\ndef register(decorated):\n    registry.append(decorated)\n    return decorated\n\n@register\ndef foo():\n    return 3\n\n@register\ndef bar():\n    return 5registry#:> [<function foo at 0x7f3de18b3710>, <function bar at 0x7f3de18b3ef0>]registry[0]()#:> 3registry[1]()#:> 5"},{"path":"decorator.html","id":"example-2---decorator-with-class","chapter":"8 Decorator","heading":"8.2.2 Example 2 - Decorator with Class","text":"Extending use case aboveregister decarator, one argumentThe decorator decorate two functions, object bObserve result","code":"class Registry(object):\n    def __init__(self):\n        self._functions = []\n    def register(self,decorated):\n        self._functions.append(decorated)\n        return decorated\n    def run_all(self,*args,**kwargs):\n        return_values = []\n        for func in self._functions:\n            return_values.append(func(*args,**kwargs))\n        return return_valuesa = Registry()\nb = Registry()\n\n@a.register\ndef foo(x=3):\n    return x\n\n@b.register\ndef bar(x=5):\n    return x\n\n@a.register\n@b.register\ndef bax(x=7):\n    return xprint (a._functions)#:> [<function foo at 0x7f3de1891200>, <function bax at 0x7f3de9689e60>]print (b._functions)#:> [<function bar at 0x7f3de18914d0>, <function bax at 0x7f3de9689e60>]print (a.run_all())#:> [3, 7]print (b.run_all())#:> [5, 7]print ( a.run_all(x=9) )#:> [9, 9]print ( b.run_all(x=9) )#:> [9, 9]"},{"path":"datetime-standard-library.html","id":"datetime-standard-library","chapter":"9 datetime Standard Library","heading":"9 datetime Standard Library","text":"built-library Python. need install library.","code":""},{"path":"datetime-standard-library.html","id":"iso8601","chapter":"9 datetime Standard Library","heading":"9.1 ISO8601","text":"https://en.wikipedia.org/wiki/ISO_8601#Time_zone_designators","code":""},{"path":"datetime-standard-library.html","id":"date-time","chapter":"9 datetime Standard Library","heading":"9.1.1 Date Time","text":"UTC:   \"2007-04-05T14:30Z\"      #notice Z GMT+8:  \"2007-04-05T12:30+08:00  #notice +08:00 GMT+8:  \"2007-04-05T12:30+0800   #notice +0800 GMT+8:  \"2007-04-05T12:30+08     #notice +08","code":""},{"path":"datetime-standard-library.html","id":"date","chapter":"9 datetime Standard Library","heading":"9.1.2 Date","text":"2019-02-04 #notice timezone available","code":""},{"path":"datetime-standard-library.html","id":"module-import","chapter":"9 datetime Standard Library","heading":"9.2 Module Import","text":"","code":"from datetime import date     # module for date object\nfrom datetime import time     # module for time object\nfrom datetime import datetime # module for datetime object\nfrom datetime import timedelta"},{"path":"datetime-standard-library.html","id":"class","chapter":"9 datetime Standard Library","heading":"9.3 Class","text":"datetime library contain three class objects:\n- date (year,month,day)\n- time (hour,minute,second)\n- datetime (year,month,day,hour,minute,second)\n- timedelta: duration two datetime date object","code":""},{"path":"datetime-standard-library.html","id":"date-1","chapter":"9 datetime Standard Library","heading":"9.4 date","text":"","code":""},{"path":"datetime-standard-library.html","id":"constructor-3","chapter":"9 datetime Standard Library","heading":"9.4.1 Constructor","text":"","code":"print( date(2000,1,1) )#:> 2000-01-01print( date(year=2000,month=1,day=1) )#:> 2000-01-01print( type(date(year=2000,month=1,day=1)))#:> <class 'datetime.date'>"},{"path":"datetime-standard-library.html","id":"class-method","chapter":"9 datetime Standard Library","heading":"9.4.2 Class Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"today","chapter":"9 datetime Standard Library","heading":"9.4.2.1 today","text":"local date (UTC)","code":"date.today()#:> datetime.date(2020, 11, 20)print( date.today() )#:> 2020-11-20"},{"path":"datetime-standard-library.html","id":"convert-from-iso-fromisoformat","chapter":"9 datetime Standard Library","heading":"9.4.2.2 Convert From ISO fromisoformat","text":"strptime available date conversion. datetime conversionTo convert non-iso format date string date object, convert datetime first, date","code":"date.fromisoformat('2011-11-11')#:> datetime.date(2011, 11, 11)"},{"path":"datetime-standard-library.html","id":"instance-method","chapter":"9 datetime Standard Library","heading":"9.4.3 Instance Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"replace","chapter":"9 datetime Standard Library","heading":"9.4.3.1 replace()","text":"Replace year/month/day specified parameter, non specified params remain unchange.Example change month. can change year day combination","code":"print( date.today() )#:> 2020-11-20print( date.today().replace(month=8) )#:> 2020-08-20"},{"path":"datetime-standard-library.html","id":"weekday-isoweekday","chapter":"9 datetime Standard Library","heading":"9.4.3.2 weekday(), isoweekday()","text":"weekday(), Zero Monday\nisoweekday(), Zero Sunday","code":"print( date.today().weekday() )#:> 4print( date.today().isoweekday() )#:> 5weekdays = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\nwd = date.today().weekday()\nprint( date.today(), \"is day\", wd ,\"which is\", weekdays[wd] )#:> 2020-11-20 is day 4 which is Fri"},{"path":"datetime-standard-library.html","id":"formating-with-isoformat","chapter":"9 datetime Standard Library","heading":"9.4.3.3 Formating with isoformat()","text":"isoformat() return ISO 8601 String (YYYY-MM-DD)","code":"date.today().isoformat() # return string#:> '2020-11-20'"},{"path":"datetime-standard-library.html","id":"formating-with-strftime","chapter":"9 datetime Standard Library","heading":"9.4.3.4 Formating with strftime","text":"complete directive, see :https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior","code":"date.today().strftime(\"%m/%d\")#:> '11/20'"},{"path":"datetime-standard-library.html","id":"isocalendar","chapter":"9 datetime Standard Library","heading":"9.4.3.5 isocalendar()","text":"isocalendar return 3-tuple, (ISO year, ISO week number, ISO weekday).","code":"date.today().isocalendar() ## return tuple #:> (2020, 47, 5)"},{"path":"datetime-standard-library.html","id":"attributes","chapter":"9 datetime Standard Library","heading":"9.4.4 Attributes","text":"","code":"print( date.today().year )#:> 2020print( date.today().month )#:> 11print( date.today().day )#:> 20"},{"path":"datetime-standard-library.html","id":"date-and-datetime","chapter":"9 datetime Standard Library","heading":"9.5 date and datetime","text":"","code":""},{"path":"datetime-standard-library.html","id":"constructor-4","chapter":"9 datetime Standard Library","heading":"9.5.1 Constructor","text":"","code":"import datetime as dt\n\nprint( \n    dt.date(2000,1,1,), '\\n',\n    dt.datetime(2000,1,1,0,0,0), '\\n',\n    dt.datetime(year=2000,month=1,day=1,hour=23,minute=15,second=55),'\\n',\n    type(dt.date(2000,1,1)),'\\n',\n    type(dt.datetime(2000,1,1,0,0,0)))#:> 2000-01-01 \n#:>  2000-01-01 00:00:00 \n#:>  2000-01-01 23:15:55 \n#:>  <class 'datetime.date'> \n#:>  <class 'datetime.datetime'>"},{"path":"datetime-standard-library.html","id":"class-method-1","chapter":"9 datetime Standard Library","heading":"9.5.2 Class Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"now-and-today","chapter":"9 datetime Standard Library","heading":"9.5.2.1 now and today","text":"now() today() return current system local datetime, timezone","code":"print(  dt.datetime.now(), '\\n',\n        dt.datetime.now().date())#:> 2020-11-20 14:28:25.898918 \n#:>  2020-11-20dt.datetime.today()#:> datetime.datetime(2020, 11, 20, 14, 28, 25, 906038)"},{"path":"datetime-standard-library.html","id":"utcnow","chapter":"9 datetime Standard Library","heading":"9.5.2.2 utcnow","text":"","code":"dt.datetime.utcnow()#:> datetime.datetime(2020, 11, 20, 20, 28, 25, 916074)"},{"path":"datetime-standard-library.html","id":"combine-date-and-time","chapter":"9 datetime Standard Library","heading":"9.5.2.3 combine() date and time","text":"Apply datetime.combine() module method date time object get datetime","code":"now = dt.datetime.now()\ndt.datetime.combine(now.date(), now.time())#:> datetime.datetime(2020, 11, 20, 14, 28, 25, 922861)"},{"path":"datetime-standard-library.html","id":"convert-from-string-strptime","chapter":"9 datetime Standard Library","heading":"9.5.2.4 Convert from String strptime()","text":"Use strptime convert string datetime object","code":"%I : 12-hour\n%H : 24-hour\n%M : Minute\n%p : AM/PM\n%y : 18\n%Y : 2018\n%b : Mar\n%m : month (1 to 12)\n%d : daydatetime.strptime('2011-02-25','%Y-%m-%d')#:> datetime.datetime(2011, 2, 25, 0, 0)datetime.strptime('9-01-18','%d-%m-%y')#:> datetime.datetime(2018, 1, 9, 0, 0)datetime.strptime('09-Mar-2018','%d-%b-%Y')#:> datetime.datetime(2018, 3, 9, 0, 0)datetime.strptime('2/5/2018 4:49 PM', '%m/%d/%Y %I:%M %p')#:> datetime.datetime(2018, 2, 5, 16, 49)"},{"path":"datetime-standard-library.html","id":"convert-from-iso-fromisoformat-1","chapter":"9 datetime Standard Library","heading":"9.5.2.5 Convert from ISO fromisoformat","text":"fromisoformat() intend reverse isoformat()actually ISO compliance: Z +8 included end string, error occur","code":"#s = dt.datetime.now().isoformat()\ndt.datetime.fromisoformat(\"2019-02-05T10:22:33\")#:> datetime.datetime(2019, 2, 5, 10, 22, 33)"},{"path":"datetime-standard-library.html","id":"instance-method-1","chapter":"9 datetime Standard Library","heading":"9.5.3 Instance Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"weekday","chapter":"9 datetime Standard Library","heading":"9.5.3.1 weekday","text":"","code":"datetime.now().weekday()#:> 4"},{"path":"datetime-standard-library.html","id":"replace-1","chapter":"9 datetime Standard Library","heading":"9.5.3.2 replace","text":"","code":"datetime.now().replace(year=1999)#:> datetime.datetime(1999, 11, 20, 14, 28, 25, 988527)"},{"path":"datetime-standard-library.html","id":"convert-to-.time","chapter":"9 datetime Standard Library","heading":"9.5.3.3 convert to .time()","text":"","code":"datetime.now().time()#:> datetime.time(14, 28, 25, 998462)"},{"path":"datetime-standard-library.html","id":"convert-to-.date","chapter":"9 datetime Standard Library","heading":"9.5.3.4 Convert to .date()","text":"","code":"datetime.now().date()#:> datetime.date(2020, 11, 20)"},{"path":"datetime-standard-library.html","id":"convert-to-string","chapter":"9 datetime Standard Library","heading":"9.5.3.5 Convert to String","text":"strUse strftime()Use isoformat()","code":"str( datetime.now() )#:> '2020-11-20 14:28:26.024638'dt.datetime.now().strftime('%d-%b-%Y')#:> '20-Nov-2020'dt.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S.%fZ')  ## ISO 8601 UTC#:> '2020-11-20T20:28:26.048793Z'dt.datetime.utcnow().isoformat()#:> '2020-11-20T20:28:26.056107'"},{"path":"datetime-standard-library.html","id":"attributes-1","chapter":"9 datetime Standard Library","heading":"9.5.4 Attributes","text":"","code":"print( datetime.now().year )#:> 2020print( datetime.now().month )#:> 11print( datetime.now().day )#:> 20print( datetime.now().hour )#:> 14print( datetime.now().minute )#:> 28"},{"path":"datetime-standard-library.html","id":"time","chapter":"9 datetime Standard Library","heading":"9.6 time","text":"","code":""},{"path":"datetime-standard-library.html","id":"constructor-5","chapter":"9 datetime Standard Library","heading":"9.6.1 Constructor","text":"","code":"print( time(2) )    #default single arugement, hour#:> 02:00:00print( time(2,15) ) #default two arguments, hour, minute#:> 02:15:00print( time(hour=2,minute=15,second=30) )#:> 02:15:30"},{"path":"datetime-standard-library.html","id":"class-method-2","chapter":"9 datetime Standard Library","heading":"9.6.2 Class Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"now","chapter":"9 datetime Standard Library","heading":"9.6.2.1 now()","text":"unfortunately single function extract current time. Use time() function datetime object","code":"datetime.now().time()#:> datetime.time(14, 28, 26, 105177)"},{"path":"datetime-standard-library.html","id":"attributes-2","chapter":"9 datetime Standard Library","heading":"9.6.3 Attributes","text":"","code":"print( datetime.now().time().hour )#:> 14print( datetime.now().time().minute )#:> 28print( datetime.now().time().second )#:> 26"},{"path":"datetime-standard-library.html","id":"timedelta","chapter":"9 datetime Standard Library","heading":"9.7 timedelta","text":"years argument supportedApply timedelta datetime objecttimedelta applied time object , timedelta potentially go beyond single day (24H)","code":"delt = timedelta(days=365,minutes=33,seconds=15)now = datetime.now()\nprint ('delt+now : ', now+delt)#:> delt+now :  2021-11-20 15:01:41.137995"},{"path":"getting-external-data.html","id":"getting-external-data","chapter":"10 Getting External Data","heading":"10 Getting External Data","text":"","code":""},{"path":"plydata-dplyr-for-python.html","id":"plydata-dplyr-for-python","chapter":"11 Plydata (dplyr for Python)","heading":"11 Plydata (dplyr for Python)","text":"","code":""},{"path":"plydata-dplyr-for-python.html","id":"sample-data","chapter":"11 Plydata (dplyr for Python)","heading":"11.1 Sample Data","text":"","code":"n = 200\ncomp = ['C' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 3x Company\ndept = ['D' + i for i in np.random.randint( 1,6, size  = n).astype(str)] # 5x Department\ngrp =  ['G' + i for i in np.random.randint( 1,3, size  = n).astype(str)] # 2x Groups\nvalue1 = np.random.normal( loc=50 , scale=5 , size = n)\nvalue2 = np.random.normal( loc=20 , scale=3 , size = n)\n#value3 = np.random.normal( loc=5 , scale=30 , size = n)\n\nmydf = pd.DataFrame({\n    'comp':comp, \n    'dept':dept, \n    'grp': grp,\n    'value1':value1, \n    'value2':value2\n    #'value3':value3 \n})\nmydf.head()#:>   comp dept grp     value1     value2\n#:> 0   C1   D5  G2  44.991357  18.376559\n#:> 1   C1   D3  G1  42.629061  15.044993\n#:> 2   C3   D1  G1  53.803512  18.496985\n#:> 3   C2   D3  G1  51.387646  16.152419\n#:> 4   C2   D3  G1  52.897552  19.107399"},{"path":"plydata-dplyr-for-python.html","id":"column-manipulation","chapter":"11 Plydata (dplyr for Python)","heading":"11.2 Column Manipulation","text":"","code":""},{"path":"plydata-dplyr-for-python.html","id":"copy-column","chapter":"11 Plydata (dplyr for Python)","heading":"11.2.1 Copy Column","text":"","code":"mydf >> define(newcol = 'value1')                 # simple method for one column#:>     comp dept grp     value1     value2     newcol\n#:> 0     C1   D5  G2  44.991357  18.376559  44.991357\n#:> 1     C1   D3  G1  42.629061  15.044993  42.629061\n#:> 2     C3   D1  G1  53.803512  18.496985  53.803512\n#:> 3     C2   D3  G1  51.387646  16.152419  51.387646\n#:> 4     C2   D3  G1  52.897552  19.107399  52.897552\n#:> ..   ...  ...  ..        ...        ...        ...\n#:> 195   C3   D3  G1  44.837077  23.383648  44.837077\n#:> 196   C2   D2  G2  44.899655  17.546987  44.899655\n#:> 197   C1   D1  G2  47.806362  21.936824  47.806362\n#:> 198   C1   D5  G1  50.837563  17.498985  50.837563\n#:> 199   C1   D4  G1  51.282241  20.841696  51.282241\n#:> \n#:> [200 rows x 6 columns]mydf >> define (('newcol1', 'value1'), newcol2='value2')  # method for muiltiple new columns#:>     comp dept grp     value1     value2    newcol1    newcol2\n#:> 0     C1   D5  G2  44.991357  18.376559  44.991357  18.376559\n#:> 1     C1   D3  G1  42.629061  15.044993  42.629061  15.044993\n#:> 2     C3   D1  G1  53.803512  18.496985  53.803512  18.496985\n#:> 3     C2   D3  G1  51.387646  16.152419  51.387646  16.152419\n#:> 4     C2   D3  G1  52.897552  19.107399  52.897552  19.107399\n#:> ..   ...  ...  ..        ...        ...        ...        ...\n#:> 195   C3   D3  G1  44.837077  23.383648  44.837077  23.383648\n#:> 196   C2   D2  G2  44.899655  17.546987  44.899655  17.546987\n#:> 197   C1   D1  G2  47.806362  21.936824  47.806362  21.936824\n#:> 198   C1   D5  G1  50.837563  17.498985  50.837563  17.498985\n#:> 199   C1   D4  G1  51.282241  20.841696  51.282241  20.841696\n#:> \n#:> [200 rows x 7 columns]"},{"path":"plydata-dplyr-for-python.html","id":"new-column-from-existing-column","chapter":"11 Plydata (dplyr for Python)","heading":"11.2.2 New Column from existing Column","text":"Without specify new column name, derived expressionSpecify new column nameDefine multiple new columns one go. Observe three ways specify new columns","code":"mydf >> define ('value1*2')#:>     comp dept grp     value1     value2    value1*2\n#:> 0     C1   D5  G2  44.991357  18.376559   89.982715\n#:> 1     C1   D3  G1  42.629061  15.044993   85.258122\n#:> 2     C3   D1  G1  53.803512  18.496985  107.607023\n#:> 3     C2   D3  G1  51.387646  16.152419  102.775291\n#:> 4     C2   D3  G1  52.897552  19.107399  105.795104\n#:> ..   ...  ...  ..        ...        ...         ...\n#:> 195   C3   D3  G1  44.837077  23.383648   89.674153\n#:> 196   C2   D2  G2  44.899655  17.546987   89.799311\n#:> 197   C1   D1  G2  47.806362  21.936824   95.612724\n#:> 198   C1   D5  G1  50.837563  17.498985  101.675127\n#:> 199   C1   D4  G1  51.282241  20.841696  102.564482\n#:> \n#:> [200 rows x 6 columns]mydf >> define(value3 = 'value1*2')#:>     comp dept grp     value1     value2      value3\n#:> 0     C1   D5  G2  44.991357  18.376559   89.982715\n#:> 1     C1   D3  G1  42.629061  15.044993   85.258122\n#:> 2     C3   D1  G1  53.803512  18.496985  107.607023\n#:> 3     C2   D3  G1  51.387646  16.152419  102.775291\n#:> 4     C2   D3  G1  52.897552  19.107399  105.795104\n#:> ..   ...  ...  ..        ...        ...         ...\n#:> 195   C3   D3  G1  44.837077  23.383648   89.674153\n#:> 196   C2   D2  G2  44.899655  17.546987   89.799311\n#:> 197   C1   D1  G2  47.806362  21.936824   95.612724\n#:> 198   C1   D5  G1  50.837563  17.498985  101.675127\n#:> 199   C1   D4  G1  51.282241  20.841696  102.564482\n#:> \n#:> [200 rows x 6 columns]mydf >> define('value1*2',('newcol2','value2*2'),newcol3='value2*3')#:>     comp dept grp     value1     value2    value1*2    newcol2    newcol3\n#:> 0     C1   D5  G2  44.991357  18.376559   89.982715  36.753118  55.129677\n#:> 1     C1   D3  G1  42.629061  15.044993   85.258122  30.089985  45.134978\n#:> 2     C3   D1  G1  53.803512  18.496985  107.607023  36.993970  55.490955\n#:> 3     C2   D3  G1  51.387646  16.152419  102.775291  32.304838  48.457257\n#:> 4     C2   D3  G1  52.897552  19.107399  105.795104  38.214799  57.322198\n#:> ..   ...  ...  ..        ...        ...         ...        ...        ...\n#:> 195   C3   D3  G1  44.837077  23.383648   89.674153  46.767296  70.150944\n#:> 196   C2   D2  G2  44.899655  17.546987   89.799311  35.093974  52.640962\n#:> 197   C1   D1  G2  47.806362  21.936824   95.612724  43.873649  65.810473\n#:> 198   C1   D5  G1  50.837563  17.498985  101.675127  34.997969  52.496954\n#:> 199   C1   D4  G1  51.282241  20.841696  102.564482  41.683391  62.525087\n#:> \n#:> [200 rows x 8 columns]"},{"path":"plydata-dplyr-for-python.html","id":"select-columns","chapter":"11 Plydata (dplyr for Python)","heading":"11.2.3 Select Column(s)","text":"","code":"mydf2 = mydf >> define(newcol1='value1',newcol2='value2')\nmydf2.info()#:> <class 'pandas.core.frame.DataFrame'>\n#:> RangeIndex: 200 entries, 0 to 199\n#:> Data columns (total 7 columns):\n#:>  #   Column   Non-Null Count  Dtype  \n#:> ---  ------   --------------  -----  \n#:>  0   comp     200 non-null    object \n#:>  1   dept     200 non-null    object \n#:>  2   grp      200 non-null    object \n#:>  3   value1   200 non-null    float64\n#:>  4   value2   200 non-null    float64\n#:>  5   newcol1  200 non-null    float64\n#:>  6   newcol2  200 non-null    float64\n#:> dtypes: float64(4), object(3)\n#:> memory usage: 11.1+ KB"},{"path":"plydata-dplyr-for-python.html","id":"by-column-names","chapter":"11 Plydata (dplyr for Python)","heading":"11.2.3.1 By Column Names","text":"Exact Coumn NameColumn Name Starts …Column Name Ends …Column Name Contains …","code":"mydf2 >> select ('comp','dept','value1')#:>     comp dept     value1\n#:> 0     C1   D5  44.991357\n#:> 1     C1   D3  42.629061\n#:> 2     C3   D1  53.803512\n#:> 3     C2   D3  51.387646\n#:> 4     C2   D3  52.897552\n#:> ..   ...  ...        ...\n#:> 195   C3   D3  44.837077\n#:> 196   C2   D2  44.899655\n#:> 197   C1   D1  47.806362\n#:> 198   C1   D5  50.837563\n#:> 199   C1   D4  51.282241\n#:> \n#:> [200 rows x 3 columns]mydf2 >> select ('comp', startswith='val')#:>     comp     value1     value2\n#:> 0     C1  44.991357  18.376559\n#:> 1     C1  42.629061  15.044993\n#:> 2     C3  53.803512  18.496985\n#:> 3     C2  51.387646  16.152419\n#:> 4     C2  52.897552  19.107399\n#:> ..   ...        ...        ...\n#:> 195   C3  44.837077  23.383648\n#:> 196   C2  44.899655  17.546987\n#:> 197   C1  47.806362  21.936824\n#:> 198   C1  50.837563  17.498985\n#:> 199   C1  51.282241  20.841696\n#:> \n#:> [200 rows x 3 columns]mydf2 >> select ('comp',endswith=('1','2','3'))#:>     comp     value1     value2    newcol1    newcol2\n#:> 0     C1  44.991357  18.376559  44.991357  18.376559\n#:> 1     C1  42.629061  15.044993  42.629061  15.044993\n#:> 2     C3  53.803512  18.496985  53.803512  18.496985\n#:> 3     C2  51.387646  16.152419  51.387646  16.152419\n#:> 4     C2  52.897552  19.107399  52.897552  19.107399\n#:> ..   ...        ...        ...        ...        ...\n#:> 195   C3  44.837077  23.383648  44.837077  23.383648\n#:> 196   C2  44.899655  17.546987  44.899655  17.546987\n#:> 197   C1  47.806362  21.936824  47.806362  21.936824\n#:> 198   C1  50.837563  17.498985  50.837563  17.498985\n#:> 199   C1  51.282241  20.841696  51.282241  20.841696\n#:> \n#:> [200 rows x 5 columns]mydf2 >> select('comp', contains=('col','val'))#:>     comp     value1     value2    newcol1    newcol2\n#:> 0     C1  44.991357  18.376559  44.991357  18.376559\n#:> 1     C1  42.629061  15.044993  42.629061  15.044993\n#:> 2     C3  53.803512  18.496985  53.803512  18.496985\n#:> 3     C2  51.387646  16.152419  51.387646  16.152419\n#:> 4     C2  52.897552  19.107399  52.897552  19.107399\n#:> ..   ...        ...        ...        ...        ...\n#:> 195   C3  44.837077  23.383648  44.837077  23.383648\n#:> 196   C2  44.899655  17.546987  44.899655  17.546987\n#:> 197   C1  47.806362  21.936824  47.806362  21.936824\n#:> 198   C1  50.837563  17.498985  50.837563  17.498985\n#:> 199   C1  51.282241  20.841696  51.282241  20.841696\n#:> \n#:> [200 rows x 5 columns]"},{"path":"plydata-dplyr-for-python.html","id":"specify-column-range","chapter":"11 Plydata (dplyr for Python)","heading":"11.2.3.2 Specify Column Range","text":"","code":"mydf2 >> select ('comp', slice('value1','newcol2'))#:>     comp     value1     value2    newcol1    newcol2\n#:> 0     C1  44.991357  18.376559  44.991357  18.376559\n#:> 1     C1  42.629061  15.044993  42.629061  15.044993\n#:> 2     C3  53.803512  18.496985  53.803512  18.496985\n#:> 3     C2  51.387646  16.152419  51.387646  16.152419\n#:> 4     C2  52.897552  19.107399  52.897552  19.107399\n#:> ..   ...        ...        ...        ...        ...\n#:> 195   C3  44.837077  23.383648  44.837077  23.383648\n#:> 196   C2  44.899655  17.546987  44.899655  17.546987\n#:> 197   C1  47.806362  21.936824  47.806362  21.936824\n#:> 198   C1  50.837563  17.498985  50.837563  17.498985\n#:> 199   C1  51.282241  20.841696  51.282241  20.841696\n#:> \n#:> [200 rows x 5 columns]"},{"path":"plydata-dplyr-for-python.html","id":"drop-columns","chapter":"11 Plydata (dplyr for Python)","heading":"11.2.4 Drop Column(s)","text":"Combined Method\nCombine assignment dictionary method","code":"mydf2 >> select('newcol1','newcol2',drop=True)#:>     comp dept grp     value1     value2\n#:> 0     C1   D5  G2  44.991357  18.376559\n#:> 1     C1   D3  G1  42.629061  15.044993\n#:> 2     C3   D1  G1  53.803512  18.496985\n#:> 3     C2   D3  G1  51.387646  16.152419\n#:> 4     C2   D3  G1  52.897552  19.107399\n#:> ..   ...  ...  ..        ...        ...\n#:> 195   C3   D3  G1  44.837077  23.383648\n#:> 196   C2   D2  G2  44.899655  17.546987\n#:> 197   C1   D1  G2  47.806362  21.936824\n#:> 198   C1   D5  G1  50.837563  17.498985\n#:> 199   C1   D4  G1  51.282241  20.841696\n#:> \n#:> [200 rows x 5 columns]mydf >> rename( {'val.1' : 'value1',\n                 'val.2' : 'value2' })#:>     comp dept grp      val.1      val.2\n#:> 0     C1   D5  G2  44.991357  18.376559\n#:> 1     C1   D3  G1  42.629061  15.044993\n#:> 2     C3   D1  G1  53.803512  18.496985\n#:> 3     C2   D3  G1  51.387646  16.152419\n#:> 4     C2   D3  G1  52.897552  19.107399\n#:> ..   ...  ...  ..        ...        ...\n#:> 195   C3   D3  G1  44.837077  23.383648\n#:> 196   C2   D2  G2  44.899655  17.546987\n#:> 197   C1   D1  G2  47.806362  21.936824\n#:> 198   C1   D5  G1  50.837563  17.498985\n#:> 199   C1   D4  G1  51.282241  20.841696\n#:> \n#:> [200 rows x 5 columns]mydf >> rename( {'val.1' : 'value1',\n                 'val.2' : 'value2'\n              }, group = 'grp' )#:>     comp dept group      val.1      val.2\n#:> 0     C1   D5    G2  44.991357  18.376559\n#:> 1     C1   D3    G1  42.629061  15.044993\n#:> 2     C3   D1    G1  53.803512  18.496985\n#:> 3     C2   D3    G1  51.387646  16.152419\n#:> 4     C2   D3    G1  52.897552  19.107399\n#:> ..   ...  ...   ...        ...        ...\n#:> 195   C3   D3    G1  44.837077  23.383648\n#:> 196   C2   D2    G2  44.899655  17.546987\n#:> 197   C1   D1    G2  47.806362  21.936824\n#:> 198   C1   D5    G1  50.837563  17.498985\n#:> 199   C1   D4    G1  51.282241  20.841696\n#:> \n#:> [200 rows x 5 columns]"},{"path":"plydata-dplyr-for-python.html","id":"sorting-arrange","chapter":"11 Plydata (dplyr for Python)","heading":"11.3 Sorting (arrange)","text":"Use ‘-colName’ decending","code":"mydf >> arrange('comp', '-value1')#:>     comp dept grp     value1     value2\n#:> 37    C1   D2  G2  61.082781  18.495389\n#:> 75    C1   D5  G1  60.071749  17.671009\n#:> 148   C1   D5  G2  59.864576  22.915047\n#:> 48    C1   D4  G1  59.220959  16.136915\n#:> 64    C1   D4  G2  58.752440  17.698505\n#:> ..   ...  ...  ..        ...        ...\n#:> 83    C3   D4  G1  42.457564  20.433678\n#:> 161   C3   D2  G2  42.343989  18.665869\n#:> 109   C3   D1  G1  41.992172  19.105493\n#:> 138   C3   D1  G2  41.128355  19.948868\n#:> 11    C3   D5  G1  39.306004  23.168880\n#:> \n#:> [200 rows x 5 columns]"},{"path":"plydata-dplyr-for-python.html","id":"grouping","chapter":"11 Plydata (dplyr for Python)","heading":"11.4 Grouping","text":"","code":"mydf.info()#:> <class 'pandas.core.frame.DataFrame'>\n#:> RangeIndex: 200 entries, 0 to 199\n#:> Data columns (total 5 columns):\n#:>  #   Column  Non-Null Count  Dtype  \n#:> ---  ------  --------------  -----  \n#:>  0   comp    200 non-null    object \n#:>  1   dept    200 non-null    object \n#:>  2   grp     200 non-null    object \n#:>  3   value1  200 non-null    float64\n#:>  4   value2  200 non-null    float64\n#:> dtypes: float64(2), object(3)\n#:> memory usage: 7.9+ KBgdf = mydf >> group_by('comp','dept')\ntype(gdf)#:> <class 'plydata.types.GroupedDataFrame'>"},{"path":"plydata-dplyr-for-python.html","id":"summarization","chapter":"11 Plydata (dplyr for Python)","heading":"11.5 Summarization","text":"","code":""},{"path":"plydata-dplyr-for-python.html","id":"simple-method","chapter":"11 Plydata (dplyr for Python)","heading":"11.5.1 Simple Method","text":"Passing Multiple Expressions","code":"gdf >> summarize('n()','sum(value1)','mean(value2)')"},{"path":"plydata-dplyr-for-python.html","id":"specify-summarized-column-name","chapter":"11 Plydata (dplyr for Python)","heading":"11.5.2 Specify Summarized Column Name","text":"Assignment Method\n- Passing colName=‘expression’**\n- Column name contain special characterTuple Method (‘colName,’‘expression’)\nUse column name contain special character","code":"gdf >> summarize(count='n()',v1sum='sum(value1)',v2_mean='mean(value2)')gdf >> summarize(('count','n()'),('v1.sum','sum(value1)'),('s2.sum','sum(value2)'),v2mean=np.mean(value2))"},{"path":"plydata-dplyr-for-python.html","id":"number-of-rows-in-group","chapter":"11 Plydata (dplyr for Python)","heading":"11.5.3 Number of Rows in Group","text":"n() : total rows groupn_unique() : total rows unique value","code":"gdf >> summarize(count='n()', va11_unique='n_unique(value1)')"},{"path":"numpy-1.html","id":"numpy-1","chapter":"12 numpy","heading":"12 numpy","text":"Best array data manipulation, fastnumpy array allows single data type, unlike listSupport matrix operation","code":""},{"path":"numpy-1.html","id":"environment-setup","chapter":"12 numpy","heading":"12.1 Environment Setup","text":"","code":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport math\npd.set_option( 'display.notebook_repr_html', False)  # render Series and DataFrame as text, not HTML\npd.set_option( 'display.max_column', 10)    # number of columns\npd.set_option( 'display.max_rows', 10)     # number of rows\npd.set_option( 'display.width', 90)        # number of characters per row"},{"path":"numpy-1.html","id":"module-import-1","chapter":"12 numpy","heading":"12.2 Module Import","text":"","code":"import numpy as np\nnp.__version__\n\n## other modules#:> '1.19.1'from datetime import datetime\nfrom datetime import date\nfrom datetime import time"},{"path":"numpy-1.html","id":"data-types","chapter":"12 numpy","heading":"12.3 Data Types","text":"","code":""},{"path":"numpy-1.html","id":"numpy-data-types","chapter":"12 numpy","heading":"12.3.1 NumPy Data Types","text":"NumPy supports much greater variety numerical types Python . makes numpy much powerful https://www.numpy.org/devdocs/user/basics.types.htmlInteger: np.int8, np.int16, np.int32, np.uint8, np.uint16, np.uint32Float: np.float32, np.float64","code":""},{"path":"numpy-1.html","id":"int3264","chapter":"12 numpy","heading":"12.3.2 int32/64","text":"np.int actually python standard intnp.int32/64 NumPy specific","code":"x = np.int(13)\ny = int(13)\nprint( type(x) )#:> <class 'int'>print( type(y) )#:> <class 'int'>x = np.int32(13)\ny = np.int64(13)\nprint( type(x) )#:> <class 'numpy.int32'>print( type(y) )#:> <class 'numpy.int64'>"},{"path":"numpy-1.html","id":"float3264","chapter":"12 numpy","heading":"12.3.3 float32/64","text":"","code":"x = np.float(13)\ny = float(13)\nprint( type(x) )#:> <class 'float'>print( type(y) )#:> <class 'float'>x = np.float32(13)\ny = np.float64(13)\nprint( type(x) )#:> <class 'numpy.float32'>print( type(y) )#:> <class 'numpy.float64'>"},{"path":"numpy-1.html","id":"bool","chapter":"12 numpy","heading":"12.3.4 bool","text":"np.bool actually python standard bool","code":"x = np.bool(True)\nprint( type(x) )#:> <class 'bool'>print( type(True) )#:> <class 'bool'>"},{"path":"numpy-1.html","id":"str","chapter":"12 numpy","heading":"12.3.5 str","text":"np.str actually python standard str","code":"x = np.str(\"ali\")\nprint( type(x) )#:> <class 'str'>x = np.str_(\"ali\")\nprint( type(x) )#:> <class 'numpy.str_'>"},{"path":"numpy-1.html","id":"datetime64","chapter":"12 numpy","heading":"12.3.6 datetime64","text":"Unlike python standard datetime library, seperation date, datetime time.\ntime equivalent object\nNumPy one object: datetime64 object .","code":""},{"path":"numpy-1.html","id":"constructor-6","chapter":"12 numpy","heading":"12.3.6.1 Constructor","text":"String\nNote input string ISO8601 compliance, meaning timezone related information end string (Z +8) result error.datetime","code":"np.datetime64('2005-02')#:> numpy.datetime64('2005-02')np.datetime64('2005-02-25')#:> numpy.datetime64('2005-02-25')np.datetime64('2005-02-25T03:30')#:> numpy.datetime64('2005-02-25T03:30')np.datetime64( date.today() )#:> numpy.datetime64('2020-11-20')np.datetime64( datetime.now() )#:> numpy.datetime64('2020-11-20T14:28:29.271833')"},{"path":"numpy-1.html","id":"instance-method-2","chapter":"12 numpy","heading":"12.3.6.2 Instance Method","text":"Convert datetime using astype()","code":"dt64 = np.datetime64(\"2019-01-31\" )\ndt64.astype(datetime)#:> datetime.date(2019, 1, 31)"},{"path":"numpy-1.html","id":"nan","chapter":"12 numpy","heading":"12.3.7 nan","text":"","code":""},{"path":"numpy-1.html","id":"creating-nan","chapter":"12 numpy","heading":"12.3.7.1 Creating NaN","text":"NaN BUILT-datatype. means number, numpy float object type. Can created using two methods .","code":"import numpy as np\nimport pandas as pd\nimport math\n\nkosong1 = float('NaN')\nkosong2 = np.nan\n\nprint('Type: ', type(kosong1), '\\n',\n       'Value: ', kosong1)#:> Type:  <class 'float'> \n#:>  Value:  nanprint('Type: ', type(kosong2), '\\n',\n       'Value: ', kosong2)#:> Type:  <class 'float'> \n#:>  Value:  nan"},{"path":"numpy-1.html","id":"detecting-nan","chapter":"12 numpy","heading":"12.3.7.2 Detecting NaN","text":"Detect nan using various function panda, numpy math.","code":"print(pd.isna(kosong1), '\\n',\n      pd.isna(kosong2), '\\n',\n      np.isnan(kosong1),'\\n',\n      math.isnan(kosong2))#:> True \n#:>  True \n#:>  True \n#:>  True"},{"path":"numpy-1.html","id":"operation","chapter":"12 numpy","heading":"12.3.7.3 Operation","text":"","code":""},{"path":"numpy-1.html","id":"logical-operator","chapter":"12 numpy","heading":"12.3.7.3.1 Logical Operator","text":"","code":"print( True and kosong1,\n       kosong1 and True)#:> nan Trueprint( True or kosong1,\n       False or kosong1)#:> True nan"},{"path":"numpy-1.html","id":"comparing","chapter":"12 numpy","heading":"12.3.7.3.2 Comparing","text":"Compare nan anything results False, including .","code":"print(kosong1 > 0, kosong1==0, kosong1<0,\n      kosong1 ==1, kosong1==kosong1, kosong1==False, kosong1==True)#:> False False False False False False False"},{"path":"numpy-1.html","id":"casting","chapter":"12 numpy","heading":"12.3.7.3.3 Casting","text":"nan numpy floating value. zero value, therefore casting boolean returns True.","code":"bool(kosong1)#:> True"},{"path":"numpy-1.html","id":"numpy-array","chapter":"12 numpy","heading":"12.4 Numpy Array","text":"","code":""},{"path":"numpy-1.html","id":"concept","chapter":"12 numpy","heading":"12.4.1 Concept","text":"Structure\n- NumPy provides N-dimensional array type, ndarray\n- ndarray homogenous: every item takes size block memory, blocks\n- ndarray, seperate dtype object, describe ndarray data type\n- item extracted array, e.g., indexing, represented Python object whose type one array scalar types built NumPy. array scalars allow easy manipulation also complicated arrangements data.\n","code":""},{"path":"numpy-1.html","id":"constructor-7","chapter":"12 numpy","heading":"12.4.2 Constructor","text":"default, numpy.array autodetect data types based common denominator","code":""},{"path":"numpy-1.html","id":"dtype-int-float","chapter":"12 numpy","heading":"12.4.2.1 dType: int, float","text":"Notice example auto detected int32 data typeNotice example auto detected float64 data typeYou can specify dtype specify desired data types.\nNumPy auto convert data specifeid types. Observe convert float integer","code":"x = np.array( (1,2,3,4,5) )\nprint(x)#:> [1 2 3 4 5]print('Type: ', type(x))#:> Type:  <class 'numpy.ndarray'>print('dType:', x.dtype)#:> dType: int64x = np.array( (1,2,3,4.5,5) )\nprint(x)\n# print('Type: ', type(x))\n# print('dType:', x.dtype)#:> [1.  2.  3.  4.5 5. ]x = np.array( (1,2,3,4.5,5), dtype='int' )\nprint(x)#:> [1 2 3 4 5]print('Type: ', type(x))#:> Type:  <class 'numpy.ndarray'>print('dType:', x.dtype)#:> dType: int64"},{"path":"numpy-1.html","id":"dtype-datetime64","chapter":"12 numpy","heading":"12.4.2.2 dType: datetime64","text":"Specify dtype necessary ensure output datetime type. , output generic object type.strFrom datetime","code":"x = np.array(['2007-07-13', '2006-01-13', '2010-08-13'], dtype='datetime64')\nprint(x)#:> ['2007-07-13' '2006-01-13' '2010-08-13']print('Type: ', type(x))#:> Type:  <class 'numpy.ndarray'>print('dType:', x.dtype)#:> dType: datetime64[D]x = np.array([datetime(2019,1,12), datetime(2019,1,14),datetime(2019,3,3)], dtype='datetime64')\nprint(x)#:> ['2019-01-12T00:00:00.000000' '2019-01-14T00:00:00.000000'\n#:>  '2019-03-03T00:00:00.000000']print('Type: ', type(x))#:> Type:  <class 'numpy.ndarray'>print('dType:', x.dtype)#:> dType: datetime64[us]print('\\nElement Type:',type(x[1]))#:> \n#:> Element Type: <class 'numpy.datetime64'>"},{"path":"numpy-1.html","id":"d-array","chapter":"12 numpy","heading":"12.4.2.3 2D Array","text":"","code":"x = np.array([range(10),np.arange(10)])\nx#:> array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n#:>        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"},{"path":"numpy-1.html","id":"dimensions","chapter":"12 numpy","heading":"12.4.3 Dimensions","text":"","code":""},{"path":"numpy-1.html","id":"differentiating-dimensions","chapter":"12 numpy","heading":"12.4.3.1 Differentiating Dimensions","text":"1-D array array single list\n2-D array array made list containing lists (row list)\n2-D single row array array list containing just one list","code":""},{"path":"numpy-1.html","id":"d-array-1","chapter":"12 numpy","heading":"12.4.3.2 1-D Array","text":"Observe shape array (5,). seems like array 5 rows, empty columns !\nreally means 5 items single dimension.","code":"arr = np.array(range(5))\nprint (arr)#:> [0 1 2 3 4]print (arr.shape)#:> (5,)print (arr.ndim)#:> 1"},{"path":"numpy-1.html","id":"d-array-2","chapter":"12 numpy","heading":"12.4.3.3 2-D Array","text":"","code":"arr = np.array([range(5),range(5,10),range(10,15)])\nprint (arr)#:> [[ 0  1  2  3  4]\n#:>  [ 5  6  7  8  9]\n#:>  [10 11 12 13 14]]print (arr.shape)#:> (3, 5)print (arr.ndim)#:> 2"},{"path":"numpy-1.html","id":"d-array---single-row","chapter":"12 numpy","heading":"12.4.3.4 2-D Array - Single Row","text":"","code":"arr = np.array([range(5)])\nprint (arr)#:> [[0 1 2 3 4]]print (arr.shape)#:> (1, 5)print (arr.ndim)#:> 2"},{"path":"numpy-1.html","id":"d-array-single-column","chapter":"12 numpy","heading":"12.4.3.5 2-D Array : Single Column","text":"Using array slicing method newaxis COLUMN, turn 1D array 2D single columnUsing array slicing method newaxis ROW, turn 1D array 2D single row","code":"arr = np.arange(5)[:, np.newaxis]\nprint (arr)#:> [[0]\n#:>  [1]\n#:>  [2]\n#:>  [3]\n#:>  [4]]print (arr.shape)#:> (5, 1)print (arr.ndim)#:> 2arr = np.arange(5)[np.newaxis,:]\nprint (arr)#:> [[0 1 2 3 4]]print (arr.shape)#:> (1, 5)print (arr.ndim)#:> 2"},{"path":"numpy-1.html","id":"class-method-3","chapter":"12 numpy","heading":"12.4.4 Class Method","text":"","code":""},{"path":"numpy-1.html","id":"arange","chapter":"12 numpy","heading":"12.4.4.1 arange()","text":"Generate array sequence numbers","code":"np.arange(10)#:> array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"},{"path":"numpy-1.html","id":"ones","chapter":"12 numpy","heading":"12.4.4.2 ones()","text":"","code":"np.ones(10)  # One dimension, default is float#:> array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])np.ones((2,5),'int')  #Two dimensions#:> array([[1, 1, 1, 1, 1],\n#:>        [1, 1, 1, 1, 1]])"},{"path":"numpy-1.html","id":"zeros","chapter":"12 numpy","heading":"12.4.4.3 zeros()","text":"","code":"np.zeros( 10 )    # One dimension, default is float#:> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])np.zeros((2,5),'int')   # 2 rows, 5 columns of ZERO#:> array([[0, 0, 0, 0, 0],\n#:>        [0, 0, 0, 0, 0]])"},{"path":"numpy-1.html","id":"where","chapter":"12 numpy","heading":"12.4.4.4 where()","text":"1D array numpy.() returns items matching criteriaOn 2D array, () return array row index col index matching elements","code":"ar1 = np.array(range(10))\nprint( ar1 )#:> [0 1 2 3 4 5 6 7 8 9]print( np.where(ar1>5) )#:> (array([6, 7, 8, 9]),)ar = np.array([(1,2,3,4,5),(11,12,13,14,15),(21,22,23,24,25)])\nprint ('Data : \\n', ar)#:> Data : \n#:>  [[ 1  2  3  4  5]\n#:>  [11 12 13 14 15]\n#:>  [21 22 23 24 25]]np.where(ar>13)#:> (array([1, 1, 2, 2, 2, 2, 2]), array([3, 4, 0, 1, 2, 3, 4]))"},{"path":"numpy-1.html","id":"logical-methods","chapter":"12 numpy","heading":"12.4.4.5 Logical Methods","text":"numpy.logical_or\nPerform operation two boolean array, generate new resulting boolean arraysnumpy.logical_and\nPerform operation two boolean array, generate new resulting boolean arrays","code":"ar = np.arange(10)\nprint( ar==3 )  # boolean array 1#:> [False False False  True False False False False False False]print( ar==6 )  # boolean array 2#:> [False False False False False False  True False False False]print( np.logical_or(ar==3,ar==6 ) ) # resulting boolean#:> [False False False  True False False  True False False False]ar = np.arange(10)\nprint( ar==3 ) # boolean array 1#:> [False False False  True False False False False False False]print( ar==6 ) # boolean array 2#:> [False False False False False False  True False False False]print( np.logical_and(ar==3,ar==6 ) )  # resulting boolean#:> [False False False False False False False False False False]"},{"path":"numpy-1.html","id":"instance-method-3","chapter":"12 numpy","heading":"12.4.5 Instance Method","text":"","code":""},{"path":"numpy-1.html","id":"astype-conversion","chapter":"12 numpy","heading":"12.4.5.1 astype() conversion","text":"Convert datetime64 datetimeAfter convert datetime (non-numpy object, dtype becomes generic ‘object’.","code":"ar1 = np.array(['2007-07-13', '2006-01-13', '2010-08-13'], dtype='datetime64')\nprint( type(ar1) )  ## a numpy array#:> <class 'numpy.ndarray'>print( ar1.dtype )  ## dtype is a numpy data type#:> datetime64[D]ar2 = ar1.astype(datetime)\nprint( type(ar2) )  ## still a numpy array#:> <class 'numpy.ndarray'>print( ar2.dtype )  ## dtype becomes generic 'object'#:> object"},{"path":"numpy-1.html","id":"reshape","chapter":"12 numpy","heading":"12.4.5.2 reshape()","text":"Sample DataResphepe 1-Dim 2-DimRespahe 2-Dim 2-DimReshape 2-Dimension 2-Dim (single row)\n- Change 2x10 1x10\n- Observe [[ ]], number dimension stll 2, don’t fooledReshape 1-Dim Array 2-Dim Array (single column)better method, use newaxis, easier need input row number parameterReshape 1-Dim Array 2-Dim Array (single row)","code":"reshape ( row numbers, col numbers )a = np.array([range(5), range(10,15), range(20,25), range(30,35)])\na#:> array([[ 0,  1,  2,  3,  4],\n#:>        [10, 11, 12, 13, 14],\n#:>        [20, 21, 22, 23, 24],\n#:>        [30, 31, 32, 33, 34]])np.arange(12) # 1-D Array#:> array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])np.arange(12).reshape(3,4)  # 2-D Array#:> array([[ 0,  1,  2,  3],\n#:>        [ 4,  5,  6,  7],\n#:>        [ 8,  9, 10, 11]])np.array([range(5), range(10,15)])  # 2-D Array#:> array([[ 0,  1,  2,  3,  4],\n#:>        [10, 11, 12, 13, 14]])np.array([range(5), range(10,15)]).reshape(5,2) # 2-D Array#:> array([[ 0,  1],\n#:>        [ 2,  3],\n#:>        [ 4, 10],\n#:>        [11, 12],\n#:>        [13, 14]])np.array( [range(0,5), range(5,10)])  # 2-D Array#:> array([[0, 1, 2, 3, 4],\n#:>        [5, 6, 7, 8, 9]])np.array( [range(0,5), range(5,10)]).reshape(1,10) # 2-D Array#:> array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])np.arange(8)#:> array([0, 1, 2, 3, 4, 5, 6, 7])np.arange(8).reshape(8,1)#:> array([[0],\n#:>        [1],\n#:>        [2],\n#:>        [3],\n#:>        [4],\n#:>        [5],\n#:>        [6],\n#:>        [7]])np.arange(8)[:,np.newaxis]#:> array([[0],\n#:>        [1],\n#:>        [2],\n#:>        [3],\n#:>        [4],\n#:>        [5],\n#:>        [6],\n#:>        [7]])np.arange(8)#:> array([0, 1, 2, 3, 4, 5, 6, 7])np.arange(8)[np.newaxis,:]#:> array([[0, 1, 2, 3, 4, 5, 6, 7]])"},{"path":"numpy-1.html","id":"element-selection","chapter":"12 numpy","heading":"12.4.6 Element Selection","text":"","code":""},{"path":"numpy-1.html","id":"sample-data-1","chapter":"12 numpy","heading":"12.4.6.1 Sample Data","text":"","code":"x1 = np.array( (0,1,2,3,4,5,6,7,8))\nx2 = np.array(( (1,2,3,4,5), \n      (11,12,13,14,15),\n      (21,22,23,24,25)))\nprint(x1)#:> [0 1 2 3 4 5 6 7 8]print(x2)#:> [[ 1  2  3  4  5]\n#:>  [11 12 13 14 15]\n#:>  [21 22 23 24 25]]"},{"path":"numpy-1.html","id":"dimension","chapter":"12 numpy","heading":"12.4.6.2 1-Dimension","text":"indexing starts 0 (1)Choosing Single Element return arraySelecting multiple elments return ndarray","code":"print( x1[0]   )  ## first element#:> 0print( x1[-1]  )  ## last element#:> 8print( x1[3]   )  ## third element from start 3#:> 3print( x1[-3]  )  ## third element from end#:> 6print( x1[:3]  )  ## first 3 elements#:> [0 1 2]print( x1[-3:])   ## last 3 elements#:> [6 7 8]print( x1[3:]  )  ## all except first 3 elements#:> [3 4 5 6 7 8]print( x1[:-3] )  ## all except last 3 elements#:> [0 1 2 3 4 5]print( x1[1:4] )  ## elemnt 1 to 4 (not including 4)#:> [1 2 3]"},{"path":"numpy-1.html","id":"dimension-1","chapter":"12 numpy","heading":"12.4.6.3 2-Dimension","text":"Indexing [ row_positoins, row_positions ], index starts 0","code":"x[1:3, 1:4] # row 1 to 2 column 1 to 3#:> array([[1, 2, 3]])"},{"path":"numpy-1.html","id":"attributes-3","chapter":"12 numpy","heading":"12.4.7 Attributes","text":"","code":""},{"path":"numpy-1.html","id":"dtype","chapter":"12 numpy","heading":"12.4.7.1 dtype","text":"ndarray contain property called dtype, whcih tell us type underlying items","code":"a = np.array( (1,2,3,4,5), dtype='float' )\na.dtype#:> dtype('float64')print(a.dtype)#:> float64print( type(a[1]))#:> <class 'numpy.float64'>"},{"path":"numpy-1.html","id":"dim","chapter":"12 numpy","heading":"12.4.7.2 dim","text":"dim returns number dimensions NumPy array. Example shows 2-D array","code":"x = np.array(( (1,2,3,4,5), \n      (11,12,13,14,15),\n      (21,22,23,24,25)))\nx.ndim  #:> 2"},{"path":"numpy-1.html","id":"shape","chapter":"12 numpy","heading":"12.4.7.3 shape","text":"shape return type (rows, cols)","code":"x = np.array(( (1,2,3,4,5), \n      (11,12,13,14,15),\n      (21,22,23,24,25)))\nx.shape  #:> (3, 5)np.identity(5)#:> array([[1., 0., 0., 0., 0.],\n#:>        [0., 1., 0., 0., 0.],\n#:>        [0., 0., 1., 0., 0.],\n#:>        [0., 0., 0., 1., 0.],\n#:>        [0., 0., 0., 0., 1.]])"},{"path":"numpy-1.html","id":"operations","chapter":"12 numpy","heading":"12.4.8 Operations","text":"","code":""},{"path":"numpy-1.html","id":"arithmetic","chapter":"12 numpy","heading":"12.4.8.1 Arithmetic","text":"Sample Date***+ -**","code":"ar = np.arange(10)\nprint( ar )#:> [0 1 2 3 4 5 6 7 8 9]ar = np.arange(10)\nprint (ar)#:> [0 1 2 3 4 5 6 7 8 9]print (ar*2)#:> [ 0  2  4  6  8 10 12 14 16 18]ar = np.arange(10)\nprint (ar+2)#:> [ 2  3  4  5  6  7  8  9 10 11]print (ar-2)#:> [-2 -1  0  1  2  3  4  5  6  7]"},{"path":"numpy-1.html","id":"comparison","chapter":"12 numpy","heading":"12.4.8.2 Comparison","text":"Sample Data==>, >=, <, <=","code":"ar = np.arange(10)\nprint( ar )#:> [0 1 2 3 4 5 6 7 8 9]print( ar==3 )#:> [False False False  True False False False False False False]print( ar>3 )#:> [False False False False  True  True  True  True  True  True]print( ar<=3 )#:> [ True  True  True  True False False False False False False]"},{"path":"numpy-1.html","id":"random-numbers","chapter":"12 numpy","heading":"12.5 Random Numbers","text":"","code":""},{"path":"numpy-1.html","id":"uniform-distribution","chapter":"12 numpy","heading":"12.5.1 Uniform Distribution","text":"","code":""},{"path":"numpy-1.html","id":"random-integer-with-replacement","chapter":"12 numpy","heading":"12.5.1.1 Random Integer (with Replacement)","text":"randint() Return random integers low (inclusive) high (exclusive)","code":"np.random.randint( low )                  # generate an integer, i, which         i < low\nnp.random.randint( low, high )            # generate an integer, i, which  low <= i < high\nnp.random.randint( low, high, size=1)     # generate an ndarray of integer, single dimension\nnp.random.randint( low, high, size=(r,c)) # generate an ndarray of integer, two dimensions np.random.randint( 10 )#:> 6np.random.randint( 10, 20 )#:> 16np.random.randint( 10, high=20, size=5)   # single dimension#:> array([15, 18, 14, 11, 13])np.random.randint( 10, 20, (3,5) )        # two dimensions#:> array([[18, 19, 14, 17, 11],\n#:>        [15, 11, 11, 19, 10],\n#:>        [12, 11, 16, 19, 10]])"},{"path":"numpy-1.html","id":"random-integer-with-or-without-replacement","chapter":"12 numpy","heading":"12.5.1.2 Random Integer (with or without replacement)","text":"","code":"numpy.random .choice( a, size, replace=True)\n # sampling from a, \n #   if a is integer, then it is assumed sampling from arange(a)\n #   if a is an 1-D array, then sampling from this arraynp.random.choice(10,5, replace=False) # take 5 samples from 0:19, without replacement#:> array([6, 0, 4, 1, 2])np.random.choice( np.arange(10,20), 5, replace=False)#:> array([11, 13, 10, 14, 15])"},{"path":"numpy-1.html","id":"random-float","chapter":"12 numpy","heading":"12.5.1.3 Random Float","text":"randf() Generate float numbers 0.0 1.0uniform() Return random float low (inclusive) high (exclusive)","code":"np.random.ranf(size=None)np.random.ranf(4)#:> array([0.34719156, 0.35147161, 0.59755853, 0.10528617])np.random.uniform( low )                  # generate an float, i, which         f < low\nnp.random.uniform( low, high )            # generate an float, i, which  low <= f < high\nnp.random.uniform( low, high, size=1)     # generate an array of float, single dimension\nnp.random.uniform( low, high, size=(r,c)) # generate an array of float, two dimensions np.random.uniform( 2 )#:> 1.633967952019189np.random.uniform( 2,5, size=(4,4) )#:> array([[2.06434886, 3.66304024, 3.52751507, 4.08096456],\n#:>        [4.19814857, 2.95277079, 3.63566489, 4.69076522],\n#:>        [2.34947052, 4.17895391, 4.49808652, 3.51828276],\n#:>        [3.67805721, 3.22648964, 3.2674474 , 2.8441559 ]])"},{"path":"numpy-1.html","id":"normal-distribution","chapter":"12 numpy","heading":"12.5.2 Normal Distribution","text":"","code":"numpy. random.randn (n_items)       # 1-D standard normal (mean=0, stdev=1)\nnumpy. random.randn (nrows, ncols)  # 2-D standard normal (mean=0, stdev=1)\nnumpy. random.standard_normal( size=None )                # default to mean = 0, stdev = 1, non-configurable\nnumpy. random.normal         ( loc=0, scale=1, size=None) # loc = mean, scale = stdev, size = dimension"},{"path":"numpy-1.html","id":"standard-normal-distribution","chapter":"12 numpy","heading":"12.5.2.1 Standard Normal Distribution","text":"Generate random normal numbers gaussion distribution (mean=0, stdev=1)One DimensionTwo DimensionsObserve: randn(), standard_normal() normal() able generate standard normal numbers","code":"np.random.standard_normal(3)#:> array([-0.29832127, -1.52835978, -1.69015261])np.random.randn(3)#:> array([-1.36143442, -1.03616391,  0.30469669])np.random.randn(2,4)#:> array([[ 0.18301414, -0.81780387,  2.33753414,  1.35667554],\n#:>        [ 1.04592906,  0.14818631,  2.3902418 , -2.07301317]])np.random.standard_normal((2,4))#:> array([[-0.83193773,  0.67788051, -0.96400219, -0.12383149],\n#:>        [ 0.95843138, -1.02865802, -0.95976146, -1.81295684]])np.random.seed(15)\nprint (np.random.randn(5))#:> [-0.31232848  0.33928471 -0.15590853 -0.50178967  0.23556889]np.random.seed(15)\nprint (np.random.normal ( size = 5 )) # stdev and mean not specified, default to standard normal#:> [-0.31232848  0.33928471 -0.15590853 -0.50178967  0.23556889]np.random.seed(15)\nprint (np.random.standard_normal (size=5))#:> [-0.31232848  0.33928471 -0.15590853 -0.50178967  0.23556889]"},{"path":"numpy-1.html","id":"normal-distribution-non-standard","chapter":"12 numpy","heading":"12.5.2.2 Normal Distribution (Non-Standard)","text":"","code":"np.random.seed(125)\nnp.random.normal( loc = 12, scale=1.25, size=(3,3))#:> array([[11.12645382, 12.01327885, 10.81651695],\n#:>        [12.41091248, 12.39383072, 11.49647195],\n#:>        [ 8.70837035, 12.25246312, 11.49084235]])"},{"path":"numpy-1.html","id":"linear-spacing","chapter":"12 numpy","heading":"12.5.2.3 Linear Spacing","text":"Include Endpoint\nStep = Gap divide (number elements minus 1) (2/(10-1))Include Endpoint\nStep = Gap divide (number elements minus 1) (2/(101))","code":"numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)\n# endpoint: If True, stop is the last sample, otherwise it is not includednp.linspace(1,3,10) #default endpont=True#:> array([1.        , 1.22222222, 1.44444444, 1.66666667, 1.88888889,\n#:>        2.11111111, 2.33333333, 2.55555556, 2.77777778, 3.        ])np.linspace(1,3,10,endpoint=False)#:> array([1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4, 2.6, 2.8])"},{"path":"numpy-1.html","id":"sampling-integer","chapter":"12 numpy","heading":"12.6 Sampling (Integer)","text":"","code":"random.choice( a, size=None, replace=True, p=None)  # a=integer, return <size> integers < a\nrandom.choice( a, size=None, replace=True, p=None)  # a=array-like, return <size> integers picked from list anp.random.choice (100, size=10)#:> array([58,  0, 84, 50, 89, 32, 87, 30, 66, 92])np.random.choice( [1,3,5,7,9,11,13,15,17,19,21,23], size=10, replace=False)#:> array([ 5,  1, 23, 17,  3, 13, 15,  9, 21,  7])"},{"path":"numpy-1.html","id":"nan-missing-numerical-data","chapter":"12 numpy","heading":"12.7 NaN : Missing Numerical Data","text":"aware NaN bit like data virus?infects object touchesRegardless operation, result arithmetic NaN another NaN","code":"t = np.array([1, np.nan, 3, 4]) \nt.dtype#:> dtype('float64')1 + np.nan#:> nant.sum(), t.mean(), t.max()#:> (nan, nan, nan)np.nansum(t), np.nanmean(t), np.nanmax(t)#:> (8.0, 2.6666666666666665, 4.0)"},{"path":"pandas-1.html","id":"pandas-1","chapter":"13 pandas","heading":"13 pandas","text":"","code":""},{"path":"pandas-1.html","id":"modules-import","chapter":"13 pandas","heading":"13.1 Modules Import","text":"","code":"import pandas as pd\n\n## Other Libraries\nimport numpy as np\nimport datetime as dt\nfrom datetime import datetime\nfrom datetime import date"},{"path":"pandas-1.html","id":"pandas-objects","chapter":"13 pandas","heading":"13.2 Pandas Objects","text":"","code":""},{"path":"pandas-1.html","id":"pandas-data-types","chapter":"13 pandas","heading":"13.2.1 Pandas Data Types","text":"pandas.Timestamppandas.Timedeltapandas.Periodpandas.Intervalpandas.DateTimeIndex","code":""},{"path":"pandas-1.html","id":"pandas-data-structure","chapter":"13 pandas","heading":"13.2.2 Pandas Data Structure","text":"data can ndarray, list, constantsindex must unique length data. Can integer string\ndtype none, inferredcopy copy data. Default false","code":""},{"path":"pandas-1.html","id":"class-method-4","chapter":"13 pandas","heading":"13.3 Class Method","text":"","code":""},{"path":"pandas-1.html","id":"creating-timestamp-objects","chapter":"13 pandas","heading":"13.3.1 Creating Timestamp Objects","text":"Pandas to_datetime() can:\n- Convert list dates DateTimeIndex\n- Convert list dates Series Timestamps\n- Convert single date Timestamp Object\n. Source can string, date, datetime object","code":""},{"path":"pandas-1.html","id":"from-list-to-datetimeindex","chapter":"13 pandas","heading":"13.3.1.1 From List to DateTimeIndex","text":"","code":"dti = pd.to_datetime(['2011-01-03',             # from string\n                       date(2018,4,13),         # from date\n                       datetime(2018,3,1,7,30)] # from datetime\n              )\nprint( dti,\n      '\\nObject Type:  ', type(dti),\n      '\\nObject dtype: ', dti.dtype,\n      '\\nElement Type: ', type(dti[1]))#:> DatetimeIndex(['2011-01-03 00:00:00', '2018-04-13 00:00:00', '2018-03-01 07:30:00'], dtype='datetime64[ns]', freq=None) \n#:> Object Type:   <class 'pandas.core.indexes.datetimes.DatetimeIndex'> \n#:> Object dtype:  datetime64[ns] \n#:> Element Type:  <class 'pandas._libs.tslibs.timestamps.Timestamp'>"},{"path":"pandas-1.html","id":"from-list-to-series-of-timestamps","chapter":"13 pandas","heading":"13.3.1.2 From List to Series of Timestamps","text":"","code":"sdt = pd.to_datetime(pd.Series(['2011-01-03',      # from string\n                                date(2018,4,13),        # from date\n                                datetime(2018,3,1,7,30)]# from datetime\n              ))\nprint(sdt,\n      '\\nObject Type:  ',type(sdt),\n      '\\nObject dtype: ', sdt.dtype,\n      '\\nElement Type: ',type(sdt[1]))#:> 0   2011-01-03 00:00:00\n#:> 1   2018-04-13 00:00:00\n#:> 2   2018-03-01 07:30:00\n#:> dtype: datetime64[ns] \n#:> Object Type:   <class 'pandas.core.series.Series'> \n#:> Object dtype:  datetime64[ns] \n#:> Element Type:  <class 'pandas._libs.tslibs.timestamps.Timestamp'>"},{"path":"pandas-1.html","id":"from-scalar-to-timestamp","chapter":"13 pandas","heading":"13.3.1.3 From Scalar to Timestamp","text":"","code":"print( pd.to_datetime('2011-01-03'), '\\n',\n       pd.to_datetime(date(2011,1,3)), '\\n',\n       pd.to_datetime(datetime(2011,1,3,5,30)), '\\n',\n       '\\nElement Type: ', type(pd.to_datetime(datetime(2011,1,3,5,30))))#:> 2011-01-03 00:00:00 \n#:>  2011-01-03 00:00:00 \n#:>  2011-01-03 05:30:00 \n#:>  \n#:> Element Type:  <class 'pandas._libs.tslibs.timestamps.Timestamp'>"},{"path":"pandas-1.html","id":"generate-timestamp-sequence","chapter":"13 pandas","heading":"13.3.2 Generate Timestamp Sequence","text":"function date_range() return DateTimeIndex object. Use Series() convert Series desired.","code":""},{"path":"pandas-1.html","id":"hourly","chapter":"13 pandas","heading":"13.3.2.1 Hourly","text":"start time specified, default 00:00:00.\nstart time specified, honored subsequent Timestamp elements.\nSpecify start end, sequence automatically distribute Timestamp according frequency.","code":"print(\n  pd.date_range('2018-01-01', periods=3, freq='H'),\n  pd.date_range(datetime(2018,1,1,12,30), periods=3, freq='H'),\n  pd.date_range(start='2018-01-03-1230', end='2018-01-03-18:30', freq='H'))#:> DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 01:00:00', '2018-01-01 02:00:00'], dtype='datetime64[ns]', freq='H') DatetimeIndex(['2018-01-01 12:30:00', '2018-01-01 13:30:00', '2018-01-01 14:30:00'], dtype='datetime64[ns]', freq='H') DatetimeIndex(['2018-01-03 12:30:00', '2018-01-03 13:30:00', '2018-01-03 14:30:00',\n#:>                '2018-01-03 15:30:00', '2018-01-03 16:30:00', '2018-01-03 17:30:00',\n#:>                '2018-01-03 18:30:00'],\n#:>               dtype='datetime64[ns]', freq='H')"},{"path":"pandas-1.html","id":"daily","chapter":"13 pandas","heading":"13.3.2.2 Daily","text":"frequency Day time specified, output date distributed.\ntime specified, output honor time.","code":"print(\n  pd.date_range(date(2018,1,2), periods=3, freq='D'),\n  pd.date_range('2018-01-01-1230', periods=4, freq='D'))#:> DatetimeIndex(['2018-01-02', '2018-01-03', '2018-01-04'], dtype='datetime64[ns]', freq='D') DatetimeIndex(['2018-01-01 12:30:00', '2018-01-02 12:30:00', '2018-01-03 12:30:00',\n#:>                '2018-01-04 12:30:00'],\n#:>               dtype='datetime64[ns]', freq='D')"},{"path":"pandas-1.html","id":"first-day-of-month","chapter":"13 pandas","heading":"13.3.2.3 First Day Of Month","text":"Use freq=MS, M stands montly, S stand Start. day specified, sequence start first day following month.","code":"print(\n  pd.date_range('2018-01', periods=4, freq='MS'),\n  pd.date_range('2018-01-09', periods=4, freq='MS'),\n  pd.date_range('2018-01-09 12:30:00', periods=4, freq='MS') )#:> DatetimeIndex(['2018-01-01', '2018-02-01', '2018-03-01', '2018-04-01'], dtype='datetime64[ns]', freq='MS') DatetimeIndex(['2018-02-01', '2018-03-01', '2018-04-01', '2018-05-01'], dtype='datetime64[ns]', freq='MS') DatetimeIndex(['2018-02-01 12:30:00', '2018-03-01 12:30:00', '2018-04-01 12:30:00',\n#:>                '2018-05-01 12:30:00'],\n#:>               dtype='datetime64[ns]', freq='MS')"},{"path":"pandas-1.html","id":"last-day-of-month","chapter":"13 pandas","heading":"13.3.2.4 Last Day of Month","text":"Sequence always starts end specified month.","code":"print(\n  pd.date_range('2018-01', periods=4, freq='M'),\n  pd.date_range('2018-01-09', periods=4, freq='M'),\n  pd.date_range('2018-01-09 12:30:00', periods=4, freq='M'))#:> DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30'], dtype='datetime64[ns]', freq='M') DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30'], dtype='datetime64[ns]', freq='M') DatetimeIndex(['2018-01-31 12:30:00', '2018-02-28 12:30:00', '2018-03-31 12:30:00',\n#:>                '2018-04-30 12:30:00'],\n#:>               dtype='datetime64[ns]', freq='M')"},{"path":"pandas-1.html","id":"frequency-table-crosstab","chapter":"13 pandas","heading":"13.3.3 Frequency Table (crosstab)","text":"crosstab returns Dataframe Object","code":"crosstab( index = <SeriesObj>, columns = <new_colName> )                # one dimension table\ncrosstab( index = <SeriesObj>, columns = <SeriesObj> )                  # two dimension table\ncrosstab( index = <SeriesObj>, columns = [<SeriesObj1>, <SeriesObj2>] ) # multi dimension table   \ncrosstab( index = <SeriesObj>, columns = <SeriesObj>, margines=True )   # add column and row margins"},{"path":"pandas-1.html","id":"sample-data-2","chapter":"13 pandas","heading":"13.3.3.1 Sample Data","text":"","code":"n = 200\ncomp = ['C' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 3x Company\ndept = ['D' + i for i in np.random.randint( 1,6, size  = n).astype(str)] # 5x Department\ngrp =  ['G' + i for i in np.random.randint( 1,3, size  = n).astype(str)] # 2x Groups\nvalue1 = np.random.normal( loc=50 , scale=5 , size = n)\nvalue2 = np.random.normal( loc=20 , scale=3 , size = n)\nvalue3 = np.random.normal( loc=5 , scale=30 , size = n)\n\nmydf = pd.DataFrame({\n    'comp':comp, \n    'dept':dept, \n    'grp': grp,\n    'value1':value1, \n    'value2':value2,\n    'value3':value3 })\nmydf.head()#:>   comp dept grp     value1     value2     value3\n#:> 0   C2   D4  G2  51.276501  23.944060 -19.453141\n#:> 1   C3   D5  G1  48.241634  19.823981   7.926569\n#:> 2   C1   D2  G2  52.025269  20.216081 -40.035628\n#:> 3   C2   D1  G1  55.582803  19.893167  40.971304\n#:> 4   C3   D5  G1  54.443123  23.286554  12.842095"},{"path":"pandas-1.html","id":"one-dimensiontable","chapter":"13 pandas","heading":"13.3.3.2 One DimensionTable","text":"","code":"## Frequency Countn For Company, Department\nprint(\n  pd.crosstab(index=mydf.comp, columns='counter'),'\\n\\n',\n  pd.crosstab(index=mydf.dept, columns='counter'))#:> col_0  counter\n#:> comp          \n#:> C1          72\n#:> C2          58\n#:> C3          70 \n#:> \n#:>  col_0  counter\n#:> dept          \n#:> D1          41\n#:> D2          41\n#:> D3          49\n#:> D4          44\n#:> D5          25"},{"path":"pandas-1.html","id":"two-dimension-table","chapter":"13 pandas","heading":"13.3.3.3 Two Dimension Table","text":"","code":"pd.crosstab(index=mydf.comp, columns=mydf.dept)#:> dept  D1  D2  D3  D4  D5\n#:> comp                    \n#:> C1    11  15  17  19  10\n#:> C2    16  14  15  10   3\n#:> C3    14  12  17  15  12"},{"path":"pandas-1.html","id":"higher-dimension-table","chapter":"13 pandas","heading":"13.3.3.4 Higher Dimension Table","text":"Crosstab header multi-levels index one column specified.Select sub-dataframe using multi-level referencing.","code":"tb = pd.crosstab(index=mydf.comp, columns=[mydf.dept, mydf.grp])\nprint( tb, '\\n\\n',\n       tb.columns )#:> dept  D1    D2    D3      D4     D5   \n#:> grp   G1 G2 G1 G2 G1  G2  G1  G2 G1 G2\n#:> comp                                  \n#:> C1     8  3  9  6  8   9   8  11  6  4\n#:> C2    11  5  5  9  5  10   4   6  0  3\n#:> C3     8  6  6  6  9   8  10   5  7  5 \n#:> \n#:>  MultiIndex([('D1', 'G1'),\n#:>             ('D1', 'G2'),\n#:>             ('D2', 'G1'),\n#:>             ('D2', 'G2'),\n#:>             ('D3', 'G1'),\n#:>             ('D3', 'G2'),\n#:>             ('D4', 'G1'),\n#:>             ('D4', 'G2'),\n#:>             ('D5', 'G1'),\n#:>             ('D5', 'G2')],\n#:>            names=['dept', 'grp'])print( 'Under D2:\\n', tb['D2'], '\\n\\n',\n       'Under D2-G2:\\n',tb['D2','G1'])#:> Under D2:\n#:>  grp   G1  G2\n#:> comp        \n#:> C1     9   6\n#:> C2     5   9\n#:> C3     6   6 \n#:> \n#:>  Under D2-G2:\n#:>  comp\n#:> C1    9\n#:> C2    5\n#:> C3    6\n#:> Name: (D2, G1), dtype: int64"},{"path":"pandas-1.html","id":"getting-margin","chapter":"13 pandas","heading":"13.3.3.5 Getting Margin","text":"Extend crosstab ‘margin=True’ sum rows/columns, presented new column/row named ‘’.","code":"tb = pd.crosstab(index=mydf.dept, columns=mydf.grp, margins=True)\ntb#:> grp    G1  G2  All\n#:> dept              \n#:> D1     27  14   41\n#:> D2     20  21   41\n#:> D3     22  27   49\n#:> D4     22  22   44\n#:> D5     13  12   25\n#:> All   104  96  200print(\n  'Row Sums:     \\n', tb.loc[:,'All'],\n  '\\n\\nColumn Sums:\\n', tb.loc['All'])#:> Row Sums:     \n#:>  dept\n#:> D1      41\n#:> D2      41\n#:> D3      49\n#:> D4      44\n#:> D5      25\n#:> All    200\n#:> Name: All, dtype: int64 \n#:> \n#:> Column Sums:\n#:>  grp\n#:> G1     104\n#:> G2      96\n#:> All    200\n#:> Name: All, dtype: int64"},{"path":"pandas-1.html","id":"getting-proportion","chapter":"13 pandas","heading":"13.3.3.6 Getting Proportion","text":"Use matrix operation divide row respective column sum.","code":"tb/tb.loc['All']#:> grp         G1        G2    All\n#:> dept                           \n#:> D1    0.259615  0.145833  0.205\n#:> D2    0.192308  0.218750  0.205\n#:> D3    0.211538  0.281250  0.245\n#:> D4    0.211538  0.229167  0.220\n#:> D5    0.125000  0.125000  0.125\n#:> All   1.000000  1.000000  1.000"},{"path":"pandas-1.html","id":"concatination","chapter":"13 pandas","heading":"13.3.4 Concatination","text":"","code":""},{"path":"pandas-1.html","id":"sample-data-3","chapter":"13 pandas","heading":"13.3.4.1 Sample Data","text":"","code":"s1 = pd.Series(['A1','A2','A3','A4'])\ns2 = pd.Series(['B1','B2','B3','B4'], name='B')\ns3 = pd.Series(['C1','C2','C3','C4'], name='C')"},{"path":"pandas-1.html","id":"column-wise","chapter":"13 pandas","heading":"13.3.4.2 Column-Wise","text":"Combinining Multiple Series New DataFrame\n- Added series 0,1,2,… column names (Series named originally)\n- None series ignored\n- axis=1 means column-wiseAdd Multiple Series Existing DataFrame\n- change original data frame column name\n- Added columns series 0,1,2,3,.. column name","code":"pd.concat([s1,s2,s3, None], axis=1)#:>     0   B   C\n#:> 0  A1  B1  C1\n#:> 1  A2  B2  C2\n#:> 2  A3  B3  C3\n#:> 3  A4  B4  C4df = pd.DataFrame({ 'A': s1, 'B': s2})\npd.concat([df,s3,s1, None],axis=1)#:>     A   B   C   0\n#:> 0  A1  B1  C1  A1\n#:> 1  A2  B2  C2  A2\n#:> 2  A3  B3  C3  A3\n#:> 3  A4  B4  C4  A4"},{"path":"pandas-1.html","id":"row-wise","chapter":"13 pandas","heading":"13.3.4.3 Row-Wise","text":"","code":""},{"path":"pandas-1.html","id":"external-data","chapter":"13 pandas","heading":"13.3.5 External Data","text":"","code":""},{"path":"pandas-1.html","id":"html_table-parser","chapter":"13 pandas","heading":"13.3.5.1 html_table Parser","text":"method require html5lib library.\n- Read web page, create list: contain one dataframes maps html table found\n- Scrap detectable html tables\n- Auto detect column header\n- Auto create index using number starting 0","code":"read_html(url)  # return list of dataframe(s) that maps to web table(s) structuredf_list = pd.read_html('https://www.malaysiastock.biz/Listed-Companies.aspx?type=S&s1=18')  ## read all tables\ndf = df_list[6]  ## get the specific table\n\nprint ('Total Table(s) Found : ', len(df_list), '\\n',\n       'First Table Found:      ',df)#:> Total Table(s) Found :  11 \n#:>  First Table Found:                0                                                  1\n#:> 0  Sector:  --- Filter by Sector ---  BOND ISLAMIC  CLOSED..."},{"path":"pandas-1.html","id":"csv-writing","chapter":"13 pandas","heading":"13.3.5.2 CSV Writing","text":"SyntaxExample shows column value containing different special character. Note pandas handles well default.file savedAll content retained reading back Pandas","code":"DataFrame.to_csv(\n  path_or_buf=None,   ## if not provided, result is returned as string\n  sep=', ', \n  na_rep='', \n  float_format=None, \n  columns=None,       ## list of columns name to write, if not provided, all columns are written\n  header=True,        ## write out column names\n  index=True,         ## write row label\n  index_label=None, \n  mode='w', \n  encoding=None,      ## if not provided, default to 'utf-8'\n  quoting=None, quotechar='\"', \n  line_terminator=None, \n  chunksize=None, \n  date_format=None, \n  doublequote=True, \n  escapechar=None, \n  decimal='.')\nmydf = pd.DataFrame({'Id':[10,20,30,40], \n                     'Name':  ['Aaa','Bbb','Ccc','Ddd'],\n                     'Funny': [\"world's most \\clever\", \n                     \"Bloody, damn, good\", \n                     \"many\\nmany\\nline\", \n                     'Quoting \"is\" tough']})\nmydf.set_index('Id', inplace=True)\nmydf.to_csv('data/csv_test.csv', index=True)\nmydf#:>    Name                 Funny\n#:> Id                           \n#:> 10  Aaa  world's most \\clever\n#:> 20  Bbb    Bloody, damn, good\n#:> 30  Ccc      many\\nmany\\nline\n#:> 40  Ddd    Quoting \"is\" tough\n# system('more data\\\\csv_test.csv')pd.read_csv('data/csv_test.csv', index_col='Id')#:>    Name                 Funny\n#:> Id                           \n#:> 10  Aaa  world's most \\clever\n#:> 20  Bbb    Bloody, damn, good\n#:> 30  Ccc      many\\nmany\\nline\n#:> 40  Ddd    Quoting \"is\" tough"},{"path":"pandas-1.html","id":"csv-reading","chapter":"13 pandas","heading":"13.3.5.3 CSV Reading","text":"SyntaxRefer full codec Python Codec.Default Importindex sequence integer 0,1,2…two data types detection; number (float64/int64) string (object)date parsed, hence stayed stringSpecify Data TypesTo customize data type, use dtype parameter dict definition.Parse DatetimeYou can specify multiple date-alike column parsingParse Datetime, Set Index\n- Specify names date column parse_dates=\n- date set index, type DateTimeIndex","code":"pandas.read_csv( \n    'url or filePath',                     # path to file or url \n    encoding    = 'utf_8',                 # optional: default is 'utf_8'\n    index_col   = ['colName1', ...],       # optional: specify one or more index column\n    parse_dates = ['dateCol1', ...],       # optional: specify multiple string column to convert to date\n    na_values   = ['.','na','NA','N/A'],   # optional: values that is considered NA\n    names       = ['newColName1', ... ],   # optional: overwrite column names\n    thousands   = '.',                     # optional: thousand seperator symbol\n    nrows       = n,                       # optional: load only first n rows\n    skiprows    = 0,                       # optional: don't load first n rows\n    parse_dates = False,                   # List of date column names\n    infer_datetime_format = False          # automatically parse dates\n)goo = pd.read_csv('data/goog.csv', encoding='utf_8')\nprint(goo.head(), '\\n\\n',\n      goo.info())#:> <class 'pandas.core.frame.DataFrame'>\n#:> RangeIndex: 61 entries, 0 to 60\n#:> Data columns (total 6 columns):\n#:>  #   Column  Non-Null Count  Dtype  \n#:> ---  ------  --------------  -----  \n#:>  0   Date    61 non-null     object \n#:>  1   Open    61 non-null     float64\n#:>  2   High    61 non-null     float64\n#:>  3   Low     61 non-null     float64\n#:>  4   Close   61 non-null     float64\n#:>  5   Volume  61 non-null     int64  \n#:> dtypes: float64(4), int64(1), object(1)\n#:> memory usage: 3.0+ KB\n#:>          Date        Open        High         Low       Close   Volume\n#:> 0  12/19/2016  790.219971  797.659973  786.270020  794.200012  1225900\n#:> 1  12/20/2016  796.760010  798.650024  793.270020  796.419983   925100\n#:> 2  12/21/2016  795.840027  796.676025  787.099976  794.559998  1208700\n#:> 3  12/22/2016  792.359985  793.320007  788.580017  791.260010   969100\n#:> 4  12/23/2016  790.900024  792.739990  787.280029  789.909973   623400 \n#:> \n#:>  Noned_types = {'Volume': str}\npd.read_csv('data/goog.csv', dtype=d_types).info()#:> <class 'pandas.core.frame.DataFrame'>\n#:> RangeIndex: 61 entries, 0 to 60\n#:> Data columns (total 6 columns):\n#:>  #   Column  Non-Null Count  Dtype  \n#:> ---  ------  --------------  -----  \n#:>  0   Date    61 non-null     object \n#:>  1   Open    61 non-null     float64\n#:>  2   High    61 non-null     float64\n#:>  3   Low     61 non-null     float64\n#:>  4   Close   61 non-null     float64\n#:>  5   Volume  61 non-null     object \n#:> dtypes: float64(4), object(2)\n#:> memory usage: 3.0+ KBpd.read_csv('data/goog.csv', parse_dates=['Date']).info()#:> <class 'pandas.core.frame.DataFrame'>\n#:> RangeIndex: 61 entries, 0 to 60\n#:> Data columns (total 6 columns):\n#:>  #   Column  Non-Null Count  Dtype         \n#:> ---  ------  --------------  -----         \n#:>  0   Date    61 non-null     datetime64[ns]\n#:>  1   Open    61 non-null     float64       \n#:>  2   High    61 non-null     float64       \n#:>  3   Low     61 non-null     float64       \n#:>  4   Close   61 non-null     float64       \n#:>  5   Volume  61 non-null     int64         \n#:> dtypes: datetime64[ns](1), float64(4), int64(1)\n#:> memory usage: 3.0 KBgoo3 = pd.read_csv('data/goog.csv',index_col='Date', parse_dates=['Date'])\ngoo3.info()#:> <class 'pandas.core.frame.DataFrame'>\n#:> DatetimeIndex: 61 entries, 2016-12-19 to 2017-03-17\n#:> Data columns (total 5 columns):\n#:>  #   Column  Non-Null Count  Dtype  \n#:> ---  ------  --------------  -----  \n#:>  0   Open    61 non-null     float64\n#:>  1   High    61 non-null     float64\n#:>  2   Low     61 non-null     float64\n#:>  3   Close   61 non-null     float64\n#:>  4   Volume  61 non-null     int64  \n#:> dtypes: float64(4), int64(1)\n#:> memory usage: 2.9 KB"},{"path":"pandas-1.html","id":"inspection","chapter":"13 pandas","heading":"13.3.6 Inspection","text":"","code":""},{"path":"pandas-1.html","id":"structure-info","chapter":"13 pandas","heading":"13.3.6.1 Structure info","text":"info() function print information screen. doesn’t return object","code":"dataframe.info()  # display columns and number of rows (that has no missing data)goo.info()#:> <class 'pandas.core.frame.DataFrame'>\n#:> RangeIndex: 61 entries, 0 to 60\n#:> Data columns (total 6 columns):\n#:>  #   Column  Non-Null Count  Dtype  \n#:> ---  ------  --------------  -----  \n#:>  0   Date    61 non-null     object \n#:>  1   Open    61 non-null     float64\n#:>  2   High    61 non-null     float64\n#:>  3   Low     61 non-null     float64\n#:>  4   Close   61 non-null     float64\n#:>  5   Volume  61 non-null     int64  \n#:> dtypes: float64(4), int64(1), object(1)\n#:> memory usage: 3.0+ KB"},{"path":"pandas-1.html","id":"head","chapter":"13 pandas","heading":"13.3.6.2 head","text":"","code":"goo.head()#:>          Date        Open        High         Low       Close   Volume\n#:> 0  12/19/2016  790.219971  797.659973  786.270020  794.200012  1225900\n#:> 1  12/20/2016  796.760010  798.650024  793.270020  796.419983   925100\n#:> 2  12/21/2016  795.840027  796.676025  787.099976  794.559998  1208700\n#:> 3  12/22/2016  792.359985  793.320007  788.580017  791.260010   969100\n#:> 4  12/23/2016  790.900024  792.739990  787.280029  789.909973   623400"},{"path":"pandas-1.html","id":"class-timestamp","chapter":"13 pandas","heading":"13.4 class: Timestamp","text":"enhanced version datetime standard library.https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html#pandas.Timestamp","code":""},{"path":"pandas-1.html","id":"constructor-8","chapter":"13 pandas","heading":"13.4.1 Constructor","text":"","code":""},{"path":"pandas-1.html","id":"from-number","chapter":"13 pandas","heading":"13.4.1.1 From Number","text":"","code":"print( pd.Timestamp(year=2017, month=1, day=1),'\\n',  #date-like numbers\n       pd.Timestamp(2017,1,1), '\\n',                  # date-like numbers\n       pd.Timestamp(2017,12,11,5,45),'\\n',            # datetime-like numbers\n       pd.Timestamp(2017,12,11,5,45,55,999),'\\n',     # + microseconds\n       pd.Timestamp(2017,12,11,5,45,55,999,8),'\\n',   # + nanoseconds\n       type(pd.Timestamp(2017,12,11,5,45,55,999,8)),'\\n')#:> 2017-01-01 00:00:00 \n#:>  2017-01-01 00:00:00 \n#:>  2017-12-11 05:45:00 \n#:>  2017-12-11 05:45:55.000999 \n#:>  2017-12-11 05:45:55.000999008 \n#:>  <class 'pandas._libs.tslibs.timestamps.Timestamp'>"},{"path":"pandas-1.html","id":"from-string","chapter":"13 pandas","heading":"13.4.1.2 From String","text":"Observe pandas support many string input formatYear Month Day, default timezoneYMD Hour Minute Second MsWith Timezone can included various ways.","code":"print( pd.Timestamp('2017-12-11'),'\\n',   # date-like string: year-month-day\n       pd.Timestamp('2017 12 11'),'\\n',   # date-like string: year-month-day\n       pd.Timestamp('2017 Dec 11'),'\\n',  # date-like string: year-month-day\n       pd.Timestamp('Dec 11, 2017'))      # date-like string: year-month-day#:> 2017-12-11 00:00:00 \n#:>  2017-12-11 00:00:00 \n#:>  2017-12-11 00:00:00 \n#:>  2017-12-11 00:00:00print( pd.Timestamp('2017-12-11 0545'),'\\n',     ## hour minute\n       pd.Timestamp('2017-12-11-05:45'),'\\n',\n       pd.Timestamp('2017-12-11T0545'),'\\n',\n       pd.Timestamp('2017-12-11 054533'),'\\n',   ## hour minute seconds\n       pd.Timestamp('2017-12-11 05:45:33'))#:> 2017-12-11 05:45:00 \n#:>  2017-12-11 05:45:00 \n#:>  2017-12-11 05:45:00 \n#:>  2017-12-11 05:45:33 \n#:>  2017-12-11 05:45:33print( pd.Timestamp('2017-01-01T0545Z'),'\\n',  # GMT \n       pd.Timestamp('2017-01-01T0545+9'),'\\n', # GMT+9\n       pd.Timestamp('2017-01-01T0545+0800'),'\\n',   # GMT+0800\n       pd.Timestamp('2017-01-01 0545', tz='Asia/Singapore'),'\\n')#:> 2017-01-01 05:45:00+00:00 \n#:>  2017-01-01 05:45:00+09:00 \n#:>  2017-01-01 05:45:00+08:00 \n#:>  2017-01-01 05:45:00+08:00"},{"path":"pandas-1.html","id":"from-standard-library-datetime-and-date-object","chapter":"13 pandas","heading":"13.4.1.3 From Standard Library datetime and date Object","text":"","code":"print( pd.Timestamp(date(2017,3,5)),'\\n',           # from date\n       pd.Timestamp(datetime(2017,3,5,4,30)),'\\n',  # from datetime\n       pd.Timestamp(datetime(2017,3,5,4,30), tz='Asia/Kuala_Lumpur')) # from datetime, + tz#:> 2017-03-05 00:00:00 \n#:>  2017-03-05 04:30:00 \n#:>  2017-03-05 04:30:00+08:00"},{"path":"pandas-1.html","id":"attributes-4","chapter":"13 pandas","heading":"13.4.2 Attributes","text":"can tell many things Timestamp object.Note timezone (tz) pytz object.","code":"ts = pd.Timestamp('2017-01-01T054533+0800') # GMT+0800\nprint( ts.month, '\\n',\n       ts.day, '\\n',\n       ts.year, '\\n',\n       ts.hour, '\\n',\n       ts.minute, '\\n',\n       ts.second, '\\n',\n       ts.microsecond, '\\n',\n       ts.nanosecond, '\\n',\n       ts.tz, '\\n',\n       ts.daysinmonth,'\\n',\n       ts.dayofyear, '\\n',\n       ts.is_leap_year, '\\n',\n       ts.is_month_end, '\\n',\n       ts.is_month_start, '\\n',\n       ts.dayofweek)#:> 1 \n#:>  1 \n#:>  2017 \n#:>  5 \n#:>  45 \n#:>  33 \n#:>  0 \n#:>  0 \n#:>  pytz.FixedOffset(480) \n#:>  31 \n#:>  1 \n#:>  False \n#:>  False \n#:>  True \n#:>  6ts1 = pd.Timestamp(datetime(2017,3,5,4,30), tz='Asia/Kuala_Lumpur')   # from datetime, + tz\nts2 = pd.Timestamp('2017-01-01T054533+0800') # GMT+0800\nts3 = pd.Timestamp('2017-01-01T0545')\n\nprint( ts1.tz, 'Type:', type(ts1.tz), '\\n',\n       ts2.tz, 'Type:', type(ts2.tz), '\\n',\n       ts3.tz, 'Type:', type(ts3.tz)  )#:> Asia/Kuala_Lumpur Type: <class 'pytz.tzfile.Asia/Kuala_Lumpur'> \n#:>  pytz.FixedOffset(480) Type: <class 'pytz._FixedOffset'> \n#:>  None Type: <class 'NoneType'>"},{"path":"pandas-1.html","id":"instance-methods-1","chapter":"13 pandas","heading":"13.4.3 Instance Methods","text":"","code":""},{"path":"pandas-1.html","id":"atribute-like-methods","chapter":"13 pandas","heading":"13.4.3.1 Atribute-like Methods","text":"","code":"ts = pd.Timestamp(2017,1,1)\nprint( ' Weekday:    ', ts.weekday(), '\\n',\n       'ISO Weekday:',  ts.isoweekday(), '\\n',\n       'Day Name:   ',  ts.day_name(), '\\n',\n       'ISO Calendar:',  ts.isocalendar()\n       )#:>  Weekday:     6 \n#:>  ISO Weekday: 7 \n#:>  Day Name:    Sunday \n#:>  ISO Calendar: (2016, 52, 7)"},{"path":"pandas-1.html","id":"timezones","chapter":"13 pandas","heading":"13.4.3.2 Timezones","text":"Adding Timezones Clock Shiftingtz_localize add timezone, however shift clock.timestamp gotten timezone, can easily shift clock another timezone using tz_convert()Removing TimezoneJust apply None tz_localize remove TZ infomration.","code":"ts = pd.Timestamp(2017,1,10,10,34)        ## No timezone\nts1 = ts.tz_localize('Asia/Kuala_Lumpur')  ## Add timezone\nts2 = ts1.tz_convert('UTC')                 ## Convert timezone\nprint(' Origininal Timestamp           :', ts,  '\\n',\n      'Loacalized Timestamp (added TZ):', ts1, '\\n',\n      'Converted Timestamp (shifted)  :',ts2)#:>  Origininal Timestamp           : 2017-01-10 10:34:00 \n#:>  Loacalized Timestamp (added TZ): 2017-01-10 10:34:00+08:00 \n#:>  Converted Timestamp (shifted)  : 2017-01-10 02:34:00+00:00ts = pd.Timestamp(2017,1,10,10,34)        ## No timezone\nts = ts.tz_localize('Asia/Kuala_Lumpur')  ## Add timezone\nts = ts.tz_localize(None)                 ## Convert timezone\nts#:> Timestamp('2017-01-10 10:34:00')"},{"path":"pandas-1.html","id":"formatting","chapter":"13 pandas","heading":"13.4.3.3 Formatting","text":"strftimeUse strftime() customize string format. complete directive, see : https://docs.python.org/3/library/datetime.html#strftime-strptime-behaviorisoformatUse isoformat() format ISO string (without timezone)","code":"ts = pd.Timestamp(2017,1,10,10,34)        ## No timezone\nts = ts.tz_localize('Asia/Kuala_Lumpur')  ## Add timezone\nts.strftime(\"%m/%d\")#:> '01/10'ts = pd.Timestamp(2017,1,10,10,34)        \nts1 = ts.tz_localize('Asia/Kuala_Lumpur') \nprint( ' ISO Format without TZ:', ts.isoformat(), '\\n',\n       'ISO Format with TZ   :', ts1.isoformat())#:>  ISO Format without TZ: 2017-01-10T10:34:00 \n#:>  ISO Format with TZ   : 2017-01-10T10:34:00+08:00"},{"path":"pandas-1.html","id":"type-conversion","chapter":"13 pandas","heading":"13.4.3.4 Type Conversion","text":"Convert datetime.datetime/dateUse to_pydatetime() convert standard library datetime.datetime. ‘datetime’ object, apply date() get datetime.dateConvert numpy.datetime64Use to_datetime64() convert numpy.datetime64","code":"ts = pd.Timestamp(2017,1,10,7,30,52)\nprint(\n  'Datetime:',  ts.to_pydatetime(), '\\n',\n  'Date Only:', ts.to_pydatetime().date())#:> Datetime: 2017-01-10 07:30:52 \n#:>  Date Only: 2017-01-10ts = pd.Timestamp(2017,1,10,7,30,52)\nts.to_datetime64()#:> numpy.datetime64('2017-01-10T07:30:52.000000000')"},{"path":"pandas-1.html","id":"ceil","chapter":"13 pandas","heading":"13.4.3.5 ceil","text":"","code":"print( ts.ceil(freq='D') ) # ceiling to day#:> 2017-01-11 00:00:00"},{"path":"pandas-1.html","id":"updating","chapter":"13 pandas","heading":"13.4.3.6 Updating","text":"replace()","code":"ts.replace(year=2000, month=1,day=1)#:> Timestamp('2000-01-01 07:30:52')"},{"path":"pandas-1.html","id":"class-datetimeindex","chapter":"13 pandas","heading":"13.5 class: DateTimeIndex","text":"","code":""},{"path":"pandas-1.html","id":"creating-1","chapter":"13 pandas","heading":"13.5.1 Creating","text":"Refer Pandas class method .","code":""},{"path":"pandas-1.html","id":"instance-method-4","chapter":"13 pandas","heading":"13.5.2 Instance Method","text":"","code":""},{"path":"pandas-1.html","id":"data-type-conversion","chapter":"13 pandas","heading":"13.5.2.1 Data Type Conversion","text":"Convert datetime.datetime\nUse to_pydatetime convert python standard datetime.datetime object","code":"print('Converted to List:', dti.to_pydatetime(), '\\n\\n',\n      'Converted Type:',    type(dti.to_pydatetime()))#:> Converted to List: [datetime.datetime(2011, 1, 3, 0, 0) datetime.datetime(2018, 4, 13, 0, 0)\n#:>  datetime.datetime(2018, 3, 1, 7, 30)] \n#:> \n#:>  Converted Type: <class 'numpy.ndarray'>"},{"path":"pandas-1.html","id":"structure-conversion","chapter":"13 pandas","heading":"13.5.2.2 Structure Conversion","text":"Convert Series: to_series\ncreates Series index data valueConvert DataFrame: to_frame()\nconvert single column DataFrame index value","code":"#dti = pd.date_range('2018-02', periods=4, freq='M')\ndti.to_series()#:> 2011-01-03 00:00:00   2011-01-03 00:00:00\n#:> 2018-04-13 00:00:00   2018-04-13 00:00:00\n#:> 2018-03-01 07:30:00   2018-03-01 07:30:00\n#:> dtype: datetime64[ns]dti.to_frame()#:>                                       0\n#:> 2011-01-03 00:00:00 2011-01-03 00:00:00\n#:> 2018-04-13 00:00:00 2018-04-13 00:00:00\n#:> 2018-03-01 07:30:00 2018-03-01 07:30:00"},{"path":"pandas-1.html","id":"attributes-5","chapter":"13 pandas","heading":"13.5.3 Attributes","text":"Timestamp Attributes can used upon DateTimeIndex.","code":"print( dti.weekday, '\\n',\n       dti.month, '\\n',\n       dti.daysinmonth)#:> Int64Index([0, 4, 3], dtype='int64') \n#:>  Int64Index([1, 4, 3], dtype='int64') \n#:>  Int64Index([31, 30, 31], dtype='int64')"},{"path":"pandas-1.html","id":"class-series","chapter":"13 pandas","heading":"13.6 class: Series","text":"Series allows different data types (object class) element","code":"pandas.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n- data array-like, iterable, dict or scalar\n- If dtype not specified, it will infer from data."},{"path":"pandas-1.html","id":"constructor-9","chapter":"13 pandas","heading":"13.6.1 Constructor","text":"","code":""},{"path":"pandas-1.html","id":"empty-series","chapter":"13 pandas","heading":"13.6.1.1 Empty Series","text":"Passing data constructor result empty series. default, empty series dtype float.","code":"s = pd.Series(dtype='object')\nprint (s, '\\n',\n       type(s))#:> Series([], dtype: object) \n#:>  <class 'pandas.core.series.Series'>"},{"path":"pandas-1.html","id":"from-scalar","chapter":"13 pandas","heading":"13.6.1.2 From Scalar","text":"data scalar value, index must provided. value repeated match length index","code":"pd.Series( 99, index = ['a','b','c','d'])#:> a    99\n#:> b    99\n#:> c    99\n#:> d    99\n#:> dtype: int64"},{"path":"pandas-1.html","id":"from-array-like","chapter":"13 pandas","heading":"13.6.1.3 From array-like","text":"listFrom numpy.array\nindex specified, default 0 continue incrementallyFrom DateTimeIndex","code":"pd.Series(['a','b','c','d','e'])           # from Python list#:> 0    a\n#:> 1    b\n#:> 2    c\n#:> 3    d\n#:> 4    e\n#:> dtype: objectpd.Series(np.array(['a','b','c','d','e']))#:> 0    a\n#:> 1    b\n#:> 2    c\n#:> 3    d\n#:> 4    e\n#:> dtype: objectpd.Series(pd.date_range('2011-1-1','2011-1-3'))#:> 0   2011-01-01\n#:> 1   2011-01-02\n#:> 2   2011-01-03\n#:> dtype: datetime64[ns]"},{"path":"pandas-1.html","id":"from-dictionary","chapter":"13 pandas","heading":"13.6.1.4 From Dictionary","text":"dictionary key index. Order sorted.index sequence specifeid, Series forllow index order\nObjerve missing data (index without value) marked NaN","code":"pd.Series({'a' : 0., 'c' : 5., 'b' : 2.})#:> a    0.0\n#:> c    5.0\n#:> b    2.0\n#:> dtype: float64pd.Series({'a' : 0., 'c' : 1., 'b' : 2.},index = ['a','b','c','d'])#:> a    0.0\n#:> b    2.0\n#:> c    1.0\n#:> d    NaN\n#:> dtype: float64"},{"path":"pandas-1.html","id":"specify-index","chapter":"13 pandas","heading":"13.6.1.5 Specify Index","text":"","code":"pd.Series(['a','b','c','d','e'], index=[10,20,30,40,50])#:> 10    a\n#:> 20    b\n#:> 30    c\n#:> 40    d\n#:> 50    e\n#:> dtype: object"},{"path":"pandas-1.html","id":"mix-element-types","chapter":"13 pandas","heading":"13.6.1.6 Mix Element Types","text":"dType ‘object’ mixture classes","code":"ser = pd.Series(['a',1,2,3])\nprint('Object Type :  ', type(ser),'\\n',\n      'Object dType:  ', ser.dtype,'\\n',\n      'Element 1 Type: ',type(ser[0]),'\\n',\n      'Elmeent 2 Type: ',type(ser[1]))#:> Object Type :   <class 'pandas.core.series.Series'> \n#:>  Object dType:   object \n#:>  Element 1 Type:  <class 'str'> \n#:>  Elmeent 2 Type:  <class 'int'>"},{"path":"pandas-1.html","id":"specify-data-types","chapter":"13 pandas","heading":"13.6.1.7 Specify Data Types","text":"default, dtype inferred data.","code":"ser1 = pd.Series([1,2,3])\nser2 = pd.Series([1,2,3], dtype=\"int8\")\nser3 = pd.Series([1,2,3], dtype=\"object\")\n\nprint(' Inferred:        ',ser1.dtype, '\\n',\n      'Specified int8:  ',ser2.dtype, '\\n',\n      'Specified object:',ser3.dtype)#:>  Inferred:         int64 \n#:>  Specified int8:   int8 \n#:>  Specified object: object"},{"path":"pandas-1.html","id":"accessing-series","chapter":"13 pandas","heading":"13.6.2 Accessing Series","text":"","code":"series     ( single/list/range_of_row_label/number ) # can cause confusion\nseries.loc ( single/list/range_of_row_label )\nseries.iloc( single/list/range_of_row_number )"},{"path":"pandas-1.html","id":"sample-data-4","chapter":"13 pandas","heading":"13.6.2.1 Sample Data","text":"","code":"s = pd.Series([1,2,3,4,5],index=['a','b','c','d','e']) \ns#:> a    1\n#:> b    2\n#:> c    3\n#:> d    4\n#:> e    5\n#:> dtype: int64"},{"path":"pandas-1.html","id":"by-row-numbers","chapter":"13 pandas","heading":"13.6.2.2 by Row Number(s)","text":"Single Item.\nNotice inputing number list number give different result.Multiple ItemsRange (First 3)Range (Last 3)Range ()","code":"print( 'Referencing by number:',s.iloc[1],'\\n\\n',\n       '\\nReferencing by list of number:\\n',s.iloc[[1]])#:> Referencing by number: 2 \n#:> \n#:>  \n#:> Referencing by list of number:\n#:>  b    2\n#:> dtype: int64s.iloc[[1,3]] #:> b    2\n#:> d    4\n#:> dtype: int64s.iloc[:3]#:> a    1\n#:> b    2\n#:> c    3\n#:> dtype: int64s.iloc[-3:]#:> c    3\n#:> d    4\n#:> e    5\n#:> dtype: int64s.iloc[2:3]#:> c    3\n#:> dtype: int64"},{"path":"pandas-1.html","id":"by-indexes","chapter":"13 pandas","heading":"13.6.2.3 by Index(es)","text":"Single Label. Notice difference referencing input: single index list index.Warning: index invalid, result error.Multiple LabelsIf index found, return NaN** Range Labels **","code":"print( s.loc['c'], '\\n',\n       s[['c']])#:> 3 \n#:>  c    3\n#:> dtype: int64# error: missing labels no longer supported\ns.loc[['k','c']]s.loc['b':'d']#:> b    2\n#:> c    3\n#:> d    4\n#:> dtype: int64"},{"path":"pandas-1.html","id":"filtering","chapter":"13 pandas","heading":"13.6.2.4 Filtering","text":"Use logical array filterUse \nmethod application -idiom. element calling Series, cond True element used; otherwise used.","code":"s = pd.Series(range(1,8))\ns[s<5]#:> 0    1\n#:> 1    2\n#:> 2    3\n#:> 3    4\n#:> dtype: int64.where(cond, other=nan, inplace=False)print(s.where(s<4),'\\n\\n',\n      s.where(s<4,other=None) )#:> 0    1.0\n#:> 1    2.0\n#:> 2    3.0\n#:> 3    NaN\n#:> 4    NaN\n#:> 5    NaN\n#:> 6    NaN\n#:> dtype: float64 \n#:> \n#:>  0       1\n#:> 1       2\n#:> 2       3\n#:> 3    None\n#:> 4    None\n#:> 5    None\n#:> 6    None\n#:> dtype: object"},{"path":"pandas-1.html","id":"updating-series","chapter":"13 pandas","heading":"13.6.3 Updating Series","text":"","code":""},{"path":"pandas-1.html","id":"by-row-numbers-1","chapter":"13 pandas","heading":"13.6.3.1 by Row Number(s)","text":"","code":"s = pd.Series(range(1,7), index=['a','b','c','d','e','f'])\ns[2] = 999\ns[[3,4]] = 888,777\ns#:> a      1\n#:> b      2\n#:> c    999\n#:> d    888\n#:> e    777\n#:> f      6\n#:> dtype: int64"},{"path":"pandas-1.html","id":"by-indexes-1","chapter":"13 pandas","heading":"13.6.3.2 by Index(es)","text":"","code":"s = pd.Series(range(1,7), index=['a','b','c','d','e','f'])\ns['e'] = 888\ns[['c','d']] = 777,888\ns#:> a      1\n#:> b      2\n#:> c    777\n#:> d    888\n#:> e    888\n#:> f      6\n#:> dtype: int64"},{"path":"pandas-1.html","id":"series-attributes","chapter":"13 pandas","heading":"13.6.4 Series Attributes","text":"","code":""},{"path":"pandas-1.html","id":"the-data","chapter":"13 pandas","heading":"13.6.4.1 The Data","text":"","code":"s = pd.Series([1,2,3,4,5],index=['a','b','c','d','e'],name='SuperHero') \ns#:> a    1\n#:> b    2\n#:> c    3\n#:> d    4\n#:> e    5\n#:> Name: SuperHero, dtype: int64"},{"path":"pandas-1.html","id":"the-attributes","chapter":"13 pandas","heading":"13.6.4.2 The Attributes","text":"","code":"print( ' Series Index:    ',s.index, '\\n',\n       'Series dType:    ', s.dtype, '\\n',\n       'Series Size:     ', s.size, '\\n',\n       'Series Shape:    ', s.shape, '\\n',\n       'Series Dimension:', s.ndim)#:>  Series Index:     Index(['a', 'b', 'c', 'd', 'e'], dtype='object') \n#:>  Series dType:     int64 \n#:>  Series Size:      5 \n#:>  Series Shape:     (5,) \n#:>  Series Dimension: 1"},{"path":"pandas-1.html","id":"instance-methods-2","chapter":"13 pandas","heading":"13.6.5 Instance Methods","text":"","code":""},{"path":"pandas-1.html","id":"index-manipulation","chapter":"13 pandas","heading":"13.6.5.1 Index Manipulation","text":".rename_axis().reset_index()Resetting index :\n- Convert index normal column, column named ‘index’\n- Index renumbered 1,2,3\n- Return DataFrame (became two columns)","code":"s.rename_axis('haribulan')#:> haribulan\n#:> a    1\n#:> b    2\n#:> c    3\n#:> d    4\n#:> e    5\n#:> Name: SuperHero, dtype: int64s.reset_index()#:>   index  SuperHero\n#:> 0     a          1\n#:> 1     b          2\n#:> 2     c          3\n#:> 3     d          4\n#:> 4     e          5"},{"path":"pandas-1.html","id":"structure-conversion-1","chapter":"13 pandas","heading":"13.6.5.2 Structure Conversion","text":"series structure contain value (numpy array), dtype (data type numpy array).Use values retrieve `numpy.ndarray. Use dtype understand data type.Convert List using .tolist()","code":"s = pd.Series([1,2,3,4,5])\nprint(' Series value:      ', s.values, '\\n', \n      'Series value type: ',  type(s.values), '\\n',\n      'Series dtype:      ',  s.dtype)#:>  Series value:       [1 2 3 4 5] \n#:>  Series value type:  <class 'numpy.ndarray'> \n#:>  Series dtype:       int64pd.Series.tolist(s)#:> [1, 2, 3, 4, 5]"},{"path":"pandas-1.html","id":"datatype-conversion","chapter":"13 pandas","heading":"13.6.5.3 DataType Conversion","text":"Use astype() convert another numpy supproted datatypes, results new Series.Warning: casting incompatible type result error","code":"s.astype('int8')#:> 0    1\n#:> 1    2\n#:> 2    3\n#:> 3    4\n#:> 4    5\n#:> dtype: int8"},{"path":"pandas-1.html","id":"series-operators","chapter":"13 pandas","heading":"13.6.6 Series Operators","text":"result applying operator (arithmetic logic) Series object returns new Series object","code":""},{"path":"pandas-1.html","id":"arithmetic-operator","chapter":"13 pandas","heading":"13.6.6.1 Arithmetic Operator","text":"Apply One Series ObjectApply Two Series Objects","code":"s1 = pd.Series( [100,200,300,400,500] )\ns2 = pd.Series( [10, 20, 30, 40, 50] )s1 - 100#:> 0      0\n#:> 1    100\n#:> 2    200\n#:> 3    300\n#:> 4    400\n#:> dtype: int64s1 - s2#:> 0     90\n#:> 1    180\n#:> 2    270\n#:> 3    360\n#:> 4    450\n#:> dtype: int64"},{"path":"pandas-1.html","id":"logic-operator","chapter":"13 pandas","heading":"13.6.6.2 Logic Operator","text":"Apply logic operator Series return new Series boolean resultThis can used Series DataFrame filtering","code":"bs = pd.Series(range(0,10))\nbs>3#:> 0    False\n#:> 1    False\n#:> 2    False\n#:> 3    False\n#:> 4     True\n#:> 5     True\n#:> 6     True\n#:> 7     True\n#:> 8     True\n#:> 9     True\n#:> dtype: bool~((bs>3) & (bs<8) | (bs>7))#:> 0     True\n#:> 1     True\n#:> 2     True\n#:> 3     True\n#:> 4    False\n#:> 5    False\n#:> 6    False\n#:> 7    False\n#:> 8    False\n#:> 9    False\n#:> dtype: bool"},{"path":"pandas-1.html","id":"series-.str-accesor","chapter":"13 pandas","heading":"13.6.7 Series .str Accesor","text":"underlying data str type, pandas exposed various properties methos str accessor.Available FunctionsNearly Python’s built-string methods mirrored Pandas vectorized string method. list Pandas str methods mirror Python string methods:len() lower() translate() islower()\nljust() upper() startswith() isupper()\nrjust() find() endswith() isnumeric()\ncenter() rfind() isalnum() isdecimal()\nzfill() index() isalpha() split()\nstrip() rindex() isdigit() rsplit()\nrstrip() capitalize() isspace() partition()\nlstrip() swapcase() istitle() rpartition()","code":"SeriesObj.str.operatorFunction()"},{"path":"pandas-1.html","id":"regex-extractor","chapter":"13 pandas","heading":"13.6.7.1 Regex Extractor","text":"Extract capture groups regex pattern, default DataFrame (expand=True).ouptut single columne, use expand=False make result Series, instead DataFrame.","code":"Series.str.extract(self, pat, flags=0, expand=True)\n- expand=True: if result is single column, make it a Series instead of Dataframe.s = pd.Series(['a1', 'b2', 'c3'])\nprint( \n  ' Extracted Dataframe:\\n', s.str.extract(r'([ab])(\\d)'),'\\n\\n',\n  'Extracted Dataframe witn Names:\\n', s.str.extract(r'(?P<Letter>[ab])(\\d)'))#:>  Extracted Dataframe:\n#:>       0    1\n#:> 0    a    1\n#:> 1    b    2\n#:> 2  NaN  NaN \n#:> \n#:>  Extracted Dataframe witn Names:\n#:>    Letter    1\n#:> 0      a    1\n#:> 1      b    2\n#:> 2    NaN  NaNr = s.str.extract(r'[ab](\\d)', expand=False)\nprint( r, '\\n\\n', type(r) )#:> 0      1\n#:> 1      2\n#:> 2    NaN\n#:> dtype: object \n#:> \n#:>  <class 'pandas.core.series.Series'>"},{"path":"pandas-1.html","id":"character-extractor","chapter":"13 pandas","heading":"13.6.7.2 Character Extractor","text":"startwithSlicing","code":"monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n                   'Eric Idle', 'Terry Jones', 'Michael Palin'])\nmonte#:> 0    Graham Chapman\n#:> 1       John Cleese\n#:> 2     Terry Gilliam\n#:> 3         Eric Idle\n#:> 4       Terry Jones\n#:> 5     Michael Palin\n#:> dtype: objectmonte.str.startswith('T')#:> 0    False\n#:> 1    False\n#:> 2     True\n#:> 3    False\n#:> 4     True\n#:> 5    False\n#:> dtype: boolmonte.str[0:3]#:> 0    Gra\n#:> 1    Joh\n#:> 2    Ter\n#:> 3    Eri\n#:> 4    Ter\n#:> 5    Mic\n#:> dtype: object"},{"path":"pandas-1.html","id":"splitting","chapter":"13 pandas","heading":"13.6.7.3 Splitting","text":"Split strings around given separator/delimiter either string regex.str.split() default, split split item arrayexpand=True return dataframe instead series. default, expand split possible columns.possible limit number columns splittedstr.rsplit()rsplit stands reverse split, works way, except reversed","code":"Series.str.split(self, pat=None, n=-1, expand=False)\n- pat: can be string or regexs = pd.Series(['a_b_c', 'c_d_e', np.nan, 'f_g_h_i_j'])\ns#:> 0        a_b_c\n#:> 1        c_d_e\n#:> 2          NaN\n#:> 3    f_g_h_i_j\n#:> dtype: objects.str.split('_')#:> 0          [a, b, c]\n#:> 1          [c, d, e]\n#:> 2                NaN\n#:> 3    [f, g, h, i, j]\n#:> dtype: objectprint( s.str.split('_', expand=True) )#:>      0    1    2     3     4\n#:> 0    a    b    c  None  None\n#:> 1    c    d    e  None  None\n#:> 2  NaN  NaN  NaN   NaN   NaN\n#:> 3    f    g    h     i     jprint( s.str.split('_', expand=True, n=1) )#:>      0        1\n#:> 0    a      b_c\n#:> 1    c      d_e\n#:> 2  NaN      NaN\n#:> 3    f  g_h_i_jprint( s.str.rsplit('_', expand=True, n=1) )#:>          0    1\n#:> 0      a_b    c\n#:> 1      c_d    e\n#:> 2      NaN  NaN\n#:> 3  f_g_h_i    j"},{"path":"pandas-1.html","id":"case-conversion","chapter":"13 pandas","heading":"13.6.7.4 Case Conversion","text":"","code":"SeriesObj.str.upper()\nSeriesObj.str.lower()\nSeriesObj.str.capitalize()s = pd.Series(['A', 'B', 'C', 'aAba', 'bBaca', np.nan, 'cCABA', 'dog', 'cat'])\nprint( s.str.upper(), '\\n',\n       s.str.capitalize())#:> 0        A\n#:> 1        B\n#:> 2        C\n#:> 3     AABA\n#:> 4    BBACA\n#:> 5      NaN\n#:> 6    CCABA\n#:> 7      DOG\n#:> 8      CAT\n#:> dtype: object \n#:>  0        A\n#:> 1        B\n#:> 2        C\n#:> 3     Aaba\n#:> 4    Bbaca\n#:> 5      NaN\n#:> 6    Ccaba\n#:> 7      Dog\n#:> 8      Cat\n#:> dtype: object"},{"path":"pandas-1.html","id":"number-of-characters","chapter":"13 pandas","heading":"13.6.7.5 Number of Characters","text":"","code":"s.str.len()#:> 0    1.0\n#:> 1    1.0\n#:> 2    1.0\n#:> 3    4.0\n#:> 4    5.0\n#:> 5    NaN\n#:> 6    5.0\n#:> 7    3.0\n#:> 8    3.0\n#:> dtype: float64"},{"path":"pandas-1.html","id":"string-indexing","chapter":"13 pandas","heading":"13.6.7.6 String Indexing","text":"return specified character item.","code":"s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan,'CABA', 'dog', 'cat'])\ns.str[0].values    # first char#:> array(['A', 'B', 'C', 'A', 'B', nan, 'C', 'd', 'c'], dtype=object)s.str[0:2].values  # first and second char#:> array(['A', 'B', 'C', 'Aa', 'Ba', nan, 'CA', 'do', 'ca'], dtype=object)"},{"path":"pandas-1.html","id":"series-substring-extraction","chapter":"13 pandas","heading":"13.6.7.7 Series Substring Extraction","text":"Sample DataExtract absed regex matching\n… improve …","code":"s = pd.Series(['a1', 'b2', 'c3'])\ns#:> 0    a1\n#:> 1    b2\n#:> 2    c3\n#:> dtype: objecttype(s.str.extract('([ab])(\\d)', expand=False))#:> <class 'pandas.core.frame.DataFrame'>"},{"path":"pandas-1.html","id":"series-.dt-accessor","chapter":"13 pandas","heading":"13.6.8 Series .dt Accessor","text":"underlying data datetime64 type, pandas exposed various properties methos dt accessor.","code":""},{"path":"pandas-1.html","id":"sample-data-5","chapter":"13 pandas","heading":"13.6.8.1 Sample Data","text":"","code":"s = pd.Series([\n    datetime(2000,1,1,0,0,0),\n    datetime(1999,12,15,12,34,55),\n    datetime(2020,3,8,5,7,12),\n    datetime(2018,1,1,0,0,0),\n    datetime(2003,3,4,5,6,7)\n])\ns#:> 0   2000-01-01 00:00:00\n#:> 1   1999-12-15 12:34:55\n#:> 2   2020-03-08 05:07:12\n#:> 3   2018-01-01 00:00:00\n#:> 4   2003-03-04 05:06:07\n#:> dtype: datetime64[ns]"},{"path":"pandas-1.html","id":"convert-to","chapter":"13 pandas","heading":"13.6.8.2 Convert To","text":"datetime.datetime\nUse to_pydatetime() convert numpy.array standard library datetime.datetimedatetime.date\nUse dt.date convert pandas.Series standard library datetime.date\npossible pandas.Series datetime.datetime ? , Pandas want Timestamp.","code":"pdt  = s.dt.to_pydatetime()\nprint( type(pdt) )#:> <class 'numpy.ndarray'>pdt#:> array([datetime.datetime(2000, 1, 1, 0, 0),\n#:>        datetime.datetime(1999, 12, 15, 12, 34, 55),\n#:>        datetime.datetime(2020, 3, 8, 5, 7, 12),\n#:>        datetime.datetime(2018, 1, 1, 0, 0),\n#:>        datetime.datetime(2003, 3, 4, 5, 6, 7)], dtype=object)sdt = s.dt.date\nprint( type(sdt[1] ))#:> <class 'datetime.date'>print( type(sdt))#:> <class 'pandas.core.series.Series'>sdt#:> 0    2000-01-01\n#:> 1    1999-12-15\n#:> 2    2020-03-08\n#:> 3    2018-01-01\n#:> 4    2003-03-04\n#:> dtype: object"},{"path":"pandas-1.html","id":"timestamp-attributes","chapter":"13 pandas","heading":"13.6.8.3 Timestamp Attributes","text":"Series::DateTime object support properties:\n- date\n- month\n- day\n- year\n- dayofweek\n- dayofyear\n- weekday\n- weekday_name\n- quarter\n- daysinmonth\n- hour\n- minuteFull list :https://pandas.pydata.org/pandas-docs/stable/reference/series.html#datetimelike-properties","code":"s.dt.date#:> 0    2000-01-01\n#:> 1    1999-12-15\n#:> 2    2020-03-08\n#:> 3    2018-01-01\n#:> 4    2003-03-04\n#:> dtype: objects.dt.month#:> 0     1\n#:> 1    12\n#:> 2     3\n#:> 3     1\n#:> 4     3\n#:> dtype: int64s.dt.dayofweek#:> 0    5\n#:> 1    2\n#:> 2    6\n#:> 3    0\n#:> 4    1\n#:> dtype: int64s.dt.weekday#:> 0    5\n#:> 1    2\n#:> 2    6\n#:> 3    0\n#:> 4    1\n#:> dtype: int64# error no attribute weekday_name\ns.dt.weekday_names.dt.quarter#:> 0    1\n#:> 1    4\n#:> 2    1\n#:> 3    1\n#:> 4    1\n#:> dtype: int64s.dt.daysinmonth#:> 0    31\n#:> 1    31\n#:> 2    31\n#:> 3    31\n#:> 4    31\n#:> dtype: int64s.dt.time   # extract time as time Object#:> 0    00:00:00\n#:> 1    12:34:55\n#:> 2    05:07:12\n#:> 3    00:00:00\n#:> 4    05:06:07\n#:> dtype: objects.dt.hour  # extract hour as integer#:> 0     0\n#:> 1    12\n#:> 2     5\n#:> 3     0\n#:> 4     5\n#:> dtype: int64s.dt.minute # extract minute as integer#:> 0     0\n#:> 1    34\n#:> 2     7\n#:> 3     0\n#:> 4     6\n#:> dtype: int64"},{"path":"pandas-1.html","id":"class-dataframe","chapter":"13 pandas","heading":"13.7 class: DataFrame","text":"","code":""},{"path":"pandas-1.html","id":"constructor-10","chapter":"13 pandas","heading":"13.7.1 Constructor","text":"","code":""},{"path":"pandas-1.html","id":"empty-dataframe","chapter":"13 pandas","heading":"13.7.1.1 Empty DataFrame","text":"default, empty dataframe contain coumns index.However, can also initialize empty DataFrame Index /Columns.Take note empty_df1 empty_df2 refers memory location. Meaning cantain similar data.","code":"empty_df1 = pd.DataFrame()\nempty_df2 = pd.DataFrame()\nprint(id(empty_df1), id(empty_df2), empty_df1)#:> 140189694040336 140189694018000 Empty DataFrame\n#:> Columns: []\n#:> Index: []empty_df = pd.DataFrame(columns=['A','B','C'], index=[1,2,3])\nprint( empty_df )#:>      A    B    C\n#:> 1  NaN  NaN  NaN\n#:> 2  NaN  NaN  NaN\n#:> 3  NaN  NaN  NaNempty_df1 = empty_df2 = pd.DataFrame()\nprint(id(empty_df1), id(empty_df2))#:> 140189694328016 140189694328016"},{"path":"pandas-1.html","id":"from-row-oriented-data-list-of-lists","chapter":"13 pandas","heading":"13.7.1.2 From Row Oriented Data (List of Lists)","text":"Create List ListsBasic DataFrame default Row Label Column HeaderSpecify Column Header CreationSpecify Row Label Creation","code":"DataFrame( [row_list1, row_list2, row_list3] )\nDataFrame( [row_list1, row_list2, row_list3], column = columnName_list )\nDataFrame( [row_list1, row_list2, row_list3], index  = row_label_list )pd.DataFrame ([[101,'Alice',40000,2017],\n               [102,'Bob',  24000, 2017], \n               [103,'Charles',31000,2017]] )#:>      0        1      2     3\n#:> 0  101    Alice  40000  2017\n#:> 1  102      Bob  24000  2017\n#:> 2  103  Charles  31000  2017pd.DataFrame ([[101,'Alice',40000,2017],\n               [102,'Bob',  24000, 2017], \n               [103,'Charles',31000,2017]], columns = ['empID','name','salary','year'])#:>    empID     name  salary  year\n#:> 0    101    Alice   40000  2017\n#:> 1    102      Bob   24000  2017\n#:> 2    103  Charles   31000  2017pd.DataFrame ([[101,'Alice',40000,2017],\n               [102,'Bob',  24000, 2017], \n               [103,'Charles',31000,2017]], index   = ['r1','r2','r3'] )#:>       0        1      2     3\n#:> r1  101    Alice  40000  2017\n#:> r2  102      Bob  24000  2017\n#:> r3  103  Charles  31000  2017"},{"path":"pandas-1.html","id":"from-row-oriented-data-list-of-dictionary","chapter":"13 pandas","heading":"13.7.1.3 From Row Oriented Data (List of Dictionary)","text":"Default Column Name Follow Dictionary Key\nNote missing info NaNSpecify IndexSpecify Column Header Creation, can acts column filter manual arrangement\nNote missing info NaN","code":"DataFrame( [dict1, dict2, dict3] )\nDataFrame( [row_list1, row_list2, row_list3], column=np.arrange )\nDataFrame( [row_list1, row_list2, row_list3], index=row_label_list )\n\nby default,keys will become collumn names, and autosortedpd.DataFrame ([{\"name\":\"Yong\", \"id\":1,\"zkey\":101},{\"name\":\"Gan\",\"id\":2}])#:>    name  id   zkey\n#:> 0  Yong   1  101.0\n#:> 1   Gan   2    NaNpd.DataFrame ([{\"name\":\"Yong\", \"id\":'wd1'},{\"name\":\"Gan\",\"id\":'wd2'}], \n             index = (1,2))#:>    name   id\n#:> 1  Yong  wd1\n#:> 2   Gan  wd2pd.DataFrame ([{\"name\":\"Yong\", \"id\":1, \"zkey\":101},{\"name\":\"Gan\",\"id\":2}], \n              columns=(\"name\",\"id\",\"zkey\"))#:>    name  id   zkey\n#:> 0  Yong   1  101.0\n#:> 1   Gan   2    NaN"},{"path":"pandas-1.html","id":"from-column-oriented-data","chapter":"13 pandas","heading":"13.7.1.4 From Column Oriented Data","text":"Create Dictrionary ListBy default, DataFrame arrange columns alphabetically, unless columns specifiedDefault Row LabelSpecify Row Label CreationManualy Choose Columns Arrangement","code":"DataFrame(  { 'column1': list1,\n              'column2': list2,\n              'column3': list3 } , \n              index    = row_label_list, \n              columns  = column_list)\n              data = {'empID':  [100,      101,    102,      103,     104],\n        'year':   [2017,     2017,   2017,      2018,    2018],\n        'salary': [40000,    24000,  31000,     20000,   30000],\n        'name':   ['Alice', 'Bob',  'Charles', 'David', 'Eric']}\npd.DataFrame(data)#:>    empID  year  salary     name\n#:> 0    100  2017   40000    Alice\n#:> 1    101  2017   24000      Bob\n#:> 2    102  2017   31000  Charles\n#:> 3    103  2018   20000    David\n#:> 4    104  2018   30000     Ericdata = {'empID':  [100,      101,    102,      103,     104],\n        'name':   ['Alice', 'Bob',  'Charles', 'David', 'Eric'],\n        'year':   [2017,     2017,   2017,      2018,    2018],\n        'salary': [40000,    24000,  31000,     20000,   30000] }\npd.DataFrame (data, index=['r1','r2','r3','r4','r5'])#:>     empID     name  year  salary\n#:> r1    100    Alice  2017   40000\n#:> r2    101      Bob  2017   24000\n#:> r3    102  Charles  2017   31000\n#:> r4    103    David  2018   20000\n#:> r5    104     Eric  2018   30000data = {'empID':  [100,      101,    102,      103,     104],\n        'name':   ['Alice', 'Bob',  'Charles', 'David', 'Eric'],\n        'year':   [2017,     2017,   2017,      2018,    2018],\n        'salary': [40000,    24000,  31000,     20000,   30000] }\npd.DataFrame (data, columns=('empID','name','salary'), index=['r1','r2','r3','r4','r5'])#:>     empID     name  salary\n#:> r1    100    Alice   40000\n#:> r2    101      Bob   24000\n#:> r3    102  Charles   31000\n#:> r4    103    David   20000\n#:> r5    104     Eric   30000"},{"path":"pandas-1.html","id":"operator-2","chapter":"13 pandas","heading":"13.7.2 Operator","text":"","code":""},{"path":"pandas-1.html","id":"the-data-1","chapter":"13 pandas","heading":"13.7.2.1 The Data","text":"Two dataframe created, 3 columns 3 rows. However, two matching column row names shall notice operator perform cell-wise, honoring row/column name.","code":"df1 = pd.DataFrame(data=\n  {'idx': ['row1','row2','row3'],\n   'x': [10, 20, 30],\n   'y': [1,2,3],\n   'z': [0.1, 0.2, 0.3]}).set_index('idx')\n   \ndf2 = pd.DataFrame(data=\n  {'idx': ['row1','row2','row4'],\n   'x': [13, 23, 33],\n   'z': [0.1, 0.2, 0.3],\n   'k': [11,21,31]\n   }).set_index('idx')\n   \nprint( df1, '\\n\\n', df2)#:>        x  y    z\n#:> idx             \n#:> row1  10  1  0.1\n#:> row2  20  2  0.2\n#:> row3  30  3  0.3 \n#:> \n#:>         x    z   k\n#:> idx              \n#:> row1  13  0.1  11\n#:> row2  23  0.2  21\n#:> row4  33  0.3  31"},{"path":"pandas-1.html","id":"addition","chapter":"13 pandas","heading":"13.7.2.2 Addition","text":"Adding Two DataFrameUsing + operator, non-matching row/column names result NA. However, using function add, none matching cells can assumed value.Adding Series DataFrameSpecify appropriate axis depending orientation series data. Column Row names respected operation. However, fill_value applicable apply Series.Note columns Series found dataframe, still created result. similar behaviour operating Dataframe Dataframe.","code":"r1 = df1 + df2\nr2 = df1.add(df2,fill_value=1000)\n\nprint( r1, '\\n\\n', r2)#:>        k     x   y    z\n#:> idx                    \n#:> row1 NaN  23.0 NaN  0.2\n#:> row2 NaN  43.0 NaN  0.4\n#:> row3 NaN   NaN NaN  NaN\n#:> row4 NaN   NaN NaN  NaN \n#:> \n#:>             k       x       y       z\n#:> idx                                 \n#:> row1  1011.0    23.0  1001.0     0.2\n#:> row2  1021.0    43.0  1002.0     0.4\n#:> row3     NaN  1030.0  1003.0  1000.3\n#:> row4  1031.0  1033.0     NaN  1000.3s3 = pd.Series([1,1,1], index=['row1','row2','row4'])\ns4 = pd.Series([3,3,3], index=['x','y','s'])\n\nprint('Original Data:\\n',df1,'\\n\\n',\n      'Add By Rows: \\n', df1.add(s3, axis=0), '\\n\\n',\n      'Add By Columns: \\n', df1.add(s4, axis=1))#:> Original Data:\n#:>         x  y    z\n#:> idx             \n#:> row1  10  1  0.1\n#:> row2  20  2  0.2\n#:> row3  30  3  0.3 \n#:> \n#:>  Add By Rows: \n#:>           x    y    z\n#:> row1  11.0  2.0  1.1\n#:> row2  21.0  3.0  1.2\n#:> row3   NaN  NaN  NaN\n#:> row4   NaN  NaN  NaN \n#:> \n#:>  Add By Columns: \n#:>         s     x    y   z\n#:> idx                    \n#:> row1 NaN  13.0  4.0 NaN\n#:> row2 NaN  23.0  5.0 NaN\n#:> row3 NaN  33.0  6.0 NaN"},{"path":"pandas-1.html","id":"substraction","chapter":"13 pandas","heading":"13.7.2.3 Substraction","text":"","code":"r1 = df2 - df1\nr2 = df2.sub(df1,fill_value=1000)\n\nprint( r1, '\\n\\n', r2)#:>        k    x   y    z\n#:> idx                   \n#:> row1 NaN  3.0 NaN  0.0\n#:> row2 NaN  3.0 NaN  0.0\n#:> row3 NaN  NaN NaN  NaN\n#:> row4 NaN  NaN NaN  NaN \n#:> \n#:>            k      x      y      z\n#:> idx                             \n#:> row1 -989.0    3.0  999.0    0.0\n#:> row2 -979.0    3.0  998.0    0.0\n#:> row3    NaN  970.0  997.0  999.7\n#:> row4 -969.0 -967.0    NaN -999.7r3 = (r2>0) & (r2<=3)\nprint( 'Original Data: \\n', r2, '\\n\\n',\n       'Logical Operator:\\n', r3)#:> Original Data: \n#:>            k      x      y      z\n#:> idx                             \n#:> row1 -989.0    3.0  999.0    0.0\n#:> row2 -979.0    3.0  998.0    0.0\n#:> row3    NaN  970.0  997.0  999.7\n#:> row4 -969.0 -967.0    NaN -999.7 \n#:> \n#:>  Logical Operator:\n#:>            k      x      y      z\n#:> idx                             \n#:> row1  False   True  False  False\n#:> row2  False   True  False  False\n#:> row3  False  False  False  False\n#:> row4  False  False  False  False"},{"path":"pandas-1.html","id":"attributes-6","chapter":"13 pandas","heading":"13.7.3 Attributes","text":"","code":"df = pd.DataFrame(\n    { 'empID':  [100,      101,    102,      103,     104],\n      'year1':   [2017,     2017,   2017,      2018,    2018],\n      'name':   ['Alice',  'Bob',  'Charles','David', 'Eric'],\n      'year2':   [2001,     1907,   2003,      1998,    2011],\n      'salary': [40000,    24000,  31000,     20000,   30000]},\n    columns = ['year1','salary','year2','empID','name'])"},{"path":"pandas-1.html","id":"dimensions-1","chapter":"13 pandas","heading":"13.7.3.1 Dimensions","text":"","code":"df.shape#:> (5, 5)"},{"path":"pandas-1.html","id":"index","chapter":"13 pandas","heading":"13.7.3.2 Index","text":"Underlying Index values numpy object","code":"df.index#:> RangeIndex(start=0, stop=5, step=1)df.index.values#:> array([0, 1, 2, 3, 4])"},{"path":"pandas-1.html","id":"columns","chapter":"13 pandas","heading":"13.7.3.3 Columns","text":"Underlying Index values numpy object","code":"df.columns#:> Index(['year1', 'salary', 'year2', 'empID', 'name'], dtype='object')df.columns.values#:> array(['year1', 'salary', 'year2', 'empID', 'name'], dtype=object)"},{"path":"pandas-1.html","id":"values","chapter":"13 pandas","heading":"13.7.3.4 Values","text":"Underlying Column values numpy object","code":"df.values#:> array([[2017, 40000, 2001, 100, 'Alice'],\n#:>        [2017, 24000, 1907, 101, 'Bob'],\n#:>        [2017, 31000, 2003, 102, 'Charles'],\n#:>        [2018, 20000, 1998, 103, 'David'],\n#:>        [2018, 30000, 2011, 104, 'Eric']], dtype=object)"},{"path":"pandas-1.html","id":"index-manipulation-1","chapter":"13 pandas","heading":"13.7.4 Index Manipulation","text":"index row label used interchangeably book","code":""},{"path":"pandas-1.html","id":"sample-data-6","chapter":"13 pandas","heading":"13.7.4.1 Sample Data","text":"Columns intentionaly ordered messy way","code":"df = pd.DataFrame(\n    { 'empID':  [100,      101,    102,      103,     104],\n      'year1':   [2017,     2017,   2017,      2018,    2018],\n      'name':   ['Alice',  'Bob',  'Charles','David', 'Eric'],\n      'year2':   [2001,     1907,   2003,      1998,    2011],\n      'salary': [40000,    24000,  31000,     20000,   30000]},\n    columns = ['year1','salary','year2','empID','name'])\n\nprint (df, '\\n')#:>    year1  salary  year2  empID     name\n#:> 0   2017   40000   2001    100    Alice\n#:> 1   2017   24000   1907    101      Bob\n#:> 2   2017   31000   2003    102  Charles\n#:> 3   2018   20000   1998    103    David\n#:> 4   2018   30000   2011    104     Ericprint (df.index)#:> RangeIndex(start=0, stop=5, step=1)"},{"path":"pandas-1.html","id":"convert-column-to-index","chapter":"13 pandas","heading":"13.7.4.2 Convert Column To Index","text":"inplace=True means don’t create new dataframe. Modify existing dataframeinplace=False means return new dataframe","code":"set_index('column_name', inplace=False)print(df)#:>    year1  salary  year2  empID     name\n#:> 0   2017   40000   2001    100    Alice\n#:> 1   2017   24000   1907    101      Bob\n#:> 2   2017   31000   2003    102  Charles\n#:> 3   2018   20000   1998    103    David\n#:> 4   2018   30000   2011    104     Ericprint(df.index,'\\n')#:> RangeIndex(start=0, stop=5, step=1)df.set_index('empID',inplace=True) \nprint(df)#:>        year1  salary  year2     name\n#:> empID                               \n#:> 100     2017   40000   2001    Alice\n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles\n#:> 103     2018   20000   1998    David\n#:> 104     2018   30000   2011     Ericprint(df.index) # return new DataFrameObj#:> Int64Index([100, 101, 102, 103, 104], dtype='int64', name='empID')"},{"path":"pandas-1.html","id":"convert-index-back-to-column","chapter":"13 pandas","heading":"13.7.4.3 Convert Index Back To Column","text":"Reseting index resequence index 0,1,2 etcOld index column converted back normal columnOperation support inplace** option","code":"df.reset_index(inplace=True)\nprint(df)#:>    empID  year1  salary  year2     name\n#:> 0    100   2017   40000   2001    Alice\n#:> 1    101   2017   24000   1907      Bob\n#:> 2    102   2017   31000   2003  Charles\n#:> 3    103   2018   20000   1998    David\n#:> 4    104   2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"updating-index-.index","chapter":"13 pandas","heading":"13.7.4.4 Updating Index ( .index= )","text":"Warning:\n- Updating index doesn’t reorder data sequence\n- Number elements reorder must match, otherwise error\n- label allowed repeat\n- reversable","code":"df.index = [101, 101, 101, 102, 103]\ndf#:>      empID  year1  salary  year2     name\n#:> 101    100   2017   40000   2001    Alice\n#:> 101    101   2017   24000   1907      Bob\n#:> 101    102   2017   31000   2003  Charles\n#:> 102    103   2018   20000   1998    David\n#:> 103    104   2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"reordering-index-.-reindex","chapter":"13 pandas","heading":"13.7.4.5 Reordering Index (. reindex )","text":"Reindex reorder rows according new indexThe operation reversableStart original dataframeChange order Index, always return new dataframe","code":"df.index = [101,102,103,104,105]\ndf#:>      empID  year1  salary  year2     name\n#:> 101    100   2017   40000   2001    Alice\n#:> 102    101   2017   24000   1907      Bob\n#:> 103    102   2017   31000   2003  Charles\n#:> 104    103   2018   20000   1998    David\n#:> 105    104   2018   30000   2011     Ericdf.reindex([103,102,101,104,105])#:>      empID  year1  salary  year2     name\n#:> 103    102   2017   31000   2003  Charles\n#:> 102    101   2017   24000   1907      Bob\n#:> 101    100   2017   40000   2001    Alice\n#:> 104    103   2018   20000   1998    David\n#:> 105    104   2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"rename-index","chapter":"13 pandas","heading":"13.7.4.6 Rename Index","text":"Example renamed axis columns rowsUse axis=0 row index, use axis=1 column index","code":"df.rename_axis('super_id').rename_axis('my_cols', axis=1)#:> my_cols   empID  year1  salary  year2     name\n#:> super_id                                      \n#:> 101         100   2017   40000   2001    Alice\n#:> 102         101   2017   24000   1907      Bob\n#:> 103         102   2017   31000   2003  Charles\n#:> 104         103   2018   20000   1998    David\n#:> 105         104   2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"subsetting-columns","chapter":"13 pandas","heading":"13.7.5 Subsetting Columns","text":"Select Single Column Return SeriesSelect Single/Multiple Columns Return DataFrame","code":"dataframe.columnName               # single column, name based, return Series object\ndataframe[ single_col_name ]       # single column, name based, return Series object\ndataframe[ [single_col_name] ]     # single column, name based, return DataFrame objectdataframe[ single/list_of_col_names ]                       # name based, return Dataframe object\ndataframe.loc[ : , single_col_name  ]  # single column, series\ndataframe.loc[ : , col_name_list    ]  # multiple columns, dataframe\ndataframe.loc[ : , col_name_ranage  ]  # multiple columns, dataframe\n\ndataframe.iloc[ : , col_number      ]  # single column, series\ndataframe.iloc[ : , col_number_list ]  # multiple columns, dataframe\ndataframe.iloc[ : , number_range    ]  # multiple columns, dataframe"},{"path":"pandas-1.html","id":"select-single-column","chapter":"13 pandas","heading":"13.7.5.1 Select Single Column","text":"Selecting single column always return panda::Series","code":"print( \n  df.name,           '\\n\\n',\n  df['name'],        '\\n\\n',\n  df.loc[:, 'name'], '\\n\\n',\n  df.iloc[:, 3])#:> 101      Alice\n#:> 102        Bob\n#:> 103    Charles\n#:> 104      David\n#:> 105       Eric\n#:> Name: name, dtype: object \n#:> \n#:>  101      Alice\n#:> 102        Bob\n#:> 103    Charles\n#:> 104      David\n#:> 105       Eric\n#:> Name: name, dtype: object \n#:> \n#:>  101      Alice\n#:> 102        Bob\n#:> 103    Charles\n#:> 104      David\n#:> 105       Eric\n#:> Name: name, dtype: object \n#:> \n#:>  101    2001\n#:> 102    1907\n#:> 103    2003\n#:> 104    1998\n#:> 105    2011\n#:> Name: year2, dtype: int64"},{"path":"pandas-1.html","id":"select-multiple-columns","chapter":"13 pandas","heading":"13.7.5.2 Select Multiple Columns","text":"Multiple columns return panda::Dataframe object`Example returns DataFrame Single ColumnSelect Range Columns","code":"df[['name']]  # return one column dataframe#:>         name\n#:> 101    Alice\n#:> 102      Bob\n#:> 103  Charles\n#:> 104    David\n#:> 105     Ericprint(\n  df[['name','year1']]       ,'\\n\\n',\n  df.loc[:,['name','year1']])#:>         name  year1\n#:> 101    Alice   2017\n#:> 102      Bob   2017\n#:> 103  Charles   2017\n#:> 104    David   2018\n#:> 105     Eric   2018 \n#:> \n#:>          name  year1\n#:> 101    Alice   2017\n#:> 102      Bob   2017\n#:> 103  Charles   2017\n#:> 104    David   2018\n#:> 105     Eric   2018print(\n  df.loc [ : , 'year1':'year2'], '\\n\\n',\n  df.iloc[ : , [0,3]]           ,'\\n\\n',\n  df.iloc[ : , 0:3]\n)#:>      year1  salary  year2\n#:> 101   2017   40000   2001\n#:> 102   2017   24000   1907\n#:> 103   2017   31000   2003\n#:> 104   2018   20000   1998\n#:> 105   2018   30000   2011 \n#:> \n#:>       empID  year2\n#:> 101    100   2001\n#:> 102    101   1907\n#:> 103    102   2003\n#:> 104    103   1998\n#:> 105    104   2011 \n#:> \n#:>       empID  year1  salary\n#:> 101    100   2017   40000\n#:> 102    101   2017   24000\n#:> 103    102   2017   31000\n#:> 104    103   2018   20000\n#:> 105    104   2018   30000"},{"path":"pandas-1.html","id":"by-column-name-.filter","chapter":"13 pandas","heading":"13.7.5.3 By Column Name (.filter)","text":".filter(items=None, like=None, regex=None, axis=1)like = Substring Matchesitems = list column namesregex = Regular Expression\nSelect column names contain integer","code":"df.filter( like='year',  axis='columns')  ## or axis = 1#:>      year1  year2\n#:> 101   2017   2001\n#:> 102   2017   1907\n#:> 103   2017   2003\n#:> 104   2018   1998\n#:> 105   2018   2011df.filter( items=('year1','year2'),  axis=1)  ## or axis = 1#:>      year1  year2\n#:> 101   2017   2001\n#:> 102   2017   1907\n#:> 103   2017   2003\n#:> 104   2018   1998\n#:> 105   2018   2011df.filter(regex='\\d')  ## default axis=1 if DataFrame#:>      year1  year2\n#:> 101   2017   2001\n#:> 102   2017   1907\n#:> 103   2017   2003\n#:> 104   2018   1998\n#:> 105   2018   2011"},{"path":"pandas-1.html","id":"data-type-.select_dtypes","chapter":"13 pandas","heading":"13.7.5.4 Data Type (.select_dtypes)","text":"Always return panda::DataFrame, even though single column matches.\nAllowed types :\n- number (integer float)\n- integer / float\n- datetime\n- timedelta\n- category","code":"df.select_dtypes(include=None, exclude=None)# error: no attribute get_dtype_counts\ndf.get_dtype_counts()df.select_dtypes(exclude='number')#:>         name\n#:> 101    Alice\n#:> 102      Bob\n#:> 103  Charles\n#:> 104    David\n#:> 105     Ericdf.select_dtypes(exclude=('number','object'))#:> Empty DataFrame\n#:> Columns: []\n#:> Index: [101, 102, 103, 104, 105]"},{"path":"pandas-1.html","id":"column-manipulation-1","chapter":"13 pandas","heading":"13.7.6 Column Manipulation","text":"","code":""},{"path":"pandas-1.html","id":"sample-data-7","chapter":"13 pandas","heading":"13.7.6.1 Sample Data","text":"","code":"df#:>      empID  year1  salary  year2     name\n#:> 101    100   2017   40000   2001    Alice\n#:> 102    101   2017   24000   1907      Bob\n#:> 103    102   2017   31000   2003  Charles\n#:> 104    103   2018   20000   1998    David\n#:> 105    104   2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"renaming-columns","chapter":"13 pandas","heading":"13.7.6.2 Renaming Columns","text":"Method 1 : Rename Columns (.columns =)\n- Construct new column names, check missing column names\n- Missing columns return error\n- Direct Assignment column property result change dataframeMethod 2 : Renaming Specific Column (.rename (columns=) )\n- Change column name rename function\n- Support inpalce option original dataframe change\n- Missing column OK","code":"new_columns = ['year.1','salary','year.2','empID','name']\ndf.columns = new_columns\ndf.head(2)#:>      year.1  salary  year.2  empID   name\n#:> 101     100    2017   40000   2001  Alice\n#:> 102     101    2017   24000   1907    Bobdf.rename( columns={'year.1':'year1', 'year.2':'year2'}, inplace=True)\ndf.head(2)#:>      year1  salary  year2  empID   name\n#:> 101    100    2017  40000   2001  Alice\n#:> 102    101    2017  24000   1907    Bob"},{"path":"pandas-1.html","id":"reordering-columns","chapter":"13 pandas","heading":"13.7.6.3 Reordering Columns","text":"Always return new dataframe. inplace option reordering columnsMethod 1 - reindex(columns = )\n- reindex may sounds like operation row labels, works\n- Missmatch column names result NA unfound columnMethod 2 - [ ] notation\n- Missmatch column result ERROR","code":"new_colorder = [ 'empID', 'name', 'salary', 'year1', 'year2']\ndf.reindex(columns = new_colorder).head(2)#:>      empID   name  salary  year1  year2\n#:> 101   2001  Alice    2017    100  40000\n#:> 102   1907    Bob    2017    101  24000new_colorder = [ 'empID', 'name', 'salary', 'year1', 'year2']\ndf[new_colorder]#:>      empID     name  salary  year1  year2\n#:> 101   2001    Alice    2017    100  40000\n#:> 102   1907      Bob    2017    101  24000\n#:> 103   2003  Charles    2017    102  31000\n#:> 104   1998    David    2018    103  20000\n#:> 105   2011     Eric    2018    104  30000"},{"path":"pandas-1.html","id":"duplicating-or-replacing-column","chapter":"13 pandas","heading":"13.7.6.4 Duplicating or Replacing Column","text":"New Column created instantly using [] notationDO USE dot Notation view attribute","code":"df['year3'] = df.year1\ndf#:>      year1  salary  year2  empID     name  year3\n#:> 101    100    2017  40000   2001    Alice    100\n#:> 102    101    2017  24000   1907      Bob    101\n#:> 103    102    2017  31000   2003  Charles    102\n#:> 104    103    2018  20000   1998    David    103\n#:> 105    104    2018  30000   2011     Eric    104"},{"path":"pandas-1.html","id":"dropping-columns-.drop","chapter":"13 pandas","heading":"13.7.6.5 Dropping Columns (.drop)","text":"inplace=True means column deleted original dataframe. Default False, return copy dataframeBy Column Name(s)Column Number(s)\nUse dataframe.columns produce interim list column names","code":"dataframe.drop( columns='column_name',    inplace=True/False)   # delete single column\ndataframe.drop( columns=list_of_colnames, inplace=True/False)   # delete multiple column\n\ndataframe.drop( index='row_label',         inplace=True/False)   # delete single row\ndataframe.drop( index= list_of_row_labels, inplace=True/False)   # delete multiple rows\ndf.drop( columns='year1') # drop single column#:>      salary  year2  empID     name  year3\n#:> 101    2017  40000   2001    Alice    100\n#:> 102    2017  24000   1907      Bob    101\n#:> 103    2017  31000   2003  Charles    102\n#:> 104    2018  20000   1998    David    103\n#:> 105    2018  30000   2011     Eric    104df.drop(columns=['year2','year3'])  # drop multiple columns#:>      year1  salary  empID     name\n#:> 101    100    2017   2001    Alice\n#:> 102    101    2017   1907      Bob\n#:> 103    102    2017   2003  Charles\n#:> 104    103    2018   1998    David\n#:> 105    104    2018   2011     Ericdf.drop( columns=df.columns[[3,4,5]] )   # delete columns by list of column number#:>      year1  salary  year2\n#:> 101    100    2017  40000\n#:> 102    101    2017  24000\n#:> 103    102    2017  31000\n#:> 104    103    2018  20000\n#:> 105    104    2018  30000df.drop( columns=df.columns[3:6] )       # delete columns by range of column number#:>      year1  salary  year2\n#:> 101    100    2017  40000\n#:> 102    101    2017  24000\n#:> 103    102    2017  31000\n#:> 104    103    2018  20000\n#:> 105    104    2018  30000"},{"path":"pandas-1.html","id":"subsetting-rows","chapter":"13 pandas","heading":"13.7.7 Subsetting Rows","text":"","code":"dataframe.loc[ row_label       ]  # return series, single row\ndataframe.loc[ row_label_list  ]  # multiple rows\ndataframe.loc[ boolean_list    ]  # multiple rows\n\ndataframe.iloc[ row_number       ]  # return series, single row\ndataframe.iloc[ row_number_list  ]  # multiple rows\ndataframe.iloc[ number_range     ]  # multiple rows\n\ndataframe.sample(frac=)                                        # frac = 0.6 means sampling 60% of rows randomly"},{"path":"pandas-1.html","id":"sample-data-8","chapter":"13 pandas","heading":"13.7.7.1 Sample Data","text":"","code":"df = pd.DataFrame(\n    { 'empID':  [100,      101,    102,      103,     104],\n      'year1':   [2017,     2017,   2017,      2018,    2018],\n      'name':   ['Alice',  'Bob',  'Charles','David', 'Eric'],\n      'year2':   [2001,     1907,   2003,      1998,    2011],\n      'salary': [40000,    24000,  31000,     20000,   30000]},\n    columns = ['year1','salary','year2','empID','name']).set_index(['empID'])\ndf#:>        year1  salary  year2     name\n#:> empID                               \n#:> 100     2017   40000   2001    Alice\n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles\n#:> 103     2018   20000   1998    David\n#:> 104     2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"by-index-or-boolean","chapter":"13 pandas","heading":"13.7.7.2 By Index or Boolean","text":"Single Index return SeriesList Range Indexes returns DataFrameList Boolean returns DataFrame","code":"df.loc[101]         # by single row label, return series#:> year1      2017\n#:> salary    24000\n#:> year2      1907\n#:> name        Bob\n#:> Name: 101, dtype: objectdf.loc[ [100,103] ]  # by multiple row labels#:>        year1  salary  year2   name\n#:> empID                             \n#:> 100     2017   40000   2001  Alice\n#:> 103     2018   20000   1998  Daviddf.loc[  100:103  ]  # by range of row labels#:>        year1  salary  year2     name\n#:> empID                               \n#:> 100     2017   40000   2001    Alice\n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles\n#:> 103     2018   20000   1998    Davidcriteria = (df.salary > 30000) & (df.year1==2017)\nprint (criteria)#:> empID\n#:> 100     True\n#:> 101    False\n#:> 102     True\n#:> 103    False\n#:> 104    False\n#:> dtype: boolprint (df.loc[criteria])#:>        year1  salary  year2     name\n#:> empID                               \n#:> 100     2017   40000   2001    Alice\n#:> 102     2017   31000   2003  Charles"},{"path":"pandas-1.html","id":"by-row-number","chapter":"13 pandas","heading":"13.7.7.3 By Row Number","text":"Single Row return SeriesMultiple rows returned dataframe object","code":"df.iloc[1]  # by single row number#:> year1      2017\n#:> salary    24000\n#:> year2      1907\n#:> name        Bob\n#:> Name: 101, dtype: objectdf.iloc[ [0,3] ]    # by row numbers#:>        year1  salary  year2   name\n#:> empID                             \n#:> 100     2017   40000   2001  Alice\n#:> 103     2018   20000   1998  Daviddf.iloc[  0:3  ]    # by row number range#:>        year1  salary  year2     name\n#:> empID                               \n#:> 100     2017   40000   2001    Alice\n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles"},{"path":"pandas-1.html","id":"by-expression-.query","chapter":"13 pandas","heading":"13.7.7.4 By Expression (.query)","text":".query(expr, inplace=False)","code":"df.query('salary<=31000 and year1 == 2017')#:>        year1  salary  year2     name\n#:> empID                               \n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles"},{"path":"pandas-1.html","id":"by-random-.sample","chapter":"13 pandas","heading":"13.7.7.5 By Random (.sample)","text":"","code":"np.random.seed(15)\ndf.sample(frac=0.6) #randomly pick 60% of rows, without replacement#:>        year1  salary  year2     name\n#:> empID                               \n#:> 102     2017   31000   2003  Charles\n#:> 103     2018   20000   1998    David\n#:> 104     2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"row-manipulation","chapter":"13 pandas","heading":"13.7.8 Row Manipulation","text":"","code":""},{"path":"pandas-1.html","id":"sample-data-9","chapter":"13 pandas","heading":"13.7.8.1 Sample Data","text":"","code":""},{"path":"pandas-1.html","id":"appending-rows","chapter":"13 pandas","heading":"13.7.8.2 Appending Rows","text":"Appending rows computaional intensive concatenate.\nItem can added single item multi-items (list form)Append Another DataFrameWhen ignore_index=True, pandas drop original Index recreate 0,1,2,3…recommended ignore index data source index unique.New columns added result, NaN original dataframe.Append DictionaryAppending None items(s)Adding single None item effect (nothing added).\nAdding None list form (multiple items) creates rows None.ignore_index important .Appending Items Containing None results ERROR","code":"my_df = pd.DataFrame(\n          data= {'Id':   [10,20,30],\n                 'Name': ['Aaa','Bbb','Ccc']})\n#                 .set_index('Id')\n                 \nmy_df_new = pd.DataFrame(\n            data= {'Id':   [40,50],\n                   'Name': ['Ddd','Eee'],\n                   'Age':  [12,13]})  \n                   #.set_index('Id')\n                   \nmy_df_append  = my_df.append(my_df_new, ignore_index=False)\nmy_df_noindex = my_df.append(my_df_new, ignore_index=True)\n\nprint(\"Original DataFrame:\\n\", my_df,\n      \"\\n\\nTo Be Appended DataFrame:\\n\", my_df_new,\n      \"\\n\\nAppended DataFrame (index maintained):\\n\", my_df_append,\n      \"\\n\\nAppended DataFrame (index ignored):\\n\", my_df_noindex)#:> Original DataFrame:\n#:>     Id Name\n#:> 0  10  Aaa\n#:> 1  20  Bbb\n#:> 2  30  Ccc \n#:> \n#:> To Be Appended DataFrame:\n#:>     Id Name  Age\n#:> 0  40  Ddd   12\n#:> 1  50  Eee   13 \n#:> \n#:> Appended DataFrame (index maintained):\n#:>     Id Name   Age\n#:> 0  10  Aaa   NaN\n#:> 1  20  Bbb   NaN\n#:> 2  30  Ccc   NaN\n#:> 0  40  Ddd  12.0\n#:> 1  50  Eee  13.0 \n#:> \n#:> Appended DataFrame (index ignored):\n#:>     Id Name   Age\n#:> 0  10  Aaa   NaN\n#:> 1  20  Bbb   NaN\n#:> 2  30  Ccc   NaN\n#:> 3  40  Ddd  12.0\n#:> 4  50  Eee  13.0my_df = pd.DataFrame(\n          data= {'Id':   [10,20,30],\n                 'Name': ['Aaa','Bbb','Ccc']})  \\\n                 .set_index('Id')\n\nnew_item1 = {'Id':40, 'Name': 'Ddd'}\nnew_item2 = {'Id':50, 'Name': 'Eee'}\nnew_item3 = {'Id':60, 'Name': 'Fff'}\n\nmy_df_one   = my_df.append( new_item1, ignore_index=True )\nmy_df_multi = my_df.append( [new_item2, new_item3], ignore_index=True )\n\nprint(\"Original DataFrame:\\n\", my_df,\n      \"\\n\\nAdd One Item (index ignored):\\n\", my_df_one,\n      \"\\n\\nAdd Multi Item (index ignored):\\n\", my_df_multi)#:> Original DataFrame:\n#:>     Name\n#:> Id     \n#:> 10  Aaa\n#:> 20  Bbb\n#:> 30  Ccc \n#:> \n#:> Add One Item (index ignored):\n#:>    Name    Id\n#:> 0  Aaa   NaN\n#:> 1  Bbb   NaN\n#:> 2  Ccc   NaN\n#:> 3  Ddd  40.0 \n#:> \n#:> Add Multi Item (index ignored):\n#:>    Name    Id\n#:> 0  Aaa   NaN\n#:> 1  Bbb   NaN\n#:> 2  Ccc   NaN\n#:> 3  Eee  50.0\n#:> 4  Fff  60.0single_none = my_df.append( None  )\nmulti_none  = my_df.append( [None])\n\nprint(\"Original DataFrame:\\n\", my_df,\n      \"\\n\\nAdd One None (index ignored):\\n\", single_none,\n      \"\\n\\nAdd List of None (index ignored):\\n\", multi_none)#:> Original DataFrame:\n#:>     Name\n#:> Id     \n#:> 10  Aaa\n#:> 20  Bbb\n#:> 30  Ccc \n#:> \n#:> Add One None (index ignored):\n#:>     Name\n#:> Id     \n#:> 10  Aaa\n#:> 20  Bbb\n#:> 30  Ccc \n#:> \n#:> Add List of None (index ignored):\n#:>     Name     0\n#:> 10  Aaa   NaN\n#:> 20  Bbb   NaN\n#:> 30  Ccc   NaN\n#:> 0   NaN  None# error\nmy_df.append( [new_item1, None] )"},{"path":"pandas-1.html","id":"concatenate-rows","chapter":"13 pandas","heading":"13.7.8.3 Concatenate Rows","text":"","code":""},{"path":"pandas-1.html","id":"dropping-rows-.drop","chapter":"13 pandas","heading":"13.7.8.4 Dropping Rows (.drop)","text":".drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')Row Label(s)","code":"df.drop(index=100)       # single row#:>        year1  salary  year2     name\n#:> empID                               \n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles\n#:> 103     2018   20000   1998    David\n#:> 104     2018   30000   2011     Ericdf.drop(index=[100,103])   # multiple rows#:>        year1  salary  year2     name\n#:> empID                               \n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles\n#:> 104     2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"slicing","chapter":"13 pandas","heading":"13.7.9 Slicing","text":"","code":""},{"path":"pandas-1.html","id":"sample-data-10","chapter":"13 pandas","heading":"13.7.9.1 Sample Data","text":"","code":"df#:>        year1  salary  year2     name\n#:> empID                               \n#:> 100     2017   40000   2001    Alice\n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles\n#:> 103     2018   20000   1998    David\n#:> 104     2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"getting-one-cell","chapter":"13 pandas","heading":"13.7.9.2 Getting One Cell","text":"Row Label Column Name (loc)Row Number Column Number (iloc)","code":"dataframe.loc [ row_label , col_name   ]    # by row label and column names\ndataframe.loc [ bool_list , col_name   ]    # by row label and column names\ndataframe.iloc[ row_number, col_number ]    # by row and column numberprint (df.loc[100,'year1'])#:> 2017print (df.iloc[1,2])#:> 1907"},{"path":"pandas-1.html","id":"getting-multiple-cells","chapter":"13 pandas","heading":"13.7.9.3 Getting Multiple Cells","text":"Specify rows columns (individual range)Index Column Name (loc)Boolean Row Column Names (loc)Row Column Number (iloc)","code":"dataframe.loc [ list/range_of_row_labels , list/range_col_names   ]    # by row label and column names\ndataframe.iloc[ list/range_row_numbers,    list/range_col_numbers ]    # by row numberprint (df.loc[ [101,103], ['name','year1'] ], '\\n')  # by list of row label and column names#:>         name  year1\n#:> empID              \n#:> 101      Bob   2017\n#:> 103    David   2018print (df.loc[  101:104 ,  'year1':'year2'  ], '\\n')  # by range of row label and column names#:>        year1  salary  year2\n#:> empID                      \n#:> 101     2017   24000   1907\n#:> 102     2017   31000   2003\n#:> 103     2018   20000   1998\n#:> 104     2018   30000   2011df.loc[df.year1==2017, 'year1':'year2']#:>        year1  salary  year2\n#:> empID                      \n#:> 100     2017   40000   2001\n#:> 101     2017   24000   1907\n#:> 102     2017   31000   2003print (df.iloc[ [1,4], [0,3]],'\\n' )   # by individual rows/columns#:>        year1  name\n#:> empID             \n#:> 101     2017   Bob\n#:> 104     2018  Ericprint (df.iloc[  1:4 ,  0:3], '\\n')    # by range#:>        year1  salary  year2\n#:> empID                      \n#:> 101     2017   24000   1907\n#:> 102     2017   31000   2003\n#:> 103     2018   20000   1998"},{"path":"pandas-1.html","id":"chained-indexing","chapter":"13 pandas","heading":"13.7.10 Chained Indexing","text":"Chained Index Method creates copy dataframe, modification data original dataframe affect copySuggesting, never use chain indexing","code":"dataframe.loc  [...]  [...]\ndataframe.iloc [...]  [...]df = pd.DataFrame(\n    { 'empID':  [100,      101,    102,      103,     104],\n      'year1':   [2017,     2017,   2017,      2018,    2018],\n      'name':   ['Alice',  'Bob',  'Charles','David', 'Eric'],\n      'year2':   [2001,     1907,   2003,      1998,    2011],\n      'salary': [40000,    24000,  31000,     20000,   30000]},\n    columns = ['year1','salary','year2','empID','name']).set_index(['empID'])\ndf#:>        year1  salary  year2     name\n#:> empID                               \n#:> 100     2017   40000   2001    Alice\n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles\n#:> 103     2018   20000   1998    David\n#:> 104     2018   30000   2011     Ericdf.loc[100]['year'] =2000#:> /home/msfz751/miniconda3/envs/python_book/bin/python:1: SettingWithCopyWarning: \n#:> A value is trying to be set on a copy of a slice from a DataFrame\n#:> \n#:> See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n#:> /home/msfz751/miniconda3/envs/python_book/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n#:> A value is trying to be set on a copy of a slice from a DataFrame\n#:> \n#:> See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n#:>   iloc._setitem_with_indexer(indexer, value)df  ## notice row label 100 had not been updated, because data was updated on a copy due to chain indexing#:>        year1  salary  year2     name\n#:> empID                               \n#:> 100     2017   40000   2001    Alice\n#:> 101     2017   24000   1907      Bob\n#:> 102     2017   31000   2003  Charles\n#:> 103     2018   20000   1998    David\n#:> 104     2018   30000   2011     Eric"},{"path":"pandas-1.html","id":"cell-value-replacement","chapter":"13 pandas","heading":"13.7.11 Cell Value Replacement","text":"Slicing deals square cells selection. Use mask select specific cell(s). function respect column row names.","code":""},{"path":"pandas-1.html","id":"mask","chapter":"13 pandas","heading":"13.7.11.1 mask()","text":"mask() replace value = condition met. Column row name respected","code":"ori = pd.DataFrame(data={\n     'x': [1,4,7],\n     'y': [2,5,8],\n     'z': [3,6,9]}, index=[\n     'row1','row2','row3'])\n\ndf_big = (ori >4)[['y','x','z']]\nresul1 = ori.mask(df_big, other=999)\n\nprint('Original DF: \\n', ori, '\\n\\n',\n      'Big DF : \\n', df_big, '\\n\\n',\n      'Result : \\n', resul1)#:> Original DF: \n#:>        x  y  z\n#:> row1  1  2  3\n#:> row2  4  5  6\n#:> row3  7  8  9 \n#:> \n#:>  Big DF : \n#:>            y      x      z\n#:> row1  False  False  False\n#:> row2   True  False   True\n#:> row3   True   True   True \n#:> \n#:>  Result : \n#:>          x    y    z\n#:> row1    1    2    3\n#:> row2    4  999  999\n#:> row3  999  999  999"},{"path":"pandas-1.html","id":"where-1","chapter":"13 pandas","heading":"13.7.11.2 where()","text":"reverse mask(), repalce value condition False.","code":"df.where(cond=df_big)#:>        year1  salary  year2 name\n#:> empID                           \n#:> 100      NaN     NaN    NaN  NaN\n#:> 101      NaN     NaN    NaN  NaN\n#:> 102      NaN     NaN    NaN  NaN\n#:> 103      NaN     NaN    NaN  NaN\n#:> 104      NaN     NaN    NaN  NaN"},{"path":"pandas-1.html","id":"iteration","chapter":"13 pandas","heading":"13.7.12 Iteration","text":"","code":""},{"path":"pandas-1.html","id":"loop-through-rows-.iterrows","chapter":"13 pandas","heading":"13.7.12.1 Loop Through Rows (.iterrows)","text":"","code":"df = pd.DataFrame(data=\n    { 'empID':  [100,      101,    102,      103,     104],\n      'Name':   ['Alice',  'Bob',  'Charles','David', 'Eric'],\n      'Year':   [1999,     1988,   2001,     2010,     2020]}).set_index(['empID'])\n\nfor idx, row in df.iterrows():\n  print(idx, row.Name)#:> 100 Alice\n#:> 101 Bob\n#:> 102 Charles\n#:> 103 David\n#:> 104 Eric"},{"path":"pandas-1.html","id":"loop-through-columns-.itemes","chapter":"13 pandas","heading":"13.7.12.2 Loop Through Columns (.itemes)","text":"","code":"for label, content in df.items():\n  print('Label:',            label,   '\\n\\n', \n        'Content (Series):\\n', content, '\\n\\n')#:> Label: Name \n#:> \n#:>  Content (Series):\n#:>  empID\n#:> 100      Alice\n#:> 101        Bob\n#:> 102    Charles\n#:> 103      David\n#:> 104       Eric\n#:> Name: Name, dtype: object \n#:> \n#:> \n#:> Label: Year \n#:> \n#:>  Content (Series):\n#:>  empID\n#:> 100    1999\n#:> 101    1988\n#:> 102    2001\n#:> 103    2010\n#:> 104    2020\n#:> Name: Year, dtype: int64"},{"path":"pandas-1.html","id":"data-structure","chapter":"13 pandas","heading":"13.7.13 Data Structure","text":"","code":""},{"path":"pandas-1.html","id":"instance-methods---structure","chapter":"13 pandas","heading":"13.7.13.1 Instance Methods - Structure","text":"Find column names, data type summary. Output display , data object","code":"df.info()  # return text output#:> <class 'pandas.core.frame.DataFrame'>\n#:> Int64Index: 5 entries, 100 to 104\n#:> Data columns (total 2 columns):\n#:>  #   Column  Non-Null Count  Dtype \n#:> ---  ------  --------------  ----- \n#:>  0   Name    5 non-null      object\n#:>  1   Year    5 non-null      int64 \n#:> dtypes: int64(1), object(1)\n#:> memory usage: 120.0+ bytesdf.get_dtype_counts() # return Series"},{"path":"pandas-1.html","id":"conversion-to-other-format","chapter":"13 pandas","heading":"13.7.13.2 Conversion To Other Format","text":"","code":"df.to_json()#:> '{\"Name\":{\"100\":\"Alice\",\"101\":\"Bob\",\"102\":\"Charles\",\"103\":\"David\",\"104\":\"Eric\"},\"Year\":{\"100\":1999,\"101\":1988,\"102\":2001,\"103\":2010,\"104\":2020}}'df.to_records()#:> rec.array([(100, 'Alice', 1999), (101, 'Bob', 1988),\n#:>            (102, 'Charles', 2001), (103, 'David', 2010),\n#:>            (104, 'Eric', 2020)],\n#:>           dtype=[('empID', '<i8'), ('Name', 'O'), ('Year', '<i8')])df.to_csv()#:> 'empID,Name,Year\\n100,Alice,1999\\n101,Bob,1988\\n102,Charles,2001\\n103,David,2010\\n104,Eric,2020\\n'"},{"path":"pandas-1.html","id":"class-multiindex","chapter":"13 pandas","heading":"13.8 class: MultiIndex","text":"MultiIndexing columns levels headers.","code":""},{"path":"pandas-1.html","id":"the-data-2","chapter":"13 pandas","heading":"13.8.1 The Data","text":"","code":"df = pd.DataFrame({\n     'myindex': [0, 1, 2],\n     'One_X':   [1.1,  1.1,  1.1],\n     'One_Y':   [1.2,  1.2,  1.2],\n     'Two_X':   [1.11, 1.11, 1.11],\n     'Two_Y':   [1.22, 1.22, 1.22]})\ndf.set_index('myindex',inplace=True)\ndf#:>          One_X  One_Y  Two_X  Two_Y\n#:> myindex                            \n#:> 0          1.1    1.2   1.11   1.22\n#:> 1          1.1    1.2   1.11   1.22\n#:> 2          1.1    1.2   1.11   1.22"},{"path":"pandas-1.html","id":"creating-multiindex-object","chapter":"13 pandas","heading":"13.8.2 Creating MultiIndex Object","text":"","code":""},{"path":"pandas-1.html","id":"create-from-tuples","chapter":"13 pandas","heading":"13.8.2.1 Create From Tuples","text":"MultiIndex can easily created typles:\n- Step 1: Create MultiIndex object splitting column name tuples\n- Step 2: Assign MultiIndex Object dataframe columns property.","code":"my_tuples = [tuple(c.split('_')) for c in df.columns]\ndf.columns = pd.MultiIndex.from_tuples(my_tuples)\n\nprint(' Column Headers :\\n\\n',           my_tuples,\n        '\\n\\nNew Columns: \\n\\n',         df.columns,\n        '\\n\\nTwo Layers Header DF:\\n\\n', df)#:>  Column Headers :\n#:> \n#:>  [('One', 'X'), ('One', 'Y'), ('Two', 'X'), ('Two', 'Y')] \n#:> \n#:> New Columns: \n#:> \n#:>  MultiIndex([('One', 'X'),\n#:>             ('One', 'Y'),\n#:>             ('Two', 'X'),\n#:>             ('Two', 'Y')],\n#:>            ) \n#:> \n#:> Two Layers Header DF:\n#:> \n#:>           One        Two      \n#:>            X    Y     X     Y\n#:> myindex                      \n#:> 0        1.1  1.2  1.11  1.22\n#:> 1        1.1  1.2  1.11  1.22\n#:> 2        1.1  1.2  1.11  1.22"},{"path":"pandas-1.html","id":"multiindex-object","chapter":"13 pandas","heading":"13.8.3 MultiIndex Object","text":"","code":""},{"path":"pandas-1.html","id":"levels","chapter":"13 pandas","heading":"13.8.3.1 Levels","text":"MultiIndex object contain multiple leveels, level (header) Index object.Use MultiIndex.get_level_values() entire header desired level. Note level Index objectMultiIndex.levels return unique values level.","code":"print(df.columns.get_level_values(0), '\\n',\n      df.columns.get_level_values(1))#:> Index(['One', 'One', 'Two', 'Two'], dtype='object') \n#:>  Index(['X', 'Y', 'X', 'Y'], dtype='object')print(df.columns.levels[0], '\\n',\n      df.columns.levels[1])#:> Index(['One', 'Two'], dtype='object') \n#:>  Index(['X', 'Y'], dtype='object')"},{"path":"pandas-1.html","id":"convert-multiindex-back-to-tuples","chapter":"13 pandas","heading":"13.8.3.2 Convert MultiIndex Back To Tuples","text":"","code":"df.columns.to_list()#:> [('One', 'X'), ('One', 'Y'), ('Two', 'X'), ('Two', 'Y')]"},{"path":"pandas-1.html","id":"selecting-columns","chapter":"13 pandas","heading":"13.8.4 Selecting Column(s)","text":"","code":""},{"path":"pandas-1.html","id":"sample-data-11","chapter":"13 pandas","heading":"13.8.4.1 Sample Data","text":"","code":"import itertools\ntest_df = pd.DataFrame\nmax_age = 100\n\n### Create The Columns Tuple\nlevel0_sex = ['Male','Female','Pondan']\nlevel1_age = ['Medium','High','Low']\nmy_columns = list(itertools.product(level0_sex, level1_age))\n\ntest_df = pd.DataFrame([\n             [1,2,3,4,5,6,7,8,9],\n             [11,12,13,14,15,16,17,18,19],\n             [21,22,23,24,25,26,27,28,29]], index=['row1','row2','row3'])\n\n### Create Multiindex From Tuple\ntest_df.columns = pd.MultiIndex.from_tuples(my_columns)\nprint( test_df ) #:>        Male          Female          Pondan         \n#:>      Medium High Low Medium High Low Medium High Low\n#:> row1      1    2   3      4    5   6      7    8   9\n#:> row2     11   12  13     14   15  16     17   18  19\n#:> row3     21   22  23     24   25  26     27   28  29"},{"path":"pandas-1.html","id":"select-level0-headers","chapter":"13 pandas","heading":"13.8.4.2 Select Level0 Header(s)","text":"Use [L0] notation, L0 list header namesUsing .loc[]Use .loc[ :, L0 ], L0 list headers names","code":"print( test_df[['Male','Pondan']] ,'\\n\\n',  ## Include multiple Level0 Header\n       test_df['Male'] ,          '\\n\\n',   ## Include single Level0 Header\n       test_df.Male )                       ## Same as above#:>        Male          Pondan         \n#:>      Medium High Low Medium High Low\n#:> row1      1    2   3      7    8   9\n#:> row2     11   12  13     17   18  19\n#:> row3     21   22  23     27   28  29 \n#:> \n#:>        Medium  High  Low\n#:> row1       1     2    3\n#:> row2      11    12   13\n#:> row3      21    22   23 \n#:> \n#:>        Medium  High  Low\n#:> row1       1     2    3\n#:> row2      11    12   13\n#:> row3      21    22   23print( test_df.loc[:, ['Male','Pondan']] , '\\n\\n',  ## Multiple Level0 Header\n       test_df.loc[:, 'Male'] )                     ## Single Level0 Header#:>        Male          Pondan         \n#:>      Medium High Low Medium High Low\n#:> row1      1    2   3      7    8   9\n#:> row2     11   12  13     17   18  19\n#:> row3     21   22  23     27   28  29 \n#:> \n#:>        Medium  High  Low\n#:> row1       1     2    3\n#:> row2      11    12   13\n#:> row3      21    22   23"},{"path":"pandas-1.html","id":"selecting-level-1-headers","chapter":"13 pandas","heading":"13.8.4.3 Selecting Level 1 Header(s)","text":"Use .loc[ :, (, L1)], L1 list headers names","code":"All = slice(None)\nprint( test_df.loc[ : , (All, 'High')],  '\\n\\n',  ## Signle L1 header\n       test_df.loc[ : , (All, ['High','Low'])] )  ## Multiple L1 headers#:>      Male Female Pondan\n#:>      High   High   High\n#:> row1    2      5      8\n#:> row2   12     15     18\n#:> row3   22     25     28 \n#:> \n#:>       Male     Female     Pondan    \n#:>      High Low   High Low   High Low\n#:> row1    2   3      5   6      8   9\n#:> row2   12  13     15  16     18  19\n#:> row3   22  23     25  26     28  29"},{"path":"pandas-1.html","id":"select-level-0-and-level1-headers","chapter":"13 pandas","heading":"13.8.4.4 Select Level 0 and Level1 Headers","text":"Use .loc[ :, (L0, L1)], L0 L1 list headers names","code":"test_df.loc[ : , (['Male','Pondan'], ['Medium','High'])]#:>        Male      Pondan     \n#:>      Medium High Medium High\n#:> row1      1    2      7    8\n#:> row2     11   12     17   18\n#:> row3     21   22     27   28"},{"path":"pandas-1.html","id":"select-single-l0l1-header","chapter":"13 pandas","heading":"13.8.4.5 Select single L0,L1 Header","text":"Use .loc[:, (L0,  L1) ], result Series\nUse .loc[:, (L0 ,[L1])], result DataFrame","code":"print( test_df.loc[ : , ('Female', 'High')], '\\n\\n',\n       test_df.loc[ : , ('Female', ['High'])])#:> row1     5\n#:> row2    15\n#:> row3    25\n#:> Name: (Female, High), dtype: int64 \n#:> \n#:>       Female\n#:>        High\n#:> row1      5\n#:> row2     15\n#:> row3     25"},{"path":"pandas-1.html","id":"headers-ordering","chapter":"13 pandas","heading":"13.8.5 Headers Ordering","text":"Note columns order specifeid [ ] selection respected. can remediated either Sorting rearranging.","code":""},{"path":"pandas-1.html","id":"sort-headers","chapter":"13 pandas","heading":"13.8.5.1 Sort Headers","text":"Use .sort_index() DataFrame sort headers. Note level1 sorted, jumble level0 headers.","code":"test_df_sorted_l0 = test_df.sort_index(axis=1, level=0)\ntest_df_sorted_l1 = test_df.sort_index(axis=1, level=1, ascending=False)\nprint(test_df, '\\n\\n',test_df_sorted_l0, '\\n\\n', test_df_sorted_l1)#:>        Male          Female          Pondan         \n#:>      Medium High Low Medium High Low Medium High Low\n#:> row1      1    2   3      4    5   6      7    8   9\n#:> row2     11   12  13     14   15  16     17   18  19\n#:> row3     21   22  23     24   25  26     27   28  29 \n#:> \n#:>       Female            Male            Pondan           \n#:>        High Low Medium High Low Medium   High Low Medium\n#:> row1      5   6      4    2   3      1      8   9      7\n#:> row2     15  16     14   12  13     11     18  19     17\n#:> row3     25  26     24   22  23     21     28  29     27 \n#:> \n#:>       Pondan   Male Female Pondan Male Female Pondan Male Female\n#:>      Medium Medium Medium    Low  Low    Low   High High   High\n#:> row1      7      1      4      9    3      6      8    2      5\n#:> row2     17     11     14     19   13     16     18   12     15\n#:> row3     27     21     24     29   23     26     28   22     25"},{"path":"pandas-1.html","id":"rearranging-headers","chapter":"13 pandas","heading":"13.8.5.2 Rearranging Headers","text":"Use **.reindex()** arrange columns specific order. Example shows control specific order level1 headers.","code":"cats = ['Low','Medium','High']\ntest_df.reindex(cats, level=1, axis=1)#:>      Male             Female             Pondan            \n#:>       Low Medium High    Low Medium High    Low Medium High\n#:> row1    3      1    2      6      4    5      9      7    8\n#:> row2   13     11   12     16     14   15     19     17   18\n#:> row3   23     21   22     26     24   25     29     27   28"},{"path":"pandas-1.html","id":"stacking-and-unstacking","chapter":"13 pandas","heading":"13.8.6 Stacking and Unstacking","text":"","code":"df.stack()#:>            One   Two\n#:> myindex             \n#:> 0       X  1.1  1.11\n#:>         Y  1.2  1.22\n#:> 1       X  1.1  1.11\n#:>         Y  1.2  1.22\n#:> 2       X  1.1  1.11\n#:>         Y  1.2  1.22"},{"path":"pandas-1.html","id":"stacking-columns-to-rows","chapter":"13 pandas","heading":"13.8.6.1 Stacking Columns to Rows","text":"Stacking DataFrame.stack(level_no) moving wide columns row.","code":"print('Stacking Header Level 0: \\n\\n', df.stack(0),\n      '\\n\\nStacking Header Level 1: \\n\\n', df.stack(1))#:> Stacking Header Level 0: \n#:> \n#:>                  X     Y\n#:> myindex                \n#:> 0       One  1.10  1.20\n#:>         Two  1.11  1.22\n#:> 1       One  1.10  1.20\n#:>         Two  1.11  1.22\n#:> 2       One  1.10  1.20\n#:>         Two  1.11  1.22 \n#:> \n#:> Stacking Header Level 1: \n#:> \n#:>             One   Two\n#:> myindex             \n#:> 0       X  1.1  1.11\n#:>         Y  1.2  1.22\n#:> 1       X  1.1  1.11\n#:>         Y  1.2  1.22\n#:> 2       X  1.1  1.11\n#:>         Y  1.2  1.22"},{"path":"pandas-1.html","id":"exploratory-analysis","chapter":"13 pandas","heading":"13.8.7 Exploratory Analysis","text":"","code":""},{"path":"pandas-1.html","id":"sample-data-12","chapter":"13 pandas","heading":"13.8.7.1 Sample Data","text":"","code":"df#:>          One        Two      \n#:>            X    Y     X     Y\n#:> myindex                      \n#:> 0        1.1  1.2  1.11  1.22\n#:> 1        1.1  1.2  1.11  1.22\n#:> 2        1.1  1.2  1.11  1.22"},{"path":"pandas-1.html","id":"all-stats-in-one---.describe","chapter":"13 pandas","heading":"13.8.7.2 All Stats in One - .describe()","text":"applied DataFrame object, describe shows basic statistic numeric columns:\n- Count (non-NA)\n- Unique (string)\n- Top (string)\n- Frequency (string)\n- Percentile\n- Mean\n- Min / Max\n- Standard DeviationFor Numeric Columns \ncan customize percentiles requred. Notice 0.5 percentile always although specifiedFor Numeric Object","code":"df.describe(include='number') # default\ndf.describe(include='object') # display for non-numeric columns\ndf.describe(include='all')    # display both numeric and non-numericdf.describe()#:>        One        Two      \n#:>          X    Y     X     Y\n#:> count  3.0  3.0  3.00  3.00\n#:> mean   1.1  1.2  1.11  1.22\n#:> std    0.0  0.0  0.00  0.00\n#:> min    1.1  1.2  1.11  1.22\n#:> 25%    1.1  1.2  1.11  1.22\n#:> 50%    1.1  1.2  1.11  1.22\n#:> 75%    1.1  1.2  1.11  1.22\n#:> max    1.1  1.2  1.11  1.22df.describe(percentiles=[0.9,0.3,0.2,0.1])#:>        One        Two      \n#:>          X    Y     X     Y\n#:> count  3.0  3.0  3.00  3.00\n#:> mean   1.1  1.2  1.11  1.22\n#:> std    0.0  0.0  0.00  0.00\n#:> min    1.1  1.2  1.11  1.22\n#:> 10%    1.1  1.2  1.11  1.22\n#:> 20%    1.1  1.2  1.11  1.22\n#:> 30%    1.1  1.2  1.11  1.22\n#:> 50%    1.1  1.2  1.11  1.22\n#:> 90%    1.1  1.2  1.11  1.22\n#:> max    1.1  1.2  1.11  1.22df.describe(include='all')#:>        One        Two      \n#:>          X    Y     X     Y\n#:> count  3.0  3.0  3.00  3.00\n#:> mean   1.1  1.2  1.11  1.22\n#:> std    0.0  0.0  0.00  0.00\n#:> min    1.1  1.2  1.11  1.22\n#:> 25%    1.1  1.2  1.11  1.22\n#:> 50%    1.1  1.2  1.11  1.22\n#:> 75%    1.1  1.2  1.11  1.22\n#:> max    1.1  1.2  1.11  1.22"},{"path":"pandas-1.html","id":"minmaxmeanmedian","chapter":"13 pandas","heading":"13.8.7.3 min/max/mean/median","text":"Observe, sum string concatenate column-wise, whereas row-wise sum numeric fields","code":"df.min()  # default axis=0, column-wise#:> One  X    1.10\n#:>      Y    1.20\n#:> Two  X    1.11\n#:>      Y    1.22\n#:> dtype: float64df.min(axis=1) # axis=1, row-wise#:> myindex\n#:> 0    1.1\n#:> 1    1.1\n#:> 2    1.1\n#:> dtype: float64df.sum(0)#:> One  X    3.30\n#:>      Y    3.60\n#:> Two  X    3.33\n#:>      Y    3.66\n#:> dtype: float64df.sum(1)#:> myindex\n#:> 0    4.63\n#:> 1    4.63\n#:> 2    4.63\n#:> dtype: float64"},{"path":"pandas-1.html","id":"plotting","chapter":"13 pandas","heading":"13.8.8 Plotting","text":"","code":""},{"path":"pandas-1.html","id":"class-categories","chapter":"13 pandas","heading":"13.9 class: Categories","text":"","code":""},{"path":"pandas-1.html","id":"creating-2","chapter":"13 pandas","heading":"13.9.1 Creating","text":"","code":""},{"path":"pandas-1.html","id":"from-list","chapter":"13 pandas","heading":"13.9.1.1 From List","text":"Basic (Auto Category Mapping)\nBasic syntax return categorical index sequence code 0,1,2,3… mapping first found category\ncase, low(0), high(1), medium(2)Manual Category Mapping\ncreation, can specify mapping codes category: low(0), medium(1), high(2)","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Categorical(temp)\ntemp_cat#:> ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n#:> Categories (3, object): ['high', 'low', 'medium']type( temp_cat )#:> <class 'pandas.core.arrays.categorical.Categorical'>temp_cat = pd.Categorical(temp, categories=['low','medium','high'])\ntemp_cat#:> ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n#:> Categories (3, object): ['low', 'medium', 'high']"},{"path":"pandas-1.html","id":"from-series","chapter":"13 pandas","heading":"13.9.1.2 From Series","text":"can ‘add’ categorical structure Series. methods, additional property (.cat) added categorical accessorThrough accessor, gain access various properties category .codes, .categories. .get_values() information Series itselfCan manual map category ?????Method result using .astype(‘category’)useful adding category structure existing series.","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Series(temp, dtype='category')\nprint (type(temp_cat))       # Series object#:> <class 'pandas.core.series.Series'>print (type(temp_cat.cat))   # Categorical Accessor#:> <class 'pandas.core.arrays.categorical.CategoricalAccessor'>temp_ser = pd.Series(temp)\ntemp_cat = pd.Series(temp).astype('category')\nprint (type(temp_cat))       # Series object#:> <class 'pandas.core.series.Series'>print (type(temp_cat.cat))   # Categorical Accessor#:> <class 'pandas.core.arrays.categorical.CategoricalAccessor'>temp_cat.cat.categories#:> Index(['high', 'low', 'medium'], dtype='object')"},{"path":"pandas-1.html","id":"ordering-category","chapter":"13 pandas","heading":"13.9.1.3 Ordering Category","text":"","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Categorical(temp, categories=['low','medium','high'], ordered=True)\ntemp_cat#:> ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n#:> Categories (3, object): ['low' < 'medium' < 'high']# error\ntemp_cat.get_values()temp_cat.codes#:> array([0, 2, 1, 2, 2, 0, 1, 1, 2], dtype=int8)temp_cat[0] < temp_cat[3]#:> False"},{"path":"pandas-1.html","id":"properties","chapter":"13 pandas","heading":"13.9.2 Properties","text":"","code":""},{"path":"pandas-1.html","id":"categories","chapter":"13 pandas","heading":"13.9.2.1 .categories","text":"first element’s code = 0\nsecond element’s code = 1\nthird element’s code = 2","code":"temp_cat.categories#:> Index(['low', 'medium', 'high'], dtype='object')"},{"path":"pandas-1.html","id":"codes","chapter":"13 pandas","heading":"13.9.2.2 .codes","text":"Codes actual integer value stored array. 1 represent ‘high,’","code":"temp_cat.codes#:> array([0, 2, 1, 2, 2, 0, 1, 1, 2], dtype=int8)"},{"path":"pandas-1.html","id":"rename-category","chapter":"13 pandas","heading":"13.9.3 Rename Category","text":"","code":""},{"path":"pandas-1.html","id":"renamce-to-new-category-object","chapter":"13 pandas","heading":"13.9.3.1 Renamce To New Category Object","text":".rename_categories() method return new category object new changed categories","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\nnew_temp_cat = temp_cat.rename_categories(['sejuk','sederhana','panas'])\nnew_temp_cat #:> ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n#:> Categories (3, object): ['sejuk' < 'sederhana' < 'panas']temp_cat   # original category object categories not changed#:> ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n#:> Categories (3, object): ['low' < 'medium' < 'high']"},{"path":"pandas-1.html","id":"rename-inplace","chapter":"13 pandas","heading":"13.9.3.2 Rename Inplace","text":"Observe original categories changed using .rename()","code":"temp_cat.categories = ['sejuk','sederhana','panas']\ntemp_cat   # original category object categories is changed#:> ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n#:> Categories (3, object): ['sejuk' < 'sederhana' < 'panas']"},{"path":"pandas-1.html","id":"adding-new-category","chapter":"13 pandas","heading":"13.9.4 Adding New Category","text":"return new category object added categories","code":"temp_cat_more = temp_cat.add_categories(['susah','senang'])\ntemp_cat_more#:> ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n#:> Categories (5, object): ['sejuk' < 'sederhana' < 'panas' < 'susah' < 'senang']"},{"path":"pandas-1.html","id":"removing-category","chapter":"13 pandas","heading":"13.9.5 Removing Category","text":"place, hence return new categorical object","code":""},{"path":"pandas-1.html","id":"remove-specific-categories","chapter":"13 pandas","heading":"13.9.5.1 Remove Specific Categor(ies)","text":"Elements category removed become NaN","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Categorical(temp)\ntemp_cat_removed = temp_cat.remove_categories('low')\ntemp_cat_removed#:> [NaN, 'high', 'medium', 'high', 'high', NaN, 'medium', 'medium', 'high']\n#:> Categories (2, object): ['high', 'medium']"},{"path":"pandas-1.html","id":"remove-unused-category","chapter":"13 pandas","heading":"13.9.5.2 Remove Unused Category","text":"Since categories removed used, impact element","code":"print (temp_cat_more)#:> ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n#:> Categories (5, object): ['sejuk' < 'sederhana' < 'panas' < 'susah' < 'senang']temp_cat_more.remove_unused_categories()#:> ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n#:> Categories (3, object): ['sejuk' < 'sederhana' < 'panas']"},{"path":"pandas-1.html","id":"add-and-remove-categories-in-one-step---set","chapter":"13 pandas","heading":"13.9.6 Add and Remove Categories In One Step - Set()","text":"","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Categorical(temp, ordered=True)\ntemp_cat#:> ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n#:> Categories (3, object): ['high' < 'low' < 'medium']temp_cat.set_categories(['low','medium','sederhana','susah','senang'])#:> ['low', NaN, 'medium', NaN, NaN, 'low', 'medium', 'medium', NaN]\n#:> Categories (5, object): ['low' < 'medium' < 'sederhana' < 'susah' < 'senang']"},{"path":"pandas-1.html","id":"categorical-descriptive-analysis","chapter":"13 pandas","heading":"13.9.7 Categorical Descriptive Analysis","text":"","code":""},{"path":"pandas-1.html","id":"at-one-glance","chapter":"13 pandas","heading":"13.9.7.1 At One Glance","text":"","code":"temp_cat.describe()#:>             counts     freqs\n#:> categories                  \n#:> high             4  0.444444\n#:> low              2  0.222222\n#:> medium           3  0.333333"},{"path":"pandas-1.html","id":"frequency-count","chapter":"13 pandas","heading":"13.9.7.2 Frequency Count","text":"","code":"temp_cat.value_counts()#:> high      4\n#:> low       2\n#:> medium    3\n#:> dtype: int64"},{"path":"pandas-1.html","id":"least-frequent-category-most-frequent-category-and-most-frequent-category","chapter":"13 pandas","heading":"13.9.7.3 Least Frequent Category, Most Frequent Category, and Most Frequent Category","text":"","code":"( temp_cat.min(), temp_cat.max(), temp_cat.mode() )#:> ('high', 'medium', ['high']\n#:> Categories (3, object): ['high' < 'low' < 'medium'])"},{"path":"pandas-1.html","id":"other-methods-1","chapter":"13 pandas","heading":"13.9.8 Other Methods","text":"","code":""},{"path":"pandas-1.html","id":"get_values","chapter":"13 pandas","heading":"13.9.8.1 .get_values()","text":"Since actual value stored categorical object integer codes, get_values() function return values translated *.codes** property","code":"temp_cat.get_values()  #array"},{"path":"pandas-1.html","id":"dummies","chapter":"13 pandas","heading":"13.10 Dummies","text":"get_dummies creates columns categoriesThe underlying data can string pd.CategoricalIt produces new pd.DataFrame","code":""},{"path":"pandas-1.html","id":"sample-data-13","chapter":"13 pandas","heading":"13.10.1 Sample Data","text":"","code":"df = pd.DataFrame (\n    {'A': ['A1', 'A2', 'A3','A1','A3','A1'], \n     'B': ['B1','B2','B3','B1','B1','B3'],\n     'C': ['C1','C2','C3','C1',np.nan,np.nan]})\ndf#:>     A   B    C\n#:> 0  A1  B1   C1\n#:> 1  A2  B2   C2\n#:> 2  A3  B3   C3\n#:> 3  A1  B1   C1\n#:> 4  A3  B1  NaN\n#:> 5  A1  B3  NaN"},{"path":"pandas-1.html","id":"dummies-on-array-like-data","chapter":"13 pandas","heading":"13.10.2 Dummies on Array-Like Data","text":"","code":"pd.get_dummies(df.A)#:>    A1  A2  A3\n#:> 0   1   0   0\n#:> 1   0   1   0\n#:> 2   0   0   1\n#:> 3   1   0   0\n#:> 4   0   0   1\n#:> 5   1   0   0"},{"path":"pandas-1.html","id":"dummies-on-dataframe-multiple-columns","chapter":"13 pandas","heading":"13.10.3 Dummies on DataFrame (multiple columns)","text":"","code":""},{"path":"pandas-1.html","id":"all-columns","chapter":"13 pandas","heading":"13.10.3.1 All Columns","text":"","code":"pd.get_dummies(df)#:>    A_A1  A_A2  A_A3  B_B1  B_B2  B_B3  C_C1  C_C2  C_C3\n#:> 0     1     0     0     1     0     0     1     0     0\n#:> 1     0     1     0     0     1     0     0     1     0\n#:> 2     0     0     1     0     0     1     0     0     1\n#:> 3     1     0     0     1     0     0     1     0     0\n#:> 4     0     0     1     1     0     0     0     0     0\n#:> 5     1     0     0     0     0     1     0     0     0"},{"path":"pandas-1.html","id":"selected-columns","chapter":"13 pandas","heading":"13.10.3.2 Selected Columns","text":"","code":"cols = ['A','B']\npd.get_dummies(df[cols])#:>    A_A1  A_A2  A_A3  B_B1  B_B2  B_B3\n#:> 0     1     0     0     1     0     0\n#:> 1     0     1     0     0     1     0\n#:> 2     0     0     1     0     0     1\n#:> 3     1     0     0     1     0     0\n#:> 4     0     0     1     1     0     0\n#:> 5     1     0     0     0     0     1"},{"path":"pandas-1.html","id":"dummies-with-na","chapter":"13 pandas","heading":"13.10.4 Dummies with na","text":"default, nan values ignoredMake NaN dummy variable","code":"pd.get_dummies(df.C)#:>    C1  C2  C3\n#:> 0   1   0   0\n#:> 1   0   1   0\n#:> 2   0   0   1\n#:> 3   1   0   0\n#:> 4   0   0   0\n#:> 5   0   0   0pd.get_dummies(df.C,dummy_na=True)#:>    C1  C2  C3  NaN\n#:> 0   1   0   0    0\n#:> 1   0   1   0    0\n#:> 2   0   0   1    0\n#:> 3   1   0   0    0\n#:> 4   0   0   0    1\n#:> 5   0   0   0    1"},{"path":"pandas-1.html","id":"specify-prefixes","chapter":"13 pandas","heading":"13.10.5 Specify Prefixes","text":"","code":"pd.get_dummies(df.A, prefix='col')#:>    col_A1  col_A2  col_A3\n#:> 0       1       0       0\n#:> 1       0       1       0\n#:> 2       0       0       1\n#:> 3       1       0       0\n#:> 4       0       0       1\n#:> 5       1       0       0pd.get_dummies(df[cols], prefix=['colA','colB'])#:>    colA_A1  colA_A2  colA_A3  colB_B1  colB_B2  colB_B3\n#:> 0        1        0        0        1        0        0\n#:> 1        0        1        0        0        1        0\n#:> 2        0        0        1        0        0        1\n#:> 3        1        0        0        1        0        0\n#:> 4        0        0        1        1        0        0\n#:> 5        1        0        0        0        0        1"},{"path":"pandas-1.html","id":"dropping-first-column","chapter":"13 pandas","heading":"13.10.6 Dropping First Column","text":"Dummies cause colinearity issue regression redundant column.Dropping column loose information technically","code":"pd.get_dummies(df[cols],drop_first=True)#:>    A_A2  A_A3  B_B2  B_B3\n#:> 0     0     0     0     0\n#:> 1     1     0     1     0\n#:> 2     0     1     0     1\n#:> 3     0     0     0     0\n#:> 4     0     1     0     0\n#:> 5     0     0     0     1"},{"path":"pandas-1.html","id":"dataframegroupby","chapter":"13 pandas","heading":"13.11 DataFrameGroupBy","text":"groupby() DataFrame method, returns DataFrameGroupBy objectDataFrameGroupBy object open doors dataframe aggregation summarizationDataFrameGroupBy object flexible abstraction. many ways, can simply treat DataFrameGroup ’s collection DataFrames, difficult things hood","code":""},{"path":"pandas-1.html","id":"sample-data-14","chapter":"13 pandas","heading":"13.11.1 Sample Data","text":"","code":"company = pd.read_csv('data/company.csv')\ncompany#:>    Company Department      Name  Age  Salary  Birthdate\n#:> 0       C1         D1      Yong   45   15000   1/1/1970\n#:> 1       C1         D1      Chew   35   12000   2/1/1980\n#:> 2       C1         D2       Lim   34    8000  2/19/1977\n#:> 3       C1         D3     Jessy   23    2500  3/15/1990\n#:> 4       C1         D3  Hoi Ming   55   25000  4/15/1987\n#:> ..     ...        ...       ...  ...     ...        ...\n#:> 13      C3         D3     Chang   32    7900  7/26/1973\n#:> 14      C3         D1       Ong   44   17500  8/21/1980\n#:> 15      C3         D2      Lily   41   15300  7/17/1990\n#:> 16      C3         D3     Sally   54   21000  7/19/1968\n#:> 17      C3         D3    Esther   37   13500  3/16/1969\n#:> \n#:> [18 rows x 6 columns]"},{"path":"pandas-1.html","id":"creating-groups","chapter":"13 pandas","heading":"13.11.2 Creating Groups","text":"Group can created single multiple columns","code":"com_grp = company.groupby('Company') ## Single Column\ncom_dep_grp = company.groupby(['Company','Department'])  ## Multiple Column\ntype(com_dep_grp)#:> <class 'pandas.core.groupby.generic.DataFrameGroupBy'>"},{"path":"pandas-1.html","id":"properties-1","chapter":"13 pandas","heading":"13.11.3 Properties","text":"","code":""},{"path":"pandas-1.html","id":"number-of-groups","chapter":"13 pandas","heading":"13.11.3.1 Number of Groups","text":"","code":"com_dep_grp.ngroups#:> 9"},{"path":"pandas-1.html","id":"row-numbers-associated-for-each-group","chapter":"13 pandas","heading":"13.11.3.2 Row Numbers Associated For Each Group","text":".groups property dictionary containing group key (identifying group) values (underlying row indexes group)","code":"gdict = com_dep_grp.groups       # return Dictionary\nprint( gdict.keys()   , '\\n\\n',  # group identifier\n       gdict.values()   )        # group row indexes#:> dict_keys([('C1', 'D1'), ('C1', 'D2'), ('C1', 'D3'), ('C2', 'D1'), ('C2', 'D2'), ('C2', 'D3'), ('C3', 'D1'), ('C3', 'D2'), ('C3', 'D3')]) \n#:> \n#:>  dict_values([Int64Index([0, 1], dtype='int64'), Int64Index([2], dtype='int64'), Int64Index([3, 4, 5], dtype='int64'), Int64Index([6], dtype='int64'), Int64Index([7, 8, 9], dtype='int64'), Int64Index([10, 11, 12], dtype='int64'), Int64Index([14], dtype='int64'), Int64Index([15], dtype='int64'), Int64Index([13, 16, 17], dtype='int64')])"},{"path":"pandas-1.html","id":"methods-1","chapter":"13 pandas","heading":"13.11.4 Methods","text":"","code":""},{"path":"pandas-1.html","id":"number-of-rows-in-each-group","chapter":"13 pandas","heading":"13.11.4.1 Number of Rows In Each Group","text":"","code":"com_dep_grp.size()  # return panda Series object#:> Company  Department\n#:> C1       D1            2\n#:>          D2            1\n#:>          D3            3\n#:> C2       D1            1\n#:>          D2            3\n#:>          D3            3\n#:> C3       D1            1\n#:>          D2            1\n#:>          D3            3\n#:> dtype: int64"},{"path":"pandas-1.html","id":"retrieve-rows","chapter":"13 pandas","heading":"13.11.5 Retrieve Rows","text":"","code":""},{"path":"pandas-1.html","id":"retrieve-n-th-row-of-each-grou","chapter":"13 pandas","heading":"13.11.5.1 Retrieve n-th Row Of Each Grou","text":"Row number 0-basedFor First row, use .first() nth(0)Last row, use .last() nth(-1)`","code":"print( com_dep_grp.nth(0)  , '\\n',\n       com_dep_grp.first())#:>                        Name  Age  Salary   Birthdate\n#:> Company Department                                  \n#:> C1      D1             Yong   45   15000    1/1/1970\n#:>         D2              Lim   34    8000   2/19/1977\n#:>         D3            Jessy   23    2500   3/15/1990\n#:> C2      D1             Anne   18     400   7/15/1997\n#:>         D2          Deborah   30    8600   8/15/1984\n#:>         D3          Michael   38   17000  11/30/1997\n#:> C3      D1              Ong   44   17500   8/21/1980\n#:>         D2             Lily   41   15300   7/17/1990\n#:>         D3            Chang   32    7900   7/26/1973 \n#:>                         Name  Age  Salary   Birthdate\n#:> Company Department                                  \n#:> C1      D1             Yong   45   15000    1/1/1970\n#:>         D2              Lim   34    8000   2/19/1977\n#:>         D3            Jessy   23    2500   3/15/1990\n#:> C2      D1             Anne   18     400   7/15/1997\n#:>         D2          Deborah   30    8600   8/15/1984\n#:>         D3          Michael   38   17000  11/30/1997\n#:> C3      D1              Ong   44   17500   8/21/1980\n#:>         D2             Lily   41   15300   7/17/1990\n#:>         D3            Chang   32    7900   7/26/1973print( com_dep_grp.nth(-1)  , '\\n',\n       com_dep_grp.last())#:>                        Name  Age  Salary   Birthdate\n#:> Company Department                                  \n#:> C1      D1             Chew   35   12000    2/1/1980\n#:>         D2              Lim   34    8000   2/19/1977\n#:>         D3          Sui Wei   56    3000   6/15/1990\n#:> C2      D1             Anne   18     400   7/15/1997\n#:>         D2            Jimmy   46   14000  10/31/1988\n#:>         D3          Bernard   29    9800   12/1/1963\n#:> C3      D1              Ong   44   17500   8/21/1980\n#:>         D2             Lily   41   15300   7/17/1990\n#:>         D3           Esther   37   13500   3/16/1969 \n#:>                         Name  Age  Salary   Birthdate\n#:> Company Department                                  \n#:> C1      D1             Chew   35   12000    2/1/1980\n#:>         D2              Lim   34    8000   2/19/1977\n#:>         D3          Sui Wei   56    3000   6/15/1990\n#:> C2      D1             Anne   18     400   7/15/1997\n#:>         D2            Jimmy   46   14000  10/31/1988\n#:>         D3          Bernard   29    9800   12/1/1963\n#:> C3      D1              Ong   44   17500   8/21/1980\n#:>         D2             Lily   41   15300   7/17/1990\n#:>         D3           Esther   37   13500   3/16/1969"},{"path":"pandas-1.html","id":"retrieve-n-rows-of-each-groups","chapter":"13 pandas","heading":"13.11.5.2 Retrieve N Rows Of Each Groups","text":"Example retrieve 2 rows group","code":"com_dep_grp.head(2)#:>    Company Department      Name  Age  Salary   Birthdate\n#:> 0       C1         D1      Yong   45   15000    1/1/1970\n#:> 1       C1         D1      Chew   35   12000    2/1/1980\n#:> 2       C1         D2       Lim   34    8000   2/19/1977\n#:> 3       C1         D3     Jessy   23    2500   3/15/1990\n#:> 4       C1         D3  Hoi Ming   55   25000   4/15/1987\n#:> ..     ...        ...       ...  ...     ...         ...\n#:> 11      C2         D3   Jeannie   30   12500  12/31/1980\n#:> 13      C3         D3     Chang   32    7900   7/26/1973\n#:> 14      C3         D1       Ong   44   17500   8/21/1980\n#:> 15      C3         D2      Lily   41   15300   7/17/1990\n#:> 16      C3         D3     Sally   54   21000   7/19/1968\n#:> \n#:> [14 rows x 6 columns]"},{"path":"pandas-1.html","id":"retrieve-all-rows-of-specific-group","chapter":"13 pandas","heading":"13.11.5.3 Retrieve All Rows Of Specific Group","text":"get_group() retrieves rows within specified group.","code":"com_dep_grp.get_group(('C1','D3'))#:>   Company Department      Name  Age  Salary  Birthdate\n#:> 3      C1         D3     Jessy   23    2500  3/15/1990\n#:> 4      C1         D3  Hoi Ming   55   25000  4/15/1987\n#:> 5      C1         D3   Sui Wei   56    3000  6/15/1990"},{"path":"pandas-1.html","id":"single-statistic-per-group","chapter":"13 pandas","heading":"13.11.6 Single Statistic Per Group","text":"","code":""},{"path":"pandas-1.html","id":"count","chapter":"13 pandas","heading":"13.11.6.1 count()","text":"count() valid data (null) fields within group","code":"com_dep_grp.count()  # return panda DataFrame object#:>                     Name  Age  Salary  Birthdate\n#:> Company Department                              \n#:> C1      D1             2    2       2          2\n#:>         D2             1    1       1          1\n#:>         D3             3    3       3          3\n#:> C2      D1             1    1       1          1\n#:>         D2             3    3       3          3\n#:>         D3             3    3       3          3\n#:> C3      D1             1    1       1          1\n#:>         D2             1    1       1          1\n#:>         D3             3    3       3          3"},{"path":"pandas-1.html","id":"sum","chapter":"13 pandas","heading":"13.11.6.2 sum()","text":"sums numeric columns groupTo sum specific columns group, use ['columnName'] select column.\nsingle column selected, output Series","code":"com_dep_grp.sum()#:>                     Age  Salary\n#:> Company Department             \n#:> C1      D1           80   27000\n#:>         D2           34    8000\n#:>         D3          134   30500\n#:> C2      D1           18     400\n#:>         D2          127   34600\n#:>         D3           97   39300\n#:> C3      D1           44   17500\n#:>         D2           41   15300\n#:>         D3          123   42400com_dep_grp['Age'].sum()#:> Company  Department\n#:> C1       D1             80\n#:>          D2             34\n#:>          D3            134\n#:> C2       D1             18\n#:>          D2            127\n#:>          D3             97\n#:> C3       D1             44\n#:>          D2             41\n#:>          D3            123\n#:> Name: Age, dtype: int64"},{"path":"pandas-1.html","id":"mean","chapter":"13 pandas","heading":"13.11.6.3 mean()","text":"average numeric columns groupTo average specific columns group, use ['columnName'] select column.\nsingle column selected, output Series","code":"com_dep_grp.mean()#:>                           Age        Salary\n#:> Company Department                         \n#:> C1      D1          40.000000  13500.000000\n#:>         D2          34.000000   8000.000000\n#:>         D3          44.666667  10166.666667\n#:> C2      D1          18.000000    400.000000\n#:>         D2          42.333333  11533.333333\n#:>         D3          32.333333  13100.000000\n#:> C3      D1          44.000000  17500.000000\n#:>         D2          41.000000  15300.000000\n#:>         D3          41.000000  14133.333333com_dep_grp['Age'].mean()#:> Company  Department\n#:> C1       D1            40.000000\n#:>          D2            34.000000\n#:>          D3            44.666667\n#:> C2       D1            18.000000\n#:>          D2            42.333333\n#:>          D3            32.333333\n#:> C3       D1            44.000000\n#:>          D2            41.000000\n#:>          D3            41.000000\n#:> Name: Age, dtype: float64"},{"path":"pandas-1.html","id":"multi-statistic-per-group","chapter":"13 pandas","heading":"13.11.7 Multi Statistic Per Group","text":"","code":""},{"path":"pandas-1.html","id":"single-function-to-columns","chapter":"13 pandas","heading":"13.11.7.1 Single Function To Column(s)","text":"Instructions aggregation provided form dictionary. Dictionary keys specifies column name, value function runCan use lambda x: customize calclulation entire column (x)Python built-function names can supplied without wrapping string 'function'","code":"com_dep_grp.agg({\n  'Age': sum ,                 ## Total age of the group\n  'Salary': lambda x: max(x),  ## Highest salary of the group\n  'Birthdate': 'first'         ## First birthday of the group\n})#:>                     Age  Salary   Birthdate\n#:> Company Department                         \n#:> C1      D1           80   15000    1/1/1970\n#:>         D2           34    8000   2/19/1977\n#:>         D3          134   25000   3/15/1990\n#:> C2      D1           18     400   7/15/1997\n#:>         D2          127   14000   8/15/1984\n#:>         D3           97   17000  11/30/1997\n#:> C3      D1           44   17500   8/21/1980\n#:>         D2           41   15300   7/17/1990\n#:>         D3          123   21000   7/26/1973"},{"path":"pandas-1.html","id":"multiple-function-to-columns","chapter":"13 pandas","heading":"13.11.7.2 Multiple Function to Column(s)","text":"Use list function names specify functions applied particular columnNotice output columns MultiIndex , indicating name funcitons appled level 1","code":"ag = com_dep_grp.agg({\n      'Age': ['mean', sum ],       ## Average age of the group\n      'Salary': lambda x: max(x),  ## Highest salary of the group\n      'Birthdate': 'first'         ## First birthday of the group\n    })\n    \nprint (ag, '\\n\\n', ag.columns)#:>                           Age        Salary   Birthdate\n#:>                          mean  sum <lambda>       first\n#:> Company Department                                     \n#:> C1      D1          40.000000   80    15000    1/1/1970\n#:>         D2          34.000000   34     8000   2/19/1977\n#:>         D3          44.666667  134    25000   3/15/1990\n#:> C2      D1          18.000000   18      400   7/15/1997\n#:>         D2          42.333333  127    14000   8/15/1984\n#:>         D3          32.333333   97    17000  11/30/1997\n#:> C3      D1          44.000000   44    17500   8/21/1980\n#:>         D2          41.000000   41    15300   7/17/1990\n#:>         D3          41.000000  123    21000   7/26/1973 \n#:> \n#:>  MultiIndex([(      'Age',     'mean'),\n#:>             (      'Age',      'sum'),\n#:>             (   'Salary', '<lambda>'),\n#:>             ('Birthdate',    'first')],\n#:>            )"},{"path":"pandas-1.html","id":"column-relabling","chapter":"13 pandas","heading":"13.11.7.3 Column Relabling","text":"Introduced Pandas 0.25.0, groupby aggregation relabelling supported using “named aggregation” simple tuples","code":"com_dep_grp.agg(\n  max_age     = ('Age', max),\n  salary_m100 = ('Salary',  lambda x: max(x)+100),  \n  first_bd    = ('Birthdate', 'first')\n)#:>                     max_age  salary_m100    first_bd\n#:> Company Department                                  \n#:> C1      D1               45        15100    1/1/1970\n#:>         D2               34         8100   2/19/1977\n#:>         D3               56        25100   3/15/1990\n#:> C2      D1               18          500   7/15/1997\n#:>         D2               51        14100   8/15/1984\n#:>         D3               38        17100  11/30/1997\n#:> C3      D1               44        17600   8/21/1980\n#:>         D2               41        15400   7/17/1990\n#:>         D3               54        21100   7/26/1973"},{"path":"pandas-1.html","id":"iteration-1","chapter":"13 pandas","heading":"13.11.8 Iteration","text":"DataFrameGroupBy object can thought collection named groups","code":"def print_groups (g):\n    for name,group in g:\n        print (name)\n        print (group[:2])\n        \nprint_groups (com_grp)#:> C1\n#:>   Company Department  Name  Age  Salary Birthdate\n#:> 0      C1         D1  Yong   45   15000  1/1/1970\n#:> 1      C1         D1  Chew   35   12000  2/1/1980\n#:> C2\n#:>   Company Department     Name  Age  Salary  Birthdate\n#:> 6      C2         D1     Anne   18     400  7/15/1997\n#:> 7      C2         D2  Deborah   30    8600  8/15/1984\n#:> C3\n#:>    Company Department   Name  Age  Salary  Birthdate\n#:> 13      C3         D3  Chang   32    7900  7/26/1973\n#:> 14      C3         D1    Ong   44   17500  8/21/1980com_grp#:> <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f8074bdd190>"},{"path":"pandas-1.html","id":"transform","chapter":"13 pandas","heading":"13.11.9 Transform","text":"Transform operation used combined DataFrameGroupBy objecttransform() return new DataFrame objecttransform() perform function group, expands replicate multiple rows according original DataFrame","code":"grp = company.groupby('Company')\ngrp.size()#:> Company\n#:> C1    6\n#:> C2    7\n#:> C3    5\n#:> dtype: int64grp[['Age','Salary']].transform('sum')#:>     Age  Salary\n#:> 0   248   65500\n#:> 1   248   65500\n#:> 2   248   65500\n#:> 3   248   65500\n#:> 4   248   65500\n#:> ..  ...     ...\n#:> 13  208   75200\n#:> 14  208   75200\n#:> 15  208   75200\n#:> 16  208   75200\n#:> 17  208   75200\n#:> \n#:> [18 rows x 2 columns]grp.transform( lambda x:x+10 )#:>     Age  Salary\n#:> 0    55   15010\n#:> 1    45   12010\n#:> 2    44    8010\n#:> 3    33    2510\n#:> 4    65   25010\n#:> ..  ...     ...\n#:> 13   42    7910\n#:> 14   54   17510\n#:> 15   51   15310\n#:> 16   64   21010\n#:> 17   47   13510\n#:> \n#:> [18 rows x 2 columns]"},{"path":"pandas-1.html","id":"fundamental-analysis","chapter":"13 pandas","heading":"13.12 Fundamental Analysis","text":"","code":""},{"path":"pandas-1.html","id":"missing-data","chapter":"13 pandas","heading":"13.13 Missing Data","text":"","code":""},{"path":"pandas-1.html","id":"what-is-considered-missing-data","chapter":"13 pandas","heading":"13.13.1 What Is Considered Missing Data ?","text":"","code":""},{"path":"pandas-1.html","id":"sample-data-15","chapter":"13 pandas","heading":"13.13.2 Sample Data","text":"Missing Data Column ?","code":"df = pd.DataFrame( np.random.randn(5, 3), \n                   index   =['a', 'c', 'e', 'f', 'h'],\n                   columns =['one', 'two', 'three'])\ndf['four'] = 'bar'\ndf['five'] = df['one'] > 0\n#df\ndf.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])#:>         one       two     three four   five\n#:> a -0.155909 -0.501790  0.235569  bar  False\n#:> b       NaN       NaN       NaN  NaN    NaN\n#:> c -1.763605 -1.095862 -1.087766  bar  False\n#:> d       NaN       NaN       NaN  NaN    NaN\n#:> e -0.305170 -0.473748 -0.200595  bar  False\n#:> f  0.355197  0.689518  0.410590  bar   True\n#:> g       NaN       NaN       NaN  NaN    NaN\n#:> h -0.564978  0.599391 -0.162936  bar  Falsedf.count()#:> one      5\n#:> two      5\n#:> three    5\n#:> four     5\n#:> five     5\n#:> dtype: int64len(df.index) - df.count()#:> one      0\n#:> two      0\n#:> three    0\n#:> four     0\n#:> five     0\n#:> dtype: int64df.isnull()#:>      one    two  three   four   five\n#:> a  False  False  False  False  False\n#:> c  False  False  False  False  False\n#:> e  False  False  False  False  False\n#:> f  False  False  False  False  False\n#:> h  False  False  False  False  Falsedf.describe()#:>             one       two     three\n#:> count  5.000000  5.000000  5.000000\n#:> mean  -0.486893 -0.156498 -0.161028\n#:> std    0.788635  0.772882  0.579752\n#:> min   -1.763605 -1.095862 -1.087766\n#:> 25%   -0.564978 -0.501790 -0.200595\n#:> 50%   -0.305170 -0.473748 -0.162936\n#:> 75%   -0.155909  0.599391  0.235569\n#:> max    0.355197  0.689518  0.410590"},{"path":"matplotlib-1.html","id":"matplotlib-1","chapter":"14 matplotlib","heading":"14 matplotlib","text":"","code":""},{"path":"matplotlib-1.html","id":"library","chapter":"14 matplotlib","heading":"14.1 Library","text":"","code":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nfrom plydata import define, query, select, group_by, summarize, arrange, head, rename\nimport plotnine\nfrom plotnine import *"},{"path":"matplotlib-1.html","id":"sample-data-16","chapter":"14 matplotlib","heading":"14.2 Sample Data","text":"chapter uses sample data generate code. idea simulate two categorical-alike feature, two numeric value feature:com random character ?C1?, ?C2? ?C3?dept random character ?D1?, ?D2?, ?D3?, ?D4? ?D5?grp random character randomly generated ?G1?, ?G2?value1 represents numeric value, normally distributed mean 50value2 numeric value, normally distributed mean 25","code":"n = 200\ncomp = ['C' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 3x Company\ndept = ['D' + i for i in np.random.randint( 1,6, size  = n).astype(str)] # 5x Department\ngrp =  ['G' + i for i in np.random.randint( 1,3, size  = n).astype(str)] # 2x Groups\nvalue1 = np.random.normal( loc=50 , scale=5 , size = n)\nvalue2 = np.random.normal( loc=20 , scale=3 , size = n)\nvalue3 = np.random.normal( loc=5 , scale=30 , size = n)\n\nmydf = pd.DataFrame({\n    'comp':comp, \n    'dept':dept, \n    'grp': grp,\n    'value1':value1, \n    'value2':value2,\n    'value3':value3 })\nmydf.head()#:>   comp dept grp     value1     value2     value3\n#:> 0   C1   D3  G1  47.343508  16.623546   1.741223\n#:> 1   C2   D1  G1  61.737449  22.592145  29.889468\n#:> 2   C2   D4  G1  48.773299  22.211320  17.476382\n#:> 3   C2   D2  G1  47.856641  18.504218  35.166332\n#:> 4   C3   D3  G1  51.066041  19.154196  -2.138135mydf.info()#:> <class 'pandas.core.frame.DataFrame'>\n#:> RangeIndex: 200 entries, 0 to 199\n#:> Data columns (total 6 columns):\n#:>  #   Column  Non-Null Count  Dtype  \n#:> ---  ------  --------------  -----  \n#:>  0   comp    200 non-null    object \n#:>  1   dept    200 non-null    object \n#:>  2   grp     200 non-null    object \n#:>  3   value1  200 non-null    float64\n#:>  4   value2  200 non-null    float64\n#:>  5   value3  200 non-null    float64\n#:> dtypes: float64(3), object(3)\n#:> memory usage: 9.5+ KB"},{"path":"matplotlib-1.html","id":"matlab-like-api","chapter":"14 matplotlib","heading":"14.3 MATLAB-like API","text":"good thing pylab MATLAB-style API easy get started familiar MATLAB, minumum coding overhead simple plots.However, ’d encourrage using MATLAB compatible API anything simplest figures.Instead, recommend learning using matplotlib’s object-oriented plotting API. remarkably powerful. advanced figures subplots, insets components nice work .","code":""},{"path":"matplotlib-1.html","id":"sample-data-17","chapter":"14 matplotlib","heading":"14.3.1 Sample Data","text":"","code":"# Sample Data\nx = np.linspace(0,5,10)\ny = x ** 2"},{"path":"matplotlib-1.html","id":"single-plot","chapter":"14 matplotlib","heading":"14.3.2 Single Plot","text":"","code":"plt.figure()\nplt.xlabel('x')\nplt.ylabel('y')\nplt.plot(x,y,'red')\nplt.title('My Good Data')\nplt.show()"},{"path":"matplotlib-1.html","id":"multiple-subplots","chapter":"14 matplotlib","heading":"14.3.3 Multiple Subplots","text":"call lto subplot() create new container subsequent plot command","code":"plt.figure()\nplt.subplot(1,2,1) # 1 row, 2 cols, at first box\nplt.plot(x,y,'r--')\nplt.subplot(1,2,2) # 1 row, 2 cols, at second box\nplt.plot(y,x,'g*-')\nplt.show()"},{"path":"matplotlib-1.html","id":"object-oriented-api","chapter":"14 matplotlib","heading":"14.4 Object-Oriented API","text":"","code":""},{"path":"matplotlib-1.html","id":"sample-data-18","chapter":"14 matplotlib","heading":"14.4.1 Sample Data","text":"","code":"# Sample Data\nx = np.linspace(0,5,10)\ny = x ** 2"},{"path":"matplotlib-1.html","id":"single-plot-1","chapter":"14 matplotlib","heading":"14.4.2 Single Plot","text":"One figure, one axes","code":"fig = plt.figure()\naxes = fig.add_axes([0,0,1,1]) # left, bottom, width, height (range 0 to 1)\naxes.plot(x, y, 'r')\naxes.set_xlabel('x')\naxes.set_ylabel('y')\naxes.set_title('title')\nplt.show()"},{"path":"matplotlib-1.html","id":"multiple-axes-in-one-plot","chapter":"14 matplotlib","heading":"14.4.3 Multiple Axes In One Plot","text":"still considered single plot, multiple axes","code":"fig = plt.figure()\nax1 = fig.add_axes([0, 0, 1, 1])         # main axes\nax2 = fig.add_axes([0.2, 0.5, 0.4, 0.3]) # inset axes\n\nax1.plot(x,y,'r')\nax1.set_xlabel('x')\nax1.set_ylabel('y')\n\nax2.plot(y, x, 'g')\nax2.set_xlabel('y')\nax2.set_ylabel('x')\nax2.set_title('insert title')\nplt.show()"},{"path":"matplotlib-1.html","id":"multiple-subplots-1","chapter":"14 matplotlib","heading":"14.4.4 Multiple Subplots","text":"One figure can contain multiple subplotsEach subplot one axes","code":""},{"path":"matplotlib-1.html","id":"simple-subplots---all-same-size","chapter":"14 matplotlib","heading":"14.4.4.1 Simple Subplots - all same size","text":"subplots() function return axes object iterable.Single Row Grid\nSingle row grid means axes 1-D array. Hence can use iterate axesMultiple Row Grid\nMultile row grid means axes 2-D array. Hence can use two levels loop iterate row column","code":"fig, axes = plt.subplots( nrows=1,ncols=3 )\nprint (axes.shape)for ax in axes:\n    ax.plot(x, y, 'r')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title('title')\n    ax.text(0.2,0.5,'One')\nplt.show()fig, axes = plt.subplots(2, 3, sharex='col', sharey='row')\nprint (axes.shape)for i in range(axes.shape[0]):\n    for j in range(axes.shape[1]):\n        axes[i, j].text(0.5, 0.5, str((i, j)),\n                      fontsize=18, ha='center')\nplt.show()"},{"path":"matplotlib-1.html","id":"complicated-subplots---different-size","chapter":"14 matplotlib","heading":"14.4.4.2 Complicated Subplots - different size","text":"GridSpec specify grid size figureManually specify subplot relevant grid position size-1 means last row column","code":"plt.figure(figsize=(5,5))\ngrid = plt.GridSpec(2, 3, hspace=0.4, wspace=0.4)\nplt.subplot(grid[0, 0])  #row 0, col 0\nplt.subplot(grid[0, 1:]) #row 0, col 1 to :\nplt.subplot(grid[1, :2]) #row 1, col 0:2 \nplt.subplot(grid[1, 2]); #row 1, col 2\nplt.show()plt.figure(figsize=(5,5))\ngrid = plt.GridSpec(4, 4, hspace=0.8, wspace=0.4)\nplt.subplot(grid[:3, 0])    # row 0:3, col 0\nplt.subplot(grid[:3, 1: ])  # row 0:3, col 1:\nplt.subplot(grid[3, 1: ]);  # row 3,   col 1:\nplt.show()plt.figure(figsize=(6,6))\ngrid = plt.GridSpec(4, 4, hspace=0.4, wspace=1.2)\nplt.subplot(grid[:-1, 0 ])  # row 0 till last row (not including last row), col 0\nplt.subplot(grid[:-1, 1:])  # row 0 till last row (not including last row), col 1 till end\nplt.subplot(grid[-1, 1: ]); # row last row, col 1 till end\nplt.show()"},{"path":"matplotlib-1.html","id":"figure-customization","chapter":"14 matplotlib","heading":"14.4.5 Figure Customization","text":"","code":""},{"path":"matplotlib-1.html","id":"avoid-overlap---use-tight_layout","chapter":"14 matplotlib","heading":"14.4.5.1 Avoid Overlap - Use tight_layout()","text":"Sometimes figure size small, plots overlap .\n- tight_layout() introduce extra white space subplots avoid overlap.\n- figure became wider.","code":"fig, axes = plt.subplots( nrows=1,ncols=2)\nfor ax in axes:\n    ax.plot(x, y, 'r')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title('title')\nfig.tight_layout() # adjust the positions of axes so that there is no overlap\nplt.show()"},{"path":"matplotlib-1.html","id":"avoid-overlap---change-figure-size","chapter":"14 matplotlib","heading":"14.4.5.2 Avoid Overlap - Change Figure Size","text":"","code":"fig, axes = plt.subplots( nrows=1,ncols=2,figsize=(12,3))\nfor ax in axes:\n    ax.plot(x, y, 'r')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title('title')\nplt.show()"},{"path":"matplotlib-1.html","id":"text-within-figure","chapter":"14 matplotlib","heading":"14.4.5.3 Text Within Figure","text":"","code":"fig = plt.figure()\nfig.text(0.5, 0.5, 'This Is A Sample',fontsize=18, ha='center');\naxes = fig.add_axes([0,0,1,1]) # left, bottom, width, height (range 0 to 1)\nplt.show()"},{"path":"matplotlib-1.html","id":"axes-customization","chapter":"14 matplotlib","heading":"14.4.6 Axes Customization","text":"","code":""},{"path":"matplotlib-1.html","id":"y-axis-limit","chapter":"14 matplotlib","heading":"14.4.6.1 Y-Axis Limit","text":"","code":"fig = plt.figure()\nfig.add_axes([0,0,1,1], ylim=(-2,5));\nplt.show()"},{"path":"matplotlib-1.html","id":"text-within-axes","chapter":"14 matplotlib","heading":"14.4.6.2 Text Within Axes","text":"","code":"fig, ax = plt.subplots(2, 3, sharex='col', sharey='row')\nfor i in range(2):\n    for j in range(3):\n        ax[i, j].text(0.5, 0.5, str((i, j)),\n                      fontsize=18, ha='center')\nplt.show()plt.text(0.5, 0.5, 'one',fontsize=18, ha='center')\nplt.show()"},{"path":"matplotlib-1.html","id":"share-y-axis-label","chapter":"14 matplotlib","heading":"14.4.6.3 Share Y Axis Label","text":"","code":"fig, ax = plt.subplots(2, 3, sharex='col', sharey='row') # removed inner label\nplt.show()"},{"path":"matplotlib-1.html","id":"create-subplot-individually","chapter":"14 matplotlib","heading":"14.4.6.4 Create Subplot Individually","text":"call lto subplot() create new container subsequent plot commandIterate subplots (ax) populate ","code":"plt.subplot(2,4,1)\nplt.text(0.5, 0.5, 'one',fontsize=18, ha='center')\n\nplt.subplot(2,4,8)\nplt.text(0.5, 0.5, 'eight',fontsize=18, ha='center')\nplt.show()fig, ax = plt.subplots(2, 3, sharex='col', sharey='row')\nfor i in range(2):\n    for j in range(3):\n        ax[i, j].text(0.5, 0.5, str((i, j)),\n                      fontsize=18, ha='center')\nplt.show()"},{"path":"matplotlib-1.html","id":"histogram","chapter":"14 matplotlib","heading":"14.5 Histogram","text":"","code":"plt.hist(mydf.value1, bins=12);\nplt.show()"},{"path":"matplotlib-1.html","id":"scatter-plot","chapter":"14 matplotlib","heading":"14.6 Scatter Plot","text":"","code":"plt.scatter(mydf.value1, mydf.value2)\nplt.show()"},{"path":"matplotlib-1.html","id":"bar-chart","chapter":"14 matplotlib","heading":"14.7 Bar Chart","text":"","code":"com_grp = mydf.groupby('comp')\ngrpdf = com_grp['value1'].sum().reset_index()\ngrpdfplt.bar(grpdf.comp, grpdf.value1);\nplt.xlabel('Company')\nplt.ylabel('Sum of Value 1')\nplt.show()"},{"path":"seaborn.html","id":"seaborn","chapter":"15 seaborn","heading":"15 seaborn","text":"","code":""},{"path":"seaborn.html","id":"seaborn-and-matplotlib","chapter":"15 seaborn","heading":"15.1 Seaborn and Matplotlib","text":"seaborn returns matplotlib object can modified options pyplot moduleOften, options wrapped seaborn .plot() pandas available arguments","code":""},{"path":"seaborn.html","id":"sample-data-19","chapter":"15 seaborn","heading":"15.2 Sample Data","text":"","code":"n = 100\ncomp = ['C' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 3x Company\ndept = ['D' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 5x Department\ngrp =  ['G' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 2x Groups\nvalue1 = np.random.normal( loc=50 , scale=5 , size = n)\nvalue2 = np.random.normal( loc=20 , scale=3 , size = n)\nvalue3 = np.random.normal( loc=5 , scale=30 , size = n)\n\nmydf = pd.DataFrame({\n    'comp':comp, \n    'dept':dept, \n    'grp': grp,\n    'value1':value1, \n    'value2':value2,\n    'value3':value3 \n})\nmydf.head()#:>   comp dept grp     value1     value2     value3\n#:> 0   C3   D2  G3  44.629447  16.439507  48.582119\n#:> 1   C2   D2  G2  50.110557  21.988054  34.931015\n#:> 2   C3   D2  G1  46.722299  22.605435 -22.025500\n#:> 3   C2   D1  G3  58.506386  21.534852  33.198709\n#:> 4   C2   D3  G3  40.798755  22.435606 -26.255345"},{"path":"seaborn.html","id":"scatter-plot-1","chapter":"15 seaborn","heading":"15.3 Scatter Plot","text":"","code":""},{"path":"seaborn.html","id":"x-numeric","chapter":"15 seaborn","heading":"15.3.1 2x Numeric","text":"","code":"sns.lmplot(x='value1', y='value2', data=mydf)plt.show()sns.lmplot(x='value1', y='value2', fit_reg=False, data=mydf);  #hide regresion lineplt.show()"},{"path":"seaborn.html","id":"xnumeric-1x-categorical","chapter":"15 seaborn","heading":"15.3.2 2xNumeric + 1x Categorical","text":"Use hue represent additional categorical feature","code":"sns.lmplot(x='value1', y='value2', data=mydf, hue='comp', fit_reg=False);\nplt.show()"},{"path":"seaborn.html","id":"xnumeric-2x-categorical","chapter":"15 seaborn","heading":"15.3.3 2xNumeric + 2x Categorical","text":"Use col hue represent two categorical features","code":"sns.lmplot(x='value1', y='value2', col='comp',hue='grp', fit_reg=False, data=mydf);\nplt.show()"},{"path":"seaborn.html","id":"xnumeric-3x-categorical","chapter":"15 seaborn","heading":"15.3.4 2xNumeric + 3x Categorical","text":"Use row, col hue represent three categorical features","code":"sns.lmplot(x='value1', y='value2', row='dept',col='comp', hue='grp', fit_reg=False, data=mydf);plt.show()"},{"path":"seaborn.html","id":"customization","chapter":"15 seaborn","heading":"15.3.5 Customization","text":"","code":""},{"path":"seaborn.html","id":"size","chapter":"15 seaborn","heading":"15.3.5.1 size","text":"size: height inch facetObserve even size large, lmplot fit (shrink) everything one row deafult. See example .","code":"sns.lmplot(x='value1', y='value2', col='comp',hue='grp', size=3,fit_reg=False, data=mydf)plt.show()sns.lmplot(x='value1', y='value2', col='comp',hue='grp', size=5,fit_reg=False, data=mydf)plt.show()"},{"path":"seaborn.html","id":"col_wrap","chapter":"15 seaborn","heading":"15.3.5.2 col_wrap","text":"avoid lmplot shrinking chart, use col_wrap=<col_number wrap output.\nCompare size (height facet) without col_wrap. chart larger.","code":"sns.lmplot(x='value1', y='value2', col='comp',hue='grp', size=5, col_wrap=2, fit_reg=False, data=mydf)plt.show()"},{"path":"seaborn.html","id":"histogram-1","chapter":"15 seaborn","heading":"15.4 Histogram","text":"","code":"seaborn.distplot(\n  a,               # Series, 1D Array or List\n  bins=None,\n  hist=True,\n  rug = False,\n  vertical=False\n)"},{"path":"seaborn.html","id":"x-numeric-1","chapter":"15 seaborn","heading":"15.4.1 1x Numeric","text":"","code":"sns.distplot(mydf.value1)\nplt.show()sns.distplot(mydf.value1,hist=True,rug=True,vertical=True, bins=30,color='g')\nplt.show()"},{"path":"seaborn.html","id":"bar-chart-1","chapter":"15 seaborn","heading":"15.5 Bar Chart","text":"","code":"com_grp = mydf.groupby('comp')\ngrpdf = com_grp['value1'].sum().reset_index()\ngrpdf#:>   comp       value1\n#:> 0   C1  1777.794043\n#:> 1   C2  1834.860416\n#:> 2   C3  1343.194018"},{"path":"seaborn.html","id":"x-categorical-1x-numeric","chapter":"15 seaborn","heading":"15.5.1 1x Categorical, 1x Numeric","text":"","code":"sns.barplot(x='comp',y='value1',data=grpdf)\nplt.show()"},{"path":"seaborn.html","id":"customization-1","chapter":"15 seaborn","heading":"15.5.2 Customization","text":"","code":""},{"path":"seaborn.html","id":"ordering","chapter":"15 seaborn","heading":"15.5.2.1 Ordering","text":"","code":"sns.barplot(x='comp',y='value2', hue='grp',\n            order=['C3','C2','C1'],\n            hue_order=['G1','G2','G3'],\n            data=mydf\n)\nplt.show()"},{"path":"seaborn.html","id":"flipping-xy-axis","chapter":"15 seaborn","heading":"15.5.2.2 Flipping X/Y Axis","text":"","code":"sns.barplot(x='value2',y='comp', hue='grp',data=mydf)\nplt.show()"},{"path":"seaborn.html","id":"faceting","chapter":"15 seaborn","heading":"15.6 Faceting","text":"Faceting Seaborn generic function works matplotlib various plot utility.\nsupport matplotlib well seaborn plotting utility.","code":""},{"path":"seaborn.html","id":"faceting-histogram","chapter":"15 seaborn","heading":"15.6.1 Faceting Histogram","text":"","code":"g = sns.FacetGrid(mydf, col=\"comp\", row='dept')\ng.map(plt.hist, \"value1\")plt.show()g = sns.FacetGrid(mydf, col=\"comp\", row='dept')\ng.map(plt.hist, \"value1\")plt.show()"},{"path":"seaborn.html","id":"faceting-scatter-plot","chapter":"15 seaborn","heading":"15.6.2 Faceting Scatter Plot","text":"","code":"g = sns.FacetGrid(mydf, col=\"comp\", row='dept',hue='grp')\ng.map(plt.scatter, \"value1\",\"value2\",alpha=0.7);\ng.add_legend()plt.show()"},{"path":"seaborn.html","id":"pair-grid","chapter":"15 seaborn","heading":"15.7 Pair Grid","text":"","code":""},{"path":"seaborn.html","id":"simple-pair-grid","chapter":"15 seaborn","heading":"15.7.1 Simple Pair Grid","text":"","code":"g = sns.PairGrid(mydf, hue='comp')\ng.map(plt.scatter);\ng.add_legend()plt.show()"},{"path":"seaborn.html","id":"different-diag-and-offdiag","chapter":"15 seaborn","heading":"15.7.2 Different Diag and OffDiag","text":"","code":"g = sns.PairGrid(mydf, hue='comp')\ng.map_diag(plt.hist, bins=15)g.map_offdiag(plt.scatter)g.add_legend()plt.show()"},{"path":"sklearn.html","id":"sklearn","chapter":"16 sklearn","heading":"16 sklearn","text":"machine learning library.","code":""},{"path":"sklearn.html","id":"setup-hidden","chapter":"16 sklearn","heading":"16.1 Setup (hidden)","text":"","code":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\npd.set_option( 'display.notebook_repr_html', False)  # render Series and DataFrame as text, not HTML\npd.set_option( 'display.max_column', 10)    # number of columns\npd.set_option( 'display.max_rows', 10)     # number of rows\npd.set_option( 'display.width', 90)        # number of characters per row"},{"path":"sklearn.html","id":"the-library","chapter":"16 sklearn","heading":"16.2 The Library","text":"sklearn automatically import subpackages. Therefore subpakcages must specifically loaded use.","code":"# Sample Data\nfrom sklearn                 import datasets\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import cross_validate\n\n# Preprocessing\n# from sklearn.preprocessing   import Imputer\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.preprocessing   import MinMaxScaler\nfrom sklearn.preprocessing   import StandardScaler\nfrom sklearn.preprocessing   import Normalizer\nfrom sklearn.preprocessing   import PolynomialFeatures\n\n# Model and Pipeline\nfrom sklearn.linear_model    import LinearRegression,Lasso\nfrom sklearn.pipeline        import make_pipeline\n\n# Measurement\nfrom sklearn.metrics         import *\n\nimport statsmodels.formula.api as smf"},{"path":"sklearn.html","id":"model-fitting","chapter":"16 sklearn","heading":"16.3 Model Fitting","text":"split","code":""},{"path":"sklearn.html","id":"underfitting","chapter":"16 sklearn","heading":"16.3.1 Underfitting","text":"model fit training data therefore misses trends dataThe model generalized new data, usually result simple model (enough predictors/independent variables)model poor predictive abilityFor example, fit linear model (like linear regression) data linear","code":""},{"path":"sklearn.html","id":"overfitting","chapter":"16 sklearn","heading":"16.3.2 Overfitting","text":"model trained ?well? now, well, fit closely training datasetThe model complex (.e. many features/variables compared number observations)model accurate training data probably accurate untrained new dataThe model generalized (generalized), meaning can generalize resultsThe model learns describes ?noise? training data instead actual relationships variables data","code":""},{"path":"sklearn.html","id":"just-right","chapter":"16 sklearn","heading":"16.3.3 Just Right","text":"worth noting underfitting prevalent overfittingNevertheless, want avoid problems data analysisWe want find middle ground overfitting model","code":""},{"path":"sklearn.html","id":"model-tuning","chapter":"16 sklearn","heading":"16.4 Model Tuning","text":"highly complex model tend overfitA flexible model tend underfitComplexity can reduced :\n- Less features\n- Less degree polynomial features\n- Apply generalization (tuning hyperparameters)split","code":""},{"path":"sklearn.html","id":"high-level-ml-process","chapter":"16 sklearn","heading":"16.5 High Level ML Process","text":"split","code":""},{"path":"sklearn.html","id":"built-in-datasets","chapter":"16 sklearn","heading":"16.6 Built-in Datasets","text":"sklearn included popular datasets play \ndataset type Bunch.\nuseful data (array) form properties:\n- keys (display data availabe within dataset)\n- data (common)\n- target (common)\n- DESCR (common)\n- feature_names (dataset)\n- target_names (dataset)\n- images (dataset)","code":""},{"path":"sklearn.html","id":"diabetes-regression","chapter":"16 sklearn","heading":"16.6.1 diabetes (regression)","text":"","code":""},{"path":"sklearn.html","id":"load-dataset","chapter":"16 sklearn","heading":"16.6.1.1 Load Dataset","text":"","code":"diabetes = datasets.load_diabetes()\nprint (type(diabetes))#:> <class 'sklearn.utils.Bunch'>"},{"path":"sklearn.html","id":"keys","chapter":"16 sklearn","heading":"16.6.1.2 keys","text":"","code":"diabetes.keys()#:> dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])"},{"path":"sklearn.html","id":"features-and-target","chapter":"16 sklearn","heading":"16.6.1.3 Features and Target","text":".data = features - two dimension array\n.target = target - one dimension array","code":"print (type(diabetes.data))#:> <class 'numpy.ndarray'>print (type(diabetes.target))#:> <class 'numpy.ndarray'>print (diabetes.data.shape)#:> (442, 10)print (diabetes.target.shape)#:> (442,)"},{"path":"sklearn.html","id":"load-with-xy-convenient-method","chapter":"16 sklearn","heading":"16.6.1.4 Load with X,y (Convenient Method)","text":"using return_X_y = True, data loaded X, target loaded y","code":"X,y      = datasets.load_diabetes(return_X_y=True)print (X.shape)#:> (442, 10)print (y.shape)#:> (442,)"},{"path":"sklearn.html","id":"digits-classification","chapter":"16 sklearn","heading":"16.6.2 digits (Classification)","text":"copy test set UCI ML hand-written digits datasets","code":"digits = datasets.load_digits()\nprint (type(digits))#:> <class 'sklearn.utils.Bunch'>print (type(digits.data))#:> <class 'numpy.ndarray'>digits.keys()#:> dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])digits.target_names#:> array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"},{"path":"sklearn.html","id":"data","chapter":"16 sklearn","heading":"16.6.2.1 data","text":"","code":"digits.data.shape  # features#:> (1797, 64)digits.target.shape # target#:> (1797,)"},{"path":"sklearn.html","id":"images","chapter":"16 sklearn","heading":"16.6.2.2 Images","text":"images 3 dimensional arrayThere 1797 samples, sample 8x8 pixelsEach element represent data make target","code":"digits.images.shape#:> (1797, 8, 8)type(digits.images)#:> <class 'numpy.ndarray'>print (digits.target[100])#:> 4print (digits.images[100])#:> [[ 0.  0.  0.  2. 13.  0.  0.  0.]\n#:>  [ 0.  0.  0.  8. 15.  0.  0.  0.]\n#:>  [ 0.  0.  5. 16.  5.  2.  0.  0.]\n#:>  [ 0.  0. 15. 12.  1. 16.  4.  0.]\n#:>  [ 0.  4. 16.  2.  9. 16.  8.  0.]\n#:>  [ 0.  0. 10. 14. 16. 16.  4.  0.]\n#:>  [ 0.  0.  0.  0. 13.  8.  0.  0.]\n#:>  [ 0.  0.  0.  0. 13.  6.  0.  0.]]plt.matshow(digits.images[100]) "},{"path":"sklearn.html","id":"loading-into-xy-convenient-method","chapter":"16 sklearn","heading":"16.6.2.3 Loading Into X,y (Convenient Method)","text":"","code":"X,y = datasets.load_digits(return_X_y=True)X.shape#:> (1797, 64)y.shape#:> (1797,)"},{"path":"sklearn.html","id":"iris-classification","chapter":"16 sklearn","heading":"16.6.3 iris (Classification)","text":"","code":"iris = datasets.load_iris()iris.keys()#:> dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"},{"path":"sklearn.html","id":"feature-names","chapter":"16 sklearn","heading":"16.6.3.1 Feature Names","text":"","code":"iris.feature_names#:> ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']"},{"path":"sklearn.html","id":"target","chapter":"16 sklearn","heading":"16.6.3.2 target","text":"","code":"iris.target_names#:> array(['setosa', 'versicolor', 'virginica'], dtype='<U10')iris.target#:> array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n#:>        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n#:>        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n#:>        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n#:>        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n#:>        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n#:>        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"},{"path":"sklearn.html","id":"train-test-data-splitting","chapter":"16 sklearn","heading":"16.7 Train Test Data Splitting","text":"","code":""},{"path":"sklearn.html","id":"sample-data-20","chapter":"16 sklearn","heading":"16.7.1 Sample Data","text":"Generate 100 rows data, 3x features (X1,X2,X3), one dependant variable (Y)","code":"n = 21  # number of samples\nI = 5  # intercept value\nE = np.random.randint( 1,20, n)  # Error\nx1 = np.random.randint( 1,n+1, n)\nx2 = np.random.randint( 1,n+1, n)\nx3 = np.random.randint( 1,n+1, n)\ny = 0.1*x1 + 0.2*x2 + 0.3*x3 + E + I\nmydf = pd.DataFrame({\n    'y':y,\n    'x1':x1,\n    'x2':x2,\n    'x3':x3\n})\nmydf.shape#:> (21, 4)"},{"path":"sklearn.html","id":"one-time-split","chapter":"16 sklearn","heading":"16.7.2 One Time Split","text":"sklearn::train_test_split() two forms:\n- Take one DF, split 2 DF (sklearn modeling use method\n- Take two DFs, split 4 DF","code":"mydf.head()#:>       y  x1  x2  x3\n#:> 0  34.9  17  21  20\n#:> 1  13.0   5   3   3\n#:> 2  26.4  13  17   9\n#:> 3  26.4  21   9  15\n#:> 4  17.9  17   4  18"},{"path":"sklearn.html","id":"method-1-split-one-dataframe-into-two-train-test","chapter":"16 sklearn","heading":"16.7.2.1 Method 1: Split One Dataframe Into Two (Train & Test)","text":"split","code":"traindf, testdf = train_test_split( df, test_size=, random_state= ) \n # random_state : seed number (integer), optional\n # test_size    : fraction of 1, 0.2 means 20%traindf, testdf = train_test_split(mydf,test_size=0.2, random_state=25)print (len(traindf))#:> 16print (len(testdf))#:> 5"},{"path":"sklearn.html","id":"method-2-split-two-dataframe-xy-into-four-x_traintest-y_traintest","chapter":"16 sklearn","heading":"16.7.2.2 Method 2: Split Two DataFrame (X,Y) into Four x_train/test, y_train/test","text":"splitSplit DataFrame X Y FirstThen Split X/Y x_train/test, y_train/test","code":"x_train, x_test, y_train, y_test = train_test_split( X,Y, test_size=, random_state= )\n # random_state : seed number (integer), optional\n # test_size    : fraction of 1, 0.2 means 20%feature_cols = ['x1','x2','x3']\nX = mydf[feature_cols]\nY = mydf.yx_train, x_test, y_train, y_test = train_test_split( X,Y, test_size=0.2, random_state=25)\nprint (len(x_train))#:> 16print (len(x_test))#:> 5"},{"path":"sklearn.html","id":"k-fold","chapter":"16 sklearn","heading":"16.7.3 K-Fold","text":"splitsuffle=False (default), meaning index number taken continouslyshuffle=True","code":"KFold(n_splits=3, shuffle=False, random_state=None)kf = KFold(n_splits=7)for train_index, test_index in kf.split(X):\n  print (train_index, test_index)#:> [ 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [0 1 2]\n#:> [ 0  1  2  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [3 4 5]\n#:> [ 0  1  2  3  4  5  9 10 11 12 13 14 15 16 17 18 19 20] [6 7 8]\n#:> [ 0  1  2  3  4  5  6  7  8 12 13 14 15 16 17 18 19 20] [ 9 10 11]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 15 16 17 18 19 20] [12 13 14]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 18 19 20] [15 16 17]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17] [18 19 20]kf = KFold(n_splits=7, shuffle=True)for train_index, test_index in kf.split(X):\n  print (train_index, test_index)#:> [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 16 17 19 20] [ 6 15 18]\n#:> [ 0  1  3  4  5  6  7  8  9 10 12 13 14 15 16 17 18 19] [ 2 11 20]\n#:> [ 0  1  2  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20] [ 3  4 16]\n#:> [ 0  1  2  3  4  5  6  7  9 10 11 14 15 16 17 18 19 20] [ 8 12 13]\n#:> [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 20] [ 0 17 19]\n#:> [ 0  2  3  4  6  7  8  9 11 12 13 14 15 16 17 18 19 20] [ 1  5 10]\n#:> [ 0  1  2  3  4  5  6  8 10 11 12 13 15 16 17 18 19 20] [ 7  9 14]"},{"path":"sklearn.html","id":"leave-one-out","chapter":"16 sklearn","heading":"16.7.4 Leave One Out","text":"dataset N rows, Leave One split N-1 times, time leaving one row test, remaning training set.Due high number test sets (number samples-1) cross-validation method can costly. large datasets one favor KFold.","code":"loo = LeaveOneOut()for train_index, test_index in loo.split(X):\n  print (train_index, test_index)#:> [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [0]\n#:> [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [1]\n#:> [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [2]\n#:> [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [3]\n#:> [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [4]\n#:> [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [5]\n#:> [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [6]\n#:> [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20] [7]\n#:> [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15 16 17 18 19 20] [8]\n#:> [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20] [9]\n#:> [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15 16 17 18 19 20] [10]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14 15 16 17 18 19 20] [11]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20] [12]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19 20] [13]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19 20] [14]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18 19 20] [15]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20] [16]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20] [17]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20] [18]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20] [19]\n#:> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] [20]X#:>     x1  x2  x3\n#:> 0   17  21  20\n#:> 1    5   3   3\n#:> 2   13  17   9\n#:> 3   21   9  15\n#:> 4   17   4  18\n#:> ..  ..  ..  ..\n#:> 16  15   3  10\n#:> 17  15  20  12\n#:> 18  17   6  11\n#:> 19  14  13  16\n#:> 20   8   1  10\n#:> \n#:> [21 rows x 3 columns]"},{"path":"sklearn.html","id":"polynomial-transform","chapter":"16 sklearn","heading":"16.8 Polynomial Transform","text":"can used part feature engineering, introduce new features data seems fit quadradic model.","code":""},{"path":"sklearn.html","id":"single-variable","chapter":"16 sklearn","heading":"16.8.1 Single Variable","text":"","code":""},{"path":"sklearn.html","id":"sample-data-21","chapter":"16 sklearn","heading":"16.8.1.1 Sample Data","text":"Data must 2-D polynomial features can applied. Code convert 1D array 2D array.","code":"x = np.array([1, 2, 3, 4, 5])\nX = x[:,np.newaxis]\nX#:> array([[1],\n#:>        [2],\n#:>        [3],\n#:>        [4],\n#:>        [5]])"},{"path":"sklearn.html","id":"degree-1","chapter":"16 sklearn","heading":"16.8.1.2 Degree 1","text":"One Degree means maintain original features. new features created.","code":"PolynomialFeatures(degree=1, include_bias=False).fit_transform(X)#:> array([[1.],\n#:>        [2.],\n#:>        [3.],\n#:>        [4.],\n#:>        [5.]])"},{"path":"sklearn.html","id":"degree-2","chapter":"16 sklearn","heading":"16.8.1.3 Degree 2","text":"Degree-1 original feature: x\nDegree-2 additional features: x^2","code":"PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)#:> array([[ 1.,  1.],\n#:>        [ 2.,  4.],\n#:>        [ 3.,  9.],\n#:>        [ 4., 16.],\n#:>        [ 5., 25.]])"},{"path":"sklearn.html","id":"degree-3","chapter":"16 sklearn","heading":"16.8.1.4 Degree 3","text":"Degree-1 original feature: x\nDegree-2 additional features: x^2\nDegree-3 additional features: x^3","code":"PolynomialFeatures(degree=3, include_bias=False).fit_transform(X)#:> array([[  1.,   1.,   1.],\n#:>        [  2.,   4.,   8.],\n#:>        [  3.,   9.,  27.],\n#:>        [  4.,  16.,  64.],\n#:>        [  5.,  25., 125.]])"},{"path":"sklearn.html","id":"degree-4","chapter":"16 sklearn","heading":"16.8.1.5 Degree 4","text":"Degree-1 original feature: x\nDegree-2 additional features: x^2\nDegree-3 additional features: x^3\nDegree-3 additional features: x^4","code":"PolynomialFeatures(degree=4, include_bias=False).fit_transform(X)#:> array([[  1.,   1.,   1.,   1.],\n#:>        [  2.,   4.,   8.,  16.],\n#:>        [  3.,   9.,  27.,  81.],\n#:>        [  4.,  16.,  64., 256.],\n#:>        [  5.,  25., 125., 625.]])"},{"path":"sklearn.html","id":"two-variables","chapter":"16 sklearn","heading":"16.8.2 Two Variables","text":"","code":""},{"path":"sklearn.html","id":"sample-data-22","chapter":"16 sklearn","heading":"16.8.2.1 Sample Data","text":"","code":"X = pd.DataFrame( {'x1': [1, 2, 3, 4, 5 ],\n                   'x2': [6, 7, 8, 9, 10]})\nX#:>    x1  x2\n#:> 0   1   6\n#:> 1   2   7\n#:> 2   3   8\n#:> 3   4   9\n#:> 4   5  10"},{"path":"sklearn.html","id":"degree-2-1","chapter":"16 sklearn","heading":"16.8.2.2 Degree 2","text":"","code":"Degree-1 original   features:  x1,     x2  \nDegree-2 additional features:  x1^2,   x2^2,   x1:x2 PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)#:> array([[  1.,   6.,   1.,   6.,  36.],\n#:>        [  2.,   7.,   4.,  14.,  49.],\n#:>        [  3.,   8.,   9.,  24.,  64.],\n#:>        [  4.,   9.,  16.,  36.,  81.],\n#:>        [  5.,  10.,  25.,  50., 100.]])"},{"path":"sklearn.html","id":"degree-3-1","chapter":"16 sklearn","heading":"16.8.2.3 Degree 3","text":"","code":"Degree-1 original   features:  x1,       x2  \nDegree-2 additional features:  x1^2,     x2^2,   x1:x2 \nDegree-3 additional features:  x1^3,     x2^3    x1:x2^2    x2:x1^2PolynomialFeatures(degree=3, include_bias=False).fit_transform(X)#:> array([[   1.,    6.,    1.,    6.,   36.,    1.,    6.,   36.,  216.],\n#:>        [   2.,    7.,    4.,   14.,   49.,    8.,   28.,   98.,  343.],\n#:>        [   3.,    8.,    9.,   24.,   64.,   27.,   72.,  192.,  512.],\n#:>        [   4.,    9.,   16.,   36.,   81.,   64.,  144.,  324.,  729.],\n#:>        [   5.,   10.,   25.,   50.,  100.,  125.,  250.,  500., 1000.]])"},{"path":"sklearn.html","id":"imputation-of-missing-data","chapter":"16 sklearn","heading":"16.9 Imputation of Missing Data","text":"","code":""},{"path":"sklearn.html","id":"sample-data-23","chapter":"16 sklearn","heading":"16.9.1 Sample Data","text":"","code":"from numpy import nan\nX = np.array([[ nan, 0,   3  ],\n              [ 3,   7,   9  ],\n              [ 3,   5,   2  ],\n              [ 4,   nan, 6  ],\n              [ 8,   8,   1  ]])\n\ny = np.array([14, 16, -1,  8, -5])"},{"path":"sklearn.html","id":"imputer","chapter":"16 sklearn","heading":"16.9.2 Imputer","text":"","code":""},{"path":"sklearn.html","id":"mean-strategy","chapter":"16 sklearn","heading":"16.9.2.1 mean strategy","text":"","code":"imp = SimpleImputer(strategy='mean')\nX2 = imp.fit_transform(X)\nX2#:> array([[4.5, 0. , 3. ],\n#:>        [3. , 7. , 9. ],\n#:>        [3. , 5. , 2. ],\n#:>        [4. , 5. , 6. ],\n#:>        [8. , 8. , 1. ]])"},{"path":"sklearn.html","id":"scaling","chapter":"16 sklearn","heading":"16.10 Scaling","text":"possible insignificant variable larger range dominating objective function.\ncan remove problem scaling features range.","code":""},{"path":"sklearn.html","id":"sample-data-24","chapter":"16 sklearn","heading":"16.10.1 Sample Data","text":"","code":"X=mydf.filter(like='x')[:5]\nX#:>    x1  x2  x3\n#:> 0  17  21  20\n#:> 1   5   3   3\n#:> 2  13  17   9\n#:> 3  21   9  15\n#:> 4  17   4  18"},{"path":"sklearn.html","id":"minmax-scaler","chapter":"16 sklearn","heading":"16.10.2 MinMax Scaler","text":"Define Scaler ObjectTransform DataScaler Attributes","code":"MinMaxScaler( feature_range(0,1), copy=True )\n# default feature range (output result) from 0 to 1\n# default return a copy of new array, copy=False will inplace original arrayscaler = MinMaxScaler()scaler.fit_transform(X)#:> array([[0.75      , 1.        , 1.        ],\n#:>        [0.        , 0.        , 0.        ],\n#:>        [0.5       , 0.77777778, 0.35294118],\n#:>        [1.        , 0.33333333, 0.70588235],\n#:>        [0.75      , 0.05555556, 0.88235294]])data_min_: minimum value of the feature (before scaling)  \ndata_max_: maximum value of the feature (before scaling)  pd.DataFrame(list(zip(scaler.data_min_, scaler.data_max_)), \n             columns=['data_min','data_max'], \n             index=X.columns)#:>     data_min  data_max\n#:> x1       5.0      21.0\n#:> x2       3.0      21.0\n#:> x3       3.0      20.0"},{"path":"sklearn.html","id":"standard-scaler","chapter":"16 sklearn","heading":"16.10.3 Standard Scaler","text":"suitable techniques assume Gaussian distribution input variables work better rescaled data, linear regression, logistic regression linear discriminate analysis.Define Scaler ObjectTransform DataScaler Attributes\ndata transformation step , scaler mean variance information feature.","code":"StandardScaler(copy=True, with_mean=True, with_std=True)\n# copy=True : return a copy of data, instead of inplace\n# with_mean=True : centre all features by substracting with its mean\n# with_std=True  : centre all features by dividing with its stdscaler = StandardScaler()scaler.fit_transform(X)#:> array([[ 0.44232587,  1.43448707,  1.12378227],\n#:>        [-1.76930347, -1.0969607 , -1.60540325],\n#:>        [-0.29488391,  0.87194312, -0.6421613 ],\n#:>        [ 1.17953565, -0.25314478,  0.32108065],\n#:>        [ 0.44232587, -0.95632472,  0.80270162]])pd.DataFrame(list(zip(scaler.mean_, scaler.var_)), \n             columns=['mean','variance'], \n             index=X.columns)#:>     mean  variance\n#:> x1  14.6     29.44\n#:> x2  10.8     50.56\n#:> x3  13.0     38.80"},{"path":"sklearn.html","id":"pipeline","chapter":"16 sklearn","heading":"16.11 Pipeline","text":"preceding examples, can quickly become tedious transformations hand, especially wish string together multiple steps. example, might want processing pipeline looks something like :Impute missing values using meanTransform features quadraticFit linear regressionmake_pipeline takes list functions parameters. calling fit() pipeline object, functions performed sequential data flow one function another.","code":"make_pipeline (\n    function_1 (),\n    function_2 (),\n    function_3 ()\n )"},{"path":"sklearn.html","id":"sample-data-25","chapter":"16 sklearn","heading":"16.11.1 Sample Data","text":"","code":"X#:>    x1  x2  x3\n#:> 0  17  21  20\n#:> 1   5   3   3\n#:> 2  13  17   9\n#:> 3  21   9  15\n#:> 4  17   4  18y#:> array([14, 16, -1,  8, -5])"},{"path":"sklearn.html","id":"create-pipeline","chapter":"16 sklearn","heading":"16.11.2 Create Pipeline","text":"","code":"my_pipe = make_pipeline (\n    SimpleImputer            (strategy='mean'),\n    PolynomialFeatures (degree=2),\n    LinearRegression   ()\n)\ntype(my_pipe)#:> <class 'sklearn.pipeline.Pipeline'>my_pipe#:> Pipeline(steps=[('simpleimputer', SimpleImputer()),\n#:>                 ('polynomialfeatures', PolynomialFeatures()),\n#:>                 ('linearregression', LinearRegression())])"},{"path":"sklearn.html","id":"executing-pipeline","chapter":"16 sklearn","heading":"16.11.3 Executing Pipeline","text":"","code":"my_pipe.fit( X, y) # execute the pipeline#:> Pipeline(steps=[('simpleimputer', SimpleImputer()),\n#:>                 ('polynomialfeatures', PolynomialFeatures()),\n#:>                 ('linearregression', LinearRegression())])print (y)#:> [14 16 -1  8 -5]print (my_pipe.predict(X))#:> [14. 16. -1.  8. -5.]type(my_pipe)#:> <class 'sklearn.pipeline.Pipeline'>"},{"path":"sklearn.html","id":"cross-validation","chapter":"16 sklearn","heading":"16.12 Cross Validation","text":"","code":""},{"path":"sklearn.html","id":"load-data","chapter":"16 sklearn","heading":"16.12.1 Load Data","text":"","code":"X,y = datasets.load_diabetes(return_X_y=True)"},{"path":"sklearn.html","id":"choose-an-cross-validator","chapter":"16 sklearn","heading":"16.12.2 Choose An Cross Validator","text":"","code":"kf = KFold(n_splits=5)"},{"path":"sklearn.html","id":"run-cross-validation","chapter":"16 sklearn","heading":"16.12.3 Run Cross Validation","text":"Single Scorer\nUse default scorer estimator (available)Multiple Scorer\nSpecify scorer\nhttp://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter","code":"lasso = Lasso()\ncv_results1 = cross_validate(lasso, X,y,cv=kf,\n    return_train_score=False)cv_results2 = cross_validate(lasso, X,y,cv=kf,\n    scoring=(\"neg_mean_absolute_error\",\"neg_mean_squared_error\",\"r2\"),\n    return_train_score=False)"},{"path":"sklearn.html","id":"the-result","chapter":"16 sklearn","heading":"16.12.4 The Result","text":"Result dictionary","code":"cv_results1.keys()#:> dict_keys(['fit_time', 'score_time', 'test_score'])cv_results2.keys()#:> dict_keys(['fit_time', 'score_time', 'test_neg_mean_absolute_error', 'test_neg_mean_squared_error', 'test_r2'])cv_results1#:> {'fit_time': array([0.00107646, 0.00174236, 0.0007472 , 0.00078654, 0.00084043]), 'score_time': array([0.0008533 , 0.00060225, 0.00101304, 0.00054669, 0.00101948]), 'test_score': array([0.28349047, 0.35157959, 0.3533813 , 0.33481474, 0.36453281])}cv_results2#:> {'fit_time': array([0.00155902, 0.00112081, 0.00144434, 0.0011692 , 0.00112915]), 'score_time': array([0.00154161, 0.0016377 , 0.00273466, 0.00171494, 0.00147605]), 'test_neg_mean_absolute_error': array([-50.09003423, -52.54110842, -55.02813846, -50.81121806,\n#:>        -55.60471593]), 'test_neg_mean_squared_error': array([-3491.74009759, -4113.86002091, -4046.91780932, -3489.74018715,\n#:>        -4111.92401769]), 'test_r2': array([0.28349047, 0.35157959, 0.3533813 , 0.33481474, 0.36453281])}"},{"path":"nlp.html","id":"nlp","chapter":"17 NLP","heading":"17 NLP","text":"Natural Language Processing","code":""},{"path":"nlp.html","id":"regular-expression","chapter":"17 NLP","heading":"17.1 Regular Expression","text":"Rgular expressions (called REs regexes) mandatory skill NLP. re **built-* libraryIt essentially tiny, highly specialized programming language embedded inside Python made available re moduleRegular expression patterns compiled series bytecodes executed matching engine written C","code":""},{"path":"nlp.html","id":"syntax","chapter":"17 NLP","heading":"17.1.1 Syntax","text":"two methods emply re. method compile regex first, apply multiple times subsequent code.Second method employ compile match single line. pattern reused, therefore good onetime usage .","code":"import re\npattern = re.compile(r'put pattern here')\npattern.match('put text here')import re\npattern = (r'put pattern here')\nre.match(pattern, r'put text here')  # compile and match in single line"},{"path":"nlp.html","id":"finding","chapter":"17 NLP","heading":"17.1.2 Finding","text":"","code":""},{"path":"nlp.html","id":"find-the-first-match","chapter":"17 NLP","heading":"17.1.2.1 Find The First Match","text":"two ways find first match:\n- re.search find first match anywhere text, including multiline\n- re.match find first match BEGINNING text, similar re.searchwith ^\n- returns first match, return MatchObject\n- returns None match foundReturned MatchObject provides useful information matched string.","code":"pattern1 = re.compile('123') \npattern2 = re.compile('123')\npattern3 = re.compile('^123')  # equivalent to above\ntext = 'abc123xyz'\n\n## Single Line Text Example\nprint( 're.search found a match somewhere:\\n',\n       pattern1.search(text), '\\n', ## found\n       '\\nre.match did not find anything at the beginning:\\n',\n       pattern2.match(text), '\\n',\n       '\\nre.search did not find anything at beginning too:\\n',\n       pattern3.search(text))        ## None#:> re.search found a match somewhere:\n#:>  <re.Match object; span=(3, 6), match='123'> \n#:>  \n#:> re.match did not find anything at the beginning:\n#:>  None \n#:>  \n#:> re.search did not find anything at beginning too:\n#:>  Noneage_pattern = re.compile(r'\\d+')\nage_text    = 'Ali is my teacher. He is 109 years old. his kid is 40 years old.'\nfirst_found = age_pattern.search(age_text)\n\nprint('Found Object:           ', first_found,\n      '\\nInput Text:             ', first_found.string,\n      '\\nInput Pattern:          ', first_found.re,\n      '\\nFirst Found string:     ', first_found.group(),\n      '\\nFound Start Position:   ', first_found.start(),\n      '\\nFound End Position:     ', first_found.end(),\n      '\\nFound Span:             ', first_found.span(),)#:> Found Object:            <re.Match object; span=(25, 28), match='109'> \n#:> Input Text:              Ali is my teacher. He is 109 years old. his kid is 40 years old. \n#:> Input Pattern:           re.compile('\\\\d+') \n#:> First Found string:      109 \n#:> Found Start Position:    25 \n#:> Found End Position:      28 \n#:> Found Span:              (25, 28)"},{"path":"nlp.html","id":"find-all-matches","chapter":"17 NLP","heading":"17.1.2.2 Find All Matches","text":"findall() returns matching string list. matches found, return empty list.","code":"print(\n  'Finding Two Digits:',\n  re.findall(r'\\d\\d','abc123xyz456'), '\\n',\n  '\\nFound Nothing:',\n  re.findall(r'\\d\\d','abcxyz'))#:> Finding Two Digits: ['12', '45'] \n#:>  \n#:> Found Nothing: []"},{"path":"nlp.html","id":"matching-condition","chapter":"17 NLP","heading":"17.1.3 Matching Condition","text":"","code":""},{"path":"nlp.html","id":"meta-characters","chapter":"17 NLP","heading":"17.1.3.1 Meta Characters","text":"","code":"[]     match any single character within the bracket\n[1234] is the same as [1-4]\n[0-39] is the same as [01239]\n[a-e]  is the same as [abcde]\n[^abc] means any character except a,b,c\n[^0-9] means any character except 0-9\na|b:   a or b\n{n,m}  at least n repetition, but maximum m repetition\n()     groupingpattern = re.compile(r'[a-z]+')\ntext1 = \"tempo\"\ntext2 = \"tempo1\"\ntext3 = \"123 tempo1\"\ntext4 = \" tempo\"\nprint(\n  'Matching Text1:', pattern.match(text1),\n  '\\nMatching Text2:', pattern.match(text2),\n  '\\nMatching Text3:', pattern.match(text3),\n  '\\nMatching Text4:', pattern.match(text4))#:> Matching Text1: <re.Match object; span=(0, 5), match='tempo'> \n#:> Matching Text2: <re.Match object; span=(0, 5), match='tempo'> \n#:> Matching Text3: None \n#:> Matching Text4: None"},{"path":"nlp.html","id":"special-sequence","chapter":"17 NLP","heading":"17.1.3.2 Special Sequence","text":"Word Boundary Using \\b:\\bABC match specified characters beginning word (delimited space, \\t, \\n), beginning newlineABC\\b match specified characters end word (delimited space, \\t, \\n), end line","code":". : [^\\n]\n\\d: [0-9]              \\D: [^0-9]\n\\s: [ \\t\\n\\r\\f\\v]      \\S: [^ \\t\\n\\r\\f\\v]\n\\w: [a-zA-Z0-9_]       \\W: [^a-zA-Z0-9_]\n\\t: tab\n\\n: newline\n\\b: word boundry (delimited by space, \\t, \\n)text = \"ABCD ABC XYZABC\"\npattern1 = re.compile(r'\\bABC')\npattern2 = re.compile(r'ABC\\b')\npattern3 = re.compile(r'\\bABC\\b')\n\nprint('Match word that begins ABC:',\n  pattern1.findall(text), '\\n',\n  'Match word that ends with ABC:',\n  pattern2.findall(text),'\\n',\n  'Match isolated word with ABC:',\n  pattern3.findall(text))#:> Match word that begins ABC: ['ABC', 'ABC'] \n#:>  Match word that ends with ABC: ['ABC', 'ABC'] \n#:>  Match isolated word with ABC: ['ABC']"},{"path":"nlp.html","id":"repetition","chapter":"17 NLP","heading":"17.1.3.3 Repetition","text":"repetition used, re greedy; try repeat many times possible. later portions pattern don’t match, matching engine back try fewer repetitions.? Zero 1 Occurance+ Least One Occurance* Zero Occurance Occurance","code":"?:    zero or 1 occurance\n*:    zero or more occurance\n+:    one  or more occurancetext = 'abcbcdd'\npattern = re.compile(r'a[bcd]?b')\npattern.findall(text)#:> ['ab']text = 'abcbcdd'\npattern = re.compile(r'a[bcd]+b')\npattern.findall(text)#:> ['abcb']text = 'abcbcdd'\npattern = re.compile(r'a[bcd]*b')\npattern.findall(text)#:> ['abcb']"},{"path":"nlp.html","id":"greedy-vs-non-greedy","chapter":"17 NLP","heading":"17.1.3.4 Greedy vs Non-Greedy","text":"*, +, ? qualifiers greedy; match much text possibleIf <.*> matched <> b <c>, match entire string, just <>Adding ? qualifier makes perform match non-greedy; characters possible matched. Using RE <.*?> match ‘’","code":"text = '<a> ali baba <c>'\ngreedy_pattern     = re.compile(r'<.*>')\nnon_greedy_pattern = re.compile(r'<.*?>')\nprint( 'Greedy:      ' ,        greedy_pattern.findall(text), '\\n',\n       'Non Greedy: ', non_greedy_pattern.findall(text) )#:> Greedy:       ['<a> ali baba <c>'] \n#:>  Non Greedy:  ['<a>', '<c>']"},{"path":"nlp.html","id":"grouping-1","chapter":"17 NLP","heading":"17.1.4 Grouping","text":"() used pattern, retrive grouping components MatchObject .groups(). Result list. Example extract hours, minutes /pm list.","code":""},{"path":"nlp.html","id":"capturing-group","chapter":"17 NLP","heading":"17.1.4.1 Capturing Group","text":"","code":"text = 'Today at Wednesday, 10:50pm, we go for a walk'\npattern = re.compile(r'(\\d\\d):(\\d\\d)(am|pm)')\nm = pattern.search(text)\nprint(\n  'All Gropus: ', m.groups(), '\\n',\n  'Group 1: ', m.group(1), '\\n',\n  'Group 2: ', m.group(2), '\\n',\n  'Group 3: ', m.group(3) )#:> All Gropus:  ('10', '50', 'pm') \n#:>  Group 1:  10 \n#:>  Group 2:  50 \n#:>  Group 3:  pm"},{"path":"nlp.html","id":"non-capturing-group","chapter":"17 NLP","heading":"17.1.4.2 Non-Capturing Group","text":"(:? ) means don’t capture group","code":"text = 'Today at Wednesday, 10:50pm, we go for a walk'\npattern = re.compile(r'(:?\\d\\d):(?:\\d\\d)(am|pm)')\nm = pattern.search(text)\nprint(\n  'All Gropus: ', m.groups(), '\\n',\n  'Group 1: ', m.group(1), '\\n',\n  'Group 2: ', m.group(2) )#:> All Gropus:  ('10', 'pm') \n#:>  Group 1:  10 \n#:>  Group 2:  pm"},{"path":"nlp.html","id":"splittitng","chapter":"17 NLP","heading":"17.1.5 Splittitng","text":"Pattern used match delimters.","code":""},{"path":"nlp.html","id":"use-re.split","chapter":"17 NLP","heading":"17.1.5.1 Use re.split()","text":"","code":"print( re.split('@',  \"aa@bb @ cc \"), '\\n',\n       re.split('\\|', \"aa|bb | cc \"), '\\n',\n       re.split('\\n', \"sentence1\\nsentence2\\nsentence3\") )#:> ['aa', 'bb ', ' cc '] \n#:>  ['aa', 'bb ', ' cc '] \n#:>  ['sentence1', 'sentence2', 'sentence3']"},{"path":"nlp.html","id":"use-re.compile.split","chapter":"17 NLP","heading":"17.1.5.2 Use re.compile().split()","text":"","code":"pattern = re.compile(r\"\\|\")\npattern.split(\"aa|bb | cc \")#:> ['aa', 'bb ', ' cc ']"},{"path":"nlp.html","id":"substitution-re.sub","chapter":"17 NLP","heading":"17.1.6 Substitution re.sub()","text":"","code":""},{"path":"nlp.html","id":"found-match","chapter":"17 NLP","heading":"17.1.6.1 Found Match","text":"Example repalce anything within {{.*}}Replace &. require () grouping","code":"re.sub(r'({{.*}})', 'Durian', 'I like to eat {{Food}}.', flags=re.IGNORECASE)#:> 'I like to eat Durian.'re.sub(r'\\sAND\\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE)#:> 'Baked Beans & Spam'"},{"path":"nlp.html","id":"no-match","chapter":"17 NLP","heading":"17.1.6.2 No Match","text":"pattern found, return original text.","code":"re.sub(r'({{.*}})', 'Durian', 'I like to eat <Food>.', flags=re.IGNORECASE)#:> 'I like to eat <Food>.'"},{"path":"nlp.html","id":"practical-examples","chapter":"17 NLP","heading":"17.1.7 Practical Examples","text":"","code":""},{"path":"nlp.html","id":"extracting-float","chapter":"17 NLP","heading":"17.1.7.1 Extracting Float","text":"","code":"re_float = re.compile(r'\\d+(\\.\\d+)?')\ndef extract_float(x):\n    money = x.replace(',','')\n    result = re_float.search(money)\n    return float(result.group()) if result else float(0)\n\nprint( extract_float('123,456.78'), '\\n',\n       extract_float('rm 123.78 (30%)'), '\\n',\n       extract_float('rm 123,456.78 (30%)') )#:> 123456.78 \n#:>  123.78 \n#:>  123456.78"},{"path":"nlp.html","id":"word-tokenizer","chapter":"17 NLP","heading":"17.2 Word Tokenizer","text":"","code":""},{"path":"nlp.html","id":"custom-tokenizer","chapter":"17 NLP","heading":"17.2.1 Custom Tokenizer","text":"","code":""},{"path":"nlp.html","id":"split-by-regex-pattern","chapter":"17 NLP","heading":"17.2.1.1 Split By Regex Pattern","text":"Use regex split words based specific punctuation delimeter.\nrule : split input text one continuous occurances specified character.","code":"import re\npattern = re.compile(r\"[-\\s.,;!?]+\")\npattern.split(\"hi @ali--baba, you are aweeeeeesome! isn't it. Believe it.:)\")#:> ['hi', '@ali', 'baba', 'you', 'are', 'aweeeeeesome', \"isn't\", 'it', 'Believe', 'it', ':)']"},{"path":"nlp.html","id":"pick-by-regex-pattern-nltk.tokenize.regexptokenizer","chapter":"17 NLP","heading":"17.2.1.2 Pick By Regex Pattern nltk.tokenize.RegexpTokenizer","text":"sequence chars fall within bracket considered tokens. chars within bracket removed.","code":"from nltk.tokenize import RegexpTokenizer\nmy_tokenizer = RegexpTokenizer(r'[a-zA-Z0-9\\']+')\nmy_tokenizer.tokenize(\"hi @ali--baba, you are aweeeeeesome! isn't it. Believe it.:\")#:> ['hi', 'ali', 'baba', 'you', 'are', 'aweeeeeesome', \"isn't\", 'it', 'Believe', 'it']"},{"path":"nlp.html","id":"nltk.tokenize.word_tokenize","chapter":"17 NLP","heading":"17.2.2 nltk.tokenize.word_tokenize()","text":"Words punctuations considered tokens!","code":"import nltk\nnltk.download('punkt')#:> True\n#:> \n#:> [nltk_data] Downloading package punkt to /home/msfz751/nltk_data...\n#:> [nltk_data]   Package punkt is already up-to-date!from nltk.tokenize import word_tokenize\nprint( word_tokenize(\"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it.:)\") )#:> ['hi', '@', 'ali-baba', ',', 'you', 'are', 'aweeeeeesome', '!', 'is', \"n't\", 'it', '.', 'Believe', 'it', '.', ':', ')']"},{"path":"nlp.html","id":"nltk.tokenize.casual.casual_tokenize","chapter":"17 NLP","heading":"17.2.3 nltk.tokenize.casual.casual_tokenize()","text":"Support emojiSupport reduction repetition charsSupport removing userid (@someone)Good social media textPunctuations tokens!Example shorten repeating chars, notice aweeeeeesome becomes aweeesomeStripping User ID","code":"from nltk.tokenize.casual     import casual_tokenize\nprint( casual_tokenize(\"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it. :)\") )  #:> ['hi', '@ali', '-', 'baba', ',', 'you', 'are', 'aweeeeeesome', '!', \"isn't\", 'it', '.', 'Believe', 'it', '.', ':)']## shorten repeated chars\nprint( casual_tokenize(\"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it.:)\", \n          reduce_len=True))     #:> ['hi', '@ali', '-', 'baba', ',', 'you', 'are', 'aweeesome', '!', \"isn't\", 'it', '.', 'Believe', 'it', '.', ':)']## shorten repeated chars, stirp usernames\nprint( casual_tokenize(\"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it.:)\", \n          reduce_len=True,      \n          strip_handles=True))  #:> ['hi', '-', 'baba', ',', 'you', 'are', 'aweeesome', '!', \"isn't\", 'it', '.', 'Believe', 'it', '.', ':)']"},{"path":"nlp.html","id":"nltk.tokenize.treebank.treebankwordtokenizer.tokenize","chapter":"17 NLP","heading":"17.2.4 nltk.tokenize.treebank.TreebankWordTokenizer().tokenize()","text":"Treebank assume input text sentence, hence period combined word treated token.","code":"from nltk.tokenize.treebank   import TreebankWordTokenizer\nTreebankWordTokenizer().tokenize(\"hi @ali-baba, you are aweeeeeesome! isn't it. Believe it.:)\")#:> ['hi', '@', 'ali-baba', ',', 'you', 'are', 'aweeeeeesome', '!', 'is', \"n't\", 'it.', 'Believe', 'it.', ':', ')']"},{"path":"nlp.html","id":"corpus-token-extractor","chapter":"17 NLP","heading":"17.2.5 Corpus Token Extractor","text":"corpus collection documents (list documents).\ndocument text string containing one many sentences.Unpack list token lists using sum. get vocabulary (unique tokens), convert list set.","code":"from nltk.tokenize import word_tokenize\nfrom nlpia.data.loaders import harry_docs as corpus## Tokenize each doc to list, then add to a bigger list\ndoc_tokens=[]\nfor doc in corpus:\n  doc_tokens += [word_tokenize(doc.lower())]\n\nprint('Corpus (Contain 3 Documents):\\n',corpus,'\\n',\n      '\\nTokenized result for each document:','\\n',doc_tokens)#:> Corpus (Contain 3 Documents):\n#:>  ['The faster Harry got to the store, the faster and faster Harry would get home.', 'Harry is hairy and faster than Jill.', 'Jill is not as hairy as Harry.'] \n#:>  \n#:> Tokenized result for each document: \n#:>  [['the', 'faster', 'harry', 'got', 'to', 'the', 'store', ',', 'the', 'faster', 'and', 'faster', 'harry', 'would', 'get', 'home', '.'], ['harry', 'is', 'hairy', 'and', 'faster', 'than', 'jill', '.'], ['jill', 'is', 'not', 'as', 'hairy', 'as', 'harry', '.']]## unpack list of list to list\nvocab = sum(doc_tokens,[])\nprint('\\nCorpus Vacabulary (Unique Tokens):\\n',\n       sorted(set(vocab)))#:> \n#:> Corpus Vacabulary (Unique Tokens):\n#:>  [',', '.', 'and', 'as', 'faster', 'get', 'got', 'hairy', 'harry', 'home', 'is', 'jill', 'not', 'store', 'than', 'the', 'to', 'would']"},{"path":"nlp.html","id":"sentence-tokenizer","chapter":"17 NLP","heading":"17.3 Sentence Tokenizer","text":"detecting sentence boundry split text list sentences","code":""},{"path":"nlp.html","id":"sample-text","chapter":"17 NLP","heading":"17.3.1 Sample Text","text":"","code":"text = '''\nHello Mr. Smith, how are you doing today?\nThe weather is great, and city is awesome.\nThe sky is pinkish-blue, Dr. Alba would agree.\nYou shouldn't eat hard things i.e. cardboard, stones and bushes\n'''"},{"path":"nlp.html","id":"nltk.tokenize.punkt.punktsentencetokenizer","chapter":"17 NLP","heading":"17.3.2 ’nltk.tokenize.punkt.PunktSentenceTokenizer`","text":"PunktSentenceTokenizer sentence boundary detection algorithm. unsupervised trainable model. means can trained unlabeled data, aka text split sentencesPunkSentneceTokenizer based work published paepr: Unsupervised Multilingual Sentence Boundary Detection","code":""},{"path":"nlp.html","id":"default-behavior","chapter":"17 NLP","heading":"17.3.2.1 Default Behavior","text":"Vanila tokenizer splits sentences period ., desirable","code":"from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n#nltk.download('punkt')\ntokenizer = PunktSentenceTokenizer()\ntokenized_text = tokenizer.tokenize(text) \nfor x in tokenized_text:\n  print(x) #:> \n#:> Hello Mr.\n#:> Smith, how are you doing today?\n#:> The weather is great, and city is awesome.\n#:> The sky is pinkish-blue, Dr.\n#:> Alba would agree.\n#:> You shouldn't eat hard things i.e.\n#:> cardboard, stones and bushes"},{"path":"nlp.html","id":"pretrained-model---english-pickle","chapter":"17 NLP","heading":"17.3.2.2 Pretrained Model - English Pickle","text":"NLTK already includes pre-trained version PunktSentenceTokenizer English, can see, quite good","code":"tokenizer      = nltk.data.load('tokenizers/punkt/english.pickle')\ntokenized_text = tokenizer.tokenize(text) \nfor x in tokenized_text:\n  print(x) #:> \n#:> Hello Mr. Smith, how are you doing today?\n#:> The weather is great, and city is awesome.\n#:> The sky is pinkish-blue, Dr. Alba would agree.\n#:> You shouldn't eat hard things i.e.\n#:> cardboard, stones and bushes"},{"path":"nlp.html","id":"adding-abbreviations","chapter":"17 NLP","heading":"17.3.2.3 Adding Abbreviations","text":"pretrained tokenizer perfect, wrongly detected ‘.e.’ sentence boundaryLet’s teach Punkt adding abbreviation parameterAdding Single AbbreviationAdd List AbbreviationsIf one abbreviations, use update() list abbreviations","code":"\ntokenizer      = nltk.data.load('tokenizers/punkt/english.pickle')\n\n## Add apprevaitions to Tokenizer\ntokenizer._params.abbrev_types.add('i.e')\n\ntokenized_text = tokenizer.tokenize(text) \nfor x in tokenized_text:\n  print(x)#:> \n#:> Hello Mr. Smith, how are you doing today?\n#:> The weather is great, and city is awesome.\n#:> The sky is pinkish-blue, Dr. Alba would agree.\n#:> You shouldn't eat hard things i.e. cardboard, stones and bushesfrom nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n\n## Add Abbreviations to Tokenizer\ntokenizer =  nltk.data.load('tokenizers/punkt/english.pickle')\ntokenizer._params.abbrev_types.update(['dr', 'vs', 'mr', 'mrs', 'prof', 'inc', 'i.e'])\n\nsentences = tokenizer.tokenize(text) \nfor x in sentences:\n  print(x) #:> \n#:> Hello Mr. Smith, how are you doing today?\n#:> The weather is great, and city is awesome.\n#:> The sky is pinkish-blue, Dr. Alba would agree.\n#:> You shouldn't eat hard things i.e. cardboard, stones and bushes"},{"path":"nlp.html","id":"nltk.tokenize.sent_tokenize","chapter":"17 NLP","heading":"17.3.3 nltk.tokenize.sent_tokenize()","text":"sent_tokenize function uses instance PunktSentenceTokenizer, already trained thus well knows mark end begining sentence characters punctuation.","code":"from nltk.tokenize import sent_tokenize\n\nsentences = sent_tokenize(text)\nfor x in sentences:\n  print(x) #:> \n#:> Hello Mr. Smith, how are you doing today?\n#:> The weather is great, and city is awesome.\n#:> The sky is pinkish-blue, Dr. Alba would agree.\n#:> You shouldn't eat hard things i.e. cardboard, stones and bushes"},{"path":"nlp.html","id":"n-gram","chapter":"17 NLP","heading":"17.4 N-Gram","text":"create n-gram, first create 1-gram tokenngrams() generator, therefore, use list() convert full listConvert 1-gram 2-Gram, wrap listCombine 2-gram string object","code":"from nltk.util import ngrams \nimport re\nsentence = \"Thomas Jefferson began building the city, at the age of 25\"\npattern = re.compile(r\"[-\\s.,;!?]+\")\ntokens = pattern.split(sentence)\nprint(tokens)#:> ['Thomas', 'Jefferson', 'began', 'building', 'the', 'city', 'at', 'the', 'age', 'of', '25']ngrams(tokens,2)#:> <generator object ngrams at 0x7fcdc9eae850>grammy = list( ngrams(tokens,2) )\nprint(grammy)#:> [('Thomas', 'Jefferson'), ('Jefferson', 'began'), ('began', 'building'), ('building', 'the'), ('the', 'city'), ('city', 'at'), ('at', 'the'), ('the', 'age'), ('age', 'of'), ('of', '25')][ \" \".join(x) for x in grammy]#:> ['Thomas Jefferson', 'Jefferson began', 'began building', 'building the', 'the city', 'city at', 'at the', 'the age', 'age of', 'of 25']"},{"path":"nlp.html","id":"stopwords","chapter":"17 NLP","heading":"17.5 Stopwords","text":"","code":""},{"path":"nlp.html","id":"custom-stop-words","chapter":"17 NLP","heading":"17.5.1 Custom Stop Words","text":"Build custom stop words dictionary.Tokenize text remove stop words","code":"stop_words = ['a','an','the','on','of','off','this','is','at']sentence = \"The house is on fire\"\ntokens   = word_tokenize(sentence)\ntokens_without_stopwords = [ x for x in tokens if x not in stop_words ]\n\nprint(' Original Tokens  : ', tokens, '\\n',\n      'Removed Stopwords: ',tokens_without_stopwords)#:>  Original Tokens  :  ['The', 'house', 'is', 'on', 'fire'] \n#:>  Removed Stopwords:  ['The', 'house', 'fire']"},{"path":"nlp.html","id":"nltk-stop-words","chapter":"17 NLP","heading":"17.5.2 NLTK Stop Words","text":"Contain 179 words, list form","code":"import nltk\nnltk.download('stopwords')#:> True\n#:> \n#:> [nltk_data] Downloading package stopwords to\n#:> [nltk_data]     /home/msfz751/nltk_data...\n#:> [nltk_data]   Package stopwords is already up-to-date!import nltk\n#nltk.download('stopwords')\nnltk_stop_words = nltk.corpus.stopwords.words('english')\nprint('Total NLTK Stopwords: ', len(nltk_stop_words),'\\n',\n      nltk_stop_words)#:> Total NLTK Stopwords:  179 \n#:>  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"},{"path":"nlp.html","id":"sklearn-stop-words","chapter":"17 NLP","heading":"17.5.3 SKLearn Stop Words","text":"Contain 318 stop words, frozenset form","code":"from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\nprint(' Total Sklearn Stopwords: ', len(sklearn_stop_words),'\\n\\n',\n       sklearn_stop_words)#:>  Total Sklearn Stopwords:  318 \n#:> \n#:>  frozenset({'before', 'becomes', 'down', 'see', 'already', 'cry', 'behind', 'first', 'such', 'con', 'neither', 'however', 'was', 'something', 'against', 'either', 'thence', 'well', 'to', 'when', 'those', 'whose', 'throughout', 'never', 'third', 'been', 'empty', 'anyway', 'if', 'their', 'amount', 'etc', 'others', 'nothing', 'around', 'every', 'how', 'into', 'then', 'along', 'amongst', 'should', 'upon', 'us', 'take', 'himself', 'namely', 'not', 'de', 'under', 'all', 'out', 'twelve', 'sincere', 'through', 'thru', 'get', 'across', 'mill', 'indeed', 'each', 'whereas', 'now', 'so', 'very', 'hereafter', 'them', 'few', 'most', 'call', 'hereby', 'sometime', 'many', 'ever', 'interest', 'twenty', 'any', 'might', 'thick', 'rather', 'until', 'besides', 're', 'back', 'hers', 'cant', 'enough', 'by', 'hence', 'would', 'via', 'for', 'yours', 'couldnt', 'will', 'thus', 'fire', 'wherever', 'but', 'none', 'name', 'somehow', 'almost', 'full', 'myself', 'fill', 'hasnt', 'sixty', 'who', 'what', 'keep', 'front', 'nevertheless', 'these', 'there', 'system', 'done', 'eleven', 'three', 'seem', 'why', 'anything', 'made', 'ourselves', 'had', 'nowhere', 'with', 'un', 'give', 'another', 'perhaps', 'everywhere', 'between', 'show', 'amoungst', 'further', 'whom', 'within', 'here', 'thereby', 'your', 'during', 'too', 'yourself', 'towards', 'and', 'at', 'move', 'eg', 'eight', 'be', 'above', 'among', 'do', 'a', 'inc', 'six', 'together', 'yet', 'up', 'toward', 'whatever', 'an', 'on', 'you', 'still', 'five', 'therein', 'noone', 'although', 'whereafter', 'alone', 'as', 'we', 'always', 'often', 'has', 'this', 'next', 'else', 'whoever', 'again', 'due', 'even', 'no', 'become', 'several', 'please', 'beforehand', 'least', 'nobody', 'could', 'both', 'mostly', 'may', 'latterly', 'own', 'because', 'that', 'thereupon', 'anyhow', 'hereupon', 'off', 'less', 'only', 'it', 'whole', 'than', 'seemed', 'more', 'whence', 'hundred', 'must', 'my', 'since', 'i', 'can', 'except', 'other', 'side', 'bill', 'after', 'our', 'were', 'meanwhile', 'herself', 'in', 'two', 'ltd', 'whereby', 'put', 'bottom', 'afterwards', 'his', 'its', 'everyone', 'one', 'everything', 'find', 'anyone', 'beside', 'though', 'he', 'from', 'she', 'are', 'former', 'or', 'otherwise', 'someone', 'top', 'me', 'of', 'therefore', 'whereupon', 'am', 'the', 'nine', 'ours', 'found', 'co', 'some', 'yourselves', 'have', 'once', 'describe', 'over', 'themselves', 'mine', 'detail', 'itself', 'per', 'they', 'latter', 'whither', 'forty', 'somewhere', 'fifteen', 'beyond', 'being', 'whether', 'cannot', 'is', 'nor', 'thin', 'became', 'onto', 'go', 'whenever', 'thereafter', 'seeming', 'without', 'formerly', 'sometimes', 'seems', 'last', 'much', 'fifty', 'which', 'serious', 'while', 'herein', 'ie', 'moreover', 'part', 'where', 'him', 'ten', 'four', 'elsewhere', 'below', 'same', 'about', 'anywhere', 'her', 'also', 'becoming', 'wherein'})"},{"path":"nlp.html","id":"combined-nltk-and-sklearn-stop-words","chapter":"17 NLP","heading":"17.5.4 Combined NLTK and SKLearn Stop Words","text":"","code":"combined_stop_words = list( set(nltk_stop_words) | set(sklearn_stop_words) )\nprint('Total combined NLTK and SKLearn Stopwords:', len( combined_stop_words ),'\\n'\n      'Stopwords shared among NLTK and SKlearn  :', len( list( set(nltk_stop_words) & set(sklearn_stop_words)) ))#:> Total combined NLTK and SKLearn Stopwords: 378 \n#:> Stopwords shared among NLTK and SKlearn  : 119"},{"path":"nlp.html","id":"normalizing","chapter":"17 NLP","heading":"17.6 Normalizing","text":"Similar things combined single normalized form. reduced vocabulary.","code":""},{"path":"nlp.html","id":"case-folding","chapter":"17 NLP","heading":"17.6.1 Case Folding","text":"tokens aren’t cap normalized, end large word list.\nHowever, information often communicated capitalization word, name places. names important, consider using proper noun.","code":"tokens = ['House','Visitor','Center']\n[ x.lower() for x in tokens]#:> ['house', 'visitor', 'center']"},{"path":"nlp.html","id":"stemming","chapter":"17 NLP","heading":"17.6.2 Stemming","text":"Output stemmer necessary proper wordAutomatically convert words lower capPorter stemmer lifetime refinement 300 lines python codeStemming faster Lemmatization","code":"from nltk.stem.porter import PorterStemmer\nstemmer = PorterStemmer()\ntokens = ('house','Housing','hOuses', 'Malicious','goodness')\n[stemmer.stem(x) for x in tokens ]#:> ['hous', 'hous', 'hous', 'malici', 'good']"},{"path":"nlp.html","id":"lemmatization","chapter":"17 NLP","heading":"17.6.3 Lemmatization","text":"NLTK uses connections within princeton WordNet graph word meanings.","code":"nltk.download('wordnet')#:> True\n#:> \n#:> [nltk_data] Downloading package wordnet to /home/msfz751/nltk_data...\n#:> [nltk_data]   Package wordnet is already up-to-date!from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\nprint( lemmatizer.lemmatize(\"better\", pos ='a'), '\\n',\n       lemmatizer.lemmatize(\"better\", pos ='n') )#:> good \n#:>  betterprint( lemmatizer.lemmatize(\"good\", pos ='a'), '\\n',\n       lemmatizer.lemmatize(\"good\", pos ='n') )#:> good \n#:>  good"},{"path":"nlp.html","id":"comparing-stemming-and-lemmatization","chapter":"17 NLP","heading":"17.6.4 Comparing Stemming and Lemmatization","text":"Lemmatization slower stemming\n= Lemmatization better retaining meaningsLemmatization produce valid english wordStemming necessary produce valid english wordBoth reduce vocabulary size, increase ambiguityFor search engine application, stemming lemmatization improve recall associate documents query words, however cost reducing precision accuracy.search-based chatbot accuracy important, first search unnormalzied words.","code":""},{"path":"nlp.html","id":"wordnet","chapter":"17 NLP","heading":"17.7 Wordnet","text":"WordNet® large lexical database English. Nouns, verbs, adjectives adverbs grouped sets cognitive synonyms (synsets), expressing distinct concept. Synsets interlinked means conceptual-semantic lexical relations.WordNet superficially resembles thesaurus, groups words together based meanings. However, important distinctions:\n- WordNet interlinks just word forms—strings letters—specific senses words. result, words found close proximity one another network semantically disambiguated\n- WordNet labels semantic relations among words, whereas groupings words thesaurus follow explicit pattern meaning similarityWordnet PrincetonWordnet Online Browser","code":""},{"path":"nlp.html","id":"nltk-and-wordnet","chapter":"17 NLP","heading":"17.7.1 NLTK and Wordnet","text":"NLTK (version 3.7.6) includes English WordNet (147,307 words 117,659 synonym sets)","code":"from nltk.corpus import wordnet as wn\n\ns = set( wn.all_synsets() )\nw = set(wn.words())\nprint('Total words in wordnet  : ' ,   len(w),\n      '\\nTotal synsets in wordnet: ' , len(s) )#:> Total words in wordnet  :  147306 \n#:> Total synsets in wordnet:  117659"},{"path":"nlp.html","id":"synset","chapter":"17 NLP","heading":"17.7.2 Synset","text":"","code":""},{"path":"nlp.html","id":"notation","chapter":"17 NLP","heading":"17.7.2.1 Notation","text":"synset basic construct word wordnet. contains Word , POS tag Usage: word.pos.nnBreaking construct:","code":"wn.synset('breakdown.n.03')#:> Synset('breakdown.n.03')'breakdown' = Word\n'n'         = Part of Speech\n'03'        = Usage (01 for most common usage and a higher number would indicate lesser common usages)"},{"path":"nlp.html","id":"part-of-speech","chapter":"17 NLP","heading":"17.7.2.2 Part of Speech","text":"Wordnet support five POS tags","code":"n - NOUN\nv - VERB\na - ADJECTIVE\ns - ADJECTIVE SATELLITE\nr - ADVERBprint(wn.ADJ, wn.ADJ_SAT, wn.ADV, wn.NOUN, wn.VERB)#:> a s r n v"},{"path":"nlp.html","id":"synset-similarity","chapter":"17 NLP","heading":"17.7.2.3 Synset Similarity","text":"Let’s see similar two nouns","code":"w1 = wn.synset('dog.n.01')\nw2 = wn.synset('ship.n.01')\nprint(w1.wup_similarity(w2))#:> 0.4w1 = wn.synset('ship.n.01')\nw2 = wn.synset('boat.n.01')\nprint(w1.wup_similarity(w2))#:> 0.9090909090909091"},{"path":"nlp.html","id":"synsets","chapter":"17 NLP","heading":"17.7.3 Synsets","text":"Synsets collection synsets, synonyms share common meaningA synset (member Synsets) identified 3-part name form:synset can contain one lemmas, represent specific sense specific wordA synset can contain one Hyponyms Hypernyms. specific generalized concepts respectively. example, ‘beach house’ ‘guest house’ hyponyms ‘house.’ specific concepts ‘house.’ ‘house’ hypernym ‘guest house’ general conceptHyponyms Hypernyms also called lexical relations","code":"dogs = wn.synsets('dog') # get all synsets for word 'dog'\n\nfor d in dogs:  ## iterate through each Synset\n  print(d,':\\nDefinition:', d.definition(),\n           '\\nExample:',    d.examples(),\n           '\\nLemmas:',     d.lemma_names(),\n           '\\nHyponyms:',   d.hyponyms(), \n           '\\nHypernyms:',  d.hypernyms(), '\\n\\n')#:> Synset('dog.n.01') :\n#:> Definition: a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds \n#:> Example: ['the dog barked all night'] \n#:> Lemmas: ['dog', 'domestic_dog', 'Canis_familiaris'] \n#:> Hyponyms: [Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')] \n#:> Hypernyms: [Synset('canine.n.02'), Synset('domestic_animal.n.01')] \n#:> \n#:> \n#:> Synset('frump.n.01') :\n#:> Definition: a dull unattractive unpleasant girl or woman \n#:> Example: ['she got a reputation as a frump', \"she's a real dog\"] \n#:> Lemmas: ['frump', 'dog'] \n#:> Hyponyms: [] \n#:> Hypernyms: [Synset('unpleasant_woman.n.01')] \n#:> \n#:> \n#:> Synset('dog.n.03') :\n#:> Definition: informal term for a man \n#:> Example: ['you lucky dog'] \n#:> Lemmas: ['dog'] \n#:> Hyponyms: [] \n#:> Hypernyms: [Synset('chap.n.01')] \n#:> \n#:> \n#:> Synset('cad.n.01') :\n#:> Definition: someone who is morally reprehensible \n#:> Example: ['you dirty dog'] \n#:> Lemmas: ['cad', 'bounder', 'blackguard', 'dog', 'hound', 'heel'] \n#:> Hyponyms: [Synset('perisher.n.01')] \n#:> Hypernyms: [Synset('villain.n.01')] \n#:> \n#:> \n#:> Synset('frank.n.02') :\n#:> Definition: a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll \n#:> Example: [] \n#:> Lemmas: ['frank', 'frankfurter', 'hotdog', 'hot_dog', 'dog', 'wiener', 'wienerwurst', 'weenie'] \n#:> Hyponyms: [Synset('vienna_sausage.n.01')] \n#:> Hypernyms: [Synset('sausage.n.01')] \n#:> \n#:> \n#:> Synset('pawl.n.01') :\n#:> Definition: a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward \n#:> Example: [] \n#:> Lemmas: ['pawl', 'detent', 'click', 'dog'] \n#:> Hyponyms: [] \n#:> Hypernyms: [Synset('catch.n.06')] \n#:> \n#:> \n#:> Synset('andiron.n.01') :\n#:> Definition: metal supports for logs in a fireplace \n#:> Example: ['the andirons were too hot to touch'] \n#:> Lemmas: ['andiron', 'firedog', 'dog', 'dog-iron'] \n#:> Hyponyms: [] \n#:> Hypernyms: [Synset('support.n.10')] \n#:> \n#:> \n#:> Synset('chase.v.01') :\n#:> Definition: go after with the intent to catch \n#:> Example: ['The policeman chased the mugger down the alley', 'the dog chased the rabbit'] \n#:> Lemmas: ['chase', 'chase_after', 'trail', 'tail', 'tag', 'give_chase', 'dog', 'go_after', 'track'] \n#:> Hyponyms: [Synset('hound.v.01'), Synset('quest.v.02'), Synset('run_down.v.07'), Synset('tree.v.03')] \n#:> Hypernyms: [Synset('pursue.v.02')]"},{"path":"nlp.html","id":"part-of-speech-pos","chapter":"17 NLP","heading":"17.8 Part Of Speech (POS)","text":"corpus linguistics, part--speech tagging (POS tagging PoS tagging POST), also called grammatical tagging word-category disambiguation, process marking word text (corpus) corresponding particular part speech, based definition context—.e., relationship adjacent related words phrase, sentence, paragraphThis useful Information Retrieval, Text Speech, Word Sense DisambiguationThe primary target Part--Speech(POS) tagging identify grammatical group given word. Whether NOUN, PRONOUN, ADJECTIVE, VERB, ADVERBS, etc. based contextA simplified form commonly taught school-age children, identification words nouns, verbs, adjectives, adverbs, etc","code":""},{"path":"nlp.html","id":"tag-sets","chapter":"17 NLP","heading":"17.8.1 Tag Sets","text":"Schools commonly teach 9 parts speech English: noun, verb, article, adjective, preposition, pronoun, adverb, conjunction, interjectionHowever, clearly many categories sub-categories","code":" nltk.download('universal_tagset')"},{"path":"nlp.html","id":"universal-tagset","chapter":"17 NLP","heading":"17.8.1.1 Universal Tagset","text":"tagset contains 12 coarse tags","code":"VERB - verbs (all tenses and modes)\nNOUN - nouns (common and proper)\nPRON - pronouns\nADJ - adjectives\nADV - adverbs\nADP - adpositions (prepositions and postpositions)\nCONJ - conjunctions\nDET - determiners\nNUM - cardinal numbers\nPRT - particles or other function words\nX - other: foreign words, typos, abbreviations\n. - punctuation"},{"path":"nlp.html","id":"penn-treebank-tagset","chapter":"17 NLP","heading":"17.8.1.2 Penn Treebank Tagset","text":"popular “tag set” American English, developed Penn Treebank projectIt 36 POS tags plus 12 others punctuations special symbolsPENN POS Tagset","code":"nltk.download('tagsets')#:> True\n#:> \n#:> [nltk_data] Downloading package tagsets to /home/msfz751/nltk_data...\n#:> [nltk_data]   Package tagsets is already up-to-date!nltk.help.upenn_tagset()#:> $: dollar\n#:>     $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n#:> '': closing quotation mark\n#:>     ' ''\n#:> (: opening parenthesis\n#:>     ( [ {\n#:> ): closing parenthesis\n#:>     ) ] }\n#:> ,: comma\n#:>     ,\n#:> --: dash\n#:>     --\n#:> .: sentence terminator\n#:>     . ! ?\n#:> :: colon or ellipsis\n#:>     : ; ...\n#:> CC: conjunction, coordinating\n#:>     & 'n and both but either et for less minus neither nor or plus so\n#:>     therefore times v. versus vs. whether yet\n#:> CD: numeral, cardinal\n#:>     mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n#:>     seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n#:>     fifteen 271,124 dozen quintillion DM2,000 ...\n#:> DT: determiner\n#:>     all an another any both del each either every half la many much nary\n#:>     neither no some such that the them these this those\n#:> EX: existential there\n#:>     there\n#:> FW: foreign word\n#:>     gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n#:>     lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n#:>     terram fiche oui corporis ...\n#:> IN: preposition or conjunction, subordinating\n#:>     astride among uppon whether out inside pro despite on by throughout\n#:>     below within for towards near behind atop around if like until below\n#:>     next into if beside ...\n#:> JJ: adjective or numeral, ordinal\n#:>     third ill-mannered pre-war regrettable oiled calamitous first separable\n#:>     ectoplasmic battery-powered participatory fourth still-to-be-named\n#:>     multilingual multi-disciplinary ...\n#:> JJR: adjective, comparative\n#:>     bleaker braver breezier briefer brighter brisker broader bumper busier\n#:>     calmer cheaper choosier cleaner clearer closer colder commoner costlier\n#:>     cozier creamier crunchier cuter ...\n#:> JJS: adjective, superlative\n#:>     calmest cheapest choicest classiest cleanest clearest closest commonest\n#:>     corniest costliest crassest creepiest crudest cutest darkest deadliest\n#:>     dearest deepest densest dinkiest ...\n#:> LS: list item marker\n#:>     A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n#:>     SP-44007 Second Third Three Two * a b c d first five four one six three\n#:>     two\n#:> MD: modal auxiliary\n#:>     can cannot could couldn't dare may might must need ought shall should\n#:>     shouldn't will would\n#:> NN: noun, common, singular or mass\n#:>     common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n#:>     investment slide humour falloff slick wind hyena override subhumanity\n#:>     machinist ...\n#:> NNP: noun, proper, singular\n#:>     Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n#:>     Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n#:>     Shannon A.K.C. Meltex Liverpool ...\n#:> NNPS: noun, proper, plural\n#:>     Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n#:>     Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n#:>     Apache Apaches Apocrypha ...\n#:> NNS: noun, common, plural\n#:>     undergraduates scotches bric-a-brac products bodyguards facets coasts\n#:>     divestitures storehouses designs clubs fragrances averages\n#:>     subjectivists apprehensions muses factory-jobs ...\n#:> PDT: pre-determiner\n#:>     all both half many quite such sure this\n#:> POS: genitive marker\n#:>     ' 's\n#:> PRP: pronoun, personal\n#:>     hers herself him himself hisself it itself me myself one oneself ours\n#:>     ourselves ownself self she thee theirs them themselves they thou thy us\n#:> PRP$: pronoun, possessive\n#:>     her his mine my our ours their thy your\n#:> RB: adverb\n#:>     occasionally unabatingly maddeningly adventurously professedly\n#:>     stirringly prominently technologically magisterially predominately\n#:>     swiftly fiscally pitilessly ...\n#:> RBR: adverb, comparative\n#:>     further gloomier grander graver greater grimmer harder harsher\n#:>     healthier heavier higher however larger later leaner lengthier less-\n#:>     perfectly lesser lonelier longer louder lower more ...\n#:> RBS: adverb, superlative\n#:>     best biggest bluntest earliest farthest first furthest hardest\n#:>     heartiest highest largest least less most nearest second tightest worst\n#:> RP: particle\n#:>     aboard about across along apart around aside at away back before behind\n#:>     by crop down ever fast for forth from go high i.e. in into just later\n#:>     low more off on open out over per pie raising start teeth that through\n#:>     under unto up up-pp upon whole with you\n#:> SYM: symbol\n#:>     % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n#:> TO: \"to\" as preposition or infinitive marker\n#:>     to\n#:> UH: interjection\n#:>     Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n#:>     huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n#:>     man baby diddle hush sonuvabitch ...\n#:> VB: verb, base form\n#:>     ask assemble assess assign assume atone attention avoid bake balkanize\n#:>     bank begin behold believe bend benefit bevel beware bless boil bomb\n#:>     boost brace break bring broil brush build ...\n#:> VBD: verb, past tense\n#:>     dipped pleaded swiped regummed soaked tidied convened halted registered\n#:>     cushioned exacted snubbed strode aimed adopted belied figgered\n#:>     speculated wore appreciated contemplated ...\n#:> VBG: verb, present participle or gerund\n#:>     telegraphing stirring focusing angering judging stalling lactating\n#:>     hankerin' alleging veering capping approaching traveling besieging\n#:>     encrypting interrupting erasing wincing ...\n#:> VBN: verb, past participle\n#:>     multihulled dilapidated aerosolized chaired languished panelized used\n#:>     experimented flourished imitated reunifed factored condensed sheared\n#:>     unsettled primed dubbed desired ...\n#:> VBP: verb, present tense, not 3rd person singular\n#:>     predominate wrap resort sue twist spill cure lengthen brush terminate\n#:>     appear tend stray glisten obtain comprise detest tease attract\n#:>     emphasize mold postpone sever return wag ...\n#:> VBZ: verb, present tense, 3rd person singular\n#:>     bases reconstructs marks mixes displeases seals carps weaves snatches\n#:>     slumps stretches authorizes smolders pictures emerges stockpiles\n#:>     seduces fizzes uses bolsters slaps speaks pleads ...\n#:> WDT: WH-determiner\n#:>     that what whatever which whichever\n#:> WP: WH-pronoun\n#:>     that what whatever whatsoever which who whom whosoever\n#:> WP$: WH-pronoun, possessive\n#:>     whose\n#:> WRB: Wh-adverb\n#:>     how however whence whenever where whereby whereever wherein whereof why\n#:> ``: opening quotation mark\n#:>     ` ``"},{"path":"nlp.html","id":"claws5-tagset","chapter":"17 NLP","heading":"17.8.1.3 Claws5 Tagset","text":"Claws5 POS Tagset","code":"nltk.help.claws5_tagset()#:> AJ0: adjective (unmarked)\n#:>     good, old\n#:> AJC: comparative adjective\n#:>     better, older\n#:> AJS: superlative adjective\n#:>     best, oldest\n#:> AT0: article\n#:>     THE, A, AN\n#:> AV0: adverb (unmarked)\n#:>     often, well, longer, furthest\n#:> AVP: adverb particle\n#:>     up, off, out\n#:> AVQ: wh-adverb\n#:>     when, how, why\n#:> CJC: coordinating conjunction\n#:>     and, or\n#:> CJS: subordinating conjunction\n#:>     although, when\n#:> CJT: the conjunction THAT\n#:>     that\n#:> CRD: cardinal numeral\n#:>     3, fifty-five, 6609 (excl one)\n#:> DPS: possessive determiner form\n#:>     your, their\n#:> DT0: general determiner\n#:>     these, some\n#:> DTQ: wh-determiner\n#:>     whose, which\n#:> EX0: existential THERE\n#:>     there\n#:> ITJ: interjection or other isolate\n#:>     oh, yes, mhm\n#:> NN0: noun (neutral for number)\n#:>     aircraft, data\n#:> NN1: singular noun\n#:>     pencil, goose\n#:> NN2: plural noun\n#:>     pencils, geese\n#:> NP0: proper noun\n#:>     London, Michael, Mars\n#:> NULL: the null tag (for items not to be tagged)\n#:> ORD: ordinal\n#:>     sixth, 77th, last\n#:> PNI: indefinite pronoun\n#:>     none, everything\n#:> PNP: personal pronoun\n#:>     you, them, ours\n#:> PNQ: wh-pronoun\n#:>     who, whoever\n#:> PNX: reflexive pronoun\n#:>     itself, ourselves\n#:> POS: the possessive (or genitive morpheme)\n#:>     's or '\n#:> PRF: the preposition OF\n#:>     of\n#:> PRP: preposition (except for OF)\n#:>     for, above, to\n#:> PUL: punctuation\n#:>     left bracket - ( or [ )\n#:> PUN: punctuation\n#:>     general mark - . ! , : ; - ? ...\n#:> PUQ: punctuation\n#:>     quotation mark - ` ' \"\n#:> PUR: punctuation\n#:>     right bracket - ) or ]\n#:> TO0: infinitive marker TO\n#:>     to\n#:> UNC: \"unclassified\" items which are not words of the English lexicon\n#:> VBB: the \"base forms\" of the verb \"BE\" (except the infinitive)\n#:>     am, are\n#:> VBD: past form of the verb \"BE\"\n#:>     was, were\n#:> VBG: -ing form of the verb \"BE\"\n#:>     being\n#:> VBI: infinitive of the verb \"BE\"\n#:>     be\n#:> VBN: past participle of the verb \"BE\"\n#:>     been\n#:> VBZ: -s form of the verb \"BE\"\n#:>     is, 's\n#:> VDB: base form of the verb \"DO\" (except the infinitive)\n#:>     do\n#:> VDD: past form of the verb \"DO\"\n#:>     did\n#:> VDG: -ing form of the verb \"DO\"\n#:>     doing\n#:> VDI: infinitive of the verb \"DO\"\n#:>     do\n#:> VDN: past participle of the verb \"DO\"\n#:>     done\n#:> VDZ: -s form of the verb \"DO\"\n#:>     does\n#:> VHB: base form of the verb \"HAVE\" (except the infinitive)\n#:>     have\n#:> VHD: past tense form of the verb \"HAVE\"\n#:>     had, 'd\n#:> VHG: -ing form of the verb \"HAVE\"\n#:>     having\n#:> VHI: infinitive of the verb \"HAVE\"\n#:>     have\n#:> VHN: past participle of the verb \"HAVE\"\n#:>     had\n#:> VHZ: -s form of the verb \"HAVE\"\n#:>     has, 's\n#:> VM0: modal auxiliary verb\n#:>     can, could, will, 'll\n#:> VVB: base form of lexical verb (except the infinitive)\n#:>     take, live\n#:> VVD: past tense form of lexical verb\n#:>     took, lived\n#:> VVG: -ing form of lexical verb\n#:>     taking, living\n#:> VVI: infinitive of lexical verb\n#:>     take, live\n#:> VVN: past participle form of lex. verb\n#:>     taken, lived\n#:> VVZ: -s form of lexical verb\n#:>     takes, lives\n#:> XX0: the negative NOT or N'T\n#:>     not\n#:> ZZ0: alphabetical symbol\n#:>     A, B, c, d"},{"path":"nlp.html","id":"brown-tagset","chapter":"17 NLP","heading":"17.8.1.4 Brown Tagset","text":"Brown POS Tagset","code":"nltk.help.brown_tagset()#:> (: opening parenthesis\n#:>     (\n#:> ): closing parenthesis\n#:>     )\n#:> *: negator\n#:>     not n't\n#:> ,: comma\n#:>     ,\n#:> --: dash\n#:>     --\n#:> .: sentence terminator\n#:>     . ? ; ! :\n#:> :: colon\n#:>     :\n#:> ABL: determiner/pronoun, pre-qualifier\n#:>     quite such rather\n#:> ABN: determiner/pronoun, pre-quantifier\n#:>     all half many nary\n#:> ABX: determiner/pronoun, double conjunction or pre-quantifier\n#:>     both\n#:> AP: determiner/pronoun, post-determiner\n#:>     many other next more last former little several enough most least only\n#:>     very few fewer past same Last latter less single plenty 'nough lesser\n#:>     certain various manye next-to-last particular final previous present\n#:>     nuf\n#:> AP$: determiner/pronoun, post-determiner, genitive\n#:>     other's\n#:> AP+AP: determiner/pronoun, post-determiner, hyphenated pair\n#:>     many-much\n#:> AT: article\n#:>     the an no a every th' ever' ye\n#:> BE: verb 'to be', infinitive or imperative\n#:>     be\n#:> BED: verb 'to be', past tense, 2nd person singular or all persons plural\n#:>     were\n#:> BED*: verb 'to be', past tense, 2nd person singular or all persons plural, negated\n#:>     weren't\n#:> BEDZ: verb 'to be', past tense, 1st and 3rd person singular\n#:>     was\n#:> BEDZ*: verb 'to be', past tense, 1st and 3rd person singular, negated\n#:>     wasn't\n#:> BEG: verb 'to be', present participle or gerund\n#:>     being\n#:> BEM: verb 'to be', present tense, 1st person singular\n#:>     am\n#:> BEM*: verb 'to be', present tense, 1st person singular, negated\n#:>     ain't\n#:> BEN: verb 'to be', past participle\n#:>     been\n#:> BER: verb 'to be', present tense, 2nd person singular or all persons plural\n#:>     are art\n#:> BER*: verb 'to be', present tense, 2nd person singular or all persons plural, negated\n#:>     aren't ain't\n#:> BEZ: verb 'to be', present tense, 3rd person singular\n#:>     is\n#:> BEZ*: verb 'to be', present tense, 3rd person singular, negated\n#:>     isn't ain't\n#:> CC: conjunction, coordinating\n#:>     and or but plus & either neither nor yet 'n' and/or minus an'\n#:> CD: numeral, cardinal\n#:>     two one 1 four 2 1913 71 74 637 1937 8 five three million 87-31 29-5\n#:>     seven 1,119 fifty-three 7.5 billion hundred 125,000 1,700 60 100 six\n#:>     ...\n#:> CD$: numeral, cardinal, genitive\n#:>     1960's 1961's .404's\n#:> CS: conjunction, subordinating\n#:>     that as after whether before while like because if since for than altho\n#:>     until so unless though providing once lest s'posin' till whereas\n#:>     whereupon supposing tho' albeit then so's 'fore\n#:> DO: verb 'to do', uninflected present tense, infinitive or imperative\n#:>     do dost\n#:> DO*: verb 'to do', uninflected present tense or imperative, negated\n#:>     don't\n#:> DO+PPSS: verb 'to do', past or present tense + pronoun, personal, nominative, not 3rd person singular\n#:>     d'you\n#:> DOD: verb 'to do', past tense\n#:>     did done\n#:> DOD*: verb 'to do', past tense, negated\n#:>     didn't\n#:> DOZ: verb 'to do', present tense, 3rd person singular\n#:>     does\n#:> DOZ*: verb 'to do', present tense, 3rd person singular, negated\n#:>     doesn't don't\n#:> DT: determiner/pronoun, singular\n#:>     this each another that 'nother\n#:> DT$: determiner/pronoun, singular, genitive\n#:>     another's\n#:> DT+BEZ: determiner/pronoun + verb 'to be', present tense, 3rd person singular\n#:>     that's\n#:> DT+MD: determiner/pronoun + modal auxillary\n#:>     that'll this'll\n#:> DTI: determiner/pronoun, singular or plural\n#:>     any some\n#:> DTS: determiner/pronoun, plural\n#:>     these those them\n#:> DTS+BEZ: pronoun, plural + verb 'to be', present tense, 3rd person singular\n#:>     them's\n#:> DTX: determiner, pronoun or double conjunction\n#:>     neither either one\n#:> EX: existential there\n#:>     there\n#:> EX+BEZ: existential there + verb 'to be', present tense, 3rd person singular\n#:>     there's\n#:> EX+HVD: existential there + verb 'to have', past tense\n#:>     there'd\n#:> EX+HVZ: existential there + verb 'to have', present tense, 3rd person singular\n#:>     there's\n#:> EX+MD: existential there + modal auxillary\n#:>     there'll there'd\n#:> FW-*: foreign word: negator\n#:>     pas non ne\n#:> FW-AT: foreign word: article\n#:>     la le el un die der ein keine eine das las les Il\n#:> FW-AT+NN: foreign word: article + noun, singular, common\n#:>     l'orchestre l'identite l'arcade l'ange l'assistance l'activite\n#:>     L'Universite l'independance L'Union L'Unita l'osservatore\n#:> FW-AT+NP: foreign word: article + noun, singular, proper\n#:>     L'Astree L'Imperiale\n#:> FW-BE: foreign word: verb 'to be', infinitive or imperative\n#:>     sit\n#:> FW-BER: foreign word: verb 'to be', present tense, 2nd person singular or all persons plural\n#:>     sind sunt etes\n#:> FW-BEZ: foreign word: verb 'to be', present tense, 3rd person singular\n#:>     ist est\n#:> FW-CC: foreign word: conjunction, coordinating\n#:>     et ma mais und aber och nec y\n#:> FW-CD: foreign word: numeral, cardinal\n#:>     une cinq deux sieben unam zwei\n#:> FW-CS: foreign word: conjunction, subordinating\n#:>     bevor quam ma\n#:> FW-DT: foreign word: determiner/pronoun, singular\n#:>     hoc\n#:> FW-DT+BEZ: foreign word: determiner + verb 'to be', present tense, 3rd person singular\n#:>     c'est\n#:> FW-DTS: foreign word: determiner/pronoun, plural\n#:>     haec\n#:> FW-HV: foreign word: verb 'to have', present tense, not 3rd person singular\n#:>     habe\n#:> FW-IN: foreign word: preposition\n#:>     ad de en a par con dans ex von auf super post sine sur sub avec per\n#:>     inter sans pour pendant in di\n#:> FW-IN+AT: foreign word: preposition + article\n#:>     della des du aux zur d'un del dell'\n#:> FW-IN+NN: foreign word: preposition + noun, singular, common\n#:>     d'etat d'hotel d'argent d'identite d'art\n#:> FW-IN+NP: foreign word: preposition + noun, singular, proper\n#:>     d'Yquem d'Eiffel\n#:> FW-JJ: foreign word: adjective\n#:>     avant Espagnol sinfonica Siciliana Philharmonique grand publique haute\n#:>     noire bouffe Douce meme humaine bel serieuses royaux anticus presto\n#:>     Sovietskaya Bayerische comique schwarzen ...\n#:> FW-JJR: foreign word: adjective, comparative\n#:>     fortiori\n#:> FW-JJT: foreign word: adjective, superlative\n#:>     optimo\n#:> FW-NN: foreign word: noun, singular, common\n#:>     ballet esprit ersatz mano chatte goutte sang Fledermaus oud def kolkhoz\n#:>     roi troika canto boite blutwurst carne muzyka bonheur monde piece force\n#:>     ...\n#:> FW-NN$: foreign word: noun, singular, common, genitive\n#:>     corporis intellectus arte's dei aeternitatis senioritatis curiae\n#:>     patronne's chambre's\n#:> FW-NNS: foreign word: noun, plural, common\n#:>     al culpas vopos boites haflis kolkhozes augen tyrannis alpha-beta-\n#:>     gammas metis banditos rata phis negociants crus Einsatzkommandos\n#:>     kamikaze wohaws sabinas zorrillas palazzi engages coureurs corroborees\n#:>     yori Ubermenschen ...\n#:> FW-NP: foreign word: noun, singular, proper\n#:>     Karshilama Dieu Rundfunk Afrique Espanol Afrika Spagna Gott Carthago\n#:>     deus\n#:> FW-NPS: foreign word: noun, plural, proper\n#:>     Svenskarna Atlantes Dieux\n#:> FW-NR: foreign word: noun, singular, adverbial\n#:>     heute morgen aujourd'hui hoy\n#:> FW-OD: foreign word: numeral, ordinal\n#:>     18e 17e quintus\n#:> FW-PN: foreign word: pronoun, nominal\n#:>     hoc\n#:> FW-PP$: foreign word: determiner, possessive\n#:>     mea mon deras vos\n#:> FW-PPL: foreign word: pronoun, singular, reflexive\n#:>     se\n#:> FW-PPL+VBZ: foreign word: pronoun, singular, reflexive + verb, present tense, 3rd person singular\n#:>     s'excuse s'accuse\n#:> FW-PPO: pronoun, personal, accusative\n#:>     lui me moi mi\n#:> FW-PPO+IN: foreign word: pronoun, personal, accusative + preposition\n#:>     mecum tecum\n#:> FW-PPS: foreign word: pronoun, personal, nominative, 3rd person singular\n#:>     il\n#:> FW-PPSS: foreign word: pronoun, personal, nominative, not 3rd person singular\n#:>     ich vous sie je\n#:> FW-PPSS+HV: foreign word: pronoun, personal, nominative, not 3rd person singular + verb 'to have', present tense, not 3rd person singular\n#:>     j'ai\n#:> FW-QL: foreign word: qualifier\n#:>     minus\n#:> FW-RB: foreign word: adverb\n#:>     bas assai deja um wiederum cito velociter vielleicht simpliciter non zu\n#:>     domi nuper sic forsan olim oui semper tout despues hors\n#:> FW-RB+CC: foreign word: adverb + conjunction, coordinating\n#:>     forisque\n#:> FW-TO+VB: foreign word: infinitival to + verb, infinitive\n#:>     d'entretenir\n#:> FW-UH: foreign word: interjection\n#:>     sayonara bien adieu arigato bonjour adios bueno tchalo ciao o\n#:> FW-VB: foreign word: verb, present tense, not 3rd person singular, imperative or infinitive\n#:>     nolo contendere vive fermate faciunt esse vade noli tangere dites duces\n#:>     meminisse iuvabit gosaimasu voulez habla ksu'u'peli'afo lacheln miuchi\n#:>     say allons strafe portant\n#:> FW-VBD: foreign word: verb, past tense\n#:>     stabat peccavi audivi\n#:> FW-VBG: foreign word: verb, present participle or gerund\n#:>     nolens volens appellant seq. obliterans servanda dicendi delenda\n#:> FW-VBN: foreign word: verb, past participle\n#:>     vue verstrichen rasa verboten engages\n#:> FW-VBZ: foreign word: verb, present tense, 3rd person singular\n#:>     gouverne sinkt sigue diapiace\n#:> FW-WDT: foreign word: WH-determiner\n#:>     quo qua quod que quok\n#:> FW-WPO: foreign word: WH-pronoun, accusative\n#:>     quibusdam\n#:> FW-WPS: foreign word: WH-pronoun, nominative\n#:>     qui\n#:> HV: verb 'to have', uninflected present tense, infinitive or imperative\n#:>     have hast\n#:> HV*: verb 'to have', uninflected present tense or imperative, negated\n#:>     haven't ain't\n#:> HV+TO: verb 'to have', uninflected present tense + infinitival to\n#:>     hafta\n#:> HVD: verb 'to have', past tense\n#:>     had\n#:> HVD*: verb 'to have', past tense, negated\n#:>     hadn't\n#:> HVG: verb 'to have', present participle or gerund\n#:>     having\n#:> HVN: verb 'to have', past participle\n#:>     had\n#:> HVZ: verb 'to have', present tense, 3rd person singular\n#:>     has hath\n#:> HVZ*: verb 'to have', present tense, 3rd person singular, negated\n#:>     hasn't ain't\n#:> IN: preposition\n#:>     of in for by considering to on among at through with under into\n#:>     regarding than since despite according per before toward against as\n#:>     after during including between without except upon out over ...\n#:> IN+IN: preposition, hyphenated pair\n#:>     f'ovuh\n#:> IN+PPO: preposition + pronoun, personal, accusative\n#:>     t'hi-im\n#:> JJ: adjective\n#:>     ecent over-all possible hard-fought favorable hard meager fit such\n#:>     widespread outmoded inadequate ambiguous grand clerical effective\n#:>     orderly federal foster general proportionate ...\n#:> JJ$: adjective, genitive\n#:>     Great's\n#:> JJ+JJ: adjective, hyphenated pair\n#:>     big-large long-far\n#:> JJR: adjective, comparative\n#:>     greater older further earlier later freer franker wider better deeper\n#:>     firmer tougher faster higher bigger worse younger lighter nicer slower\n#:>     happier frothier Greater newer Elder ...\n#:> JJR+CS: adjective + conjunction, coordinating\n#:>     lighter'n\n#:> JJS: adjective, semantically superlative\n#:>     top chief principal northernmost master key head main tops utmost\n#:>     innermost foremost uppermost paramount topmost\n#:> JJT: adjective, superlative\n#:>     best largest coolest calmest latest greatest earliest simplest\n#:>     strongest newest fiercest unhappiest worst youngest worthiest fastest\n#:>     hottest fittest lowest finest smallest staunchest ...\n#:> MD: modal auxillary\n#:>     should may might will would must can could shall ought need wilt\n#:> MD*: modal auxillary, negated\n#:>     cannot couldn't wouldn't can't won't shouldn't shan't mustn't musn't\n#:> MD+HV: modal auxillary + verb 'to have', uninflected form\n#:>     shouldda musta coulda must've woulda could've\n#:> MD+PPSS: modal auxillary + pronoun, personal, nominative, not 3rd person singular\n#:>     willya\n#:> MD+TO: modal auxillary + infinitival to\n#:>     oughta\n#:> NN: noun, singular, common\n#:>     failure burden court fire appointment awarding compensation Mayor\n#:>     interim committee fact effect airport management surveillance jail\n#:>     doctor intern extern night weekend duty legislation Tax Office ...\n#:> NN$: noun, singular, common, genitive\n#:>     season's world's player's night's chapter's golf's football's\n#:>     baseball's club's U.'s coach's bride's bridegroom's board's county's\n#:>     firm's company's superintendent's mob's Navy's ...\n#:> NN+BEZ: noun, singular, common + verb 'to be', present tense, 3rd person singular\n#:>     water's camera's sky's kid's Pa's heat's throat's father's money's\n#:>     undersecretary's granite's level's wife's fat's Knife's fire's name's\n#:>     hell's leg's sun's roulette's cane's guy's kind's baseball's ...\n#:> NN+HVD: noun, singular, common + verb 'to have', past tense\n#:>     Pa'd\n#:> NN+HVZ: noun, singular, common + verb 'to have', present tense, 3rd person singular\n#:>     guy's Knife's boat's summer's rain's company's\n#:> NN+IN: noun, singular, common + preposition\n#:>     buncha\n#:> NN+MD: noun, singular, common + modal auxillary\n#:>     cowhand'd sun'll\n#:> NN+NN: noun, singular, common, hyphenated pair\n#:>     stomach-belly\n#:> NNS: noun, plural, common\n#:>     irregularities presentments thanks reports voters laws legislators\n#:>     years areas adjustments chambers $100 bonds courts sales details raises\n#:>     sessions members congressmen votes polls calls ...\n#:> NNS$: noun, plural, common, genitive\n#:>     taxpayers' children's members' States' women's cutters' motorists'\n#:>     steelmakers' hours' Nations' lawyers' prisoners' architects' tourists'\n#:>     Employers' secretaries' Rogues' ...\n#:> NNS+MD: noun, plural, common + modal auxillary\n#:>     duds'd oystchers'll\n#:> NP: noun, singular, proper\n#:>     Fulton Atlanta September-October Durwood Pye Ivan Allen Jr. Jan.\n#:>     Alpharetta Grady William B. Hartsfield Pearl Williams Aug. Berry J. M.\n#:>     Cheshire Griffin Opelika Ala. E. Pelham Snodgrass ...\n#:> NP$: noun, singular, proper, genitive\n#:>     Green's Landis' Smith's Carreon's Allison's Boston's Spahn's Willie's\n#:>     Mickey's Milwaukee's Mays' Howsam's Mantle's Shaw's Wagner's Rickey's\n#:>     Shea's Palmer's Arnold's Broglio's ...\n#:> NP+BEZ: noun, singular, proper + verb 'to be', present tense, 3rd person singular\n#:>     W.'s Ike's Mack's Jack's Kate's Katharine's Black's Arthur's Seaton's\n#:>     Buckhorn's Breed's Penny's Rob's Kitty's Blackwell's Myra's Wally's\n#:>     Lucille's Springfield's Arlene's\n#:> NP+HVZ: noun, singular, proper + verb 'to have', present tense, 3rd person singular\n#:>     Bill's Guardino's Celie's Skolman's Crosson's Tim's Wally's\n#:> NP+MD: noun, singular, proper + modal auxillary\n#:>     Gyp'll John'll\n#:> NPS: noun, plural, proper\n#:>     Chases Aderholds Chapelles Armisteads Lockies Carbones French Marskmen\n#:>     Toppers Franciscans Romans Cadillacs Masons Blacks Catholics British\n#:>     Dixiecrats Mississippians Congresses ...\n#:> NPS$: noun, plural, proper, genitive\n#:>     Republicans' Orioles' Birds' Yanks' Redbirds' Bucs' Yankees' Stevenses'\n#:>     Geraghtys' Burkes' Wackers' Achaeans' Dresbachs' Russians' Democrats'\n#:>     Gershwins' Adventists' Negroes' Catholics' ...\n#:> NR: noun, singular, adverbial\n#:>     Friday home Wednesday Tuesday Monday Sunday Thursday yesterday tomorrow\n#:>     tonight West East Saturday west left east downtown north northeast\n#:>     southeast northwest North South right ...\n#:> NR$: noun, singular, adverbial, genitive\n#:>     Saturday's Monday's yesterday's tonight's tomorrow's Sunday's\n#:>     Wednesday's Friday's today's Tuesday's West's Today's South's\n#:> NR+MD: noun, singular, adverbial + modal auxillary\n#:>     today'll\n#:> NRS: noun, plural, adverbial\n#:>     Sundays Mondays Saturdays Wednesdays Souths Fridays\n#:> OD: numeral, ordinal\n#:>     first 13th third nineteenth 2d 61st second sixth eighth ninth twenty-\n#:>     first eleventh 50th eighteenth- Thirty-ninth 72nd 1/20th twentieth\n#:>     mid-19th thousandth 350th sixteenth 701st ...\n#:> PN: pronoun, nominal\n#:>     none something everything one anyone nothing nobody everybody everyone\n#:>     anybody anything someone no-one nothin\n#:> PN$: pronoun, nominal, genitive\n#:>     one's someone's anybody's nobody's everybody's anyone's everyone's\n#:> PN+BEZ: pronoun, nominal + verb 'to be', present tense, 3rd person singular\n#:>     nothing's everything's somebody's nobody's someone's\n#:> PN+HVD: pronoun, nominal + verb 'to have', past tense\n#:>     nobody'd\n#:> PN+HVZ: pronoun, nominal + verb 'to have', present tense, 3rd person singular\n#:>     nobody's somebody's one's\n#:> PN+MD: pronoun, nominal + modal auxillary\n#:>     someone'll somebody'll anybody'd\n#:> PP$: determiner, possessive\n#:>     our its his their my your her out thy mine thine\n#:> PP$$: pronoun, possessive\n#:>     ours mine his hers theirs yours\n#:> PPL: pronoun, singular, reflexive\n#:>     itself himself myself yourself herself oneself ownself\n#:> PPLS: pronoun, plural, reflexive\n#:>     themselves ourselves yourselves\n#:> PPO: pronoun, personal, accusative\n#:>     them it him me us you 'em her thee we'uns\n#:> PPS: pronoun, personal, nominative, 3rd person singular\n#:>     it he she thee\n#:> PPS+BEZ: pronoun, personal, nominative, 3rd person singular + verb 'to be', present tense, 3rd person singular\n#:>     it's he's she's\n#:> PPS+HVD: pronoun, personal, nominative, 3rd person singular + verb 'to have', past tense\n#:>     she'd he'd it'd\n#:> PPS+HVZ: pronoun, personal, nominative, 3rd person singular + verb 'to have', present tense, 3rd person singular\n#:>     it's he's she's\n#:> PPS+MD: pronoun, personal, nominative, 3rd person singular + modal auxillary\n#:>     he'll she'll it'll he'd it'd she'd\n#:> PPSS: pronoun, personal, nominative, not 3rd person singular\n#:>     they we I you ye thou you'uns\n#:> PPSS+BEM: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 1st person singular\n#:>     I'm Ahm\n#:> PPSS+BER: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 2nd person singular or all persons plural\n#:>     we're you're they're\n#:> PPSS+BEZ: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular\n#:>     you's\n#:> PPSS+BEZ*: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular, negated\n#:>     'tain't\n#:> PPSS+HV: pronoun, personal, nominative, not 3rd person singular + verb 'to have', uninflected present tense\n#:>     I've we've they've you've\n#:> PPSS+HVD: pronoun, personal, nominative, not 3rd person singular + verb 'to have', past tense\n#:>     I'd you'd we'd they'd\n#:> PPSS+MD: pronoun, personal, nominative, not 3rd person singular + modal auxillary\n#:>     you'll we'll I'll we'd I'd they'll they'd you'd\n#:> PPSS+VB: pronoun, personal, nominative, not 3rd person singular + verb 'to verb', uninflected present tense\n#:>     y'know\n#:> QL: qualifier, pre\n#:>     well less very most so real as highly fundamentally even how much\n#:>     remarkably somewhat more completely too thus ill deeply little overly\n#:>     halfway almost impossibly far severly such ...\n#:> QLP: qualifier, post\n#:>     indeed enough still 'nuff\n#:> RB: adverb\n#:>     only often generally also nevertheless upon together back newly no\n#:>     likely meanwhile near then heavily there apparently yet outright fully\n#:>     aside consistently specifically formally ever just ...\n#:> RB$: adverb, genitive\n#:>     else's\n#:> RB+BEZ: adverb + verb 'to be', present tense, 3rd person singular\n#:>     here's there's\n#:> RB+CS: adverb + conjunction, coordinating\n#:>     well's soon's\n#:> RBR: adverb, comparative\n#:>     further earlier better later higher tougher more harder longer sooner\n#:>     less faster easier louder farther oftener nearer cheaper slower tighter\n#:>     lower worse heavier quicker ...\n#:> RBR+CS: adverb, comparative + conjunction, coordinating\n#:>     more'n\n#:> RBT: adverb, superlative\n#:>     most best highest uppermost nearest brightest hardest fastest deepest\n#:>     farthest loudest ...\n#:> RN: adverb, nominal\n#:>     here afar then\n#:> RP: adverb, particle\n#:>     up out off down over on in about through across after\n#:> RP+IN: adverb, particle + preposition\n#:>     out'n outta\n#:> TO: infinitival to\n#:>     to t'\n#:> TO+VB: infinitival to + verb, infinitive\n#:>     t'jawn t'lah\n#:> UH: interjection\n#:>     Hurrah bang whee hmpf ah goodbye oops oh-the-pain-of-it ha crunch say\n#:>     oh why see well hello lo alas tarantara rum-tum-tum gosh hell keerist\n#:>     Jesus Keeeerist boy c'mon 'mon goddamn bah hoo-pig damn ...\n#:> VB: verb, base: uninflected present, imperative or infinitive\n#:>     investigate find act follow inure achieve reduce take remedy re-set\n#:>     distribute realize disable feel receive continue place protect\n#:>     eliminate elaborate work permit run enter force ...\n#:> VB+AT: verb, base: uninflected present or infinitive + article\n#:>     wanna\n#:> VB+IN: verb, base: uninflected present, imperative or infinitive + preposition\n#:>     lookit\n#:> VB+JJ: verb, base: uninflected present, imperative or infinitive + adjective\n#:>     die-dead\n#:> VB+PPO: verb, uninflected present tense + pronoun, personal, accusative\n#:>     let's lemme gimme\n#:> VB+RP: verb, imperative + adverbial particle\n#:>     g'ahn c'mon\n#:> VB+TO: verb, base: uninflected present, imperative or infinitive + infinitival to\n#:>     wanta wanna\n#:> VB+VB: verb, base: uninflected present, imperative or infinitive; hypenated pair\n#:>     say-speak\n#:> VBD: verb, past tense\n#:>     said produced took recommended commented urged found added praised\n#:>     charged listed became announced brought attended wanted voted defeated\n#:>     received got stood shot scheduled feared promised made ...\n#:> VBG: verb, present participle or gerund\n#:>     modernizing improving purchasing Purchasing lacking enabling pricing\n#:>     keeping getting picking entering voting warning making strengthening\n#:>     setting neighboring attending participating moving ...\n#:> VBG+TO: verb, present participle + infinitival to\n#:>     gonna\n#:> VBN: verb, past participle\n#:>     conducted charged won received studied revised operated accepted\n#:>     combined experienced recommended effected granted seen protected\n#:>     adopted retarded notarized selected composed gotten printed ...\n#:> VBN+TO: verb, past participle + infinitival to\n#:>     gotta\n#:> VBZ: verb, present tense, 3rd person singular\n#:>     deserves believes receives takes goes expires says opposes starts\n#:>     permits expects thinks faces votes teaches holds calls fears spends\n#:>     collects backs eliminates sets flies gives seeks reads ...\n#:> WDT: WH-determiner\n#:>     which what whatever whichever whichever-the-hell\n#:> WDT+BER: WH-determiner + verb 'to be', present tense, 2nd person singular or all persons plural\n#:>     what're\n#:> WDT+BER+PP: WH-determiner + verb 'to be', present, 2nd person singular or all persons plural + pronoun, personal, nominative, not 3rd person singular\n#:>     whaddya\n#:> WDT+BEZ: WH-determiner + verb 'to be', present tense, 3rd person singular\n#:>     what's\n#:> WDT+DO+PPS: WH-determiner + verb 'to do', uninflected present tense + pronoun, personal, nominative, not 3rd person singular\n#:>     whaddya\n#:> WDT+DOD: WH-determiner + verb 'to do', past tense\n#:>     what'd\n#:> WDT+HVZ: WH-determiner + verb 'to have', present tense, 3rd person singular\n#:>     what's\n#:> WP$: WH-pronoun, genitive\n#:>     whose whosever\n#:> WPO: WH-pronoun, accusative\n#:>     whom that who\n#:> WPS: WH-pronoun, nominative\n#:>     that who whoever whosoever what whatsoever\n#:> WPS+BEZ: WH-pronoun, nominative + verb 'to be', present, 3rd person singular\n#:>     that's who's\n#:> WPS+HVD: WH-pronoun, nominative + verb 'to have', past tense\n#:>     who'd\n#:> WPS+HVZ: WH-pronoun, nominative + verb 'to have', present tense, 3rd person singular\n#:>     who's that's\n#:> WPS+MD: WH-pronoun, nominative + modal auxillary\n#:>     who'll that'd who'd that'll\n#:> WQL: WH-qualifier\n#:>     however how\n#:> WRB: WH-adverb\n#:>     however when where why whereby wherever how whenever whereon wherein\n#:>     wherewith wheare wherefore whereof howsabout\n#:> WRB+BER: WH-adverb + verb 'to be', present, 2nd person singular or all persons plural\n#:>     where're\n#:> WRB+BEZ: WH-adverb + verb 'to be', present, 3rd person singular\n#:>     how's where's\n#:> WRB+DO: WH-adverb + verb 'to do', present, not 3rd person singular\n#:>     howda\n#:> WRB+DOD: WH-adverb + verb 'to do', past tense\n#:>     where'd how'd\n#:> WRB+DOD*: WH-adverb + verb 'to do', past tense, negated\n#:>     whyn't\n#:> WRB+DOZ: WH-adverb + verb 'to do', present tense, 3rd person singular\n#:>     how's\n#:> WRB+IN: WH-adverb + preposition\n#:>     why'n\n#:> WRB+MD: WH-adverb + modal auxillary\n#:>     where'd"},{"path":"nlp.html","id":"tagging-techniques","chapter":"17 NLP","heading":"17.8.2 Tagging Techniques","text":"types tagging techniques:Lexical-basedRule-based (Brill)Probalistic/Stochastic-based (Conditional Random Fields-CRFs, Hidden Markov Models-HMM)Neural network-basedNLTK supports taggers:","code":"from nltk.tag.brill      import BrillTagger\nfrom nltk.tag.hunpos     import HunposTagger\nfrom nltk.tag.stanford   import StanfordTagger, StanfordPOSTagger, StanfordNERTagger\nfrom nltk.tag.hmm        import HiddenMarkovModelTagger, HiddenMarkovModelTrainer\nfrom nltk.tag.senna      import SennaTagger, SennaChunkTagger, SennaNERTagger\nfrom nltk.tag.crf        import CRFTagger\nfrom nltk.tag.perceptron import PerceptronTagger"},{"path":"nlp.html","id":"nltk-perceptrontagger","chapter":"17 NLP","heading":"17.8.2.1 nltk PerceptronTagger","text":"PerceptronTagger produce tags Penn Treebank tagset","code":"from nltk.tag import PerceptronTagger\n\nnltk.download('averaged_perceptron_tagger')#:> True\n#:> \n#:> [nltk_data] Downloading package averaged_perceptron_tagger to\n#:> [nltk_data]     /home/msfz751/nltk_data...\n#:> [nltk_data]   Package averaged_perceptron_tagger is already up-to-\n#:> [nltk_data]       date!tagger = PerceptronTagger()\nprint('Tagger Classes:', tagger.classes, \n      '\\n\\n# Classes:', len(tagger.classes))#:> Tagger Classes: {'PRP', '(', 'PRP$', 'JJR', 'JJ', 'FW', ':', 'RBS', 'VB', 'RBR', '#', 'CD', ',', 'RB', '``', 'NNPS', ')', 'NN', 'WP', '.', 'TO', 'NNP', 'CC', 'PDT', \"''\", 'WP$', 'SYM', 'WDT', 'LS', 'IN', 'VBD', 'POS', 'JJS', 'VBP', 'UH', '$', 'DT', 'MD', 'WRB', 'VBG', 'RP', 'VBZ', 'NNS', 'VBN', 'EX'} \n#:> \n#:> # Classes: 45"},{"path":"nlp.html","id":"performing-tagging-nltk.pos_tag","chapter":"17 NLP","heading":"17.8.3 Performing Tagging nltk.pos_tag()","text":"Tagging works sentence sentence:Document fist must splitted sentencesEach sentence need tokenized wordsDefault NTLK uses PerceptronTagger","code":"#nltk.download('averaged_perceptron_tagger')\n#import nltk\n#from nltk.tokenize import word_tokenize, sent_tokenize \ndoc = '''Sukanya, Rajib and Naba are my good friends. Sukanya is getting married next year. Marriage is a big step in one's life. It is both exciting and frightening. But friendship is a sacred bond between people. It is a special kind of love between us. Many of you must have tried searching for a friend but never found the right one.'''\n\nsentences = nltk.sent_tokenize(doc)\nfor sentence in sentences:\n  tokens = nltk.word_tokenize(sentence)\n  tagged = nltk.pos_tag(tokens)\n  print(tagged)#:> [('Sukanya', 'NNP'), (',', ','), ('Rajib', 'NNP'), ('and', 'CC'), ('Naba', 'NNP'), ('are', 'VBP'), ('my', 'PRP$'), ('good', 'JJ'), ('friends', 'NNS'), ('.', '.')]\n#:> [('Sukanya', 'NNP'), ('is', 'VBZ'), ('getting', 'VBG'), ('married', 'VBN'), ('next', 'JJ'), ('year', 'NN'), ('.', '.')]\n#:> [('Marriage', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('big', 'JJ'), ('step', 'NN'), ('in', 'IN'), ('one', 'CD'), (\"'s\", 'POS'), ('life', 'NN'), ('.', '.')]\n#:> [('It', 'PRP'), ('is', 'VBZ'), ('both', 'DT'), ('exciting', 'VBG'), ('and', 'CC'), ('frightening', 'NN'), ('.', '.')]\n#:> [('But', 'CC'), ('friendship', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('sacred', 'JJ'), ('bond', 'NN'), ('between', 'IN'), ('people', 'NNS'), ('.', '.')]\n#:> [('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('special', 'JJ'), ('kind', 'NN'), ('of', 'IN'), ('love', 'NN'), ('between', 'IN'), ('us', 'PRP'), ('.', '.')]\n#:> [('Many', 'JJ'), ('of', 'IN'), ('you', 'PRP'), ('must', 'MD'), ('have', 'VB'), ('tried', 'VBN'), ('searching', 'VBG'), ('for', 'IN'), ('a', 'DT'), ('friend', 'NN'), ('but', 'CC'), ('never', 'RB'), ('found', 'VBD'), ('the', 'DT'), ('right', 'JJ'), ('one', 'NN'), ('.', '.')]"},{"path":"nlp.html","id":"sentiment","chapter":"17 NLP","heading":"17.9 Sentiment","text":"","code":""},{"path":"nlp.html","id":"nltk-and-senti-wordnet","chapter":"17 NLP","heading":"17.9.1 NLTK and Senti-Wordnet","text":"SentiWordNet extends Wordnet Synsets positive negative sentiment scoresThe extension achieved via complex mix propagation methods classifiers. thus gold standard resource like WordNet (compiled humans), proven useful wide range tasksIt contains similar number synsets wordnet","code":"from nltk.corpus import sentiwordnet as swn\nnltk.download('sentiwordnet')#:> True\n#:> \n#:> [nltk_data] Downloading package sentiwordnet to\n#:> [nltk_data]     /home/msfz751/nltk_data...\n#:> [nltk_data]   Package sentiwordnet is already up-to-date!s = set( swn.all_senti_synsets() )\nprint('Total synsets in senti-wordnet  : ' ,   len(s))#:> Total synsets in senti-wordnet  :  117659"},{"path":"nlp.html","id":"senti-synset","chapter":"17 NLP","heading":"17.9.1.1 Senti-Synset","text":"Senti-Wordnet extends wordnet three(3) sentiment scores: positive, negative, objectiveAll three scores added value 1.0","code":"breakdown = swn.senti_synset('breakdown.n.03')\nprint(\n  breakdown, '\\n'\n  'Positive:', breakdown.pos_score(), '\\n',\n  'Negative:', breakdown.neg_score(), '\\n',\n  'Objective:',breakdown.obj_score()\n)#:> <breakdown.n.03: PosScore=0.0 NegScore=0.25> \n#:> Positive: 0.0 \n#:>  Negative: 0.25 \n#:>  Objective: 0.75"},{"path":"nlp.html","id":"senti-synsets","chapter":"17 NLP","heading":"17.9.1.2 Senti-Synsets","text":"Get synonmys, without POS informationGet score first synset","code":"print( list(swn.senti_synsets('slow')), '\\n\\n',  ## without POS tag\n       list(swn.senti_synsets('slow', 'a')) )   ## with POS tag#:> [SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')] \n#:> \n#:>  [SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08')]first_synset = list(swn.senti_synsets('slow','a'))[0]\n\nprint(\n  first_synset, '\\n',\n  'Positive:',  first_synset.pos_score(), '\\n',\n  'Negative:',  first_synset.neg_score(), '\\n',\n  'Objective:', first_synset.obj_score()\n)#:> <slow.a.01: PosScore=0.0 NegScore=0.0> \n#:>  Positive: 0.0 \n#:>  Negative: 0.0 \n#:>  Objective: 1.0"},{"path":"nlp.html","id":"converting-pos-tag-into-wordnet-pos-tag","chapter":"17 NLP","heading":"17.9.1.3 Converting POS-tag into Wordnet POS-tag","text":"Using FunctionUsing defaultdict","code":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import wordnet as wn\n\ndef penn_to_wn(tag):\n    \"\"\"\n    Convert between the PennTreebank tags to simple Wordnet tags\n    \"\"\"\n    if tag.startswith('J'):\n        return wn.ADJ\n    elif tag.startswith('N'):\n        return wn.NOUN\n    elif tag.startswith('R'):\n        return wn.ADV\n    elif tag.startswith('V'):\n        return wn.VERB\n    return None\n\nwt = word_tokenize(\"Star Wars is a wonderful movie\")\npenn_tags = nltk.pos_tag(wt)\nwordnet_tags = [ (x, penn_to_wn(y)) for (x,y) in penn_tags ]\n\nprint(\n'Penn Tags    :', penn_tags, \n'\\nWordnet Tags :', wordnet_tags)#:> Penn Tags    : [('Star', 'NNP'), ('Wars', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('wonderful', 'JJ'), ('movie', 'NN')] \n#:> Wordnet Tags : [('Star', 'n'), ('Wars', 'n'), ('is', 'v'), ('a', None), ('wonderful', 'a'), ('movie', 'n')]import nltk\nfrom nltk.corpus import wordnet as wn\nfrom nltk import word_tokenize, pos_tag\nfrom collections import defaultdict\n\ntag_map = defaultdict(lambda : None)\ntag_map['J'] = wn.ADJ\ntag_map['R'] = wn.ADV\ntag_map['V'] = wn.VERB\ntag_map['N'] = wn.NOUN\n\nwt = word_tokenize(\"Star Wars is a wonderful movie\")\npenn_tags = nltk.pos_tag(wt)\nwordnet_tags = [ (x, tag_map[y[0]]) for (x,y) in penn_tags ]\n\nprint(\n'Penn Tags    :', penn_tags, \n'\\nWordnet Tags :', wordnet_tags)#:> Penn Tags    : [('Star', 'NNP'), ('Wars', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('wonderful', 'JJ'), ('movie', 'NN')] \n#:> Wordnet Tags : [('Star', 'n'), ('Wars', 'n'), ('is', 'v'), ('a', None), ('wonderful', 'a'), ('movie', 'n')]"},{"path":"nlp.html","id":"vader","chapter":"17 NLP","heading":"17.9.2 Vader","text":"rule based sentiment analyzer, contain 7503 lexiconsIt good social media lexicon contain emoji short form textContain 3 n-gramSupported NTLK install vader seperately (pip install vaderSentiment)","code":""},{"path":"nlp.html","id":"vader-lexicon","chapter":"17 NLP","heading":"17.9.2.1 Vader Lexicon","text":"lexicon dictionary. make iterable, need convert list:\n- Step 1: Convert dict dict_items, list containing items, item one dict\n- Step 2: Unpack dict_items listThere four N-Gram lexiconIf stemming lemmatization used, stem/lemmatize vader lexicon ","code":"#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer   ## seperate pip installed library\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nnltk.download('vader_lexicon')#:> True\n#:> \n#:> [nltk_data] Downloading package vader_lexicon to\n#:> [nltk_data]     /home/msfz751/nltk_data...\n#:> [nltk_data]   Package vader_lexicon is already up-to-date!vader_lex  = SentimentIntensityAnalyzer().lexicon  # get the lexicon dictionary\nvader_list = list(vader_lex.items())               # convert to items then list\nprint( 'Total Vader Lexicon:', len(vader_lex),'\\n',\n        vader_list[1:10], vader_list[220:240] )#:> Total Vader Lexicon: 7502 \n#:>  [('%)', -0.4), ('%-)', -1.5), ('&-:', -0.4), ('&:', -0.7), (\"( '}{' )\", 1.6), ('(%', -0.9), (\"('-:\", 2.2), (\"(':\", 2.3), ('((-:', 2.1)] [('b^d', 2.6), ('cwot', -2.3), (\"d-':\", -2.5), ('d8', -3.2), ('d:', 1.2), ('d:<', -3.2), ('d;', -2.9), ('d=', 1.5), ('doa', -2.3), ('dx', -3.0), ('ez', 1.5), ('fav', 2.0), ('fcol', -1.8), ('ff', 1.8), ('ffs', -2.8), ('fkm', -2.4), ('foaf', 1.8), ('ftw', 2.0), ('fu', -3.7), ('fubar', -3.0)]print('List of N-grams: ')#:> List of N-grams:[ (tok,score) for tok, score in vader_list if \" \" in tok]#:> [(\"( '}{' )\", 1.6), (\"can't stand\", -2.0), ('fed up', -1.8), ('screwed up', -1.5)][ (tok,score) for tok, score in vader_list if \"lov\" in tok]#:> [('beloved', 2.3), ('lovable', 3.0), ('love', 3.2), ('loved', 2.9), ('lovelies', 2.2), ('lovely', 2.8), ('lover', 2.8), ('loverly', 2.8), ('lovers', 2.4), ('loves', 2.7), ('loving', 2.9), ('lovingly', 3.2), ('lovingness', 2.7), ('unlovable', -2.7), ('unloved', -1.9), ('unlovelier', -1.9), ('unloveliest', -1.9), ('unloveliness', -2.0), ('unlovely', -2.1), ('unloving', -2.3)]"},{"path":"nlp.html","id":"polarity-scoring","chapter":"17 NLP","heading":"17.9.2.2 Polarity Scoring","text":"Scoring result dictionary :negneuposcompound\nneg, neu, pos adds 1.0Example shows polarity two sentences:","code":"corpus = [\"Python is a very useful but hell difficult to learn\",\n        \":) :) :(\"]\nfor doc in corpus:\n  print(doc, '-->', \"\\n:\", SentimentIntensityAnalyzer().polarity_scores(doc) )#:> Python is a very useful but hell difficult to learn --> \n#:> : {'neg': 0.554, 'neu': 0.331, 'pos': 0.116, 'compound': -0.8735}\n#:> :) :) :( --> \n#:> : {'neg': 0.326, 'neu': 0.0, 'pos': 0.674, 'compound': 0.4767}"},{"path":"nlp.html","id":"feature-representation","chapter":"17 NLP","heading":"17.10 Feature Representation","text":"","code":""},{"path":"nlp.html","id":"the-data-3","chapter":"17 NLP","heading":"17.10.1 The Data","text":"corpus collection multiple documents. example, document represented sentence.","code":"corpus = [\n   'This is the first document, :)',\n   'This document is the second document.',\n   'And this is a third one',\n   'Is this the first document?',\n]"},{"path":"nlp.html","id":"frequency-count-1","chapter":"17 NLP","heading":"17.10.2 Frequency Count","text":"Using purely frequency count feature obviously bias long document (contain lot words, hence words within document high frequency).","code":""},{"path":"nlp.html","id":"tokenizer","chapter":"17 NLP","heading":"17.10.2.1 + Tokenizer","text":"Default Tokenizer\ndefault, vectorizer apply tokenizer select minimum 2-chars alphanumeric words. train vectorizer using fit_transform().Custom Tokenizer\ncan use custom tokenizer, function return list words. Example uses nltk RegexpTokenizer function, retains one alphanumeric characters.1 2-Word-Gram Tokenizer\nUse ngram_range() specify range grams needed.Apply Trained Vectorizer\nvectorizer trained, can apply new corpus. Tokens vectorizer vocubulary ignored.","code":"from sklearn.feature_extraction.text import CountVectorizer\nvec = CountVectorizer()          # initialize the vectorizer\nX   = vec.fit_transform(corpus)  # FIT the vectorizer, return fitted data\nprint(pd.DataFrame(X.toarray(), columns=vec.get_feature_names()),'\\n\\n',\n      'Vocabulary: ', vec.vocabulary_)#:>    and  document  first  is  one  second  the  third  this\n#:> 0    0         1      1   1    0       0    1      0     1\n#:> 1    0         2      0   1    0       1    1      0     1\n#:> 2    1         0      0   1    1       0    0      1     1\n#:> 3    0         1      1   1    0       0    1      0     1 \n#:> \n#:>  Vocabulary:  {'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}my_tokenizer = RegexpTokenizer(r'[a-zA-Z0-9\\']+')  ## Custom Tokenizer\nvec2 = CountVectorizer(tokenizer=my_tokenizer.tokenize) ## custom tokenizer's function\nX2   = vec2.fit_transform(corpus)  # FIT the vectorizer, return fitted data\nprint(pd.DataFrame(X2.toarray(), columns=vec2.get_feature_names()),'\\n\\n',\n      'Vocabulary: ', vec.vocabulary_)#:>    a  and  document  first  is  one  second  the  third  this\n#:> 0  0    0         1      1   1    0       0    1      0     1\n#:> 1  0    0         2      0   1    0       1    1      0     1\n#:> 2  1    1         0      0   1    1       0    0      1     1\n#:> 3  0    0         1      1   1    0       0    1      0     1 \n#:> \n#:>  Vocabulary:  {'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}vec3 = CountVectorizer(ngram_range=(1,2))          # initialize the vectorizer\nX3   = vec3.fit_transform(corpus)     # FIT the vectorizer, return fitted data\nprint(pd.DataFrame(X3.toarray(), columns=vec3.get_feature_names()),'\\n\\n',\n      'Vocabulary: ', vec.vocabulary_)#:>    and  and this  document  document is  first  ...  third one  this  this document  \\\n#:> 0    0         0         1            0      1  ...          0     1              0   \n#:> 1    0         0         2            1      0  ...          0     1              1   \n#:> 2    1         1         0            0      0  ...          1     1              0   \n#:> 3    0         0         1            0      1  ...          0     1              0   \n#:> \n#:>    this is  this the  \n#:> 0        1         0  \n#:> 1        0         0  \n#:> 2        1         0  \n#:> 3        0         1  \n#:> \n#:> [4 rows x 22 columns] \n#:> \n#:>  Vocabulary:  {'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}new_corpus = [\"My Name is Charlie Angel\", \"I love to watch Star Wars\"]\nXX = vec.transform(new_corpus)\npd.DataFrame(XX.toarray(), columns=vec.get_feature_names())#:>    and  document  first  is  one  second  the  third  this\n#:> 0    0         0      0   1    0       0    0      0     0\n#:> 1    0         0      0   0    0       0    0      0     0"},{"path":"nlp.html","id":"stop-words","chapter":"17 NLP","heading":"17.10.2.2 + Stop Words","text":"Vectorizer can optionally use stop words list. Use stop_words=english apply filtering using sklearn built-stop word. can replace english word list object.","code":"vec4 = CountVectorizer(stop_words='english') ## sklearn stopwords list\nX4 = vec4.fit_transform(corpus)\npd.DataFrame(X4.toarray(), columns=vec4.get_feature_names())#:>    document  second\n#:> 0         1       0\n#:> 1         2       1\n#:> 2         0       0\n#:> 3         1       0"},{"path":"nlp.html","id":"tfidf","chapter":"17 NLP","heading":"17.10.3 TFIDF","text":"","code":""},{"path":"nlp.html","id":"equation","chapter":"17 NLP","heading":"17.10.3.1 Equation","text":"\\[tf(t,d) = \\text{occurances term t document t} \\\\\nn     = \\text{number documents} \\\\\ndf(t) = \\text{number documents containing term t} \\\\\nidf(t)  = log \\frac{n}{df(t))} + 1 \\\\\nidf(t)  = log \\frac{1+n}{1+df(t))} + 1 \\text{.... smoothing, prevent zero division} \\\\\ntfidf(t) = tf(t) * idf(t,d)    \\text{.... raw, normalization tf(t)} \\\\\ntfidf(t) = \\frac{tf(t,d)}{||V||_2} * idf(t)    \\text{.... tf normalized euclidean norm}\\]","code":""},{"path":"nlp.html","id":"tfidftransformer","chapter":"17 NLP","heading":"17.10.3.2 TfidfTransformer","text":"generate TFIDF vectors, first run CountVectorizer get frequency vector matrix. take output transformer.","code":"from sklearn.feature_extraction.text import TfidfTransformer\n\ncorpus = [\n    \"apple apple apple apple apple banana\",\n    \"apple apple\",\n    \"apple apple apple banana\",\n    \"durian durian durian\"]\n    \ncount_vec = CountVectorizer()\nX = count_vec.fit_transform(corpus)\n\ntransformer1 = TfidfTransformer(smooth_idf=False,norm=None)\ntransformer2 = TfidfTransformer(smooth_idf=False,norm='l2')\ntransformer3 = TfidfTransformer(smooth_idf=True,norm='l2')\n\ntfidf1 = transformer1.fit_transform(X)\ntfidf2 = transformer2.fit_transform(X)\ntfidf3 = transformer3.fit_transform(X)\n\nprint(\n  'Frequency Count: \\n', pd.DataFrame(X.toarray(), columns=count_vec.get_feature_names()),\n  '\\n\\nVocabulary: ', count_vec.vocabulary_,\n  '\\n\\nTFIDF Without Norm:\\n',tfidf1.toarray(), \n  '\\n\\nTFIDF with L2 Norm:\\n',tfidf2.toarray(),  \n  '\\n\\nTFIDF with L2 Norm (smooth):\\n',tfidf3.toarray())#:> Frequency Count: \n#:>     apple  banana  durian\n#:> 0      5       1       0\n#:> 1      2       0       0\n#:> 2      3       1       0\n#:> 3      0       0       3 \n#:> \n#:> Vocabulary:  {'apple': 0, 'banana': 1, 'durian': 2} \n#:> \n#:> TFIDF Without Norm:\n#:>  [[6.43841036 1.69314718 0.        ]\n#:>  [2.57536414 0.         0.        ]\n#:>  [3.86304622 1.69314718 0.        ]\n#:>  [0.         0.         7.15888308]] \n#:> \n#:> TFIDF with L2 Norm:\n#:>  [[0.96711783 0.25432874 0.        ]\n#:>  [1.         0.         0.        ]\n#:>  [0.91589033 0.40142857 0.        ]\n#:>  [0.         0.         1.        ]] \n#:> \n#:> TFIDF with L2 Norm (smooth):\n#:>  [[0.97081492 0.23982991 0.        ]\n#:>  [1.         0.         0.        ]\n#:>  [0.92468843 0.38072472 0.        ]\n#:>  [0.         0.         1.        ]]"},{"path":"nlp.html","id":"tfidfvectorizer","chapter":"17 NLP","heading":"17.10.3.3 TfidfVectorizer","text":"vectorizer gives end end processing corpus TFIDF vector matrix, including tokenization, stopwords.","code":"from sklearn.feature_extraction.text import TfidfVectorizer\nmy_tokenizer = RegexpTokenizer(r'[a-zA-Z0-9\\']+')  ## Custom Tokenizer\n\nvec1 = TfidfVectorizer(tokenizer=my_tokenizer.tokenize,  stop_words='english') #default smooth_idf=True, norm='l2'\nvec2 = TfidfVectorizer(tokenizer=my_tokenizer.tokenize, stop_words='english',smooth_idf=False)\nvec3 = TfidfVectorizer(tokenizer=my_tokenizer.tokenize, stop_words='english', norm=None)\n\nX1   = vec1.fit_transform(corpus)  # FIT the vectorizer, return fitted data\nX2   = vec2.fit_transform(corpus)  # FIT the vectorizer, return fitted data\nX3   = vec3.fit_transform(corpus)  # FIT the vectorizer, return fitted data\n\nprint(\n  'TFIDF Features (Default with Smooth and L2 Norm):\\n',\n  pd.DataFrame(X1.toarray().round(3), columns=vec1.get_feature_names()),\n  '\\n\\nTFIDF Features (without Smoothing):\\n',\n  pd.DataFrame(X2.toarray().round(3), columns=vec2.get_feature_names()),\n  '\\n\\nTFIDF Features (without L2 Norm):\\n',\n  pd.DataFrame(X3.toarray().round(3), columns=vec3.get_feature_names())\n  )#:> TFIDF Features (Default with Smooth and L2 Norm):\n#:>     apple  banana  durian\n#:> 0  0.971   0.240     0.0\n#:> 1  1.000   0.000     0.0\n#:> 2  0.925   0.381     0.0\n#:> 3  0.000   0.000     1.0 \n#:> \n#:> TFIDF Features (without Smoothing):\n#:>     apple  banana  durian\n#:> 0  0.967   0.254     0.0\n#:> 1  1.000   0.000     0.0\n#:> 2  0.916   0.401     0.0\n#:> 3  0.000   0.000     1.0 \n#:> \n#:> TFIDF Features (without L2 Norm):\n#:>     apple  banana  durian\n#:> 0  6.116   1.511   0.000\n#:> 1  2.446   0.000   0.000\n#:> 2  3.669   1.511   0.000\n#:> 3  0.000   0.000   5.749"},{"path":"nlp.html","id":"appliction","chapter":"17 NLP","heading":"17.11 Appliction","text":"","code":""},{"path":"nlp.html","id":"document-similarity","chapter":"17 NLP","heading":"17.11.1 Document Similarity","text":"Document1 Document 2 mutiplicate Document0, therefore consine similarity .","code":"documents = (\n    \"apple apple banana\",\n    \"apple apple banana apple apple banana\",\n    \"apple apple banana apple apple banana apple apple banana\")\n    \nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vec = TfidfVectorizer()\ntfidf_matrix = tfidf_vec.fit_transform(documents)\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nprint('Cosine Similarity betwen doc0 and doc1:\\n',cosine_similarity(tfidf_matrix[0], tfidf_matrix[1]))#:> Cosine Similarity betwen doc0 and doc1:\n#:>  [[1.]]print('Cosine Similarity betwen doc1 and doc2:\\n',cosine_similarity(tfidf_matrix[1], tfidf_matrix[2]))#:> Cosine Similarity betwen doc1 and doc2:\n#:>  [[1.]]print('Cosine Similarity betwen doc1 and doc2:\\n',cosine_similarity(tfidf_matrix[0], tfidf_matrix[2]))#:> Cosine Similarity betwen doc1 and doc2:\n#:>  [[1.]]"},{"path":"nlp.html","id":"naive-bayes","chapter":"17 NLP","heading":"17.12 Naive Bayes","text":"","code":""},{"path":"nlp.html","id":"libraries","chapter":"17 NLP","heading":"17.12.1 Libraries","text":"","code":"from nlpia.data.loaders import get_data\nfrom nltk.tokenize.casual     import casual_tokenize\nfrom collections import Counter"},{"path":"nlp.html","id":"the-data-4","chapter":"17 NLP","heading":"17.12.2 The Data","text":"","code":"movies = get_data('hutto_movies')   # download data\nprint(movies.head(), '\\n\\n',\n      movies.describe())#:>     sentiment                                               text\n#:> id                                                              \n#:> 1    2.266667  The Rock is destined to be the 21st Century's ...\n#:> 2    3.533333  The gorgeously elaborate continuation of ''The...\n#:> 3   -0.600000                     Effective but too tepid biopic\n#:> 4    1.466667  If you sometimes like to go to the movies to h...\n#:> 5    1.733333  Emerges as something rare, an issue movie that... \n#:> \n#:>            sentiment\n#:> count  10605.000000\n#:> mean       0.004831\n#:> std        1.922050\n#:> min       -3.875000\n#:> 25%       -1.769231\n#:> 50%       -0.080000\n#:> 75%        1.833333\n#:> max        3.941176"},{"path":"nlp.html","id":"bag-of-words","chapter":"17 NLP","heading":"17.12.3 Bag of Words","text":"Tokenize record, remove single character token, convert list counters (words-frequency pair).item list counter, represent word frequency within recordConvert NaN 0 features integer","code":"bag_of_words = []\nfor text in movies.text:\n    tokens = casual_tokenize(text, reduce_len=True, strip_handles=True)  # tokenize\n    tokens = [x for x in tokens if len(x)>1]                  ## remove single char token\n    bag_of_words.append( Counter(tokens, strip_handles=True)  ## add to our BoW\n    )\n\nunique_words =  list( set([ y  for x in bag_of_words  for y in x.keys()]) )\n\nprint(\"Total Rows: \", len(bag_of_words),'\\n\\n',\n      'Row 1 BoW: ',bag_of_words[:1],'\\n\\n',    # see the first two records\n      'Row 2 BoW: ', bag_of_words[:2], '\\n\\n',\n      'Total Unique Words: ', len(unique_words))#:> Total Rows:  10605 \n#:> \n#:>  Row 1 BoW:  [Counter({'to': 2, 'The': 1, 'Rock': 1, 'is': 1, 'destined': 1, 'be': 1, 'the': 1, '21st': 1, \"Century's\": 1, 'new': 1, 'Conan': 1, 'and': 1, 'that': 1, \"he's\": 1, 'going': 1, 'make': 1, 'splash': 1, 'even': 1, 'greater': 1, 'than': 1, 'Arnold': 1, 'Schwarzenegger': 1, 'Jean': 1, 'Claud': 1, 'Van': 1, 'Damme': 1, 'or': 1, 'Steven': 1, 'Segal': 1, 'strip_handles': 1})] \n#:> \n#:>  Row 2 BoW:  [Counter({'to': 2, 'The': 1, 'Rock': 1, 'is': 1, 'destined': 1, 'be': 1, 'the': 1, '21st': 1, \"Century's\": 1, 'new': 1, 'Conan': 1, 'and': 1, 'that': 1, \"he's\": 1, 'going': 1, 'make': 1, 'splash': 1, 'even': 1, 'greater': 1, 'than': 1, 'Arnold': 1, 'Schwarzenegger': 1, 'Jean': 1, 'Claud': 1, 'Van': 1, 'Damme': 1, 'or': 1, 'Steven': 1, 'Segal': 1, 'strip_handles': 1}), Counter({'of': 4, 'The': 2, 'gorgeously': 1, 'elaborate': 1, 'continuation': 1, 'Lord': 1, 'the': 1, 'Rings': 1, 'trilogy': 1, 'is': 1, 'so': 1, 'huge': 1, 'that': 1, 'column': 1, 'words': 1, 'cannot': 1, 'adequately': 1, 'describe': 1, 'co': 1, 'writer': 1, 'director': 1, 'Peter': 1, \"Jackson's\": 1, 'expanded': 1, 'vision': 1, \"Tolkien's\": 1, 'Middle': 1, 'earth': 1, 'strip_handles': 1})] \n#:> \n#:>  Total Unique Words:  20686bows_df = pd.DataFrame.from_records(bag_of_words)\nbows_df = bows_df.fillna(0).astype(int)  # replace NaN with 0, change to integer\nbows_df.head()#:>    The  Rock  is  destined  to  ...  Bearable  Staggeringly  ve  muttering  dissing\n#:> 0    1     1   1         1   2  ...         0             0   0          0        0\n#:> 1    2     0   1         0   0  ...         0             0   0          0        0\n#:> 2    0     0   0         0   0  ...         0             0   0          0        0\n#:> 3    0     0   1         0   4  ...         0             0   0          0        0\n#:> 4    0     0   0         0   0  ...         0             0   0          0        0\n#:> \n#:> [5 rows x 20686 columns]"},{"path":"nlp.html","id":"build-the-model","chapter":"17 NLP","heading":"17.12.4 Build The Model","text":"","code":"from sklearn.naive_bayes import MultinomialNB\ntrain_y  = movies.sentiment>0   # label\ntrain_X  = bows_df              # features\nnb_model = MultinomialNB().fit( train_X, train_y)"},{"path":"nlp.html","id":"train-set-prediction","chapter":"17 NLP","heading":"17.12.5 Train Set Prediction","text":"First, make prediction training data, compare ground truth.","code":"train_predicted = nb_model.predict(bows_df)\nprint(\"Accuracy: \", np.mean(train_predicted==train_y).round(4))#:> Accuracy:  0.9357"},{"path":"web-scrapping.html","id":"web-scrapping","chapter":"18 Web Scrapping","heading":"18 Web Scrapping","text":"","code":""},{"path":"web-scrapping.html","id":"requests","chapter":"18 Web Scrapping","heading":"18.1 requests","text":"","code":""},{"path":"web-scrapping.html","id":"creating-a-session","chapter":"18 Web Scrapping","heading":"18.1.1 Creating A Session","text":"","code":"import requests\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\nimport random\n\n\n_retries = Retry(connect=10,read=10,backoff_factor=1)   # backoff is incremental interval in seconds between retries\n_timeout = (10,10)  ## connect, read timeout in seconds\n\nrqs = requests.Session()\nrqs.mount( 'http://' ,  HTTPAdapter(max_retries= _retries))\nrqs.mount( 'https://' , HTTPAdapter(max_retries= _retries))link1 = 'https://www.yahoo.com'\nlink2 = 'http://mamamia777.com.au'\n#user_agent = {'User-Agent': random.choice(_USER_AGENTS)}\n#response1  = rqs.get(link1, timeout=_timeout)\n#response2  = rqs.get(link2, timeout=_timeout)  print (page1.status_code)"},{"path":"web-scrapping.html","id":"rotating-broswer","chapter":"18 Web Scrapping","heading":"18.1.2 Rotating Broswer","text":"","code":"_USER_AGENTS = [\n   #Chrome\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n    #Firefox\n    'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n    'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n    'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n    'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n    'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)']"},{"path":"web-scrapping.html","id":"beautifulsoup","chapter":"18 Web Scrapping","heading":"18.2 BeautifulSoup","text":"","code":""},{"path":"web-scrapping.html","id":"module-import-2","chapter":"18 Web Scrapping","heading":"18.2.1 Module Import","text":"","code":"from bs4 import BeautifulSoup"},{"path":"web-scrapping.html","id":"html-tag-parsing","chapter":"18 Web Scrapping","heading":"18.2.2 HTML Tag Parsing","text":"","code":""},{"path":"web-scrapping.html","id":"sample-data-26","chapter":"18 Web Scrapping","heading":"18.2.2.1 Sample Data","text":"","code":"my_html = '''\n<div id=\"my-id1\" class='title'> \n    <p>This Is My Title<\/p>\n    \n    <div id=\"my-id2\" class='subtitle' custom_attr='funny'>\n        <p>This is Subtitle<\/p>\n    <\/div>\n    \n    <div id=\"my-id3\" class='title',   custom_attr='funny'>\n        <p>This is paragraph1<\/p>\n        <p>This is paragraph2<\/p>\n        <h3>This is paragraph3<\/h3>\n    <\/div>\n<\/div>\n'''\nsoup = BeautifulSoup(my_html)"},{"path":"web-scrapping.html","id":"first-match","chapter":"18 Web Scrapping","heading":"18.2.2.2 First Match","text":"ID Selector\nEverthing selected tag returned.Class SelectorAttribute Selector","code":"soup.find(id='my-id1')#:> <div class=\"title\" id=\"my-id1\">\n#:> <p>This Is My Title<\/p>\n#:> <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n#:> <p>This is Subtitle<\/p>\n#:> <\/div>\n#:> <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n#:> <p>This is paragraph1<\/p>\n#:> <p>This is paragraph2<\/p>\n#:> <h3>This is paragraph3<\/h3>\n#:> <\/div>\n#:> <\/div>soup.find(class_='subtitle')#:> <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n#:> <p>This is Subtitle<\/p>\n#:> <\/div>soup.find(custom_attr='funny')#:> <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n#:> <p>This is Subtitle<\/p>\n#:> <\/div>soup.find(       custom_attr='funny')#:> <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n#:> <p>This is Subtitle<\/p>\n#:> <\/div>soup.find('div', custom_attr='funny')#:> <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n#:> <p>This is Subtitle<\/p>\n#:> <\/div>"},{"path":"web-scrapping.html","id":"find-all-matches-1","chapter":"18 Web Scrapping","heading":"18.2.2.3 Find All Matches","text":"find_allCSS Selector using select()can achieved using css selector. return array result (multiple matches).granular exmaple css selector.Using contains()Combining ID, Class Custom Attribute selector","code":"soup = BeautifulSoup(my_html)\nmultiple_result = soup.find_all(class_='title')\nprint( 'Item 0: \\n',     multiple_result[0],\n       '\\n\\nItem 1: \\n', multiple_result[1])#:> Item 0: \n#:>  <div class=\"title\" id=\"my-id1\">\n#:> <p>This Is My Title<\/p>\n#:> <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n#:> <p>This is Subtitle<\/p>\n#:> <\/div>\n#:> <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n#:> <p>This is paragraph1<\/p>\n#:> <p>This is paragraph2<\/p>\n#:> <h3>This is paragraph3<\/h3>\n#:> <\/div>\n#:> <\/div> \n#:> \n#:> Item 1: \n#:>  <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n#:> <p>This is paragraph1<\/p>\n#:> <p>This is paragraph2<\/p>\n#:> <h3>This is paragraph3<\/h3>\n#:> <\/div>multiple_result = soup.select('.title')\nprint( 'Item 0: \\n',     multiple_result[0],\n       '\\n\\nItem 1: \\n', multiple_result[1])#:> Item 0: \n#:>  <div class=\"title\" id=\"my-id1\">\n#:> <p>This Is My Title<\/p>\n#:> <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n#:> <p>This is Subtitle<\/p>\n#:> <\/div>\n#:> <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n#:> <p>This is paragraph1<\/p>\n#:> <p>This is paragraph2<\/p>\n#:> <h3>This is paragraph3<\/h3>\n#:> <\/div>\n#:> <\/div> \n#:> \n#:> Item 1: \n#:>  <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n#:> <p>This is paragraph1<\/p>\n#:> <p>This is paragraph2<\/p>\n#:> <h3>This is paragraph3<\/h3>\n#:> <\/div>soup.select('#my-id1 div.subtitle')#:> [<div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n#:> <p>This is Subtitle<\/p>\n#:> <\/div>]soup.select(\"p:contains('This is paragraph')\")#:> [<p>This is paragraph1<\/p>, <p>This is paragraph2<\/p>]soup.select(\"div#my-id3.title[custom_attr='funny']:contains('This is paragraph')\")#:> [<div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n#:> <p>This is paragraph1<\/p>\n#:> <p>This is paragraph2<\/p>\n#:> <h3>This is paragraph3<\/h3>\n#:> <\/div>]"},{"path":"web-scrapping.html","id":"meta-parsing","chapter":"18 Web Scrapping","heading":"18.2.3 Meta Parsing","text":"","code":"my_meta = '''\n<meta property=\"description\"   content=\"KUALA LUMPUR: blah blah\"   category=\"Malaysia\">\n<meta property=\"publish-date\"  content=\"2012-01-03\">\n'''\nsoup = BeautifulSoup(my_meta)\nsoup.find('meta', property='description')['content']#:> 'KUALA LUMPUR: blah blah'soup.find('meta', property='description')['category']#:> 'Malaysia'soup.find('meta', property='publish-date')['content']#:> '2012-01-03'soup.find('meta', category='Malaysia')['property']#:> 'description'"},{"path":"web-scrapping.html","id":"getting-content","chapter":"18 Web Scrapping","heading":"18.2.4 Getting Content","text":"","code":""},{"path":"web-scrapping.html","id":"get-content-get_textstrip-separator","chapter":"18 Web Scrapping","heading":"18.2.4.1 Get Content get_text(strip=, separator=)","text":"Use strip=True strip whitespace beginning end bit textUse `separator=‘\\n’ specify string used join bits text togetherIt recommended use strip=True, separator='\\n' result different operating system consistantstrip=True combine separator retain user readable text portion tag, separator seperating ","code":"soup = BeautifulSoup(my_html)\nelem = soup.find(id = \"my-id3\")\nelem.get_text(strip=False)#:> '\\nThis is paragraph1\\nThis is paragraph2\\nThis is paragraph3\\n'elem.get_text(strip=True, separator='\\n')#:> 'This is paragraph1\\nThis is paragraph2\\nThis is paragraph3'"},{"path":"web-scrapping.html","id":"splitting-content","chapter":"18 Web Scrapping","heading":"18.2.4.2 Splitting Content","text":"useful split using separator list string.","code":"elem = soup.find(id = \"my-id3\")\nelem.get_text(strip=True, separator='\\n').split('\\n')#:> ['This is paragraph1', 'This is paragraph2', 'This is paragraph3']"},{"path":"web-scrapping.html","id":"traversing","chapter":"18 Web Scrapping","heading":"18.2.5 Traversing","text":"","code":""},{"path":"web-scrapping.html","id":"get-the-element","chapter":"18 Web Scrapping","heading":"18.2.5.1 Get The Element","text":"","code":"elems = soup.select(\"div#my-id3.title[custom_attr='funny']:contains('This is paragraph')\")\nelem = elems[0]\nelem#:> <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n#:> <p>This is paragraph1<\/p>\n#:> <p>This is paragraph2<\/p>\n#:> <h3>This is paragraph3<\/h3>\n#:> <\/div>"},{"path":"web-scrapping.html","id":"traversing-children","chapter":"18 Web Scrapping","heading":"18.2.5.2 Traversing Children","text":"Children List findChildren()Next Children findNext()element children, get immediate childIf element children, find next element hierechy","code":"elem.findChildren()#:> [<p>This is paragraph1<\/p>, <p>This is paragraph2<\/p>, <h3>This is paragraph3<\/h3>]first_child = elem.fin\nprint( \nelem.findNext().get_text(strip=True), '\\n', \nelem.findNext().findNext().get_text(strip=True), '\\n')#:> This is paragraph1 \n#:>  This is paragraph2"},{"path":"web-scrapping.html","id":"traversing-to-parent-parent","chapter":"18 Web Scrapping","heading":"18.2.5.3 Traversing To Parent parent()","text":"","code":"elem_parent = elem.parent\nelem_parent.attrs#:> {'id': 'my-id1', 'class': ['title']}"},{"path":"web-scrapping.html","id":"get-the-sibling-findprevioussibling","chapter":"18 Web Scrapping","heading":"18.2.5.4 Get The Sibling findPreviousSibling()","text":"Sibling element level hierachy","code":"elem_prev_sib = elem.findPreviousSibling()\nelem_prev_sib.attrs#:> {'id': 'my-id2', 'class': ['subtitle'], 'custom_attr': 'funny'}"},{"path":"finance.html","id":"finance","chapter":"19 Finance","heading":"19 Finance","text":"","code":""},{"path":"finance.html","id":"getting-data","chapter":"19 Finance","heading":"19.1 Getting Data","text":"","code":""},{"path":"finance.html","id":"pandas_datareder","chapter":"19 Finance","heading":"19.1.1 pandas_datareder","text":"","code":""},{"path":"finance.html","id":"ohlc-eod-pricing","chapter":"19 Finance","heading":"19.1.1.1 OHLC EOD Pricing","text":"HLOC columns adjusted splits‘Adj Close’ columns adjusted split dividendsstart end date must string","code":"import pandas_datareader as pdrpdr.data.DataReader('PUBM.KL',\n                    start='2015-1-1', \n                    end='2019-12-31', \n                    data_source='yahoo')#:>                  High        Low       Open      Close     Volume  Adj Close\n#:> Date                                                                        \n#:> 2015-01-02  18.280001  18.020000  18.260000  18.219999  1689000.0  15.345568\n#:> 2015-01-05  18.240000  17.760000  18.240000  17.820000  2667800.0  15.008673\n#:> 2015-01-06  17.799999  17.500000  17.780001  17.600000  5042600.0  14.823381\n#:> 2015-01-07  17.700001  17.580000  17.600000  17.580000  4913200.0  14.806539\n#:> 2015-01-08  17.680000  17.559999  17.580000  17.600000  4121100.0  14.823381\n#:> ...               ...        ...        ...        ...        ...        ...\n#:> 2019-12-24  20.020000  19.719999  20.000000  19.820000  1405800.0  19.361732\n#:> 2019-12-26  19.860001  19.639999  19.820000  19.680000   600300.0  19.224972\n#:> 2019-12-27  19.940001  19.660000  19.680000  19.879999  1325700.0  19.420345\n#:> 2019-12-30  20.000000  19.780001  19.879999  19.980000  2180200.0  19.518034\n#:> 2019-12-31  19.900000  19.400000  19.799999  19.440001  3430600.0  18.990520\n#:> \n#:> [1239 rows x 6 columns]"},{"path":"finance.html","id":"splits-and-dividends","chapter":"19 Finance","heading":"19.1.1.2 Splits and Dividends","text":"method similar getting pricing data, except different data_sources used.","code":"pdr.DataReader('AAPL',\n  data_source = 'yahoo-actions',\n  start='2014-01-06', \n  end='2015-06-15'\n)#:>               action     value\n#:> 2015-05-07  DIVIDEND  0.130000\n#:> 2015-02-05  DIVIDEND  0.117500\n#:> 2014-11-06  DIVIDEND  0.117500\n#:> 2014-08-07  DIVIDEND  0.117500\n#:> 2014-06-09     SPLIT  0.142857\n#:> 2014-05-08  DIVIDEND  0.117500\n#:> 2014-02-06  DIVIDEND  0.108930"},{"path":"finance.html","id":"merging-ohlc-and-splitsdividends","chapter":"19 Finance","heading":"19.1.1.3 Merging OHLC and Splits/Dividends","text":"Use pandas.merge() function combine prices splits dataframe new dataframe. Non matching line NaN.Alternatively, use pandas column assignment splits dataframe price dataframe, automatically ‘merge’ based index. approach reuse existing dataframe instead creating new one.","code":"prices = pdr.DataReader('AAPL',\n  data_source = 'yahoo',\n  start='2014-06-06', \n  end='2014-06-12'\n)\n\nactions = pdr.DataReader('AAPL',\n  data_source = 'yahoo-actions',\n  start='2014-06-06', \n  end='2014-06-12'\n)pd.merge(prices, actions, how='outer', left_index=True, right_index=True) \\\n  .loc[:,['High','Low','Open','Close','action','value']]#:>                  High        Low       Open      Close action     value\n#:> 2014-06-06  23.259285  23.016787  23.210714  23.056072    NaN       NaN\n#:> 2014-06-09  23.469999  22.937500  23.174999  23.424999  SPLIT  0.142857\n#:> 2014-06-10  23.762501  23.392500  23.682501  23.562500    NaN       NaN\n#:> 2014-06-11  23.690001  23.367500  23.532499  23.465000    NaN       NaN\n#:> 2014-06-12  23.530001  22.975000  23.510000  23.072500    NaN       NaNprices['action'], prices['value'] = actions.action, actions.value\nprices[['High','Low','Open','Close','action','value']]#:>                  High        Low       Open      Close action     value\n#:> Date                                                                   \n#:> 2014-06-06  23.259285  23.016787  23.210714  23.056072    NaN       NaN\n#:> 2014-06-09  23.469999  22.937500  23.174999  23.424999  SPLIT  0.142857\n#:> 2014-06-10  23.762501  23.392500  23.682501  23.562500    NaN       NaN\n#:> 2014-06-11  23.690001  23.367500  23.532499  23.465000    NaN       NaN\n#:> 2014-06-12  23.530001  22.975000  23.510000  23.072500    NaN       NaN"},{"path":"finance.html","id":"query-multiple-stocks","chapter":"19 Finance","heading":"19.1.1.4 Query Multiple Stocks","text":"** multiple symbols supplied DataReader, dictionary containing multiple stock’s result returned.Iterate dictionary get dataframe data","code":"stocks = ['MLYBY', 'AAPL']\nmy_dict = pdr.DataReader( stocks,\n  data_source = 'yahoo-actions',\n  start='2014-01-06', \n  end='2015-06-15'\n)\n\nprint(my_dict.keys())#:> dict_keys(['MLYBY', 'AAPL'])for i in my_dict.items():\n  print('\\n\\nStock: ', i[0],\n        '\\nDataFrame:', i[1])#:> \n#:> \n#:> Stock:  MLYBY \n#:> DataFrame:               action  value\n#:> 2015-04-22  DIVIDEND  0.178\n#:> 2014-09-24  DIVIDEND  0.152\n#:> 2014-04-29  DIVIDEND  0.192\n#:> \n#:> \n#:> Stock:  AAPL \n#:> DataFrame:               action     value\n#:> 2015-05-07  DIVIDEND  0.130000\n#:> 2015-02-05  DIVIDEND  0.117500\n#:> 2014-11-06  DIVIDEND  0.117500\n#:> 2014-08-07  DIVIDEND  0.117500\n#:> 2014-06-09     SPLIT  0.142857\n#:> 2014-05-08  DIVIDEND  0.117500\n#:> 2014-02-06  DIVIDEND  0.108930"},{"path":"finance.html","id":"yfinance","chapter":"19 Finance","heading":"19.1.2 yfinance","text":"yFinanceSupport Yahoo , better alternativeThis library advantage calculating adjsuted OHLC split dividends.Dividends Splits conveniently incorporated pricing dataframe, manual merging necessary.Multiple symbols represented columnsThis library provides stock information (exchanges supported though)","code":""},{"path":"finance.html","id":"stock-info","chapter":"19 Finance","heading":"19.1.2.1 Stock Info","text":"plenty infomration can get form dictionary returend info","code":"import yfinance as yf\nstock = yf.Ticker('AAPL')\nstock.info.keys()#:> dict_keys(['zip', 'sector', 'fullTimeEmployees', 'longBusinessSummary', 'city', 'phone', 'state', 'country', 'companyOfficers', 'website', 'maxAge', 'address1', 'industry', 'previousClose', 'regularMarketOpen', 'twoHundredDayAverage', 'trailingAnnualDividendYield', 'payoutRatio', 'volume24Hr', 'regularMarketDayHigh', 'navPrice', 'averageDailyVolume10Day', 'totalAssets', 'regularMarketPreviousClose', 'fiftyDayAverage', 'trailingAnnualDividendRate', 'open', 'toCurrency', 'averageVolume10days', 'expireDate', 'yield', 'algorithm', 'dividendRate', 'exDividendDate', 'beta', 'circulatingSupply', 'startDate', 'regularMarketDayLow', 'priceHint', 'currency', 'trailingPE', 'regularMarketVolume', 'lastMarket', 'maxSupply', 'openInterest', 'marketCap', 'volumeAllCurrencies', 'strikePrice', 'averageVolume', 'priceToSalesTrailing12Months', 'dayLow', 'ask', 'ytdReturn', 'askSize', 'volume', 'fiftyTwoWeekHigh', 'forwardPE', 'fromCurrency', 'fiveYearAvgDividendYield', 'fiftyTwoWeekLow', 'bid', 'tradeable', 'dividendYield', 'bidSize', 'dayHigh', 'exchange', 'shortName', 'longName', 'exchangeTimezoneName', 'exchangeTimezoneShortName', 'isEsgPopulated', 'gmtOffSetMilliseconds', 'quoteType', 'symbol', 'messageBoardId', 'market', 'annualHoldingsTurnover', 'enterpriseToRevenue', 'beta3Year', 'profitMargins', 'enterpriseToEbitda', '52WeekChange', 'morningStarRiskRating', 'forwardEps', 'revenueQuarterlyGrowth', 'sharesOutstanding', 'fundInceptionDate', 'annualReportExpenseRatio', 'bookValue', 'sharesShort', 'sharesPercentSharesOut', 'fundFamily', 'lastFiscalYearEnd', 'heldPercentInstitutions', 'netIncomeToCommon', 'trailingEps', 'lastDividendValue', 'SandP52WeekChange', 'priceToBook', 'heldPercentInsiders', 'nextFiscalYearEnd', 'mostRecentQuarter', 'shortRatio', 'sharesShortPreviousMonthDate', 'floatShares', 'enterpriseValue', 'threeYearAverageReturn', 'lastSplitDate', 'lastSplitFactor', 'legalType', 'lastDividendDate', 'morningStarOverallRating', 'earningsQuarterlyGrowth', 'dateShortInterest', 'pegRatio', 'lastCapGain', 'shortPercentOfFloat', 'sharesShortPriorMonth', 'category', 'fiveYearAverageReturn', 'regularMarketPrice', 'logo_url'])print(stock.info['longName'])#:> Apple Inc."},{"path":"finance.html","id":"ohlc-eod-pricing-1","chapter":"19 Finance","heading":"19.1.2.2 OHLC EOD Pricing","text":"Split AdjustedOHLC columns adjusted splits (auto_adjust=False)‘Adj Close’ columns adjusted split dividends‘start’ ‘end’ date must stringSplit Dividends AdjustedOHLC columns adjusted splits dividends (auto_adjust=True)Therefore, ‘Adj Close’ column redundant, hence removed.","code":"stock = yf.Ticker('AAPL')\nstock.history(  start='2014-06-06', end='2015-06-15', auto_adjust = False)#:>                  Open       High        Low      Close  Adj Close     Volume  Dividends  \\\n#:> Date                                                                                      \n#:> 2014-06-06  23.210714  23.259285  23.016787  23.056072  20.639763  349938400        0.0   \n#:> 2014-06-09  23.174999  23.469999  22.937500  23.424999  20.970028  301660000        0.0   \n#:> 2014-06-10  23.682501  23.762501  23.392500  23.562500  21.093121  251108000        0.0   \n#:> 2014-06-11  23.532499  23.690001  23.367500  23.465000  21.005835  182724000        0.0   \n#:> 2014-06-12  23.510000  23.530001  22.975000  23.072500  20.654472  218996000        0.0   \n#:> ...               ...        ...        ...        ...        ...        ...        ...   \n#:> 2015-06-08  32.224998  32.302502  31.707500  31.950001  29.103498  210699200        0.0   \n#:> 2015-06-09  31.674999  32.020000  31.405001  31.855000  29.016962  224301600        0.0   \n#:> 2015-06-10  31.980000  32.334999  31.962500  32.220001  29.349443  156349200        0.0   \n#:> 2015-06-11  32.294998  32.544998  32.119999  32.147499  29.283403  141563600        0.0   \n#:> 2015-06-12  32.047501  32.082500  31.777500  31.792500  28.960032  147544800        0.0   \n#:> \n#:>             Stock Splits  \n#:> Date                      \n#:> 2014-06-06           0.0  \n#:> 2014-06-09           7.0  \n#:> 2014-06-10           0.0  \n#:> 2014-06-11           0.0  \n#:> 2014-06-12           0.0  \n#:> ...                  ...  \n#:> 2015-06-08           0.0  \n#:> 2015-06-09           0.0  \n#:> 2015-06-10           0.0  \n#:> 2015-06-11           0.0  \n#:> 2015-06-12           0.0  \n#:> \n#:> [257 rows x 8 columns]import yfinance as yf\nstock = yf.Ticker('AAPL')\nstock.history(  start='2014-06-06', end='2015-06-15', auto_adjust = True)#:>                  Open       High        Low      Close     Volume  Dividends  \\\n#:> Date                                                                           \n#:> 2014-06-06  20.778198  20.821679  20.604594  20.639763  349938400        0.0   \n#:> 2014-06-09  20.746228  21.010312  20.533619  20.970028  301660000        0.0   \n#:> 2014-06-10  21.200545  21.272161  20.940937  21.093121  251108000        0.0   \n#:> 2014-06-11  21.066260  21.207255  20.918553  21.005835  182724000        0.0   \n#:> 2014-06-12  21.046122  21.064026  20.567191  20.654472  218996000        0.0   \n#:> ...               ...        ...        ...        ...        ...        ...   \n#:> 2015-06-08  29.353996  29.424594  28.882603  29.103498  210699200        0.0   \n#:> 2015-06-09  28.852998  29.167263  28.607055  29.016962  224301600        0.0   \n#:> 2015-06-10  29.130824  29.454196  29.114883  29.349443  156349200        0.0   \n#:> 2015-06-11  29.417761  29.645488  29.258353  29.283403  141563600        0.0   \n#:> 2015-06-12  29.192314  29.224196  28.946368  28.960032  147544800        0.0   \n#:> \n#:>             Stock Splits  \n#:> Date                      \n#:> 2014-06-06           0.0  \n#:> 2014-06-09           7.0  \n#:> 2014-06-10           0.0  \n#:> 2014-06-11           0.0  \n#:> 2014-06-12           0.0  \n#:> ...                  ...  \n#:> 2015-06-08           0.0  \n#:> 2015-06-09           0.0  \n#:> 2015-06-10           0.0  \n#:> 2015-06-11           0.0  \n#:> 2015-06-12           0.0  \n#:> \n#:> [257 rows x 7 columns]"},{"path":"finance.html","id":"splits-and-dividends-1","chapter":"19 Finance","heading":"19.1.2.3 Splits and Dividends","text":"Getting Splits DividendsGetting Dividends OnlyGetting Splits ","code":"stock.actions#:>             Dividends  Stock Splits\n#:> Date                               \n#:> 2014-06-09     0.0000           7.0\n#:> 2014-08-07     0.1175           0.0\n#:> 2014-11-06     0.1175           0.0\n#:> 2015-02-05     0.1175           0.0\n#:> 2015-05-07     0.1300           0.0stock.dividends#:> Date\n#:> 2014-08-07    0.1175\n#:> 2014-11-06    0.1175\n#:> 2015-02-05    0.1175\n#:> 2015-05-07    0.1300\n#:> Name: Dividends, dtype: float64stock.splits#:> Date\n#:> 2014-06-09    7.0\n#:> Name: Stock Splits, dtype: float64"},{"path":"finance.html","id":"query-using-periods","chapter":"19 Finance","heading":"19.1.2.4 Query Using Periods","text":"Available periods : 1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max","code":"stock = yf.Ticker('AAPL')\nstock.history(periods='max')#:>                   Open        High         Low       Close     Volume  Dividends  \\\n#:> Date                                                                               \n#:> 2020-10-20  115.999868  118.775087  115.430850  117.307617  124423700        0.0   \n#:> 2020-10-21  116.469064  118.505551  116.249442  116.668724   89946000        0.0   \n#:> 2020-10-22  117.247713  117.836701  114.392638  115.550644  101988000        0.0   \n#:> 2020-10-23  116.189547  116.349275  114.083180  114.841873   82572600        0.0   \n#:> 2020-10-26  113.813643  116.349269  112.685584  114.851852  111850700        0.0   \n#:> ...                ...         ...         ...         ...        ...        ...   \n#:> 2020-11-16  118.919998  120.989998  118.150002  120.300003   91183000        0.0   \n#:> 2020-11-17  119.550003  120.669998  118.959999  119.389999   74271000        0.0   \n#:> 2020-11-18  118.610001  119.820000  118.000000  118.029999   76322100        0.0   \n#:> 2020-11-19  117.589996  119.059998  116.809998  118.639999   73860200        0.0   \n#:> 2020-11-20  118.639999  118.769997  117.500000  117.610001   54692629        0.0   \n#:> \n#:>             Stock Splits  \n#:> Date                      \n#:> 2020-10-20             0  \n#:> 2020-10-21             0  \n#:> 2020-10-22             0  \n#:> 2020-10-23             0  \n#:> 2020-10-26             0  \n#:> ...                  ...  \n#:> 2020-11-16             0  \n#:> 2020-11-17             0  \n#:> 2020-11-18             0  \n#:> 2020-11-19             0  \n#:> 2020-11-20             0  \n#:> \n#:> [24 rows x 7 columns]"},{"path":"finance.html","id":"query-multiple-stocks-1","chapter":"19 Finance","heading":"19.1.2.5 Query Multiple Stocks","text":"**Use download() function query multiple stocks.default, grouped column. Access data result['Column']['Symbol']group Symbol, use group_by parameter. , access data result['Symbol']['Column']default, threads=True parallel downloading.","code":"stocks = ['MLYBY','AAPL']\ndf1 = yf.download(stocks, start='2014-06-06', end='2014-06-15')#:> \n[                       0%                       ]\n[*********************100%***********************]  2 of 2 completeddf2 = yf.download(stocks, start='2014-06-06', end='2014-06-15', group_by='ticker')#:> \n[                       0%                       ]\n[*********************100%***********************]  2 of 2 completedprint('Group by Column Name:\\n', df1['Close']['AAPL'], '\\n\\n',\n      'Group by Symbol:     ]n', df2['AAPL']['Close'])#:> Group by Column Name:\n#:>  Date\n#:> 2014-06-06    23.056072\n#:> 2014-06-09    23.424999\n#:> 2014-06-10    23.562500\n#:> 2014-06-11    23.465000\n#:> 2014-06-12    23.072500\n#:> 2014-06-13    22.820000\n#:> Name: AAPL, dtype: float64 \n#:> \n#:>  Group by Symbol:     ]n Date\n#:> 2014-06-06    23.056072\n#:> 2014-06-09    23.424999\n#:> 2014-06-10    23.562500\n#:> 2014-06-11    23.465000\n#:> 2014-06-12    23.072500\n#:> 2014-06-13    22.820000\n#:> Name: Close, dtype: float64"},{"path":"finance.html","id":"world-trading","chapter":"19 Finance","heading":"19.1.3 world trading","text":"","code":""},{"path":"finance.html","id":"ohlc-eod-pricing-2","chapter":"19 Finance","heading":"19.1.3.1 OHLC EOD Pricing","text":"","code":""},{"path":"finance.html","id":"charting","chapter":"19 Finance","heading":"19.2 Charting","text":"","code":"import cufflinks as cf  # Cufflinks\n#cf.set_config_file(offline=True)  # set the plotting mode to offline"},{"path":"finance.html","id":"price-comparison","chapter":"19 Finance","heading":"19.2.1 Price Comparison","text":"","code":"stocks = ['XOM']\ndf = yf.download(stocks, start='2020-01-01', end='2020-01-30')\ndf['Close']\ndf.iplot()stocks = ['CVX']\ndf = yf.download(stocks, start='2019-01-01', end='2019-12-31')\ndf['Close']\ndf.iplot()# stocks = ['AAPL','MLYBY', 'PUBM.KL', 'HLFBF','1295.KL']\n# stocks = ['AAPL','MLYBY', 'PUBM.KL', 'HLFBF']\nstocks = ['AAPL']\ndf = yf.download(stocks, start='2020-01-01', end='2020-01-30')\ndf['Close']\ndf.iplot()stock = yf.Ticker('PUBM.KL')\n#stock.history(periods='max')\nstock.history(  start='2014-06-06', end='2015-06-15', auto_adjust = True)stock = yf.Ticker('1295.KL')\nstock.history(  start='2014-06-06', end='2015-06-15', auto_adjust = True)stocks = ['MLYBY']\ndf = yf.download('MLYBY', start='2018-12-03', end='2019-03-21')\ndf"}]
